2
Science
Using neuroscience to develop artificial intelligence
<p>When the mathematician Alan Turing posed the question “Can machines think?” in the first line of his seminal 1950 paper that ushered in the quest for artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence (AI) (<i>1</i>), the only known systems carrying out complex computations were biological nervous systems. It is not surprising, therefore, that scientists in the nascent field of AI turned to brain circuits as a source for guidance. One path that was taken since the early attempts to perform <strong><span style="color:yellowgreen">intellig</span></strong>ent computation by brain-like circuits (<i>2</i>), and which led recently to remarkable successes, can be described as a highly reductionist approach to model cortical circuitry. In its basic current form, known as a “deep network” (or deep net) architecture, this brain-inspired model is built from successive layers of neuron-like elements, connected by adjustable weights, called “synapses” after their biological counterparts (<i>3</i>). The application of deep nets and related methods to AI systems has been transformative. They proved superior to previously known methods in central areas of AI research, including computer vision, speech recognition and production, and playing complex games. Practical applications are already in broad use, in areas such as computer vision and speech and text translation, and large-scale efforts are under way in many other areas. Here, I discuss how additional aspects of brain circuitry could supply cues for guiding network models toward broader aspects of cognition and general AI.</p>
http://sciencemag.org/cgi/content/summary/363/6428/692
10.1126/science.aau6595
None

2
Science
A generative vision model that trains with high data efficiency and breaks text-based CAPTCHAs
<p>Learning from a few examples and generalizing to markedly different situations are capabilities of human visual <strong><span style="color:yellowgreen">intellig</span></strong>ence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, we introduce a probabilistic generative model for vision in which message-passing–based inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Our model emphasizes aspects such as data efficiency and compositionality that may be important in the path toward general artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence.</p>
http://sciencemag.org/cgi/content/abstract/358/6368/eaag2612
10.1126/science.aag2612
['human']

2
Science
DeepStack: Expert-level artificial intelligence in heads-up no-limit poker
<p>Artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence has seen several breakthroughs in recent years, with games often serving as milestones. A common feature of these games is that players have perfect information. Poker, the quintessential game of imperfect information, is a long-standing challenge problem in artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence. We introduce DeepStack, an algorithm for imperfect-information settings. It combines recursive reasoning to handle information asymmetry, decomposition to focus computation on the relevant decision, and a form of intuition that is automatically learned from self-play using deep learning. In a study involving 44,000 hands of poker, DeepStack defeated, with statistical significance, professional poker players in heads-up no-limit Texas hold’em. The approach is theoretically sound and is shown to produce strategies that are more difficult to exploit than prior approaches.</p>
http://sciencemag.org/cgi/content/abstract/356/6337/508
10.1126/science.aam6960
None

1
Science
Human-level performance in 3D multiplayer games with population-based reinforcement learning
<p>Reinforcement learning (RL) has shown great success in increasingly complex single-agent environments and two-player turn-based games. However, the real world contains multiple agents, each learning and acting independently to cooperate and compete with other agents. We used a tournament-style evaluation to demonstrate that an agent can achieve human-level performance in a three-dimensional multiplayer first-person video game, <i>Quake III Arena</i> in Capture the Flag mode, using only pixels and game points scored as input. We used a two-tier optimization process in which a population of independent RL agents are trained concurrently from thousands of parallel matches on randomly generated environments. Each agent learns its own internal reward signal and rich representation of the world. These results indicate the great potential of multiagent reinforcement learning for artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence research.</p>
http://sciencemag.org/cgi/content/abstract/364/6443/859
10.1126/science.aau6249
['human']

1
Science
Mechanoresponsive self-growing hydrogels inspired by muscle training
<p>Living tissues, such as muscle, autonomously grow and remodel themselves to adapt to their surrounding mechanical environment through metabolic processes. By contrast, typical synthetic materials cannot grow and reconstruct their structures once formed. We propose a strategy for developing “self-growing” polymeric materials that respond to repetitive mechanical stress through an effective mechanochemical transduction. Robust double-network hydrogels provided with a sustained monomer supply undergo self-growth, and the materials are substantially strengthened under repetitive loading through a structural destruction-reconstruction process. This strategy also endows the hydrogels with tailored functions at desired positions by mechanical stamping. This work may pave the way for the development of self-growing gel materials for applications such as soft robots and <strong><span style="color:yellowgreen">intellig</span></strong>ent devices.</p>
http://sciencemag.org/cgi/content/abstract/363/6426/504
10.1126/science.aau9533
None

1
Science
Computers turn neural signals into speech
<p>For many people who are paralyzed and unable to speak, signals of what they'd like to say hide in their brains. No one has been able to decipher those signals directly. But three research teams recently made progress in turning data from electrodes surgically placed on the brain into computer-generated speech. These teams haven't yet managed to re-create speech that people merely imagine. But by monitoring parts of the brain as participants either read aloud, silently mouthed speech, or listened to recordings, the researchers were able to use computational models called neural networks to reconstruct words and sentences that were close enough, in some cases, to be <strong><span style="color:yellowgreen">intellig</span></strong>ible to human listeners.</p>
http://sciencemag.org/cgi/content/summary/363/6422/14
None
['human']

1
Science
A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play
<p>The game of chess is the longest-studied domain in the history of artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.</p>
http://sciencemag.org/cgi/content/abstract/362/6419/1140
10.1126/science.aar6404
['Japanese chess', 'human']

1
Science
Brain scientists dive into deep neural networks
<p>At the Conference on Cognitive Computational Neuroscience this month, researchers presented new tools for comparing data collected from living brains with readouts from computational models known as deep neural networks. Such comparisons might offer up new hypotheses about how humans interpret sights and sounds, understand language, or navigate the world. Until recently, artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence couldn't come anywhere close to human performance on tasks like recognizing sounds or classifying images. But deep neural networks, loosely inspired by the brain, have logged increasingly impressive performances, especially on visual tasks. That has led some neuroscientists to wonder whether these models could yield insight into how our own brains process information.</p>
http://sciencemag.org/cgi/content/summary/361/6408/1177
None
['human']

1
Science
Neural scene representation and rendering
<p>Scene representation—the process of converting visual sensory data into concise descriptions—is a requirement for <strong><span style="color:yellowgreen">intellig</span></strong>ent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (GQN), a framework within which machines learn to represent scenes using only their own sensors. The GQN takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The GQN demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.</p>
http://sciencemag.org/cgi/content/abstract/360/6394/1204
10.1126/science.aar6170
['human']

1
Science
China's ambitious brain science project inches forward
<p>The nascent China Brain Project took another step toward reality last week with the launch of the Shanghai Research Center for Brain Science and Brain-Inspired Intelligence. The new center and its Beijing counterpart, launched 2 months ago, are both expected to become part of an ambitious national effort to bring China to the forefront of neuroscience. Government planners called for brain research to be a key science and technology project in the nation's 13th Five-Year Plan, adopted in spring 2016. But details of the project—expected to rival similar U.S. and European efforts in scale and ambition—are still being worked out.</p>
http://sciencemag.org/cgi/content/summary/360/6391/840
None
None

1
Science
Superhuman AI for heads-up no-limit poker: Libratus beats top professionals
<p>No-limit Texas hold’em is the most popular form of poker. Despite artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence (AI) successes in perfect-information games, the private information and massive game tree have made no-limit poker difficult to tackle. We present Libratus, an AI that, in a 120,000-hand competition, defeated four top human specialist professionals in heads-up no-limit Texas hold’em, the leading benchmark and long-standing challenge problem in imperfect-information game solving. Our game-theoretic approach features application-independent techniques: an algorithm for computing a blueprint for the overall strategy, an algorithm that fleshes out the details of the strategy for subgames that are reached during play, and a self-improver algorithm that fixes potential weaknesses that opponents have identified in the blueprint strategy.</p>
http://sciencemag.org/cgi/content/abstract/359/6374/418
10.1126/science.aao1733
['human']

1
Science
Semantics derived automatically from language corpora contain human-like biases
<p>Machine learning is a means to derive artificial <strong><span style="color:yellowgreen">intellig</span></strong>ence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.</p>
http://sciencemag.org/cgi/content/abstract/356/6334/183
10.1126/science.aal4230
['insects', 'human']

1
Science
Deception by Flexible Alarm Mimicry in an African Bird
<sec><title>Trick and Treat</title><p>Forked-tailed drongos are a particularly <strong><span style="color:yellowgreen">intellig</span></strong>ent type of bird found in Africa. Drongos associate with many other bird and mammal species, which can learn to respond to drongo warning calls. Drongos are also exceptional mimics of the other species' alarm calls. Though the increased vigilance across these multi species associations is a benefit to all, drongos sometimes use these calls as ploys to scare associated species away from food, which the drongos then steal. However, without some approach to maintain the effectiveness of this deception, the drongos' ploy would soon be detected. <bold>Flower <i>et al.</i></bold> (p. 513) now show that drongos are able to fool their target species longer by flexibly varying the type of call they give.</p></sec>
http://sciencemag.org/cgi/content/abstract/344/6183/513
10.1126/science.1249723
['bird', 'Drongos']

1
PLANT PHYSIOLOGY
Plant Phenotyping: An Active Vision Cell for Three-Dimensional Plant Shoot Reconstruction
<p>Three-dimensional (3D) computer-generated models of plants are urgently needed to support both phenotyping and simulation-based studies such as photosynthesis modeling. However, the construction of accurate 3D plant models is challenging, as plants are complex objects with an intricate leaf structure, often consisting of thin and highly reflective surfaces that vary in shape and size, forming dense, complex, crowded scenes. We address these issues within an image-based method by taking an active vision approach, one that investigates the scene to <strong><span style="color:yellowgreen">intellig</span></strong>ently capture images, to image acquisition. Rather than use the same camera positions for all plants, our technique is to acquire the images needed to reconstruct the target plant, tuning camera placement to match the plant’s individual structure. Our method also combines volumetric- and surface-based reconstruction methods and determines the necessary images based on the analysis of voxel clusters. We describe a fully automatic plant modeling/phenotyping cell (or module) comprising a six-axis robot and a high-precision turntable. By using a standard color camera, we overcome the difficulties associated with laser-based plant reconstruction methods. The 3D models produced are compared with those obtained from fixed cameras and evaluated by comparison with data obtained by x-ray microcomputed tomography across different plant structures. Our results show that our method is successful in improving the accuracy and quality of data obtained from a variety of plant types.</p>
http://plantphysiol.org/cgi/content/abstract/178/2/524
10.1104/pp.18.00664
['plants']

