7
The Bone & Joint Journal
Discharge on the day of surgery following unicompartmental knee arthroplasty within the United Kingdom NHS
<sec><title>Aims</title><p>Unicompartmental knee arthroplasty (UKA) has been successfully   performed in the United States healthcare system on outpatients.   Despite differences in healthcare structure and financial environment,   we hypothesised that it would be feasible to replicate this success   and perform UKA with safe day of surgery <strong><span style="color:yellowgreen">discharg</span></strong>e within the NHS,   in the United Kingdom. This has not been reported in any other United   Kingdom centres.</p></sec><sec><title>Patients and Methods</title><p>We report our experience of implementing a pathway to allow safe   day of surgery <strong><span style="color:yellowgreen">discharg</span></strong>e following UKA. Data were prospectively   collected on 72 patients who underwent UKA as a day case between   December 2011 and September 2015. </p></sec><sec><title>Results</title><p>A total of 61 patients (85%) were <strong><span style="color:yellowgreen">discharg</span></strong>ed on the same day.   The most common reason for failure was logistical; five patients   had their operation too late in the day. Three patients failed to   mobilise safely, two had inadequate control of pain and one had   a leaking wound. The mean length of stay for those who were not   <strong><span style="color:yellowgreen">discharg</span></strong>ed on the same day was 1.2 nights (1 to 3). During the same   time, 58 patients underwent planned inpatient UKA, as they were deemed   inappropriate for <strong><span style="color:yellowgreen">discharg</span></strong>e on the day of surgery. However, three   of these were safely <strong><span style="color:yellowgreen">discharg</span></strong>ed on the same day.</p><p>Follow-up data, 24 hours post-operatively, were available for   70 patients; 51 (73%) reported no or mild pain, 14 (20%) had moderate   pain and five (7%) had severe pain. There were no re-admissions.   All patients had a high level of satisfaction.</p></sec><sec><title>Conclusion</title><p>We found that patients can be safely and effectively <strong><span style="color:yellowgreen">discharg</span></strong>ed   on the day of surgery after UKA, with high levels of satisfaction.   This clearly offers improved management of resources and financial   savings to healthcare trusts.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:788–92.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/6/788
10.1302/0301-620X.99B6.BJJ-2016-0540.R2
None

6
Circulation
Impact of Bystander Automated External Defibrillator Use on Survival and Functional Outcomes in Shockable Observed Public Cardiac Arrests
<sec><title>Background:</title><p>Survival following out-of-hospital cardiac arrest (OHCA) with shockable rhythms can be improved with early defibrillation. Although shockable OHCA accounts for only ≈25% of overall arrests, ≈60% of public OHCAs are shockable, offering the possibility of restoring thousands of individuals to full recovery with early defibrillation by bystanders. We sought to determine the association of bystander automated external defibrillator use with survival and functional outcomes in shockable observed public OHCA.</p></sec><sec><title>Methods:</title><p>From 2011 to 2015, the Resuscitation Outcomes Consortium prospectively collected detailed information on all cardiac arrests at 9 regional centers. The exposures were shock administration by a bystander-applied automated external defibrillator in comparison with initial defibrillation by emergency medical services. The primary outcome measure was <strong><span style="color:yellowgreen">discharg</span></strong>e with normal or near-normal (favorable) functional status defined as a modified Rankin Score ≤2. Survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e was the secondary outcome measure.</p></sec><sec><title>Results:</title><p>Among 49 555 OHCAs, 4115 (8.3%) observed public OHCAs were analyzed, of which 2500 (60.8%) were shockable. A bystander shock was applied in 18.8% of the shockable arrests. Patients shocked by a bystander were significantly more likely to survive to <strong><span style="color:yellowgreen">discharg</span></strong>e (66.5% versus 43.0%) and be <strong><span style="color:yellowgreen">discharg</span></strong>ed with favorable functional outcome (57.1% versus 32.7%) than patients initially shocked by emergency medical services. After adjusting for known predictors of outcome, the odds ratio associated with a bystander shock was 2.62 (95% confidence interval, 2.07–3.31) for survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e and 2.73 (95% confidence interval, 2.17–3.44) for <strong><span style="color:yellowgreen">discharg</span></strong>e with favorable functional outcome. The benefit of bystander shock increased progressively as emergency medical services response time became longer.</p></sec><sec><title>Conclusions:</title><p>Bystander automated external defibrillator use before emergency medical services arrival in shockable observed public OHCA was associated with better survival and functional outcomes. Continued emphasis on public automated external defibrillator utilization programs may further improve outcomes of OHCA.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/20/2104
10.1161/CIRCULATIONAHA.117.030700
None

5
Circulation
ICare-ACS (Improving Care Processes for Patients With Suspected Acute Coronary Syndrome)
<sec><title>Background:</title><p>Efforts to safely reduce length of stay for emergency department patients with symptoms suggestive of acute coronary syndrome (ACS) have had mixed success. Few system-wide efforts affecting multiple hospital emergency departments have ever been evaluated. We evaluated the effectiveness of a nationwide implementation of clinical pathways for potential ACS in disparate hospitals.</p></sec><sec><title>Methods:</title><p>This was a multicenter pragmatic stepped-wedge before-and-after trial in 7 New Zealand acute care hospitals with 31 332 patients investigated for suspected ACS with serial troponin measurements. The implementation was a clinical pathway for the assessment of patients with suspected ACS that included a clinical pathway document in paper or electronic format, structured risk stratification, specified time points for electrocardiographic and serial troponin testing within 3 hours of arrival, and directions for combining risk stratification and electrocardiographic and troponin testing in an accelerated diagnostic protocol. Implementation was monitored for >4 months and compared with usual care over the preceding 6 months. The main outcome measure was the odds of <strong><span style="color:yellowgreen">discharg</span></strong>e within 6 hours of presentation</p></sec><sec><title>Results:</title><p>There were 11 529 participants in the preimplementation phase (range, 284–3465) and 19 803 in the postimplementation phase (range, 395–5039). Overall, the mean 6-hour <strong><span style="color:yellowgreen">discharg</span></strong>e rate increased from 8.3% (range, 2.7%–37.7%) to 18.4% (6.8%–43.8%). The odds of being <strong><span style="color:yellowgreen">discharg</span></strong>ed within 6 hours increased after clinical pathway implementation. The odds ratio was 2.4 (95% confidence interval, 2.3–2.6). In patients without ACS, the median length of hospital stays decreased by 2.9 hours (95% confidence interval, 2.4–3.4). For patients <strong><span style="color:yellowgreen">discharg</span></strong>ed within 6 hours, there was no change in 30-day major adverse cardiac event rates (0.52% versus 0.44%; <i>P</i>=0.96). In these patients, no adverse event occurred when clinical pathways were correctly followed.</p></sec><sec><title>Conclusions:</title><p>Implementation of clinical pathways for suspected ACS reduced the length of stay and increased the proportions of patients safely <strong><span style="color:yellowgreen">discharg</span></strong>ed within 6 hours.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.anzctr.org.au/</ext-link> (Australian and New Zealand Clinical Trials Registry). Unique identifier: ACTRN12617000381381.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/4/354
10.1161/CIRCULATIONAHA.117.031984
None

5
Circulation
Hospital Variation in Adherence Rates to Secondary Prevention Medications and the Implications on Quality
<sec><title>Background:</title><p>Medication adherence is important to improve the long-term outcomes after acute myocardial infarction (MI). We hypothesized that there is significant variation among US hospitals in terms of medication adherence after MI, and that patients treated at hospitals with higher medication adherence after MI will have better long-term cardiovascular outcomes.</p></sec><sec><title>Methods:</title><p>We identified 19 704 Medicare patients <strong><span style="color:yellowgreen">discharg</span></strong>ed after acute MI from 347 US hospitals participating in the ACTION Registry-GWTG (Acute Coronary Treatment and Intervention Outcomes Network Registry-Get With the Guidelines) from January 2, 2007, to October 1, 2010. Using linked Medicare Part D prescription filling data, medication adherence was defined as proportion of days covered >80% within 90 days after <strong><span style="color:yellowgreen">discharg</span></strong>e. Cox proportional hazards modeling was used to compare 2-year major adverse cardiovascular events among hospitals with high, moderate, and low 90-day medication adherence.</p></sec><sec><title>Results:</title><p>By 90 days after MI, overall rates of adherence to medications prescribed at <strong><span style="color:yellowgreen">discharg</span></strong>e were 68% for β-blockers, 63% for statins, 64% for angiotensin-converting enzyme inhibitors/angiotensin receptor blockers, and 72% for thienopyridines. Adherence to these medications up to 90 days varied significantly among hospitals: β-blockers (proportion of days covered >80%; 59% to 75%), statins (55% to 69%), thienopyridines (64% to 77%), and angiotensin-converting enzyme inhibitors/angiotensin receptor blockers (57% to 69%). Compared with hospitals in the lowest quartile of 90-day composite medication adherence, hospitals with the highest adherence had lower unadjusted and adjusted 2-year major adverse cardiovascular event risk (27.5% versus 35.3%; adjusted hazard ratio, 0.88; 95% confidence interval, 0.80–0.96). High-adherence hospitals also had lower adjusted rates of death or readmission (hazard ratio, 0.90; 95% confidence interval, 0.85–0.96), whereas there was no difference in mortality after adjustment.</p></sec><sec><title>Conclusions:</title><p>Use of secondary prevention medications after <strong><span style="color:yellowgreen">discharg</span></strong>e varies significantly among US hospitals and is inversely associated with 2-year outcomes. Hospitals may improve medication adherence after <strong><span style="color:yellowgreen">discharg</span></strong>e and patient outcomes through better coordination of care between inpatient and outpatient settings.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/20/2128
10.1161/CIRCULATIONAHA.117.029160
None

5
Circulation
Treatment With Tissue Plasminogen Activator in the Golden Hour and the Shape of the 4.5-Hour Time-Benefit Curve in the National United States Get With The Guidelines-Stroke Population
<sec><title>Background:</title><p>Earlier tissue plasminogen activator treatment improves ischemic stroke outcome, but aspects of the time-benefit relationship still not well delineated are: (1) the degree of additional benefit accrued with treatment in the first 60 minutes after onset, and (2) the shape of the time-benefit curve through 4.5 hours.</p></sec><sec><title>Methods:</title><p>We analyzed patients who had acute ischemic stroke treated with intravenous tissue plasminogen activator within 4.5 hours of onset from the Get With The Guidelines-Stroke US national program. Onset-to-treatment time was analyzed as a continuous, potentially nonlinear variable and as a categorical variable comparing patients treated within 60 minutes of onset with later epochs.</p></sec><sec><title>Results:</title><p>Among 65 384 tissue plasminogen activator–treated patients, the median onset-to-treatment time was 141 minutes (interquartile range, 110–173) and 878 patients (1.3%) were treated within the first 60 minutes. Treatment within 60 minutes, compared with treatment within 61 to 270 minutes, was associated with increased odds of <strong><span style="color:yellowgreen">discharg</span></strong>e to home (adjusted odds ratio, 1.25; 95% confidence interval, 1.07–1.45), independent ambulation at <strong><span style="color:yellowgreen">discharg</span></strong>e (adjusted odds ratio, 1.22; 95% confidence interval, 1.03–1.45), and freedom from disability (modified Rankin Scale 0–1) at <strong><span style="color:yellowgreen">discharg</span></strong>e (adjusted odds ratio, 1.72; 95% confidence interval, 1.21–2.46), without increased hemorrhagic complications or in-hospital mortality. The pace of decline in benefit of tissue plasminogen activator from onset-to-treatment times of 20 through 270 minutes was mildly nonlinear for <strong><span style="color:yellowgreen">discharg</span></strong>e to home, with more rapid benefit loss in the first 170 minutes than later, and linear for independent ambulation and in-hospital mortality.</p></sec><sec><title>Conclusions:</title><p>Thrombolysis started within the first 60 minutes after onset is associated with best outcomes for patients with acute ischemic stroke, and benefit declined more rapidly early after onset for the ability to be <strong><span style="color:yellowgreen">discharg</span></strong>ed home. These findings support intensive efforts to organize stroke systems of care to improve the timeliness of thrombolytic therapy in acute ischemic stroke.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/2/128
10.1161/CIRCULATIONAHA.116.023336
None

5
Circulation
Association Between Duration of Resuscitation and Favorable Outcome After Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Little evidence guides the appropriate duration of resuscitation in out-of-hospital cardiac arrest, and case features justifying longer or shorter durations are ill defined. We estimated the impact of resuscitation duration on the probability of favorable functional outcome in out-of-hospital cardiac arrest using a large, multicenter cohort.</p></sec><sec><title>Methods:</title><p>This was a secondary analysis of a North American, single-blind, multicenter, cluster-randomized, clinical trial (ROC-PRIMED [Resuscitation Outcomes Consortium Prehospital Resuscitation Using an Impedance Valve and Early Versus Delayed]) of consecutive adults with nontraumatic, emergency medical services–treated out-of-hospital cardiac arrest. Primary exposure was duration of resuscitation in minutes (onset of professional resuscitation to return of spontaneous circulation [ROSC] or termination of resuscitation). Primary outcome was survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e with favorable outcome (modified Rankin scale [mRS] score of 0–3). Subjects were additionally classified as survival with unfavorable outcome (mRS score of 4–5), ROSC without survival (mRS score of 6), or without ROSC. Subject accrual was plotted as a function of resuscitation duration, and the dynamic probability of favorable outcome at <strong><span style="color:yellowgreen">discharg</span></strong>e was estimated for the whole cohort and subgroups. Adjusted logistic regression models tested the association between resuscitation duration and survival with favorable outcome.</p></sec><sec><title>Results:</title><p>The primary cohort included 11 368 subjects (median age, 69 years [interquartile range, 56–81 years]; 7121 men [62.6%]). Of these, 4023 (35.4%) achieved ROSC, 1232 (10.8%) survived to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e, and 905 (8.0%) had an mRS score of 0 to 3 at <strong><span style="color:yellowgreen">discharg</span></strong>e. Distribution of cardiopulmonary resuscitation duration differed by outcome (<i>P</i><0.00001). For cardiopulmonary resuscitation duration up to 37.0 minutes (95% confidence interval, 34.9–40.9 minutes), 99% with an eventual mRS score of 0 to 3 at <strong><span style="color:yellowgreen">discharg</span></strong>e achieved ROSC. The dynamic probability of an mRS score of 0 to 3 at <strong><span style="color:yellowgreen">discharg</span></strong>e declined over elapsed resuscitation duration, but subjects with initial shockable cardiac rhythm, witnessed cardiac arrest, and bystander cardiopulmonary resuscitation were more likely to survive with favorable outcome after prolonged efforts (30–40 minutes). After adjustment for prehospital (odds ratio, 0.93; 95% confidence interval, 0.92–0.95) and inpatient (odds ratio, 0.97; 95% confidence interval, 0.95–0.99) covariates, resuscitation duration was associated with survival to <strong><span style="color:yellowgreen">discharg</span></strong>e with an mRS score of 0 to 3.</p></sec><sec><title>Conclusions:</title><p>Shorter resuscitation duration was associated with likelihood of favorable outcome at hospital <strong><span style="color:yellowgreen">discharg</span></strong>e. Subjects with favorable case features were more likely to survive prolonged resuscitation up to 47 minutes.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT00394706.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2084
10.1161/CIRCULATIONAHA.116.023309
None

4
Science
Plastic waste associated with disease on coral reefs
<p>Plastic <strong><span style="color:yellowgreen">wast</span></strong>e can promote microbial colonization by pathogens implicated in outbreaks of disease in the ocean. We assessed the influence of plastic <strong><span style="color:yellowgreen">wast</span></strong>e on disease risk in 124,000 reef-building corals from 159 reefs in the Asia-Pacific region. The likelihood of disease increases from 4% to 89% when corals are in contact with plastic. Structurally complex corals are eight times more likely to be affected by plastic, suggesting that microhabitats for reef-associated organisms and valuable fisheries will be disproportionately affected. Plastic levels on coral reefs correspond to estimates of terrestrial mismanaged plastic <strong><span style="color:yellowgreen">wast</span></strong>e entering the ocean. We estimate that 11.1 billion plastic items are entangled on coral reefs across the Asia-Pacific and project this number to increase 40% by 2025. Plastic <strong><span style="color:yellowgreen">wast</span></strong>e management is critical for reducing diseases that threaten ecosystem health and human livelihoods.</p>
http://sciencemag.org/cgi/content/abstract/359/6374/460
10.1126/science.aar3320
['human']

4
Circulation
<i>Enterococcus faecalis</i> Infective Endocarditis
<sec><title>Background—</title><p>Because of the nephrotoxic effects of aminoglycosides, the Danish guidelines on infective endocarditis were changed in January 2007, reducing gentamicin treatment in enterococcal infective endocarditis from 4 to 6 weeks to only 2 weeks. In this pilot study, we compare outcomes in patients with <i>Enterococcus faecalis</i> infective endocarditis treated in the years before and after endorsement of these new recommendations.</p></sec><sec><title>Methods and Results—</title><p>A total of 84 consecutive patients admitted with definite left-sided <i>E faecalis</i> endocarditis in the period of 2002 to 2011 were enrolled. Forty-one patients were treated before and 43 patients were treated after January 1, 2007. There were no significant differences in baseline characteristics. At hospitalization, the 2 groups had similar estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rates of 66 and 75 mL/min (<i>P</i>=0.22). Patients treated before January 2007 received gentamicin for a significantly longer period (28 versus 14 days; <i>P</i><0.001). The primary outcome, 1-year event-free survival, did not differ: 66% versus 69%, respectively (<i>P</i>=0.75). At <strong><span style="color:yellowgreen">discharg</span></strong>e, the patients treated before 2007 had a lower estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate (45 versus 66 mL/min; <i>P</i>=0.008) and a significantly greater decrease in estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate (median, 11 versus 1 mL/min; <i>P</i>=0.009) compared with those treated after 2007.</p></sec><sec><title>Conclusions—</title><p>Our present pilot study suggests that the recommended 2-week treatment with gentamicin seems adequate and preferable in treating non–high-level aminoglycoside-resistant <i>E faecalis</i> infective endocarditis. The longer duration of gentamicin treatment is associated with worse renal function. Although the certainty of the clinical outcomes is limited by the sample size, outcomes appear to be no worse with the shorter treatment duration. Randomized, controlled studies are warranted to substantiate these results.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/17/1810
10.1161/CIRCULATIONAHA.112.001170
['Enterococcus', 'Enterococcus faecalis']

3
Science Signaling
YAP-mediated mechanotransduction determines the podocyte’s response to damage
<p>Podocytes are terminally differentiated cells of the kidney <strong><span style="color:yellowgreen">filtrat</span></strong>ion barrier. They are subjected to physiological <strong><span style="color:yellowgreen">filtrat</span></strong>ion pressure and considerable mechanical strain, which can be further increased in various kidney diseases. When injury causes cytoskeletal reorganization and morphological alterations of these cells, the <strong><span style="color:yellowgreen">filtrat</span></strong>ion barrier may become compromised and allow proteins to leak into the urine (a condition called proteinuria). Using time-resolved proteomics, we showed that podocyte injury stimulated the activity of the transcriptional coactivator YAP and the expression of YAP target genes in a rat model of glomerular disease before the development of proteinuria. Although the activities of YAP and its ortholog TAZ are activated by mechanical stress in most cell types, injury reduced YAP and TAZ activity in cultured human and mouse podocyte cell lines grown on stiff substrates. Culturing these cells on soft matrix or inhibiting stress fiber formation recapitulated the damage-induced YAP up-regulation observed in vivo, indicating a mechanotransduction-dependent mechanism of YAP activation in podocytes. YAP overexpression in cultured podocytes increased the abundance of extracellular matrix–related proteins that can contribute to fibrosis. YAP activity was increased in mouse models of diabetic nephropathy, and the YAP target <i>CTGF</i> was highly expressed in renal biopsies from glomerular disease patients. Although overexpression of human YAP in mice induced mild proteinuria, pharmacological inhibition of the interaction between YAP and its partner TEAD in rats ameliorated glomerular disease and reduced damage-induced mechanosignaling in the glomeruli. Thus, perturbation of YAP-dependent mechanosignaling is a potential therapeutic target for treating some glomerular diseases.</p>
http://classic.stke.sciencemag.org/cgi/content/summary/10/474/eaaf8165
10.1126/scisignal.aaf8165
['human']

3
Journal of Experimental Biology
Measuring gill paracellular permeability with polyethylene glycol-4000 in freely swimming trout: proof of principle
<p>The influence of swimming activity on gill paracellular permeability has not been measured previously in fishes. We critically assessed the use of tritium-labeled polyethylene glycol ([<sup>3</sup>H]PEG-4000) for this purpose, a substance that is also a classic marker for extracellular fluid volume, glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate and drinking rate. Tests (8 h) on resting freshwater trout showed that when measuring [<sup>3</sup>H]PEG-4000 clearance from the plasma in the efflux direction, correction for a large excretion via glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion was essential, necessitating urinary catheterization. When measuring [<sup>3</sup>H]PEG-4000 clearance from the water in the influx direction, correction for a significant uptake by drinking was essential, necessitating terminal gut removal, whereas glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion losses were minimal. After correction for these alternate routes of loss and uptake, [<sup>3</sup>H]PEG-4000 clearance rates by efflux from the plasma and by influx from the water were identical, showing that gill paracellular permeability is not rectified, and can be measured in either direction. The influx technique with terminal gut removal was used to assess gill paracellular permeability in trout without urinary catheters freely swimming at 1.2 body lengths s<sup>−1</sup> for 8 h. Branchial [<sup>3</sup>H]PEG-4000 clearance rate (by influx from the water) increased significantly by ~80% in accord with a similar measured increase in O<sub>2</sub> consumption rate. Thus in trout, gill paracellular permeability does increase during exercise, in accord with the traditional concept of the osmorespiratory compromise.</p>
http://jeb.biologists.org/cgi/content/abstract/217/9/1425
10.1242/jeb.099879
None

3
The Bone & Joint Journal
Antisepsis of the skin before spinal surgery with povidone iodine-alcohol followed by chlorhexidine gluconate-alcohol <i>versus</i> povidone iodine-alcohol applied twice for the prevention of contamination of the wound by bacteria
<sec><title>Aims</title><p>The aim of this study was to determine whether the sequential   application of povidone iodine-alcohol (PVI) followed by chlorhexidine   gluconate-alcohol (CHG) would reduce surgical wound <strong><span style="color:yellowgreen">contamin</span></strong>ation   to a greater extent than PVI applied twice in patients undergoing   spinal surgery.</p></sec><sec><title>Patients and Methods</title><p>A single-centre, interventional, two arm, parallel group randomised   controlled trial was undertaken, involving 407 patients who underwent   elective spinal surgery.</p><p>For 203 patients, the skin was disinfected before surgery using   PVI (10% [w/w (1% w/w available iodine)] in 95% industrial denatured   alcohol, povidone iodine; Videne Alcoholic Tincture) twice, and   for 204 patients using PVI once followed by CHG (2% [w/v] chlorhexidine   gluconate in 70% [v/v] isopropyl alcohol; Chloraprep with tint).   The primary outcome measure was <strong><span style="color:yellowgreen">contamin</span></strong>ation of the wound determined   by aerobic and anaerobic bacterial growth from samples taken after   disinfection.</p></sec><sec><title>Results</title><p>The detection of viable bacteria in any one of the samples taken   after disinfection (culture-positive) was significantly lower in   the group treated with both PVI and CHG than in the group treated   with PVI alone (59 (29.1%) <i>versus</i> 85 (41.7%), p   = 0.009; odds ratio 0.574;    95% confidence interval, 0.380 to 0.866).</p></sec><sec><title>Conclusions</title><p>Antisepsis of the skin with the sequential application of PVI   and CHG more effectively reduces the <strong><span style="color:yellowgreen">contamin</span></strong>ation of a surgical   wound than PVI alone.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1354–65.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/10/1354
10.1302/0301-620X.99B10.BJJ-2017-0291.R1
None

3
Circulation
Association Between Early Hyperoxia Exposure After Resuscitation From Cardiac Arrest and Neurological Disability
<sec><title>Background:</title><p>Studies examining the association between hyperoxia exposure after resuscitation from cardiac arrest and clinical outcomes have reported conflicting results. Our objective was to test the hypothesis that early postresuscitation hyperoxia is associated with poor neurological outcome.</p></sec><sec><title>Methods:</title><p>This was a multicenter prospective cohort study. We included adult patients with cardiac arrest who were mechanically ventilated and received targeted temperature management after return of spontaneous circulation. We excluded patients with cardiac arrest caused by trauma or sepsis. Per protocol, partial pressure of arterial oxygen (Pa<sc>o</sc><sub>2</sub>) was measured at 1 and 6 hours after return of spontaneous circulation. Hyperoxia was defined as a Pa<sc>o</sc><sub>2</sub> >300 mm Hg during the initial 6 hours after return of spontaneous circulation. The primary outcome was poor neurological function at hospital <strong><span style="color:yellowgreen">discharg</span></strong>e, defined as a modified Rankin Scale score >3. Multivariable generalized linear regression with a log link was used to test the association between Pa<sc>o</sc><sub>2</sub> and poor neurological outcome. To assess whether there was an association between other supranormal Pa<sc>o</sc><sub>2</sub> levels and poor neurological outcome, we used other Pa<sc>o</sc><sub>2</sub> cut points to define hyperoxia (ie, 100, 150, 200, 250, 350, 400 mm Hg).</p></sec><sec><title>Results:</title><p>Of the 280 patients included, 105 (38%) had exposure to hyperoxia. Poor neurological function at hospital <strong><span style="color:yellowgreen">discharg</span></strong>e occurred in 70% of patients in the entire cohort and in 77% versus 65% among patients with versus without exposure to hyperoxia respectively (absolute risk difference, 12%; 95% confidence interval, 1–23). Hyperoxia was independently associated with poor neurological function (relative risk, 1.23; 95% confidence interval, 1.11–1.35). On multivariable analysis, a 1-hour-longer duration of hyperoxia exposure was associated with a 3% increase in risk of poor neurological outcome (relative risk, 1.03; 95% confidence interval, 1.02–1.05). We found that the association with poor neurological outcome began at ≥300 mm Hg.</p></sec><sec><title>Conclusions:</title><p>Early hyperoxia exposure after resuscitation from cardiac arrest was independently associated with poor neurological function at hospital <strong><span style="color:yellowgreen">discharg</span></strong>e.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/20/2114
10.1161/CIRCULATIONAHA.117.032054
None

3
Circulation
Antiarrhythmic Drugs for Nonshockable-Turned-Shockable Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Out-of-hospital cardiac arrest (OHCA) commonly presents with nonshockable rhythms (asystole and pulseless electric activity). It is unknown whether antiarrhythmic drugs are safe and effective when nonshockable rhythms evolve to shockable rhythms (ventricular fibrillation/pulseless ventricular tachycardia [VF/VT]) during resuscitation.</p></sec><sec><title>Methods:</title><p>Adults with nontraumatic OHCA, vascular access, and VF/VT anytime after ≥1 shock(s) were prospectively randomized, double-blind, to receive amiodarone, lidocaine, or placebo by paramedics. Patients presenting with initial shock-refractory VF/VT were previously reported. The current study was a prespecified analysis in a separate cohort that initially presented with nonshockable OHCA and was randomized on subsequently developing shock-refractory VF/VT. The primary outcome was survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e. Secondary outcomes included <strong><span style="color:yellowgreen">discharg</span></strong>e functional status and adverse drug-related effects.</p></sec><sec><title>Results:</title><p>Of 37 889 patients with OHCA, 3026 with initial VF/VT and 1063 with initial nonshockable-turned-shockable rhythms were treatment-eligible, were randomized, and received their assigned drug. Baseline characteristics among patients with nonshockable-turned-shockable rhythms were balanced across treatment arms, except that recipients of a placebo included fewer men and were less likely to receive bystander cardiopulmonary resuscitation. Active-drug recipients in this cohort required fewer shocks, supplemental doses of their assigned drug, and ancillary antiarrhythmic drugs than recipients of a placebo (<i>P</i><0.05). In all, 16 (4.1%) amiodarone, 11 (3.1%) lidocaine, and 6 (1.9%) placebo-treated patients survived to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e (<i>P</i>=0.24). No significant interaction between treatment assignment and <strong><span style="color:yellowgreen">discharg</span></strong>e survival occurred with the initiating OHCA rhythm (asystole, pulseless electric activity, or VF/VT). Survival in each of these categories was consistently higher with active drugs, although the trends were not statistically significant. Adjusted absolute differences (95% confidence interval) in survival from nonshockable-turned-shockable arrhythmias with amiodarone versus placebo were 2.3% (−0.3, 4.8), <i>P</i>=0.08, and for lidocaine versus placebo 1.2% (−1.1, 3.6), <i>P</i>=0.30. More than 50% of these survivors were functionally independent or required minimal assistance. Drug-related adverse effects were infrequent.</p></sec><sec><title>Conclusions:</title><p>Outcome from nonshockable-turned-shockable OHCA is poor but not invariably fatal. Although not statistically significant, point estimates for survival were greater after amiodarone or lidocaine than placebo, without increased risk of adverse effects or disability and consistent with previously observed favorable trends from treatment of initial shock-refractory VF/VT with these drugs. Together the findings may signal a clinical benefit that invites further investigation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01401647.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2119
10.1161/CIRCULATIONAHA.117.028624
None

3
Circulation
Medical Therapy for Secondary Prevention and Long-Term Outcome in Patients With Myocardial Infarction With Nonobstructive Coronary Artery Disease
<sec><title>Background:</title><p>Myocardial infarction with nonobstructive coronary arteries (MINOCA) occurs in 5% to 10% of all patients with myocardial infarction. Clinical trials of secondary prevention treatment in MINOCA patients are lacking. Therefore, the aim of this study was to examine the associations between treatment with statins, renin-angiotensin system blockers, β-blockers, dual antiplatelet therapy, and long-term cardiovascular events.</p></sec><sec><title>Methods:</title><p>This is an observational study of MINOCA patients recorded in the SWEDEHEART registry (the Swedish Web-system for Enhancement and Development of Evidence-based care in Heart disease Evaluated According to Recommended Therapy) between July 2003 and June 2013 and followed until December 2013 for outcome events in the Swedish Cause of Death Register and National Patient Register. Of 199 162 myocardial infarction admissions, 9466 consecutive unique patients with MINOCA were identified. Among those, the 9136 patients surviving the first 30 days after <strong><span style="color:yellowgreen">discharg</span></strong>e constituted the study population. Mean age was 65.3 years, and 61% were women. No patient was lost to follow-up. A stratified propensity score analysis was performed to match treated and untreated groups. The association between treatment and outcome was estimated by comparing between treated and untreated groups by using Cox proportional hazards models. The exposures were treatment at <strong><span style="color:yellowgreen">discharg</span></strong>e with statins, angiotensin-converting enzyme inhibitors/angiotensin receptor blockers, β-blockers, and dual antiplatelet therapy. The primary end point was major adverse cardiac events defined as all-cause mortality, hospitalization for myocardial infarction, ischemic stroke, and heart failure.</p></sec><sec><title>Results:</title><p>At <strong><span style="color:yellowgreen">discharg</span></strong>e, 84.5%, 64.1%, 83.4%, and 66.4% of the patients were on statins, angiotensin-converting enzyme inhibitors/angiotensin receptor blockers, β-blockers, and dual antiplatelet therapy, respectively. During the follow-up of a mean of 4.1 years, 2183 (23.9%) patients experienced a major adverse cardiac event. The hazard ratios (95% confidence intervals) for major adverse cardiac events were 0.77 (0.68–0.87), 0.82 (0.73–0.93), and 0.86 (0.74–1.01) in patients on statins, angiotensin-converting enzyme inhibitors/angiotensin receptor blockers, and β-blockers, respectively. For patients on dual antiplatelet therapy followed for 1 year, the hazard ratio was 0.90 (0.74–1.08).</p></sec><sec><title>Conclusions:</title><p>The results indicate long-term beneficial effects of treatment with statins and angiotensin-converting enzyme inhibitors/angiotensin receptor blockers on outcome in patients with MINOCA, a trend toward a positive effect of β-blocker treatment, and a neutral effect of dual antiplatelet therapy. Properly powered randomized clinical trials to confirm these results are warranted.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/16/1481
10.1161/CIRCULATIONAHA.116.026336
None

3
Circulation
High On-Treatment Platelet Reactivity as a Risk Factor for Secondary Prevention After Coronary Stent Revascularization
<sec><title>Background—</title><p>Individualizing antiplatelet therapy after platelet function testing did not improve outcome after coronary stenting in the Assessment by a Double Randomization of a Conventional Antiplatelet Strategy Versus a Monitoring-Guided Strategy for Drug-Eluting Stent Implantation and of Treatment Interruption Versus Continuation One Year After Stenting (ARCTIC) study. Whether results are different during the phase of secondary prevention starting after hospital <strong><span style="color:yellowgreen">discharg</span></strong>e, when periprocedural events have been excluded, is unknown.</p></sec><sec><title>Methods and Results—</title><p>In ARCTIC, 2440 patients were randomized before coronary stenting to a strategy of platelet function monitoring (VerifyNow P2Y<sub>12</sub>/aspirin point-of-care assay) with drug adjustment in suboptimal responders to antiplatelet therapy or to a conventional strategy without monitoring and without drug or dose changes. We performed a landmark analysis starting at the time of hospital <strong><span style="color:yellowgreen">discharg</span></strong>e evaluating the primary end point of death, myocardial infarction, stent thrombosis, stroke, or urgent revascularization through 1 year. After <strong><span style="color:yellowgreen">discharg</span></strong>e, the primary end point occurred in 8.6% of patients in the monitoring arm and 7.9% in the conventional arm (hazard ratio, 1.105; 95% confidence interval, 0.835–1.461; <i>P</i>=0.48). Stent thrombosis or urgent revascularization occurred in 4.4% and 4.5% in the monitoring and conventional arms, respectively (<i>P</i>=0.99). There was no difference for any of the other ischemic end points. Major bleeding event rates were 1.8% in the monitoring arm and 2.8% in the conventional arm (<i>P</i>=0.11), whereas major or minor bleeding event rates were 2.3% and 3.4%, respectively (<i>P</i>=0.10).</p></sec><sec><title>Conclusions—</title><p>Detection of platelet hyper-reactivity by platelet function testing in patients undergoing coronary stenting with further therapeutic adjustment does not reduce ischemic recurrences after intervention. On-treatment platelet hyperreactivity cannot be considered as a risk factor requiring intervention for secondary prevention after percutaneous coronary revascularization.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00827411.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/21/2136
10.1161/CIRCULATIONAHA.113.007524
None

3
Circulation
Association Between Physician Follow-Up and Outcomes of Care After Chest Pain Assessment in High-Risk Patients
<sec><title>Background—</title><p>Assessment of chest pain is one of the most common reasons for emergency department visits in developed countries. Although guidelines recommend primary care physician (PCP) follow-up for patients who are subsequently <strong><span style="color:yellowgreen">discharg</span></strong>ed, little is known about the relationship between physician follow-up and clinical outcomes.</p></sec><sec><title>Methods and Results—</title><p>An observational study was conducted on patients with higher baseline risk, defined as having diabetes mellitus or established cardiovascular disease, who were evaluated for chest pain, <strong><span style="color:yellowgreen">discharg</span></strong>ed, and without adverse clinical outcomes for 30 days in Ontario from 2004 to 2010. Multivariable proportional hazard models were constructed to adjust for potential confounding between physician groups (cardiologist, PCP, or none). Among 56767 included patients, 17% were evaluated by cardiologists, 58% were evaluated by PCPs alone, and 25% had no physician follow-up. The mean age was 66±15 years, and 53% were male. The highest rates of diagnostic testing, medical therapy, and coronary revascularization were seen among patients treated by cardiologists. At 1 year, the rate of death or MI was 5.5% (95% confidence interval, 5.0–5.9) in the cardiology group, 7.7% (95% confidence interval, 7.4–7.9) in the PCP group, and 8.6% (95% confidence interval, 8.2–9.1) in the no-physician group. After adjustment, cardiologist follow-up was associated with significantly lower adjusted hazard ratio of death or MI compared with PCP (hazard ratio, 0.85; 95% confidence interval, 0.78–0.92) and no physician (hazard ratio, 0.79; 95% confidence interval, 0.71–0.88) follow-up.</p></sec><sec><title>Conclusions—</title><p>Among patients with higher baseline cardiovascular risk who were <strong><span style="color:yellowgreen">discharg</span></strong>ed from the emergency department after evaluation for chest pain in Ontario, follow-up with a cardiologist was associated with a decreased risk of all-cause mortality or hospitalization for MI at 1 year compared with follow-up with a PCP or no physician follow-up.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/13/1386
10.1161/CIRCULATIONAHA.112.000737
None

2
Tree Physiology
Sexual competition affects biomass partitioning, carbon–nutrient balance, Cd allocation and ultrastructure of <i>Populus cathayana</i> females and males exposed to Cd stress
<p>Although increasing attention has been paid to plant adaptation to soil heavy metal <strong><span style="color:yellowgreen">contamin</span></strong>ation, competition and neighbor effects have been largely overlooked, especially in dioecious plants. In this study, we investigated growth as well as biochemical and ultrastructural responses of <i>Populus cathayana</i> Rehder females and males to cadmium (Cd) stress under different sexual competition patterns. The results showed that competition significantly affects biomass partitioning, photosynthetic capacity, leaf and root ultrastructure, Cd accumulation, the contents of polyphenols, and structural and nonstructural carbohydrates. Compared with single-sex cultivation, plants of opposite sexes exposed to sexual competition accumulated more Cd in tissues and their growth was more strongly inhibited, indicating enhanced Cd toxicity under sexual competition. Under intrasexual competition, females showed greater Cd accumulation, more serious damage at the ultrastructural level and greater reduction in physiological activity than under intersexual competition, while males performed better under intrasexual competition than under intersexual competition. Males improved the female microenvironment by greater Cd uptake and lower resource consumption under intersexual competition. These results demonstrate that the sex of neighbor plants and competition affect sexual differences in growth and in key physiological processes under Cd stress. The asymmetry of sexual competition highlighted here might regulate population structure, and spatial segregation and phytoremediation potential of both sexes in <i>P. cathayana</i> growing in heavy metal-<strong><span style="color:yellowgreen">contamin</span></strong>ated soils.</p>
http://treephys.oxfordjournals.org/cgi/content/abstract/36/11/1353
10.1093/treephys/tpw054
['Populus', 'plants']

2
Science
Perivascular dendritic cells elicit anaphylaxis by relaying allergens to mast cells via microvesicles
<p>Anaphylactic reactions are triggered when allergens enter the blood circulation and activate immunoglobulin E (IgE)–sensitized mast cells (MCs), causing systemic <strong><span style="color:yellowgreen">discharg</span></strong>e of prestored proinflammatory mediators. As MCs are extravascular, how they perceive circulating allergens remains a conundrum. Here, we describe the existence of a CD301b<sup>+</sup> perivascular dendritic cell (DC) subset that continuously samples blood and relays antigens to neighboring MCs, which vigorously degranulate and trigger anaphylaxis. DC antigen transfer involves the active <strong><span style="color:yellowgreen">discharg</span></strong>e of surface-associated antigens on 0.5- to 1.0-micrometer microvesicles (MVs) generated by vacuolar protein sorting 4 (VPS4). Antigen sharing by DCs is not limited to MCs, as neighboring DCs also acquire antigen-bearing MVs. This capacity of DCs to distribute antigen-bearing MVs to various immune cells in the perivascular space potentiates inflammatory and immune responses to blood-borne antigens.</p>
http://sciencemag.org/cgi/content/abstract/362/6415/eaao0666
10.1126/science.aao0666
None

2
Science
Suppressing corrosion in primary aluminum–air batteries via oil displacement
<p>Primary aluminum–air batteries boast high theoretical energy densities, but negative electrode corrosion irreversibly limits their shelf life. Most corrosion mitigation methods are insufficient or compromise power and energy density. We suppressed open-circuit corrosion by displacing electrolyte from the electrode surface with a nonconducting oil during battery standby. High power and energy density are enabled by displacing the oil with electrolyte for battery <strong><span style="color:yellowgreen">discharg</span></strong>e. The underwater-oleophobic wetting properties of the designed cell surfaces allow for reversible oil displacement. We demonstrate this method in an aluminum–air cell that achieves a 420% increase in usable energy density and 99.99% reduction in corrosion, which lowers self-<strong><span style="color:yellowgreen">discharg</span></strong>e to a rate of 0.02% a month and enables system energy densities of 700 watt-hours per liter and 900 watt-hours per kilogram.</p>
http://sciencemag.org/cgi/content/abstract/362/6415/658
10.1126/science.aat9149
None

2
Science
Designing river flows to improve food security futures in the Lower Mekong Basin
<p>Rivers provide unrivaled opportunity for clean energy via hydropower, but little is known about the potential impact of dam-building on the food security these rivers provide. In tropical rivers, rainfall drives a periodic flood pulse fueling fish production and delivering nutrition to more than 150 million people worldwide. Hydropower will modulate this flood pulse, thereby threatening food security. We identified variance components of the Mekong River flood pulse that predict yield in one of the largest freshwater fisheries in the world. We used these variance components to design an algorithm for a managed hydrograph to explore future yields. This algorithm mimics attributes of <strong><span style="color:yellowgreen">discharg</span></strong>e variance that drive fishery yield: prolonged low flows followed by a short flood pulse. Designed flows increased yield by a factor of 3.7 relative to historical hydrology. Managing desired components of <strong><span style="color:yellowgreen">discharg</span></strong>e variance will lead to greater efficiency in the Lower Mekong Basin food system.</p>
http://sciencemag.org/cgi/content/abstract/358/6368/eaao1053
10.1126/science.aao1053
['fish']

2
Science
A small-molecule inhibitor of TRPC5 ion channels suppresses progressive kidney disease in animal models
<p>Progressive kidney diseases are often associated with scarring of the kidney’s <strong><span style="color:yellowgreen">filtrat</span></strong>ion unit, a condition called focal segmental glomerulosclerosis (FSGS). This scarring is due to loss of podocytes, cells critical for glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion, and leads to proteinuria and kidney failure. Inherited forms of FSGS are caused by Rac1-activating mutations, and Rac1 induces TRPC5 ion channel activity and cytoskeletal remodeling in podocytes. Whether TRPC5 activity mediates FSGS onset and progression is unknown. We identified a small molecule, AC1903, that specifically blocks TRPC5 channel activity in glomeruli of proteinuric rats. Chronic administration of AC1903 suppressed severe proteinuria and prevented podocyte loss in a transgenic rat model of FSGS. AC1903 also provided therapeutic benefit in a rat model of hypertensive proteinuric kidney disease. These data indicate that TRPC5 activity drives disease and that TRPC5 inhibitors may be valuable for the treatment of progressive kidney diseases.</p>
http://sciencemag.org/cgi/content/abstract/358/6368/1332
10.1126/science.aal4178
None

2
Science
Metabolic recycling of ammonia via glutamate dehydrogenase supports breast cancer biomass
<p>Ammonia is a ubiquitous by-product of cellular metabolism; however, the biological consequences of ammonia production are not fully understood, especially in cancer. We found that ammonia is not merely a toxic <strong><span style="color:yellowgreen">wast</span></strong>e product but is recycled into central amino acid metabolism to maximize nitrogen utilization. In our experiments, human breast cancer cells primarily assimilated ammonia through reductive amination catalyzed by glutamate dehydrogenase (GDH); secondary reactions enabled other amino acids, such as proline and aspartate, to directly acquire this nitrogen. Metabolic recycling of ammonia accelerated proliferation of breast cancer. In mice, ammonia accumulated in the tumor microenvironment and was used directly to generate amino acids through GDH activity. These data show that ammonia is not only a secreted <strong><span style="color:yellowgreen">wast</span></strong>e product but also a fundamental nitrogen source that can support tumor biomass.</p>
http://sciencemag.org/cgi/content/abstract/358/6365/941
10.1126/science.aam9305
['Ammonia', 'human']

2
Science
Estimating the health benefits of environmental regulations
<p>Assessing health benefits of policies addressing environmental <strong><span style="color:yellowgreen">contamin</span></strong>ants is important for decision-making and for informing the public about how policy affects their welfare (<i>1</i>). Benefits analysis, one side of benefit-cost analysis (BCA), can be relatively straightforward when sufficient data are available on dose-response relationships, changes in exposure expected from a proposed policy, and other key inputs. But despite progress, benefits analysis for health effects is needlessly constrained by analytic practices that are scientifically outdated and inconsistent with economic theory. These limitations can result in exclusion of important health effects from the estimated benefits of reducing exposure to toxic environmental <strong><span style="color:yellowgreen">contamin</span></strong>ants, which, in turn, affects net benefits calculations that inform public policy. Fortunately, economic theory and scientific advances in the risk assessment literature provide a way forward.</p>
http://sciencemag.org/cgi/content/summary/357/6350/457
10.1126/science.aam8204
None

2
Journal of Experimental Biology
Gastrointestinal and renal responses to variable water intake in whitebellied sunbirds and New Holland honeyeaters
<p>Nectarivores face a constant challenge in terms of water balance, experiencing water loading or dehydration when switching between food plants or between feeding and fasting. To understand how whitebellied sunbirds and New Holland honeyeaters meet the challenges of varying preformed water load, we used the elimination of intramuscular-injected [<sup>14</sup>C]-<sc>l</sc>-glucose and <sup>3</sup>H<sub>2</sub>O to quantify intestinal and renal water handling on diets varying in sugar concentration. Both sunbirds and honeyeaters showed significant modulation of intestinal water absorption, allowing excess water to be shunted through the intestine when on dilute diets. Despite reducing their fractional water absorption, both species showed linear increases in water flux and fractional body water turnover as water intake increased (both afternoon and morning), suggesting that the modulation of fractional water absorption was not sufficient to completely offset dietary water loads. In both species, glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate was independent of water gain (but was higher for the afternoon), as was renal fractional water reabsorption (measured in the afternoon). During the natural overnight fast, both sunbirds and honeyeaters arrested whole kidney function. Evaporative water loss in sunbirds was variable but correlated with water gain. Both sunbirds and honeyeaters appear to modulate intestinal water absorption as an important component of water regulation to help deal with massive preformed water loads. Shutting down glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate during the overnight fast is another way of saving energy for osmoregulatory function. Birds maintain osmotic balance on diets varying markedly in preformed water load by varying both intestinal water absorption and excretion through the intestine and kidneys.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1537
10.1242/jeb.075176
['Birds', 'plants']

2
The Bone & Joint Journal
Is computer navigation when used in the surgery of iliosacral pelvic bone tumours safer for the patient?
<sec><title>Aims</title><p>Due to the complex anatomy of the pelvis, limb-sparing resections   of pelvic tumours achieving adequate surgical margins, can often   be difficult. The advent of computer navigation has improved the   precision of resection of these lesions, though there is little   evidence comparing resection with or without the assistance of navigation.</p><p>Our aim was to evaluate the efficacy of navigation-assisted surgery   for the resection of pelvic bone tumours involving the posterior   ilium and sacrum. </p></sec><sec><title>Patients and Methods</title><p>Using our prospectively updated institutional database, we conducted   a retrospective case control study of 21 patients who underwent   resection of the posterior ilium and sacrum, for the treatment of   a primary sarcoma of bone, between 1987 and 2015. The resection   was performed with the assistance of navigation in nine patients   and without navigation in 12. We assessed the accuracy of navigation-assisted   surgery, as defined by the surgical margin and how this affects   the rate of local recurrence, the disease-free survival and the   effects on peri-and post-operative morbidity. </p></sec><sec><title>Results</title><p>The mean age of the patients was 36.4 years (15 to 66). The mean   size of the tumour was 10.9 cm. In the navigation-assisted group,   the margin was wide in two patients (16.7%), marginal in six (66.7%)   and wide-<strong><span style="color:yellowgreen">contamin</span></strong>ated in one (11.1%) with no intralesional margin.   In the non-navigated-assisted group; the margin was wide in two   patients (16.7%), marginal in five (41.7%), intralesional in three   (25.0%) and wide-<strong><span style="color:yellowgreen">contamin</span></strong>ated in two (16.7%). Local recurrence occurred   in two patients in the navigation-assisted group (22.2%) and six   in the non-navigation-assisted group (50.0%). The disease-free survival   was significantly better when operated with navigation-assistance   (p = 0.048). The blood loss and operating time were less in the   navigated-assisted group, as was the risk of a foot drop post-operatively.</p></sec><sec><title>Conclusion </title><p>The introduction of navigation-assisted surgery for the resection   of tumours of the posterior ilium and sacrum has increased the safety   for the patients and allows for a better oncological outcome. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:261–6.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/2/261
10.1302/0301-620X.99B2.BJJ-2016-0149.R2
None

2
Circulation
Worsening Renal Function in Patients With Acute Heart Failure Undergoing Aggressive Diuresis Is Not Associated With Tubular Injury
<sec><title>Background:</title><p>Worsening renal function (WRF) in the setting of aggressive diuresis for acute heart failure treatment may reflect renal tubular injury or simply indicate a hemodynamic or functional change in glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion. Well-validated tubular injury biomarkers, <i>N</i>-acetyl-β-<sc>d</sc>-glucosaminidase, neutrophil gelatinase-associated lipocalin, and kidney injury molecule 1, are now available that can quantify the degree of renal tubular injury. The ROSE-AHF trial (Renal Optimization Strategies Evaluation–Acute Heart Failure) provides an experimental platform for the study of mechanisms of WRF during aggressive diuresis for acute heart failure because the ROSE-AHF protocol dictated high-dose loop diuretic therapy in all patients. We sought to determine whether tubular injury biomarkers are associated with WRF in the setting of aggressive diuresis and its association with prognosis.</p></sec><sec><title>Methods:</title><p>Patients in the multicenter ROSE-AHF trial with baseline and 72-hour urine tubular injury biomarkers were analyzed (n=283). WRF was defined as a ≥20% decrease in glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate estimated with cystatin C.</p></sec><sec><title>Results:</title><p>Consistent with protocol-driven aggressive dosing of loop diuretics, participants received a median 560 mg IV furosemide equivalents (interquartile range, 300–815 mg), which induced a urine output of 8425 mL (interquartile range, 6341–10 528 mL) over the 72-hour intervention period. Levels of <i>N</i>-acetyl-β-<sc>d</sc>-glucosaminidase and kidney injury molecule 1 did not change with aggressive diuresis (both <i>P</i>>0.59), whereas levels of neutrophil gelatinase-associated lipocalin decreased slightly (−8.7 ng/mg; interquartile range, −169 to 35 ng/mg; <i>P</i><0.001). WRF occurred in 21.2% of the population and was not associated with an increase in any marker of renal tubular injury: neutrophil gelatinase-associated lipocalin (<i>P</i>=0.21), <i>N</i>-acetyl-β-<sc>d</sc>-glucosaminidase (<i>P</i>=0.46), or kidney injury molecule 1 (<i>P</i>=0.22). Increases in neutrophil gelatinase-associated lipocalin, <i>N</i>-acetyl-β-<sc>d</sc>-glucosaminidase, and kidney injury molecule 1 were paradoxically associated with improved survival (adjusted hazard ratio, 0.80 per 10 percentile increase; 95% confidence interval, 0.69–0.91; <i>P</i>=0.001).</p></sec><sec><title>Conclusions:</title><p>Kidney tubular injury does not appear to have an association with WRF in the context of aggressive diuresis of patients with acute heart failure. These findings reinforce the notion that the small to moderate deteriorations in renal function commonly encountered with aggressive diuresis are dissimilar from traditional causes of acute kidney injury.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/19/2016
10.1161/CIRCULATIONAHA.117.030112
None

2
Circulation
NT-proBNP (N-Terminal pro-B-Type Natriuretic Peptide)-Guided Therapy in Acute Decompensated Heart Failure
<sec><title>Background:</title><p>The concept of natriuretic peptide guidance has been extensively studied in patients with chronic heart failure (HF), with only limited success. The effect of NT-proBNP (N-terminal probrain natriuretic peptide)-guided therapy in patients with acute decompensated HF using a relative NT-proBNP target has not been investigated. This study aimed to assess whether NT-proBNP-guided therapy of patients with acute decompensated HF using a relative NT-proBNP target would lead to improved outcomes compared with conventional therapy.</p></sec><sec><title>Methods:</title><p>We conducted a prospective randomized controlled trial to study the impact of in-hospital guidance for acute decompensated HF treatment by a predefined NT-proBNP target (>30% reduction from admission to <strong><span style="color:yellowgreen">discharg</span></strong>e) versus conventional treatment. Patients with acute decompensated HF with NT-proBNP levels >1700 ng/L were eligible. After achieving clinical stability, 405 patients were randomized to either NT-proBNP-guided or conventional treatment (1:1). The primary end point was dual: a composite of all-cause mortality and HF readmissions in 180 days and the number of days alive out of the hospital in 180 days. Secondary end points were all-cause mortality within 180 days, HF readmissions within 180 days, and a composite of all-cause mortality and HF readmissions within 90 days.</p></sec><sec><title>Results:</title><p>Significantly more patients in the NT-proBNP-guided therapy group were <strong><span style="color:yellowgreen">discharg</span></strong>ed with an NT-proBNP reduction of >30% (80% versus 64%, <i>P</i>=0.001). Nonetheless, NT-proBNP-guided therapy did not significantly improve the combined event rate for all-cause mortality and HF readmissions (hazard ratio, 0.96; 95% confidence interval, 0.72–1.37; <i>P</i>=0.99) or the median number of days alive outside of the hospital (178 versus 179 days for NT-proBNP versus conventional patients, <i>P</i>=0.39). Guided therapy also did not significantly improve any of the secondary end points.</p></sec><sec><title>Conclusions:</title><p>The PRIMA II trial (Can NT-ProBNP-Guided Therapy During Hospital Admission for Acute Decompensated Heart Failure Reduce Mortality and Readmissions?) demonstrates that the guidance of HF therapy to reach an NT-proBNP reduction of >30% after clinical stabilization did not improve 6-month outcomes.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.trialregister.nl</ext-link>. Unique identifier: NTR3279.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/16/1671
10.1161/CIRCULATIONAHA.117.029882
None

2
Circulation
Long-Term Potassium Monitoring and Dynamics in Heart Failure and Risk of Mortality
<sec><title>Background:</title><p>The prognostic value of long-term potassium monitoring and dynamics in heart failure has not been characterized completely. We sought to determine the association between serum potassium values collected at follow-up with all-cause mortality in a prospective and consecutive cohort of patients <strong><span style="color:yellowgreen">discharg</span></strong>ed from a previous acute heart failure admission.</p></sec><sec><title>Methods:</title><p>Serum potassium was measured at every physician-patient encounter, including hospital admissions and ambulatory settings. The multivariable-adjusted association of serum potassium with mortality was assessed by using comprehensive state-of-the-art regression methods that can accommodate time-dependent exposure modeling.</p></sec><sec><title>Results:</title><p>The study sample included 2164 patients with a total of 16 116 potassium observations. Mean potassium at <strong><span style="color:yellowgreen">discharg</span></strong>e was 4.3±0.48 mEq/L. Hypokalemia (<3.5 mEq/L), normokalemia (3.5–5.0 mEq/L), and hyperkalemia (>5 mEq/L) were observed at the index admission in 77 (3.6%), 1965 (90.8%), and 122 (5.6%) patients, respectively. At a median follow-up of 2.8 years (range, 0.03–12.8 years), 1090 patients died (50.4%). On a continuous scale, the multivariable-adjusted association of potassium values and mortality revealed a nonlinear association (U-shaped) with higher risk at both ends of its distribution (omnibus <i>P</i>=0.001). Likewise, the adjusted hazard ratios for hypokalemia and hyperkalemia, normokalemia as reference, were 2.35 (95% confidence interval, 1.40–3.93; <i>P</i>=0.001) and 1.55 (95% confidence interval, 1.11–2.16; <i>P</i>=0.011), respectively (omnibus <i>P</i>=0.0003). Furthermore, dynamic changes in potassium were independently associated with substantial differences in mortality risk. Potassium normalization was independently associated with lower mortality risk (<i>P</i>=0.001).</p></sec><sec><title>Conclusions:</title><p>Either modeled continuously or categorically, serum potassium levels during long-term monitoring were independently associated with mortality in patients with heart failure. Likewise, persistence of abnormal potassium levels was linked to a higher risk of death in comparison with patients who maintained or returned to normal values.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/13/1320
10.1161/CIRCULATIONAHA.117.030576
None

2
Circulation
Use of a Single Baseline Versus Multiyear 24-Hour Urine Collection for Estimation of Long-Term Sodium Intake and Associated Cardiovascular and Renal Risk
<sec><title>Background:</title><p>A decrease in sodium intake has been shown to lower blood pressure, but data from cohort studies on the association with cardiovascular and renal outcomes are inconsistent. In these studies, sodium intake was often estimated with a single baseline measurement, which may be inaccurate considering day-to-day changes in sodium intake and sodium excretion. We compared the effects of single versus repetitive follow-up 24-hour urine samples on the relation between sodium intake and long-term cardiorenal outcomes.</p></sec><sec><title>Methods:</title><p>We selected adult subjects with an estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate >60 mL/min/1.73m<sup>2</sup>, an outpatient 24-hour urine sample between 1998 and 1999, and at least 1 collection during a 17-year follow-up. Sodium intake was estimated with a single baseline collection and the average of samples collected during a 1-, 5-, and 15-year follow-up. We used Cox regression analysis and the landmark approach to investigate the relation between sodium intake and cardiovascular (cardiovascular events or mortality) and renal (end-stage renal disease: dialysis, transplantation, and/or >60% estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate decline, or mortality) outcomes.</p></sec><sec><title>Results:</title><p>We included 574 subjects with 9776 twenty-four–hour urine samples. Average age was 47 years, and 46% were male. Median follow-up was 16.2 years. Average 24-hour sodium excretion, ranging from 3.8 to 3.9 g (165–170 mmol), was equal among all methods (<i>P</i>=0.88). However, relative to a single baseline measurement, 50% of the subjects had a >0.8-g (>34-mmol) difference in sodium intake with long-term estimations. As a result, 45%, 49%, and 50% of all subjects switched between tertiles of sodium intake when the 1-, 5-, or 15-year average was used, respectively. Consequently, hazard ratios for cardiorenal outcome changed up to 85% with the use of sodium intake estimations from short-term (1-year) and long-term (5-year) follow-up instead of baseline estimations.</p></sec><sec><title>Conclusions:</title><p>Relative to a single baseline 24-hour sodium measurement, the use of subsequent 24-hour urine samples resulted in different estimations of an individual’s sodium intake, whereas population averages remained similar. This finding had significant consequences for the association between sodium intake and long-term cardiovascular and renal outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/10/917
10.1161/CIRCULATIONAHA.117.029028
None

2
Circulation
Hospital Variation in Time to Epinephrine for Nonshockable In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>For patients with in-hospital cardiac arrests attributable to nonshockable rhythms, delays in epinephrine administration beyond 5 minutes is associated with worse survival. However, the extent of hospital variation in delayed epinephrine administration and its effect on hospital-level outcomes is unknown.</p></sec><sec><title>Methods:</title><p>Within Get With The Guidelines-Resuscitation, we identified 103 932 adult patients (≥18 years) at 548 hospitals with an in-hospital cardiac arrest attributable to a nonshockable rhythm who received at least 1 dose of epinephrine between 2000 and 2014. We constructed 2-level hierarchical regression models to quantify hospital variation in rates of delayed epinephrine administration (>5 minutes) and its association with hospital rates of survival to <strong><span style="color:yellowgreen">discharg</span></strong>e and survival with functional recovery.</p></sec><sec><title>Results:</title><p>Overall, 13 213 (12.7%) patients had delays to epinephrine, and this rate varied markedly across hospitals (range, 0%–53.8%). The odds of delay in epinephrine administration were 58% higher at 1 randomly selected hospital in comparison with a similar patient at another randomly selected hospital (median odds ratio, 1.58; 95% confidence interval, 1.51–1.64). The median risk-standardized survival rate was 12.0% (range, 5.4%–31.9%), and the risk-standardized survival with functional recovery was 7.4% (range, 0.9%–30.8%). There was an inverse correlation between a hospital’s rate of delayed epinephrine administration and its risk-standardized rate of survival to <strong><span style="color:yellowgreen">discharg</span></strong>e (ρ=–0.22, <i>P</i><0.0001) and survival with functional recovery (ρ=–0.14, <i>P</i>=0.001). In comparison with a median survival rate of 12.9% (interquartile range, 11.1%–15.4%) at hospitals in the lowest quartile of epinephrine delay, risk-standardized survival was 16% lower at hospitals in the quartile with the highest rate of epinephrine delays (10.8%; interquartile range, 9.7%–12.7%).</p></sec><sec><title>Conclusions:</title><p>Delays in epinephrine administration following in-hospital cardiac arrest are common and variy across hospitals. Hospitals with high rates of delayed epinephrine administration had lower rates of overall survival for in-hospital cardiac arrest attributable to nonshockable rhythm. Further studies are needed to determine whether improving hospital performance on time to epinephrine administration, especially at hospitals with poor performance on this metric, will lead to improved outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2105
10.1161/CIRCULATIONAHA.116.025459
None

1
The Bone & Joint Journal
The evolution of fracture clinic design
<sec><title>Aims</title><p>Fracture clinics are often characterised by the referral of large   numbers of unselected patients with minor injuries not requiring   investigation or intervention, long waiting times and recurrent   unnecessary reviews. Our experience had been of an unsustainable   system and we implemented a ‘Trauma Triage Clinic’ (TTC) in order   to rationalise and regulate access to our fracture service. The   British Orthopaedic Association’s guidelines have required a prospective evaluation   of this change of practice, and we report our experience and results.</p></sec><sec><title>Patients and Methods</title><p>We review the management of all 12 069 patients referred to our   service in the calendar year 2014, with a minimum of one year follow-up   during the calendar year 2015. </p></sec><sec><title>Results</title><p>Following the successful introduction of the TTC, only 2836 patients   (23.5%) who would previously have been reviewed in the general fracture   clinic were brought back to such a clinic to be seen by a surgeon.   An additional 2366 patients (19.6%) were brought back to a sub-specialist   injury-specific clinic. Another 2776 patients (23%) with relatively   predictable injuries were reviewed by a nurse practitioner according   to an established protocol or specific consultant instructions.   A further 3222 patients (26.7%) were <strong><span style="color:yellowgreen">discharg</span></strong>ed from the service   without attending the clinic. No significant errors or omissions   occurred with the introduction of the TTC.</p></sec><sec><title>Conclusion</title><p>We have found that our TTC allows large numbers of referrals   to be reviewed and triaged safely and effectively, to the benefit   and satisfaction of patients, consultants, trainees, staff and the   organisation. This paper provides the first large-scale review of   the instigation of a TTC, and its effect, acceptability and safety.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:503–7.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/503
10.1302/0301-620X.99B4.BJJ-2016-0870.R1
None

1
The Bone & Joint Journal
‘Hot Joints’ infection protocol reduces unnecessary post-operative re-admissions following total hip and knee arthroplasty
<sec><title>Aims</title><p>To evaluate the effectiveness of an institutionally developed   algorithm for evaluation and diagnosis of prosthetic joint injection   and to determine the impact of this protocol on overall hospital   re-admissions.p</p></sec><sec><title>Patients and Methods</title><p>We retrospectively evaluated 2685 total hip arthroplasty (THA)   and total knee arthroplasty (TKA) patients prior to (1263) and following   (1422) the introduction of an infection detection protocol. The   protocol used conservative thresholds for C-reactive protein to   direct the medical attendant to aspirate the joint. The protocol   incorporated a clear set of laboratory and clinical criteria that   allowed a patient to be <strong><span style="color:yellowgreen">discharg</span></strong>ed home if all were met. Patients were   included if they presented to our emergency department within 120   days post-operatively with concerns for swelling, pain or infection   and were excluded if they had an unambiguous infection or if their   chief complaint was non-orthopaedic in nature.</p></sec><sec><title>Results</title><p>Concern for infection was the single most common (32%) reason   for presentation. A total of 296 patients made an emergency visit   and were included following THA or TKA. In the pre-protocol cohort,   11 of 27 patients were formally re-admitted to the hospital with   concern for infection but only five (45%) patients had actual infections   and received additional treatment. In comparison, in the post-protocol   cohort, 11 patients were admitted for suspected infection, nine   (82%) of whom were truly infected (p = 0.04). Sensitivity increased   from 83% to 100% and specificity increased from 71% to 96%. Implementation   of this protocol did not miss any infections.</p></sec><sec><title>Conclusion</title><p>A standardised protocol for evaluation of THA and TKA infections   significantly reduced unnecessary hospital re-admissions. The protocol   was both sensitive and specific and did not compromise quality of   care.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1603–10.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/12/1603
10.1302/0301-620X.99B12-BJJ-2017-0566.R1
None

1
The Bone & Joint Journal
Evaluation of fever in the immediate post-operative period following shoulder arthroplasty
<sec><title>Aims</title><p>To determine the incidence and timing of post-operative fevers   following shoulder arthroplasty and the resulting investigations   performed.</p></sec><sec><title>Patients and Methods</title><p>A retrospective review was conducted of all patients undergoing   shoulder arthroplasty over a nine-year period. The charts of all   patients with a post-operative fever (≥ 38.6°C) were reviewed and   the results of all investigations were analysed.</p></sec><sec><title>Results</title><p>A total of 2167 cases (in 1911 patients) were included of whom   92 (4.2%) had a documented fever. Obese cases had a significantly   greater risk for fever (relative risk 1.53; 95% confidence interval   1.02 to 2.32; p = 0.041). Investigations were performed in 43/92   cases (46.7%), with a diagnosis being made in six cases (6.6% of   the total, two of whom had their diagnosis made post-<strong><span style="color:yellowgreen">discharg</span></strong>e).</p></sec><sec><title>Conclusion</title><p>Around one in 25 cases develop a fever following shoulder arthroplasty;   most have no infective aetiology. These patients may be being over-investigated;   investigations should be performed in patients with persistent fever   or on those with an identifiable source of infection on clinical   examination.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1515–19.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1515
10.1302/0301-620X.99B11.BJJ-2017-0469.R1
None

1
The Bone & Joint Journal
Proximal femoral resection without post-operative traction for the painful dislocated hip in young patients with cerebral palsy
<p>Proximal femoral resection (PFR) is a proven   pain-relieving procedure for the management of patients with severe cerebral   palsy and a painful displaced hip. Previous authors have recommended   post-operative traction or immobilisation to prevent a recurrence   of pain due to proximal migration of the femoral stump. We present   a series of 79 PFRs in 63 patients, age 14.7 years (10 to 26; 35   male, 28 female), none of whom had post-operative traction or immobilisation.</p><p>A total of 71 hips (89.6%) were reported to be pain free or to   have mild pain following surgery. Four children underwent further   resection for persistent pain; of these, three had successful resolution   of pain and one had no benefit. A total of 16 hips (20.2%) showed   radiographic evidence of heterotopic ossification, all of which   had formed within one year of surgery. Four patients had a wound   infection, one of which needed debridement; all recovered fully.   A total of 59 patients (94%) reported improvements in seating and   hygiene.</p><p>The results are as good as or better than the historical results   of using traction or immobilisation. We recommend that following   PFR, children can be managed without traction or immobilisation,   and can be <strong><span style="color:yellowgreen">discharg</span></strong>ed earlier and with fewer complications. However,   care should be taken with severely dystonic patients, in whom more   extensive femoral resection should be considered in combination   with management of the increased tone.</p><p>Cite this article: <i>Bone Joint J</i> 2014; 96-B:701–6.</p>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/96-B/5/701
10.1302/0301-620X.96B5.32963
None

1
The Bone & Joint Journal
An interobserver reliability comparison between the Orthopaedic Trauma Association’s open fracture classification and the Gustilo and Anderson classification
<sec><title>Aims</title><p>To evaluate interobserver reliability of the Orthopaedic Trauma   Association’s open fracture classification system (OTA-OFC).</p></sec><sec><title>Patients and Methods</title><p>Patients of any age with a first presentation of an open long   bone fracture were included. Standard radiographs, wound photographs,   and a short clinical description were given to eight orthopaedic   surgeons, who independently evaluated the injury using both the   Gustilo and Anderson (GA) and OTA-OFC classifications. The responses   were compared for variability using Cohen’s kappa.</p></sec><sec><title>Results</title><p>The overall interobserver agreement was ĸ = 0.44 for the GA classification   and ĸ = 0.49 for OTA-OFC, which reflects moderate agreement (0.41   to 0.60) for both classifications. The agreement in the five categories   of OTA-OFC was: for skin, ĸ = 0.55 (moderate); for muscle, ĸ = 0.44   (moderate); for arterial injury, ĸ = 0.74 (substantial); for <strong><span style="color:yellowgreen">contamin</span></strong>ation, ĸ =   0.35 (fair); and for bone loss, ĸ = 0.41 (moderate).</p></sec><sec><title>Conclusion</title><p>Although the OTA-OFC, with similar interobserver agreement to   GA, offers a more detailed description of open fractures, further   development may be needed to make it a reliable and robust tool.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:242–6.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/242
10.1302/0301-620X.100B2.BJJ-2017-0367.R1
None

1
The Bone & Joint Journal
Cost-effective peri-operative pain management
<sec><title>Aims</title><p>The aim of this study was to determine the optimal regimen for   the management of pain following total knee arthroplasty (TKA) by   comparing the outcomes and cost-effectiveness of different protocols   implemented at a large, urban, academic medical centre.</p></sec><sec><title>Patients and Methods</title><p>Between September 2013 and September 2015, we used a series of   modifications to our standard regimen for the management of pain   after TKA. In May 2014, there was a department-wide transition from   protocols focused on femoral nerve blocks (FNB) to periarticular   injections of liposomal bupivacaine. In February 2015, patient-controlled analgesia   (PCA) was removed from the protocol while continuing liposomal bupivacaine   injections. Quality measures and hospital costs were compared between   the three protocols.</p></sec><sec><title>Results</title><p>The cohort being treated with PCA-less liposomal bupivacaine   injections had a significantly higher percentage of patients who   were <strong><span style="color:yellowgreen">discharg</span></strong>ed to their home (p = 0.010) and a significantly shorter   length of stay (p < 0.001). Patient-reported Hospital Consumer   Assessment of Healthcare Providers and Systems (HCAHPS) scores relating   to pain being “well-controlled” and “overall pain management” also   favoured this cohort (p = 0.214 and p = 0.463, respectively), in   which cost was significantly lower compared with the other two cohorts   (p = 0.005).</p></sec><sec><title>Conclusion</title><p>The replacement of FNBs injections and the removal of PCAs, both   of which are known to be associated with high rates of adverse outcomes,   and the addition of liposomal bupivacaine periarticular injections   to a multimodal pain regimen, led to improvements in many quality   measures, HCAHPS pain scores, and cost-effectiveness.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B(1   Supple A):55–61.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1_Supple_A/55
10.1302/0301-620X.100B1.BJJ-2017-0549.R1
None

1
Disease Models & Mechanisms
Leptin induces muscle wasting in a zebrafish <i>kras</i>-driven hepatocellular carcinoma (HCC) model
<p><bold>Summary:</bold> Through a zebrafish model, this study demonstrates that leptin plays an important role in cancer-induced muscle <strong><span style="color:yellowgreen">wast</span></strong>ing and that the leptin pathway may be a therapeutic target in cancer cachexia.</p>
http://dmm.biologists.org/cgi/content/abstract/12/2/dmm038240
10.1242/dmm.038240
['zebrafish']

1
Disease Models & Mechanisms
Inorganic arsenic causes fatty liver and interacts with ethanol to cause alcoholic liver disease in zebrafish
<p><bold>Summary:</bold> Using zebrafish, the authors show that exposure to a common environmental <strong><span style="color:yellowgreen">contamin</span></strong>ant, inorganic arsenic, increases the risk of alcoholic liver disease.</p>
http://dmm.biologists.org/cgi/content/abstract/11/2/dmm031575
10.1242/dmm.031575
['zebrafish']

1
Disease Models & Mechanisms
Dynamic changes in the mouse skeletal muscle proteome during denervation-induced atrophy
<p><bold>Summary:</bold> Comprehensive proteomic profiling of protein expression, synthesis and ubiquitination during skeletal muscle atrophy reveals that complex regulatory networks are activated during muscle <strong><span style="color:yellowgreen">wast</span></strong>ing.</p>
http://dmm.biologists.org/cgi/content/abstract/10/7/881
10.1242/dmm.028910
None

1
Development
Pollen differentiation as well as pollen tube guidance and discharge are independent of the presence of gametes
<p><bold>Summary:</bold> Cell biological analyses in <i>Arabidopsis</i> show that the vegetative cell differentiates without the presence of the actual gametes, and is solely sufficient for pollen tube germination, guidance, ovule penetration and pollen tube <strong><span style="color:yellowgreen">discharg</span></strong>e.</p>
http://dev.biologists.org/cgi/content/abstract/145/1/dev152645
10.1242/dev.152645
['Arabidopsis']

1
Circulation
How Do Resuscitation Teams at Top-Performing Hospitals for In-Hospital Cardiac Arrest Succeed?
<sec><title>Background:</title><p>In-hospital cardiac arrest (IHCA) is common, and outcomes vary substantially across US hospitals, but reasons for these differences are largely unknown. We set out to better understand how top-performing hospitals organize their resuscitation teams to achieve high survival rates for IHCA.</p></sec><sec><title>Methods:</title><p>We calculated risk-standardized IHCA survival to <strong><span style="color:yellowgreen">discharg</span></strong>e rates across American Heart Association Get With The Guidelines–Resuscitation registry hospitals between 2012 and 2014. We identified geographically and academically diverse hospitals in the top, middle, and bottom quartiles of survival for IHCA and performed a qualitative study that included site visits with in-depth interviews of clinical and administrative staff at 9 hospitals. With the use of thematic analysis, data were analyzed to identify salient themes of perceived performance by informants.</p></sec><sec><title>Results:</title><p>Across 9 hospitals, we interviewed 158 individuals from multiple disciplines including physicians (17.1%), nurses (45.6%), other clinical staff (17.1%), and administration (20.3%). We identified 4 broad themes related to resuscitation teams: (1) team design, (2) team composition and roles, (3) communication and leadership during IHCA, and (4) training and education. Resuscitation teams at top-performing hospitals demonstrated the following features: dedicated or designated resuscitation teams; participation of diverse disciplines as team members during IHCA; clear roles and responsibilities of team members; better communication and leadership during IHCA; and in-depth mock codes.</p></sec><sec><title>Conclusions:</title><p>Resuscitation teams at hospitals with high IHCA survival differ from non–top-performing hospitals. Our findings suggest core elements of successful resuscitation teams that are associated with better outcomes and form the basis for future work to improve IHCA.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/2/154
10.1161/CIRCULATIONAHA.118.033674
None

1
Circulation
Duct Stenting Versus Modified Blalock-Taussig Shunt in Neonates With Duct-Dependent Pulmonary Blood Flow
<sec><title>Background:</title><p>Infants born with cardiac abnormalities causing dependence on the arterial duct for pulmonary blood flow are often palliated with a shunt usually between the subclavian artery and either pulmonary artery. A so-called modified Blalock-Taussig shunt allows progress through early life to an age and weight at which repair or further more stable palliation can be safely achieved. Modified Blalock-Taussig shunts continue to present concern for postprocedural instability and early mortality such that other alternatives continue to be explored. Duct stenting (DS) is emerging as one such alternative with potential for greater early stability and improved survival.</p></sec><sec><title>Methods:</title><p>The purpose of this study was to compare postprocedural outcomes and survival to next-stage palliative or reparative surgery between patients undergoing a modified Blalock-Taussig shunt or a DS in infants with duct-dependent pulmonary blood flow. All patients undergoing cardiac surgery and congenital interventions in the United Kingdom are prospectively recruited to an externally validated national outcome audit. From this audit, participating UK centers identified infants <30 days of age undergoing either a Blalock-Taussig shunt or a DS for cardiac conditions with duct-dependent pulmonary blood flow between January 2012 and December 31, 2015. One hundred seventy-one patients underwent a modified Blalock-Taussig shunt, and in 83 patients, DS was attempted. Primary and secondary outcomes of survival and need for extracorporeal support were analyzed with multivariable logistic regression. Longer-term mortality before repair and reintervention were analyzed with Cox proportional hazards regression. All multivariable analyses accommodated a propensity score to balance patient characteristics between the groups.</p></sec><sec><title>Results:</title><p>There was an early (to <strong><span style="color:yellowgreen">discharg</span></strong>e) survival advantage for infants before next-stage surgery in the DS group (odds ratio, 4.24; 95% confidence interval, 1.37–13.14; <i>P</i>=0.012). There was also a difference in the need for postprocedural extracorporeal support in favor of the DS group (odds ratio, 0.22; 95% confidence interval, 0.05–1.05; <i>P</i>=0.058). Longer-term survival outcomes showed a reduced risk of death before repair in the DS group (hazard ratio, 0.25; 95% confidence interval, 0.07–0.85; <i>P</i>=0.026) but a slightly increased risk of reintervention (hazard ratio, 1.50; 95% confidence interval, 0.85–2.64; <i>P</i>=0.165).</p></sec><sec><title>Conclusions:</title><p>DS is emerging as a preferred alternative to a surgical shunt for neonatal palliation with evidence for greater postprocedural stability and improved patient survival to destination surgical treatment.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/6/581
10.1161/CIRCULATIONAHA.117.028972
None

1
Circulation
0/1-Hour Triage Algorithm for Myocardial Infarction in Patients With Renal Dysfunction
<sec><title>Background:</title><p>The European Society of Cardiology recommends a 0/1-hour algorithm for rapid rule-out and rule-in of non–ST-segment elevation myocardial infarction using high-sensitivity cardiac troponin (hs-cTn) concentrations irrespective of renal function. Because patients with renal dysfunction (RD) frequently present with increased hs-cTn concentrations even in the absence of non–ST-segment elevation myocardial infarction, concern has been raised regarding the performance of the 0/1-hour algorithm in RD.</p></sec><sec><title>Methods:</title><p>In a prospective multicenter diagnostic study enrolling unselected patients presenting with suspected non–ST-segment elevation myocardial infarction to the emergency department, we assessed the diagnostic performance of the European Society of Cardiology 0/1-hour algorithm using hs-cTnT and hs-cTnI in patients with RD, defined as an estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate <60 mL/min/1.73 m<sup>2</sup>, and compared it to patients with normal renal function. The final diagnosis was centrally adjudicated by 2 independent cardiologists using all available information, including cardiac imaging. Safety was quantified as sensitivity in the rule-out zone, accuracy as the specificity in the rule-in zone, and efficacy as the proportion of the overall cohort assigned to either rule-out or rule-in based on the 0- and 1-hour sample.</p></sec><sec><title>Results:</title><p>Among 3254 patients, RD was present in 487 patients (15%). The prevalence of non–ST-segment elevation myocardial infarction was substantially higher in patients with RD compared with patients with normal renal function (31% versus 13%, <i>P</i><0.001). Using hs-cTnT, patients with RD had comparable sensitivity of rule-out (100.0% [95% confidence interval {CI}, 97.6–100.0] versus 99.2% [95% CI, 97.6–99.8]; <i>P</i>=0.559), lower specificity of rule-in (88.7% [95% CI, 84.8–91.9] versus 96.5% [95% CI, 95.7–97.2]; <i>P</i><0.001), and lower overall efficacy (51% versus 81%, <i>P</i><0.001), mainly driven by a much lower percentage of patients eligible for rule-out (18% versus 68%, <i>P</i><0.001) compared with patients with normal renal function. Using hs-cTnI, patients with RD had comparable sensitivity of rule-out (98.6% [95% CI, 95.0–99.8] versus 98.5% [95% CI, 96.5–99.5]; <i>P</i>=1.0), lower specificity of rule-in (84.4% [95% CI, 79.9–88.3] versus 91.7% [95% CI, 90.5–92.9]; <i>P</i><0.001), and lower overall efficacy (54% versus 76%, <i>P</i><0.001; proportion ruled out, 18% versus 58%, <i>P</i><0.001) compared with patients with normal renal function.</p></sec><sec><title>Conclusions:</title><p>In patients with RD, the safety of the European Society of Cardiology 0/1-hour algorithm is high, but specificity of rule-in and overall efficacy are decreased. Modifications of the rule-in and rule-out thresholds did not improve the safety or overall efficacy of the 0/1-hour algorithm.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00470587.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/5/436
10.1161/CIRCULATIONAHA.117.028901
None

1
Circulation
High-Sensitivity Cardiac Troponin and the Risk Stratification of Patients With Renal Impairment Presenting With Suspected Acute Coronary Syndrome
<sec><title>Background:</title><p>High-sensitivity cardiac troponin testing may improve the risk stratification and diagnosis of myocardial infarction, but concentrations can be challenging to interpret in patients with renal impairment, and the effectiveness of testing in this group is uncertain.</p></sec><sec><title>Methods:</title><p>In a prospective multicenter study of consecutive patients with suspected acute coronary syndrome, we evaluated the performance of high-sensitivity cardiac troponin I in those with and without renal impairment (estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate <60mL/min/1.73m<sup>2</sup>). The negative predictive value and sensitivity of troponin concentrations below the risk stratification threshold (5 ng/L) at presentation were reported for a primary outcome of index type 1 myocardial infarction, or type 1 myocardial infarction or cardiac death at 30 days. The positive predictive value and specificity at the 99th centile diagnostic threshold (16 ng/L in women, 34 ng/L in men) was determined for index type 1 myocardial infarction. Subsequent type 1 myocardial infarction and cardiac death were reported at 1 year.</p></sec><sec><title>Results:</title><p>Of 4726 patients identified, 904 (19%) had renal impairment. Troponin concentrations <5 ng/L at presentation identified 17% of patients with renal impairment as low risk for the primary outcome (negative predictive value, 98.4%; 95% confidence interval [CI], 96.0%–99.7%; sensitivity 98.9%; 95%CI, 97.5%–99.9%), in comparison with 56% without renal impairment (<i>P</i><0.001) with similar performance (negative predictive value, 99.7%; 95% CI, 99.4%–99.9%; sensitivity 98.4%; 95% CI, 97.2%–99.4%). The positive predictive value and specificity at the 99th centile were lower in patients with renal impairment at 50.0% (95% CI, 45.2%–54.8%) and 70.9% (95% CI, 67.5%–74.2%), respectively, in comparison with 62.4% (95% CI, 58.8%–65.9%) and 92.1% (95% CI, 91.2%–93.0%) in those without. At 1 year, patients with troponin concentrations >99th centile and renal impairment were at greater risk of subsequent myocardial infarction or cardiac death than those with normal renal function (24% versus 10%; adjusted hazard ratio, 2.19; 95% CI, 1.54–3.11).</p></sec><sec><title>Conclusions:</title><p>In suspected acute coronary syndrome, high-sensitivity cardiac troponin identified fewer patients with renal impairment as low risk and more as high risk, but with lower specificity for type 1 myocardial infarction. Irrespective of diagnosis, patients with renal impairment and elevated cardiac troponin concentrations had a 2-fold greater risk of a major cardiac event than those with normal renal function, and should be considered for further investigation and treatment.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01852123.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/5/425
10.1161/CIRCULATIONAHA.117.030320
None

1
Circulation
Canagliflozin for Primary and Secondary Prevention of Cardiovascular Events
<sec><title>Background:</title><p>Canagliflozin is a sodium glucose cotransporter 2 inhibitor that significantly reduces the composite of cardiovascular death, nonfatal myocardial infarction, or nonfatal stroke in patients with type 2 diabetes mellitus and elevated cardiovascular risk. The comparative effects among participants with and without a history of cardiovascular disease (secondary versus primary prevention) were prespecified for evaluation.</p></sec><sec><title>Methods:</title><p>The CANVAS Program (Canagliflozin Cardiovascular Assessment Study) randomly assigned 10 142 participants with type 2 diabetes mellitus to canagliflozin or placebo. The primary prevention cohort comprised individuals ≥50 years of age with ≥2 risk factors for cardiovascular events but with no prior cardiovascular event, and the secondary prevention cohort comprised individuals ≥30 years of age with a prior cardiovascular event. The primary end point was a composite of cardiovascular death, nonfatal myocardial infarction, or nonfatal stroke. Secondary outcomes included heart failure hospitalization and a renal composite (40% reduction in estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate, renal replacement therapy, or renal death).</p></sec><sec><title>Results:</title><p>Primary prevention participants (N=3486; 34%) were younger (63 versus 64 years of age), were more often female (45% versus 31%), and had a longer duration of diabetes mellitus (14 versus 13 years) compared with secondary prevention participants (N=6656; 66%). The primary end point event rate was higher in the secondary prevention group compared with the primary prevention group (36.9 versus 15.7/1000 patient-years, <i>P</i><0.001). In the total cohort, the primary end point was reduced with canagliflozin compared with placebo (26.9 versus 31.5/1000 patient-years; hazard ratio [HR], 0.86; 95% confidence interval [CI], 0.75–0.97; <i>P</i><0.001 for noninferiority, <i>P</i>=0.02 for superiority) with no statistical evidence of heterogeneity (interaction <i>P</i> value=0.18) between the primary (HR, 0.98; 95% CI, 0.74–1.30) and secondary prevention (HR, 0.82; 95% CI, 0.72–0.95) cohorts. Renal outcomes (HR, 0.59; 95% CI, 0.44–0.79 versus HR, 0.63; 95% CI, 0.39–1.02; interaction <i>P</i> value=0.73) and heart failure hospitalization (HR, 0.68; 95% CI, 0.51–0.90 versus HR, 0.64; 95% CI, 0.35–1.15; interaction <i>P</i> value=0.91) were similarly reduced in the secondary and primary prevention cohorts, respectively. Lower extremity amputations were similarly increased in the secondary and primary prevention cohorts (HR, 2.07; 95% CI, 1.43–3.00 versus HR, 1.52; 95% CI, 0.70–3.29; interaction <i>P</i> value=0.63).</p></sec><sec><title>Conclusions:</title><p>Patients with type 2 diabetes mellitus and prior cardiovascular events had higher rates of cardiovascular outcomes compared with the primary prevention patients. Canagliflozin reduced cardiovascular and renal outcomes with no statistical evidence of heterogeneity of the treatment effect across the primary and secondary prevention groups. Additional studies will provide further insights into the effects of canagliflozin in these patient populations.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifiers: NCT01032629 and NCT01989754.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/4/323
10.1161/CIRCULATIONAHA.117.032038
None

1
Circulation
Empagliflozin and Clinical Outcomes in Patients With Type 2 Diabetes Mellitus, Established Cardiovascular Disease, and Chronic Kidney Disease
<sec><title>Background:</title><p>Empagliflozin, a sodium-glucose cotransporter 2 inhibitor, reduced cardiovascular morbidity and mortality in patients with type 2 diabetes mellitus and established cardiovascular disease in the EMPA-REG OUTCOME trial (Empagliflozin Cardiovascular Outcome Event Trial in Type 2 Diabetes Mellitus Patients). Urinary glucose excretion with empagliflozin decreases with declining renal function, resulting in less potency for glucose lowering in patients with kidney disease. We investigated the effects of empagliflozin on clinical outcomes in patients with type 2 diabetes mellitus, established cardiovascular disease, and chronic kidney disease.</p></sec><sec><title>Methods:</title><p>Patients with type 2 diabetes mellitus, established cardiovascular disease, and estimated glomerular <strong><span style="color:yellowgreen">filtrat</span></strong>ion rate (eGFR) ≥30 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> at screening were randomized to receive empagliflozin 10 mg, empagliflozin 25 mg, or placebo once daily in addition to standard of care. We analyzed cardiovascular death, hospitalization for heart failure, all-cause hospitalization, and all-cause mortality in patients with prevalent kidney disease (defined as eGFR <60 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> and/or urine albumin-creatinine ratio >300 mg/g) at baseline. Additional analyses were performed in subgroups by baseline eGFR (<45, 45–<60, 60–<90, ≥90 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup>) and baseline urine albumin-creatinine ratio (>300, 30–≤300, <30 mg/g).</p></sec><sec><title>Results:</title><p>Of 7020 patients treated, 2250 patients had prevalent kidney disease at baseline, of whom 67% had a diagnosis of type 2 diabetes mellitus for >10 years, 58% were receiving insulin, and 84% were taking angiotensin-converting enzyme inhibitors or angiotensin receptor blockers. In patients with prevalent kidney disease at baseline, empagliflozin reduced the risk of cardiovascular death by 29% compared with placebo (hazard ratio [HR], 0.71; 95% confidence interval [CI], 0.52–0.98), the risk of all-cause mortality by 24% (HR, 0.76; 95% CI, 0.59–0.99), the risk of hospitalization for heart failure by 39% (HR, 0.61; 95% CI, 0.42–0.87), and the risk of all-cause hospitalization by 19% (HR, 0.81; 95% CI, 0.72–0.92). Effects of empagliflozin on these outcomes were consistent across categories of eGFR and urine albumin-creatinine ratio at baseline and across the 2 doses studied. The adverse event profile of empagliflozin in patients with eGFR <60 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> was consistent with the overall trial population.</p></sec><sec><title>Conclusions:</title><p>Empagliflozin improved clinical outcomes and reduced mortality in vulnerable patients with type 2 diabetes mellitus, established cardiovascular disease, and chronic kidney disease.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01131676.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/2/119
10.1161/CIRCULATIONAHA.117.028268
None

1
Circulation
Hemodynamic and Echocardiographic Comparison of the Lotus and CoreValve Transcatheter Aortic Valves in Patients With High and Extreme Surgical Risk
<sec><title>Background:</title><p>Comparative echocardiographic data on transcatheter aortic valve replacement systems from randomized trials are limited. The REPRISE III trial (Repositionable Percutaneous Replacement of Stenotic Aortic Valve through Implantation of Lotus Valve System – Randomized Clinical Evaluation) is a multicenter, randomized comparison of a mechanically expanded (Lotus) versus self-expanding (CoreValve) transcatheter aortic valve replacement device. This analysis rigorously assesses Doppler-derived valve hemodynamics and the impact on outcomes at 1 year in patients with extreme/high surgical risk treated with Lotus and CoreValve from REPRISE III.</p></sec><sec><title>Methods:</title><p>REPRISE III includes patients with extreme- and high-risk aortic stenosis. Patients were enrolled at 55 centers. All transthoracic echocardiograms with Doppler were obtained following a standard protocol up to 12 months postimplant and analyzed by a core laboratory. Valve size, mean gradient, aortic valve area, and Doppler velocity index and their impact on clinical outcomes are reported. Additional parameters including paravalvular leak were evaluated using a multiparametric approach.</p></sec><sec><title>Results:</title><p>A total of 912 patients were randomly assigned (2:1 ratio; 607 Lotus:305 CoreValve). Median age was 84 years, 51% of the patients were women, and the Society of Thoracic Surgeons score was 6.8±4.1. CoreValve demonstrated lower gradients and larger aortic valve area and Doppler velocity index than Lotus at <strong><span style="color:yellowgreen">discharg</span></strong>e; the difference decreased in subsequent follow-up up to a year (all <i>P</i><0.01). Lotus had lower rates of paravalvular leak that persisted over time (<i>P</i><0.05). Similar outcomes were seen when comparing each valve type by size group (small, medium, large). The hemodynamic differences between valves did not translate into worse clinical outcomes. All-cause mortality was not different between the 2 groups in any of the 3 valve sizes. When comparing patients with normal valve gradients (<20 mm Hg, n=780) with those with abnormal gradients (>20 mm Hg, n=48) in the entire patient population, all-cause mortality was not different. This was also not significant when evaluating each valve type separately. Similarly, there were no differences for aortic valve area >1.1 cm<sup>2</sup> or <1.1 cm<sup>2</sup> and for Doppler velocity index >0.35 or <0.35 (all <i>P</i>=not significant).</p></sec><sec><title>Conclusions:</title><p>Lotus had significantly greater freedom from moderate or severe paravalvular leak and smaller valve area and higher gradients than CoreValve. The hemodynamic differences were not associated with any clinical differences in the composite end point of mortality, disabling stroke, and moderate paravalvular leak or with quality of life at 1 year of follow-up.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02202434.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/24/2557
10.1161/CIRCULATIONAHA.118.034129
['Lotus']

1
Circulation
Hospital Readmission After Perioperative Acute Myocardial Infarction Associated With Noncardiac Surgery
<sec><title>Background:</title><p>Acute myocardial infarction (AMI) is a major cardiovascular complication of noncardiac surgery. We aimed to evaluate the frequency, causes, and outcomes of 30-day hospital readmission after perioperative AMI.</p></sec><sec><title>Methods:</title><p>Patients who were diagnosed with AMI during hospitalization for major noncardiac surgery were identified using the 2014 US Nationwide Readmission Database. Rates, causes, and costs of 30-day readmissions after noncardiac surgery with and without perioperative AMI were identified.</p></sec><sec><title>Results:</title><p>Among 3 807 357 hospitalizations for major noncardiac surgery, 8085 patients with perioperative AMI were identified. A total of 1135 patients (14.0%) with perioperative AMI died in-hospital during the index admission. Survivors of perioperative AMI were more likely to be readmitted within 30 days than surgical patients without perioperative AMI (19.1% versus 6.5%, <i>P</i><0.001). The most common indications for 30-day rehospitalization were management of infectious complications (30.0%), cardiovascular complications (25.3%), and bleeding (10.4%). In-hospital mortality during hospital readmission in the first 30 days after perioperative AMI was 11.3%. At 6 months, the risk of death was 17.6% and ≥1 hospital readmission was 36.2%.</p></sec><sec><title>Conclusions:</title><p>Among patients undergoing noncardiac surgery who develop a perioperative MI, ≈1 in 3 suffer from in-hospital death or hospital readmission in the first 30 days after <strong><span style="color:yellowgreen">discharg</span></strong>e. Strategies to improve outcomes of surgical patients early after perioperative AMI are warranted.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/22/2332
10.1161/CIRCULATIONAHA.117.032086
None

1
Circulation
Association Between Prompt Defibrillation and Epinephrine Treatment With Long-Term Survival After In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Prior studies have reported higher in-hospital survival with prompt defibrillation and epinephrine treatment in patients with in-hospital cardiac arrest (IHCA). Whether this survival benefit persists after <strong><span style="color:yellowgreen">discharg</span></strong>e is unknown.</p></sec><sec><title>Methods:</title><p>We linked data from a national IHCA registry with Medicare files and identified 36 961 patients ≥65 years of age with an IHCA at 517 hospitals between 2000 and 2011. Patients with IHCA caused by pulseless ventricular tachycardia or ventricular fibrillation were stratified by prompt (≤2 minutes) versus delayed (>2 minutes) defibrillation, whereas patients with IHCA caused by asystole or pulseless electric activity were stratified by prompt (≤5 minutes) versus delayed (>5 minutes) epinephrine treatment. The association between prompt treatment and long-term survival for each rhythm type was assessed with multivariable hierarchical modified Poisson regression models.</p></sec><sec><title>Results:</title><p>Of 8119 patients with an IHCA caused by ventricular tachycardia or ventricular fibrillation, the rate of 1-year survival was higher in those treated with prompt defibrillation than with delayed defibrillation (25.7% [1466 of 5714] versus 15.5% [373 of 2405]; adjusted relative risk [RR], 1.49; 95% confidence interval [CI] 1.32–1.69; <i>P</i><0.0001). This survival advantage persisted at 3 years (19.1% versus 11.0%; adjusted RR, 1.45; 95% CI, 1.23–1.69; <i>P</i><0.0001) and at 5 years (14.7% versus 7.9%; adjusted RR, 1.50; 95% CI, 1.22–1.83; <i>P</i><0.0001). Of 28 842 patients with an IHCA caused by asystole/pulseless electric activity, the rate of 1-year survival with prompt epinephrine treatment was higher than with delayed treatment (5.4% [1341 of 24 885] versus 4.3% [168 of 3957]; adjusted RR, 1.20; 95% CI, 1.02–1.41; <i>P</i>=0.02), but this survival benefit was no longer present at 3 years (3.5% versus 2.9%; adjusted RR, 1.17; 95% CI, 0.95–1.45; <i>P</i>=0.15) and at 5 years (2.3% versus 1.9%; adjusted RR, 1.18; 95% CI, 0.88–1.58; <i>P</i>=0.27).</p></sec><sec><title>Conclusions:</title><p>Prompt defibrillation for IHCA caused by ventricular tachycardia or ventricular fibrillation was associated with higher rates of long-term survival throughout 5 years of follow-up, whereas prompt epinephrine treatment for asystole/pulseless electric activity was associated with greater survival at 1 year but not at 3 or 5 years. By quantifying the greater survival associated with timely defibrillation and epinephrine administration, these findings provide important insights into the durability of survival benefits for 2 process-of-care measures in current resuscitation guidelines.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/19/2041
10.1161/CIRCULATIONAHA.117.030488
None

1
Circulation
Association Between Diastolic Blood Pressure During Pediatric In-Hospital Cardiopulmonary Resuscitation and Survival
<sec><title>Background:</title><p>On the basis of laboratory cardiopulmonary resuscitation (CPR) investigations and limited adult data demonstrating that survival depends on attaining adequate arterial diastolic blood pressure (DBP) during CPR, the American Heart Association recommends using blood pressure to guide pediatric CPR. However, evidence-based blood pressure targets during pediatric CPR remain an important knowledge gap for CPR guidelines.</p></sec><sec><title>Methods:</title><p>All children ≥37 weeks’ gestation and <19 years old in Collaborative Pediatric Critical Care Research Network intensive care units with chest compressions for ≥1 minute and invasive arterial blood pressure monitoring before and during CPR between July 1, 2013, and June 31, 2016, were included. Mean DBP during CPR and Utstein-style standardized cardiac arrest data were collected. The hypothesis was that DBP ≥25 mm Hg during CPR in infants and ≥30 mm Hg in children ≥1 year old would be associated with survival. Primary outcome was survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e. Secondary outcome was survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e with favorable neurological outcome, defined as Pediatric Cerebral Performance Categories 1 to 3 or no worse than prearrest baseline. Multivariable Poisson regression models with robust error estimates were used to estimate the relative risk of outcomes.</p></sec><sec><title>Results:</title><p>Blinded investigators analyzed blood pressure waveforms during CPR from 164 children, including 60% <1 year old, 60% with congenital heart disease, and 54% after cardiac surgery. The immediate cause of arrest was hypotension in 67%, respiratory decompensation in 44%, and arrhythmia in 19%. Median duration of CPR was 8 minutes (quartiles, 3 and 27 minutes). Ninety percent survived the event, 68% with return of spontaneous circulation and 22% by extracorporeal life support. Forty-seven percent survived to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e, and 43% survived to <strong><span style="color:yellowgreen">discharg</span></strong>e with favorable neurological outcome. Maintaining mean DBP ≥25 mm Hg in infants and ≥30 mm Hg in children ≥1 year old occurred in 101 of 164 children (62%) and was associated with survival (adjusted relative risk, 1.7; 95% confidence interval, 1.2–2.6; <i>P</i>=0.007) and survival with favorable neurological outcome (adjusted relative risk, 1.6; 95% confidence interval, 1.1–2.5; <i>P</i>=0.02).</p></sec><sec><title>Conclusions:</title><p>These data demonstrate that mean DBP ≥25 mm Hg during CPR in infants and ≥30 mm Hg in children ≥1 year old was associated with greater likelihood of survival to hospital <strong><span style="color:yellowgreen">discharg</span></strong>e and survival with favorable neurological outcome.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/17/1784
10.1161/CIRCULATIONAHA.117.032270
None

