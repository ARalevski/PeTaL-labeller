2
The Bone & Joint Journal
Low-intensity pulsed ultrasound does not influence bone healing by distraction osteogenesis
<sec><title>Aims</title><p>The aim of this double-blind prospective randomised controlled   trial was to assess whether low intensity pulsed ultrasound (LIPUS)   accelerated or enhanced the rate of bone healing in adult patients   undergoing distraction osteogenesis.</p></sec><sec><title>Patients and Methods</title><p>A total of 62 adult patients undergoing limb lengthening or bone   transport by distraction osteogenesis were randomised to treatment   with either an active (n = 32) or a placebo (n = 30) ultrasound   device. A standardised corticotomy was performed in the proximal   tibial metaphysis and a circular Ilizarov frame was used in all   patients. The rate of distraction was also standardised. The primary   outcome measure was the time to removal of the frame after adjusting   for the length of distraction in days/cm for both the per protocol   (PP) and the intention-to-treat (ITT) groups. The assessor was blinded   to the form of treatment. A secondary outcome was to identify <strong><span style="color:yellowgreen">covari</span></strong>ates affecting   the time to removal of the frame.</p></sec><sec><title>Results</title><p>There was no difference in the time to removal of the frame between   the PP (difference in favour of the control group was 10.1 days/cm,   95% confidence interval (CI) -3.2 to 23.4, p = 0.054) or ITT (difference   5.0 days/cm, 95% CI -8.2 to 18.21, p = 0.226) groups. The smoking   status was the only <strong><span style="color:yellowgreen">covari</span></strong>ate which increased the time to removal   of the frame (hazard ratio 0.47, 95% CI 0.22 to 0.97, p = 0.042).</p></sec><sec><title>Conclusion</title><p>LIPUS does not influence the rate of bone healing in patients   who undergo distraction osteogenesis. Smoking may influence bone   healing. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:494–502.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/494
10.1302/0301-620X.99B4.BJJ-2016-0559.R1
None

2
Circulation
Effect of Intensive Blood Pressure Lowering on Left Ventricular Hypertrophy in Patients With Hypertension
<sec><title>Background:</title><p>It is currently unknown whether intensive blood pressure (BP) lowering beyond that recommended would lead to more lowering of the risk of left ventricular hypertrophy (LVH) in patients with hypertension and whether reducing the risk of LVH explains the reported cardiovascular disease (CVD) benefits of intensive BP lowering in this population.</p></sec><sec><title>Methods:</title><p>This analysis included 8164 participants (mean age, 67.9 years; 35.3% women; 31.2% blacks) with hypertension but no diabetes mellitus from the SPRINT trial (Systolic Blood Pressure Intervention Trial): 4086 randomly assigned to intensive BP lowering (target SBP <120 mm Hg) and 4078 assigned to standard BP lowering (target SBP <140 mm Hg). Progression and regression of LVH as defined by Cornell voltage criteria derived from standard 12-lead ECGs recorded at baseline and biannually were compared between treatment arms during a median follow-up of 3.81 years. The effect of intensive (versus standard) BP lowering on the SPRINT primary CVD outcome (a composite of myocardial infarction, acute coronary syndrome, stroke, heart failure, and CVD death) was compared before and after adjustment for LVH as a time-varying <strong><span style="color:yellowgreen">covari</span></strong>ate.</p></sec><sec><title>Results:</title><p>Among SPRINT participants without baseline LVH (n=7559), intensive (versus standard) BP lowering was associated with a 46% lower risk of developing LVH (hazard ratio=0.54; 95% confidence interval, 0.43–0.68). Similarly, among SPRINT participants with baseline LVH (n=605, 7.4%), those assigned to the intensive (versus standard) BP lowering were 66% more likely to regress/improve their LVH (hazard ratio=1.66; 95% confidence interval, 1.31–2.11). Adjustment for LVH as a time-varying <strong><span style="color:yellowgreen">covari</span></strong>ate did not substantially attenuate the effect of intensive BP therapy on CVD events (hazard ratio of intensive versus standard BP lowering on CVD, 0.76 [95% confidence interval, 0.64–0.90] and 0.77 [95% confidence interval, 0.65–0.91] before and after adjustment for LVH as a time-varying <strong><span style="color:yellowgreen">covari</span></strong>ate, respectively).</p></sec><sec><title>Conclusions:</title><p>Among patients with hypertension but no diabetes mellitus, intensive BP lowering (target systolic BP <120 mm Hg) compared with standard BP lowering (target systolic BP <140 mm Hg) resulted in lower rates of developing new LVH in those without LVH and higher rates of regression of LVH in those with existing LVH. This favorable effect on LVH did not explain most of the reduction in CVD events associated with intensive BP lowering in the SPRINT trial.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01206062.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/5/440
10.1161/CIRCULATIONAHA.117.028441
None

2
Circulation
Duration of Ventilations During Cardiopulmonary Resuscitation by Lay Rescuers and First Responders
<sec><title>Background—</title><p>The 2010 guidelines for cardiopulmonary resuscitation allow 5 seconds to give 2 breaths to deliver sufficient chest compressions and to keep perfusion pressure high. This study aims to determine whether the recommended short interruption for ventilations by trained lay rescuers and first responders can be achieved and to evaluate its consequence for chest compressions and survival.</p></sec><sec><title>Methods and Results—</title><p>From a prospective data collection of out-of-hospital cardiac arrest, we used automatic external defibrillator recordings of cardiopulmonary resuscitation by rescuers who had received a standard European Resuscitation Council basic life support and automatic external defibrillator course. Ventilation periods and total compressions delivered per minute during each 2 minutes of cardiopulmonary resuscitation cycle were measured, and the chest compression fraction was calculated. Neurological intact survival to discharge was studied in relation to these factors and <strong><span style="color:yellowgreen">covari</span></strong>ates. We included 199 automatic external defibrillator recordings. The median interruption time for 2 ventilations was 7 seconds (25th–75th percentile, 6–9 seconds). Of all rescuers, 21% took <5 seconds and 83% took <10 seconds for a ventilation period; 97%, 88%, and 63% of rescuers were able to deliver >60, >70, and >80 chest compressions per minute, respectively. The median chest compression fraction was 65% (25th–75th percentile, 59%–71%). Survival was 25% (49 of 199), not associated with long or short ventilation pauses when controlled for <strong><span style="color:yellowgreen">covari</span></strong>ates.</p></sec><sec><title>Conclusions—</title><p>The great majority of rescuers can give 2 rescue breaths in <10 seconds and deliver at least 70 compressions in a minute. Longer pauses for ventilations are not associated with worse outcome. Guidelines may allow longer pauses for ventilations with no detriment to survival.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/15/1585
10.1161/CIRCULATIONAHA.112.000841
None

1
Science
Joint profiling of chromatin accessibility and gene expression in thousands of single cells
<p>Although we can increasingly measure transcription, chromatin, methylation, and other aspects of molecular biology at single-cell resolution, most assays survey only one aspect of cellular biology. Here we describe sci-CAR, a combinatorial indexing–based coassay that jointly profiles chromatin accessibility and mRNA (CAR) in each of thousands of single cells. As a proof of concept, we apply sci-CAR to 4825 cells, including a time series of dexamethasone treatment, as well as to 11,296 cells from the adult mouse kidney. With the resulting data, we compare the pseudotemporal dynamics of chromatin accessibility and gene expression, reconstruct the chromatin accessibility profiles of cell types defined by RNA profiles, and link cis-regulatory sites to their target genes on the basis of the <strong><span style="color:yellowgreen">covari</span></strong>ance of chromatin accessibility and transcription across large numbers of single cells.</p>
http://sciencemag.org/cgi/content/abstract/361/6409/1380
10.1126/science.aau0730
None

1
Science
Evidence for a neural law of effect
<p>Thorndike’s law of effect states that actions that lead to reinforcements tend to be repeated more often. Accordingly, neural activity patterns leading to reinforcement are also reentered more frequently. Reinforcement relies on dopaminergic activity in the ventral tegmental area (VTA), and animals shape their behavior to receive dopaminergic stimulation. Seeking evidence for a neural law of effect, we found that mice learn to reenter more frequently motor cortical activity patterns that trigger optogenetic VTA self-stimulation. Learning was accompanied by gradual shaping of these patterns, with participating neurons progressively increasing and aligning their <strong><span style="color:yellowgreen">covari</span></strong>ance to that of the target pattern. Motor cortex patterns that lead to phasic dopaminergic VTA activity are progressively reinforced and shaped, suggesting a mechanism by which animals select and shape actions to reliably achieve reinforcement.</p>
http://sciencemag.org/cgi/content/abstract/359/6379/1024
10.1126/science.aao6058
['animals']

1
Science
Learning and attention reveal a general relationship between population activity and behavior
<p>Prior studies have demonstrated that correlated variability changes with cognitive processes that improve perceptual performance. We tested whether correlated variability <strong><span style="color:yellowgreen">covari</span></strong>es with subjects’ performance—whether performance improves quickly with attention or slowly with perceptual learning. We found a single, consistent relationship between correlated variability and behavioral performance, regardless of the time frame of correlated variability change. This correlated variability was oriented along the dimensions in population space used by the animal on a trial-by-trial basis to make decisions. That subjects’ choices were predicted by specific dimensions that were aligned with the correlated variability axis clarifies long-standing paradoxes about the relationship between shared variability and behavior.</p>
http://sciencemag.org/cgi/content/abstract/359/6374/463
10.1126/science.aao0284
None

1
PLANT PHYSIOLOGY
Variable Mesophyll Conductance among Soybean Cultivars Sets a Tradeoff between Photosynthesis and Water-Use-Efficiency
<p>Photosynthetic efficiency is a critical determinant of crop yield potential, although it remains below the theoretical optimum in modern crop varieties. Enhancing mesophyll conductance (i.e. the rate of carbon dioxide diffusion from substomatal cavities to the sites of carboxylation) may increase photosynthetic and water use efficiencies. To improve water use efficiency, mesophyll conductance should be increased without concomitantly increasing stomatal conductance. Here, we partition the variance in mesophyll conductance to within- and among-cultivar components across soybean (<i>Glycine max</i>) grown under both controlled and field conditions and examine the <strong><span style="color:yellowgreen">covari</span></strong>ation of mesophyll conductance with photosynthetic rate, stomatal conductance, water use efficiency, and leaf mass per area. We demonstrate that mesophyll conductance varies more than 2-fold and that 38% of this variation is due to cultivar identity. As expected, mesophyll conductance is positively correlated with photosynthetic rates. However, a strong positive correlation between mesophyll and stomatal conductance among cultivars apparently impedes positive scaling between mesophyll conductance and water use efficiency in soybean. Contrary to expectations, photosynthetic rates and mesophyll conductance both increased with increasing leaf mass per area. The presence of genetic variation for mesophyll conductance suggests that there is potential to increase photosynthesis and mesophyll conductance by selecting for greater leaf mass per area. Increasing water use efficiency, though, is unlikely unless there is simultaneous stabilizing selection on stomatal conductance.</p>
http://plantphysiol.org/cgi/content/abstract/174/1/241
10.1104/pp.16.01940
['Glycine', 'Glycine max', 'soybean']

1
Molecular Biology and Evolution
Correcting for Differential Transcript Coverage Reveals a Strong Relationship between Alternative Splicing and Organism Complexity
<p>What at the genomic level underlies organism complexity? Although several genomic features have been associated with organism complexity, in the case of alternative splicing, which has long been proposed to explain the variation in complexity, no such link has been established. Here, we analyzed over 39 million expressed sequence tags available for 47 eukaryotic species with fully sequenced genomes to obtain a comparable index of alternative splicing estimates, which corrects for the distorting effect of a variable number of transcripts per species—an important obstacle for comparative studies of alternative splicing. We find that alternative splicing has steadily increased over the last 1,400 My of eukaryotic evolution and is strongly associated with organism complexity, assayed as the number of cell types. Importantly, this association is not explained as a by-product of <strong><span style="color:yellowgreen">covari</span></strong>ance between alternative splicing with other variables previously linked to complexity including gene content, protein length, proteome disorder, and protein interactivity. In addition, we found no evidence to suggest that the relationship of alternative splicing to cell type number is explained by drift due to reduced <i>N</i><sub>e</sub> in more complex species. Taken together, our results firmly establish alternative splicing as a significant predictor of organism complexity and are, in principle, consistent with an important role of transcript diversification through alternative splicing as a means of determining a genome’s functional information capacity.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/31/6/1402
10.1093/molbev/msu083
None

1
Journal of Experimental Biology
A new research paradigm for bivariate allometry: combining ANOVA and non-linear regression
<p><bold>Summary:</bold> A method for performing the equivalent of an analysis of <strong><span style="color:yellowgreen">covari</span></strong>ance on bivariate data that are curvilinear on the arithmetic scale.</p>
http://jeb.biologists.org/cgi/content/abstract/221/7/jeb177519
10.1242/jeb.177519
None

1
The Bone & Joint Journal
Long-term outcomes of cemented <i>versus</i> cementless humeral components in arthroplasty of the shoulder
<sec><title>Aims</title><p>In the initial development of total shoulder arthroplasty (TSA),   the humeral component was usually fixed with cement. Cementless   components were subsequently introduced. The aim of this study was   to compare the long-term outcome of cemented and cementless humeral   components in arthroplasty of the shoulder.</p></sec><sec><title>Patients and Methods</title><p>All patients who underwent primary arthroplasty of the shoulder   at our institution between 1970 and 2012 were included in the study.   There were 4636 patients with 1167 cemented humeral components and   3469 cementless components. Patients with the two types of fixation   were matched for nine different <strong><span style="color:yellowgreen">covari</span></strong>ates using a propensity score   analysis. A total of 551 well-balanced pairs of patients with cemented   and cementless components were available after matching for comparison   of the outcomes. The clinical outcomes which were analysed included loosening   of the humeral component determined at revision surgery, periprosthetic   fractures, post-operative infection and operating time.</p></sec><sec><title>Results</title><p>The overall five-, ten-, 15- and 20-year rates of survival were   98.9%, 97.2%, 95.5%, and 94.4%, respectively. Survival without loosening   at 20 years was 98% for cemented components and 92.4% for cementless   components. After propensity score matching including fixation as   determined by the design of the component, humeral loosening was   also found to be significantly higher in the cementless group. Survival   without humeral loosening at 20 years was 98.7% for cemented components   and 91.0% for cementless components. There was no significant difference   in the risk of intra- or post-operative fracture. The rate of survival   without deep infection and the mean operating time were significantly   higher in the cemented group.</p></sec><sec><title>Conclusion</title><p>Both types of fixation give rates of long-term survival of >   90%. Cemented components have better rates of survival without loosening   but this should be weighed against increased operating time and   the risk of bony destruction of the proximal humerus at the time   of revision of a cemented humeral component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:666–73.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/666
10.1302/0301-620X.99B5.BJJ-2016-0910.R1
None

1
The Bone & Joint Journal
Costs, quality of life and cost-effectiveness of arthroscopic and open repair for rotator cuff tears
<sec><title>Aims</title><p>A trial-based comparison of the use of resources, costs and quality   of life outcomes of arthroscopic and open surgical management for   rotator cuff tears in the United Kingdom NHS was performed using   data from the United Kingdom Rotator Cuff Study (UKUFF) randomised   controlled trial.</p></sec><sec><title>Patients and Methods</title><p>Using data from 273 patients, healthcare-related use of resources,   costs and quality-adjusted life years (QALYs) were estimated at   12 months and 24 months after surgery on an intention-to-treat basis   with adjustment for <strong><span style="color:yellowgreen">covari</span></strong>ates. Uncertainty about the incremental   cost-effectiveness ratio for arthroscopic <i>versus</i> open   management at 24 months of follow-up was incorporated using bootstrapping.   Multiple imputation methods were used to deal with missing data.</p></sec><sec><title>Results</title><p>There were no significant differences between the arthroscopic   and open groups in terms of total mean use and cost of resources   or QALYs at any time post-operatively. Open management dominated   arthroscopic management in 59.8% of bootstrapped cost and effect   differences. The probability that arthroscopic management was cost-effective   compared with open management at a willingness-to-pay threshold   of £20 000 per QALY gained was 20.9%.</p></sec><sec><title>Conclusion</title><p>There was no significant overall difference in the use or cost   of resources or quality of life between arthroscopic and open management   in the trial. There was uncertainty about which strategy was most   cost-effective.</p><p>Cite this article: <i>Bone Joint J</i> 2016;98-B:1648–55.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/98-B/12/1648
10.1302/0301-620X.98B12.BJJ-2016-0121.R1
None

1
Circulation
Association of Human Immunodeficiency Virus Infection and Risk of Peripheral Artery Disease
<sec><title>Background:</title><p>The effect of human immunodeficiency virus (HIV) on the development of peripheral artery disease (PAD) remains unclear. We investigated whether HIV infection is associated with an increased risk of PAD after adjustment for traditional atherosclerotic risk factors in a large cohort of HIV-infected (HIV+) and demographically similar HIV-uninfected veterans.</p></sec><sec><title>Methods:</title><p>We studied participants in the Veterans Aging Cohort Study from April 1, 2003 through December 31, 2014. We excluded participants with known prior PAD or prevalent cardiovascular disease (myocardial infarction, stroke, coronary heart disease, and congestive heart failure) and analyzed the effect of HIV status on the risk of incident PAD events after adjusting for demographics, PAD risk factors, substance use, CD4 cell count, HIV-1 ribonucleic acid, and antiretroviral therapy. The primary outcome is incident peripheral artery disease events. Secondary outcomes include mortality and amputation in subjects with incident PAD events by HIV infection status, viral load, and CD4 count.</p></sec><sec><title>Results:</title><p>Among 91 953 participants, over a median follow up of 9.0 years, there were 7708 incident PAD events. Rates of incident PAD events per 1000 person-years were higher among HIV+ (11.9; 95% confidence interval [CI], 11.5–12.4) than uninfected veterans (9.9; 95% CI, 9.6–10.1). After adjustment for demographics, PAD risk factors, and other <strong><span style="color:yellowgreen">covari</span></strong>ates, HIV+ veterans had an increased risk of incident PAD events compared with uninfected veterans (hazard ratio [HR], 1.19; 95% CI, 1.13–1.25). This risk was highest among those with time-updated HIV viral load >500 copies/mL (HR, 1.51; 95% CI, 1.38–1.65) and CD4 cell counts <200 cells/mm<sup>3</sup> (HR, 1.91; 95% CI, 1.71–2.13). In contrast, HIV+ veterans with time updated CD4 cell count ≥500 cells/mm<sup>3</sup> had no increased risk of PAD (HR, 1.03; 95% CI, 0.96–1.11). Mortality rates after incident PAD events are high regardless of HIV status. HIV infection did not affect rates of amputation after incident PAD events.</p></sec><sec><title>Conclusions:</title><p>Infection with HIV is associated with a 19% increased risk of PAD beyond that explained by traditional atherosclerotic risk factors. However, for those with sustained CD4 cell counts <200 cells/mm<sup>3</sup>, the risk of incident PAD events is nearly 2-fold higher whereas for those with sustained CD4 cell counts ≥500 cells/mm<sup>3</sup> there is no excess risk of incident PAD events compared with uninfected people.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/3/255
10.1161/CIRCULATIONAHA.117.032647
['human']

1
Circulation
Transcatheter Interatrial Shunt Device for the Treatment of Heart Failure With Preserved Ejection Fraction (REDUCE LAP-HF I [Reduce Elevated Left Atrial Pressure in Patients With Heart Failure])
<sec><title>Background:</title><p>In nonrandomized, open-label studies, a transcatheter interatrial shunt device (IASD, Corvia Medical) was associated with lower pulmonary capillary wedge pressure (PCWP), fewer symptoms, and greater quality of life and exercise capacity in patients with heart failure (HF) and midrange or preserved ejection fraction (EF ≥40%). We conducted the first randomized sham-controlled trial to evaluate the IASD in HF with EF ≥40%.</p></sec><sec><title>Methods:</title><p>REDUCE LAP-HF I (Reduce Elevated Left Atrial Pressure in Patients With Heart Failure) was a phase 2, randomized, parallel-group, blinded multicenter trial in patients with New York Heart Association class III or ambulatory class IV HF, EF ≥40%, exercise PCWP ≥25 mm Hg, and PCWP-right atrial pressure gradient ≥5 mm Hg. Participants were randomized (1:1) to the IASD versus a sham procedure (femoral venous access with intracardiac echocardiography but no IASD placement). The participants and investigators assessing the participants during follow-up were blinded to treatment assignment. The primary effectiveness end point was exercise PCWP at 1 month. The primary safety end point was major adverse cardiac, cerebrovascular, and renal events at 1 month. PCWP during exercise was compared between treatment groups using a mixed-effects repeated measures model analysis of <strong><span style="color:yellowgreen">covari</span></strong>ance that included data from all available stages of exercise.</p></sec><sec><title>Results:</title><p>A total of 94 patients were enrolled, of whom 44 met inclusion/exclusion criteria and were randomized to the IASD (n=22) and control (n=22) groups. Mean age was 70±9 years, and 50% were female. At 1 month, the IASD resulted in a greater reduction in PCWP compared with sham control (<i>P</i>=0.028 accounting for all stages of exercise). Peak PCWP decreased by 3.5±6.4 mm Hg in the treatment group versus 0.5±5.0 mm Hg in the control group (<i>P</i>=0.14). There were no peri-procedural or 1-month major adverse cardiac, cerebrovascular, and renal events in the IASD group and 1 event (worsening renal function) in the control group (<i>P</i>=1.0).</p></sec><sec><title>Conclusions:</title><p>In patients with HF and EF ≥40%, IASD treatment reduces PCWP during exercise. Whether this mechanistic effect will translate into sustained improvements in symptoms and outcomes requires further evaluation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://clinicaltrials.gov</ext-link>. Unique identifier: NCT02600234.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/4/364
10.1161/CIRCULATIONAHA.117.032094
None

1
Circulation
Cardiorespiratory Fitness, Coronary Artery Calcium, and Cardiovascular Disease Events in a Cohort of Generally Healthy Middle-Age Men
<sec><title>Background:</title><p>A robust literature demonstrates that coronary artery calcification (CAC) and cardiorespiratory fitness (CRF) are independent predictors of cardiovascular disease (CVD) events. Much less is known about the joint associations of CRF and CAC with CVD risk. In the setting of high CAC, high versus low CRF has been associated with decreased CVD events. The goal of this study was to assess the effect of continuous levels of CRF on CVD risk in the setting of increasing CAC burden.</p></sec><sec><title>Methods:</title><p>We studied 8425 men without clinical CVD who underwent preventive medicine examinations that included an objective measurement of CRF and CAC between 1998 and 2007. There were 383 CVD events during an average follow-up of 8.4 years. Parametric proportional hazards regression models based on a Gompertz mortality rule were used to estimate total CVD incidence rates at 70 years of age as well as hazard ratios for the included <strong><span style="color:yellowgreen">covari</span></strong>ates.</p></sec><sec><title>Results:</title><p>CVD events increased with increasing CAC and decreased with increasing CRF. Adjusting for CAC level (scores of 0, 1–99, 100–399, and ≥400), for each additional MET of fitness, there was an 11% lower risk for CVD events (hazard ratio, 0.89; 95% confidence interval, 0.84-0.94). When CAC and CRF were considered together, there was a strong association between continuous CRF and CVD incidence rates in all CAC groups.</p></sec><sec><title>Conclusions:</title><p>In a large cohort of generally healthy men, there is an attenuation of CVD risk at all CAC levels with higher CRF.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/18/1888
10.1161/CIRCULATIONAHA.117.032708
None

1
Circulation
Long-Term Outcomes in Patients With Type 2 Myocardial Infarction and Myocardial Injury
<sec><title>Background:</title><p>Type 2 myocardial infarction and myocardial injury are common in clinical practice, but long-term consequences are uncertain. We aimed to define long-term outcomes and explore risk stratification in patients with type 2 myocardial infarction and myocardial injury.</p></sec><sec><title>Methods:</title><p>We identified consecutive patients (n=2122) with elevated cardiac troponin I concentrations (≥0.05 µg/L) at a tertiary cardiac center. All diagnoses were adjudicated as per the universal definition of myocardial infarction. The primary outcome was all-cause death. Secondary outcomes included major adverse cardiovascular events (eg, nonfatal myocardial infarction or cardiovascular death) and noncardiovascular death. To explore competing risks, cause-specific hazard ratios were obtained using Cox regression models.</p></sec><sec><title>Results:</title><p>The adjudicated index diagnosis was type 1 or 2 myocardial infarction or myocardial injury in 1171 (55.2%), 429 (20.2%), and 522 (24.6%) patients, respectively. At 5 years, all-cause death rates were higher in those with type 2 myocardial infarction (62.5%) or myocardial injury (72.4%) compared with type 1 myocardial infarction (36.7%). The majority of excess deaths in those with type 2 myocardial infarction or myocardial injury were because of noncardiovascular causes (hazard ratio, 2.32; 95% confidence interval, 1.92–2.81 versus type 1 myocardial infarction). Despite this finding, the observed crude major adverse cardiovascular event rates were similar between groups (30.6% versus 32.6%), with differences apparent after adjustment for <strong><span style="color:yellowgreen">covari</span></strong>ates (hazard ratio, 0.82; 95% confidence interval, 0.69–0.96). Coronary heart disease was an independent predictor of major adverse cardiovascular events in those with type 2 myocardial infarction or myocardial injury (hazard ratio, 1.71; 95% confidence interval, 1.31–2.24).</p></sec><sec><title>Conclusions:</title><p>Despite an excess in noncardiovascular death, patients with type 2 myocardial infarction or myocardial injury have a similar crude rate of major adverse cardiovascular events as those with type 1 myocardial infarction. Identifying underlying coronary heart disease in this vulnerable population may help target therapies that could modify future risk.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/12/1236
10.1161/CIRCULATIONAHA.117.031806
None

1
Circulation
Integrated Noninvasive Physiological Assessment of Coronary Circulatory Function and Impact on Cardiovascular Mortality in Patients With Stable Coronary Artery Disease
<sec><title>Background:</title><p>It is suggested that the integration of maximal myocardial blood flow (MBF) and coronary flow reserve (CFR), termed coronary flow capacity, allows for comprehensive evaluation of patients with known or suspected stable coronary artery disease. Because management decisions are predicated on clinical risk, we sought to determine the independent and integrated value of maximal MBF and CFR for predicting cardiovascular death.</p></sec><sec><title>Methods:</title><p>MBF and CFR were quantified in 4029 consecutive patients (median age 66 years, 50.5% women) referred for rest/stress myocardial perfusion positron emission tomography scans from January 2006 to December 2013. The primary outcome was cardiovascular mortality. Maximal MBF <1.8 mL·g<sup>−1</sup>·min<sup>−1</sup> and CFR<2 were considered impaired. Four patient groups were identified based on the concordant or discordant impairment of maximal MBF or CFR. Association of maximal MBF and CFR with cardiovascular death was assessed using Cox and Poisson regression analyses.</p></sec><sec><title>Results:</title><p>A total of 392 (9.7%) cardiovascular deaths occurred over a median follow-up of 5.6 years. CFR was a stronger predictor of cardiovascular mortality than maximal MBF beyond traditional cardiovascular risk factors, left ventricular ejection fraction, myocardial scar and ischemia, rate-pressure product, type of radiotracer or stress agent used, and revascularization after scan (adjusted hazard ratio, 1.79; 95% confidence interval [CI], 1.38–2.31; <i>P</i><0.001 per unit decrease in CFR after adjustment for maximal MBF and clinical <strong><span style="color:yellowgreen">covari</span></strong>ates; and adjusted hazard ratio, 1.03; 95% CI, 0.84–1.27; <i>P</i>=0.8 per unit decrease in maximal MBF after adjustment for CFR and clinical <strong><span style="color:yellowgreen">covari</span></strong>ates). In univariable analyses, patients with concordant impairment of CFR and maximal MBF had high cardiovascular mortality of 3.3% (95% CI, 2.9–3.7) per year. Patients with impaired CFR but preserved maximal MBF had an intermediate cardiovascular mortality of 1.7% (95% CI, 1.3–2.1) per year. These patients were predominantly women (70%). Patients with preserved CFR but impaired maximal MBF had low cardiovascular mortality of 0.9% (95% CI, 0.6–1.6) per year. Patients with concordantly preserved CFR and maximal MBF had the lowest cardiovascular mortality of 0.4% (95 CI, 0.3–0.6) per year. In multivariable analysis, the cardiovascular mortality risk gradient across the 4 concordant or discordant categories was independently driven by impaired CFR irrespective of impairment in maximal MBF.</p></sec><sec><title>Conclusions:</title><p>CFR is a stronger predictor of cardiovascular mortality than maximal MBF. Concordant and discordant categories based on integrating CFR and maximal MBF identify unique prognostic phenotypes of patients with known or suspected coronary artery disease.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/24/2325
10.1161/CIRCULATIONAHA.117.029992
None

1
Circulation
Conscious Sedation Versus General Anesthesia for Transcatheter Aortic Valve Replacement
<sec><title>Background:</title><p>Conscious sedation is used during transcatheter aortic valve replacement (TAVR) with limited evidence as to the safety and efficacy of this practice.</p></sec><sec><title>Methods:</title><p>The National Cardiovascular Data Registry Society of Thoracic Surgeons/American College of Cardiology Transcatheter Valve Therapy Registry was used to characterize the anesthesia choice and clinical outcomes of all US patients undergoing elective percutaneous transfemoral TAVR between April 1, 2014, and June 30, 2015. Raw and inverse probability of treatment-weighted analyses were performed to compare patients undergoing TAVR with general anesthesia with patients undergoing TAVR with conscious sedation on an intention-to-treat basis for the primary outcome of in-hospital mortality, and secondary outcomes including 30-day mortality, in-hospital and 30-day death/stroke, procedural success, intensive care unit and hospital length-of-stay, and rates of discharge to home. Post hoc falsification end point analyses were performed to evaluate for residual confounding.</p></sec><sec><title>Results:</title><p>Conscious sedation was used in 1737/10 997 (15.8%) cases with a significant trend of increasing usage over the time period studied (<i>P</i> for trend<0.001). In raw analyses, intraprocedural success with conscious sedation and general anesthesia was similar (98.2% versus 98.5%, <i>P</i>=0.31). The conscious sedation group was less likely to experience in-hospital (1.6% versus 2.5%, <i>P</i>=0.03) and 30-day death (2.9% versus 4.1%, <i>P</i>=0.03). Conversion from conscious sedation to general anesthesia was noted in 102 of 1737 (5.9%) of conscious sedation cases. After inverse probability of treatment-weighted adjustment for 51 <strong><span style="color:yellowgreen">covari</span></strong>ates, conscious sedation was associated with lower procedural success (97.9% versus 98.6%, <i>P</i><0.001) and a reduced rate of mortality at the in-hospital (1.5% versus 2.4%, <i>P</i><0.001) and 30-day (2.3% versus 4.0%, <i>P</i><0.001) time points. Conscious sedation was associated with reductions in procedural inotrope requirement, intensive care unit and hospital length of stay (6.0 versus 6.5 days, <i>P</i><0.001), and combined 30-day death/stroke rates (4.8% versus 6.4%, <i>P</i><0.001). Falsification end point analyses of vascular complications, bleeding, and new pacemaker/defibrillator implantation demonstrated no significant differences between groups after adjustment.</p></sec><sec><title>Conclusions:</title><p>In US practice, conscious sedation is associated with briefer length of stay and lower in-hospital and 30-day mortality in comparison with TAVR with general anesthesia in both unadjusted and adjusted analyses. These results suggest the safety of conscious sedation in this population, although comparative effectiveness analyses using observational data cannot definitively establish the superiority of one technique over another.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2132
10.1161/CIRCULATIONAHA.116.026656
None

1
Circulation
Sex Differences in 1-Year All-Cause Rehospitalization in Patients After Acute Myocardial Infarction
<sec><title>Background:</title><p>Compared with men, women are at higher risk of rehospitalization in the first month after discharge for acute myocardial infarction (AMI). However, it is unknown whether this risk extends to the full year and varies by age. Explanatory factors potentially mediating the relationship between sex and rehospitalization remain unexplored and are needed to reduce readmissions. The aim of this study was to assess sex differences and factors associated with 1-year rehospitalization rates after AMI.</p></sec><sec><title>Methods:</title><p>We recruited 3536 patients (33% women) ≥18 years of age hospitalized with AMI from 24 US centers into the TRIUMPH study (Translational Research Investigating Underlying Disparities in Acute Myocardial Infarction Patients’ Health Status). Data were obtained by medical record abstraction and patient interviews, and a physician panel adjudicated hospitalizations within the first year after AMI. We compared sex differences in rehospitalization using a Cox proportional hazards model, following sequential adjustment for <strong><span style="color:yellowgreen">covari</span></strong>ates and testing for an age-sex interaction.</p></sec><sec><title>Results:</title><p>One-year crude all-cause rehospitalization rates for women were significantly higher than men after AMI (hazard ratio, 1.29 for women; 95% confidence interval, 1.12−1.48). After adjustment for demographics and clinical factors, women had a persistent 26% higher risk of rehospitalization (hazard ratio, 1.26; 95% confidence interval, 1.08−1.47). However, after adjustment for health status and psychosocial factors (hazard ratio, 1.14; 95% confidence interval, 0.96−1.35), the association was attenuated. No significant age-sex interaction was found for 1-year rehospitalization, suggesting that the increased risk applied to both older and younger women.</p></sec><sec><title>Conclusions:</title><p>Regardless of age, women have a higher risk of rehospitalization compared with men over the first year after AMI. Although the increased risk persisted after adjustment for clinical factors, the poorer health and psychosocial state of women attenuated the difference.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/6/521
10.1161/CIRCULATIONAHA.116.024993
None

1
Circulation
Discovery and Validation of Agonistic Angiotensin Receptor Autoantibodies as Biomarkers of Adverse Outcomes
<sec><title>Background:</title><p>Agonistic angiotensin II type 1 receptor autoantibodies (AT1RaAbs) have not been associated with functional measures or risk for adverse health outcomes. AT1RaAbs could be used to stratify patient risk and to identify patients who can benefit from angiotensin receptor blocker treatment.</p></sec><sec><title>Methods:</title><p>Demographic and physiological <strong><span style="color:yellowgreen">covari</span></strong>ates were measured in a discovery set of community-dwelling adults from Baltimore (N=255) and AT1RaAb associations with physical function tests and outcomes assessed. A group from Chicago (N=60) was used for validation of associations and to explore the impact of angiotensin receptor blocker treatment.</p></sec><sec><title>Results:</title><p>The Baltimore group had 28 subjects with falls, 32 frail subjects, and 5 deaths. Higher AT1RaAbs correlated significantly with interleukin-6 (Spearman <i>r</i>=0.33, <i>P</i><0.0001), systolic blood pressure (Spearman <i>r</i>=0.28, <i>P</i><0.0001), body mass index (Spearman <i>r</i>=0.28, <i>P</i><0.0001), weaker grip strength (Spearman <i>r</i>=–0.34, <i>P</i><0.01), and slower walking speed (Spearman <i>r</i>=–0.30, <i>P</i><0.05). Individuals with high AT1RaAbs were 3.9 (95% confidence interval, 1.38–11.0) times more likely to be at high risk after adjusting for age (<i>P</i><0.05). Every 1 µg/mL increase in AT1RaAbs increased the odds of falling 30% after adjusting for age, sex, body mass index, and blood pressure. The Chicago group had 46 subjects with falls and 60 deaths. Serum AT1RaAb levels were significantly correlated with grip strength (Spearman <i>r</i>=–0.57, <i>P</i><0.005), walking speed (Spearman <i>r</i>=–0.47, <i>P</i><0.005), and falls (Spearman <i>r</i>=0.30, <i>P</i><0.05). Every 1 µg/mL increase in AT1RaAbs, decreased time to death by 9% after adjusting for age, sex, body mass index, and blood pressure. Chronic treatment with angiotensin receptor blockers was associated with better control of systolic blood pressure and attenuation of decline in both grip strength and time to death.</p></sec><sec><title>Conclusions:</title><p>In older individuals, higher AT1RaAb levels were associated with inflammation, hypertension, and adverse outcomes. Angiotensin receptor blocker treatment may blunt the harm associated with high levels of AT1RaAb.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/5/449
10.1161/CIRCULATIONAHA.116.022385
None

1
Circulation
Impact of Left Atrial Appendage Closure During Cardiac Surgery on the Occurrence of Early Postoperative Atrial Fibrillation, Stroke, and Mortality
<sec><title>Background:</title><p>Prophylactic exclusion of the left atrial appendage (LAA) is often performed during cardiac surgery ostensibly to reduce the risk of stroke. However, the clinical impact of LAA closure in humans remains inconclusive.</p></sec><sec><title>Methods:</title><p>Of 10 633 adults who underwent coronary artery bypass grafting and valve surgery between January 2000 and December 2005, 9792 patients with complete baseline characteristics, surgery procedure, and follow-up data were included in this analysis. A propensity score–matching analysis based on 28 pretreatment <strong><span style="color:yellowgreen">covari</span></strong>ates was performed and 461 matching pairs were derived and analyzed to estimate the association of LAA closure with early postoperative atrial fibrillation (POAF) (atrial fibrillation ≤30 days of surgery), ischemic stroke, and mortality.</p></sec><sec><title>Results:</title><p>In the propensity-matched cohort, the overall incidence of POAF was 53.9%. In this group, the rate of early POAF among the patients who underwent LAA closure was 68.6% versus 31.9% for those who did not undergo the procedure (<i>P</i><0.001). LAA closure was independently associated with an increased risk of early POAF (adjusted odds ratio, 3.88; 95% confidence interval, 2.89–5.20), but did not significantly influence the risk of stroke (adjusted hazard ratio, 1.07; 95% confidence interval, 0.72–1.58) or mortality (adjusted hazard ratio, 0.92; 95% confidence interval, 0.75–1.13).</p></sec><sec><title>Conclusions:</title><p>After adjustment for treatment allocation bias, LAA closure during routine cardiac surgery was significantly associated with an increased risk of early POAF, but it did not influence the risk of stroke or mortality. It remains uncertain whether prophylactic exclusion of the LAA is warranted for stroke prevention during non–atrial fibrillation-related cardiac surgery.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/4/366
10.1161/CIRCULATIONAHA.116.021952
None

1
Circulation
Incident Type 2 Myocardial Infarction in a Cohort of Patients Undergoing Coronary or Peripheral Arterial Angiography
<sec><title>Background:</title><p>Despite growing recognition of type 2 myocardial infarction (T2MI; related to supply/demand mismatch), little is known about its risk factors or its association with outcome.</p></sec><sec><title>Methods:</title><p>A single-center cohort of patients undergoing coronary or peripheral angiography with or without intervention was prospectively enrolled and followed for incident type 1 and T2MI, and major adverse cardiovascular events (MACE, a composite of all-cause death, nonfatal myocardial infarction [MI], heart failure, stroke, transient ischemic attack, peripheral arterial complication, and cardiac arrhythmia), as well. T2MI was adjudicated using criteria from the Third Universal Definition of MI. Baseline characteristics, blood samples, and angiography information were obtained. Major end points subsequent to first MI were assessed using landmark analyses to compare the rates of first events only where everyone with a prior history of any MACE before MI were censored and adjusted for follow-up times. Cox proportional hazard models were used for time-to-event analyses with age and sex forced into all models and additional <strong><span style="color:yellowgreen">covari</span></strong>ates evaluated by using the stepwise option for the selection.</p></sec><sec><title>Results:</title><p>One thousand two hundred fifty-one patients were enrolled and followed for a median of 3.4 years. Of these patients, 152 (12.2%) had T2MI during follow-up; T2MI was frequently recurrent. Multivariable predictors of T2MI were older age, lower systolic blood pressure, history of coronary artery disease, heart failure, chronic obstructive pulmonary disease, diabetes mellitus, nitrate use, and elevated concentrations of glucose, N-terminal pro-B type natriuretic peptide, and cystatin C. Patients with T2MI had higher rates of subsequent adverse events than those without T2MI (per 100 person-years: MACE, 53.7 versus 21.1, <i>P</i><0.001; all-cause death, 23.3 versus 3.3, <i>P</i><0.001; cardiovascular death, 17.5 versus 2.6, <i>P</i><0.001; heart failure events, 22.4 versus 7.4, <i>P</i><0.001); these rates are similar to those seen in patients with type 1 MI. Incident diagnosis of T2MI strongly predicted risk for subsequent MACE (adjusted hazard ratio, 1.90; 95% confidence interval, 1.46–2.48; <i>P</i><0.001), all-cause death (adjusted hazard ratio, 2.96; 95% confidence interval, 2.01–4.36; <i>P</i><0.001), and cardiovascular death (adjusted hazard ratio, 2.16; 95% confidence interval, 1.36–3.43; <i>P</i>=0.001).</p></sec><sec><title>Conclusions:</title><p>T2MI is common and associated with poor prognosis. Studies evaluating treatment strategies for management of T2MI are needed.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00842868.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/2/116
10.1161/CIRCULATIONAHA.116.023052
None

