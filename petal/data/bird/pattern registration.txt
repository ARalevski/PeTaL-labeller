7
Circulation
Three Arterial Grafts Improve Late Survival
<sec><title>Background:</title><p>Little evidence shows whether a third arterial graft provides superior outcomes compared with the use of 2 arterial grafts in patients undergoing coronary artery bypass grafting. A meta-analysis of all the propensity score-<strong><span style="color:yellowgreen">match</span></strong>ed observational studies comparing the long-term outcomes of coronary artery bypass grafting with the use of 2-arterial versus 3-arterial grafts was performed.</p></sec><sec><title>Methods:</title><p>A literature search was conducted using MEDLINE, EMBASE, and Web of Science to identify relevant articles. Long-term mortality in the propensity score-<strong><span style="color:yellowgreen">match</span></strong>ed populations was the primary end point. Secondary end points were in-hospital/30-day mortality for the propensity score-<strong><span style="color:yellowgreen">match</span></strong>ed populations and long-term mortality for the un<strong><span style="color:yellowgreen">match</span></strong>ed populations. In the <strong><span style="color:yellowgreen">match</span></strong>ed population, time-to-event outcome for long-term mortality was extracted as hazard ratios, along with their variance. Statistical pooling of survival (time-to-event) was performed according to a random effect model, computing risk estimates with 95% confidence intervals.</p></sec><sec><title>Results:</title><p>Eight propensity score-<strong><span style="color:yellowgreen">match</span></strong>ed studies reporting on 10 287 <strong><span style="color:yellowgreen">match</span></strong>ed patients (2-arterial graft: 5346; 3-arterial graft: 4941) were selected for final <strong><span style="color:yellowgreen">comparison</span></strong>. The mean follow-up time ranged from 37.2 to 196.8 months. The use of 3 arterial grafts was not statistically associated with early mortality (hazard ratio, 0.93; 95% confidence interval, 0.71–1.22; <i>P</i>=0.62). The use of 3 arterial grafts was associated with statistically significantly lower hazard for late death (hazard ratio, 0.8; 95% confidence interval, 0.75–0.87; <i>P</i><0.001), irrespective of sex and diabetic mellitus status. This result was qualitatively similar in the un<strong><span style="color:yellowgreen">match</span></strong>ed population (hazard ratio, 0.57; 95% confidence interval, 0.33–0.98; <i>P</i>=0.04).</p></sec><sec><title>Conclusions:</title><p>The use of a third arterial conduit in patients with coronary artery bypass grafting is not associated with higher operative risk and is associated with superior long-term survival, irrespective of sex and diabetic mellitus status.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/11/1036
10.1161/CIRCULATIONAHA.116.025453
None

7
Circulation
Long-Term Survival of Patients With Radiation Heart Disease Undergoing Cardiac Surgery
<sec><title>Background—</title><p>Thoracic radiation results in radiation-associated heart disease (RAHD), often requiring cardiothoracic surgery (CTS). We sought to measure long-term survival in RAHD patients undergoing CTS, to compare them with a <strong><span style="color:yellowgreen">match</span></strong>ed control population undergoing similar surgical procedures, and to identify potential predictors of long-term survival.</p></sec><sec><title>Methods and Results—</title><p>In this retrospective observational cohort study of patients undergoing CTS, <strong><span style="color:yellowgreen">match</span></strong>ed on the basis of age, sex, and type/time of CTS, 173 RAHD patients (75% women; age, 63±14 years) and 305 <strong><span style="color:yellowgreen">comparison</span></strong> patients (74% women; age, 63±4 years) were included. The vast majority of RAHD patients had prior breast cancer (53%) and Hodgkin lymphoma (27%), and the mean time from radiation was 18±12 years. Clinical and surgical parameters were recorded. The preoperative EuroSCORE and all-cause mortality were recorded. The mean EuroSCOREs were similar in the RAHD and <strong><span style="color:yellowgreen">comparison</span></strong> groups (7.8±3 versus 7.4±3, respectively; <i>P</i>=0.1). Proximal coronary artery disease was higher in patients with RAHD versus the <strong><span style="color:yellowgreen">comparison</span></strong> patients (45% versus 38%; <i>P</i>=0.09), whereas redo CTS was lower in the RACD versus the <strong><span style="color:yellowgreen">comparison</span></strong> group (20% versus 29%; <i>P</i>=0.02). About two thirds of patients in either group had combination surgical procedures. During a mean follow-up of 7.6±3 years, a significantly higher proportion of patients died in the RAHD group than in the <strong><span style="color:yellowgreen">comparison</span></strong> group (55% versus 28%; <i>P</i><0.001). On multivariable Cox proportional hazard analysis, RAHD (2.47; 95% confidence interval, 1.82–3.36), increasing EuroSCORE (1.22; 95% confidence interval, 1.16–1.29), and lack of β-blockers (0.66; 95% confidence interval, 0.47–0.93) were associated with increased mortality (all <i>P</i><0.01).</p></sec><sec><title>Conclusions—</title><p>In patients undergoing CTS, RAHD portends increased long-term mortality. Alternative treatment strategies may be required in RAHD to improve long-term survival.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/14/1476
10.1161/CIRCULATIONAHA.113.001435
None

6
Circulation
Association of Statin Dose With Amputation and Survival in Patients With Peripheral Artery Disease
<sec><title>Background:</title><p>Statin dose guidelines for patients with peripheral artery disease (PAD) are largely based on coronary artery disease and stroke data. The aim of this study is to determine the effect of statin intensity on PAD outcomes of amputation and mortality.</p></sec><sec><title>Methods:</title><p>Using an observational cohort study design and a validated algorithm, we identified patients with incident PAD (2003–2014) in the national Veterans Affairs data. Highest statin intensity exposure (high-intensity versus low-to-moderate–intensity versus antiplatelet therapy but no statin use) was determined within 1 year of diagnosis of PAD. Outcomes of interest were lower extremity amputations and death. The association of statin intensity with incident amputation and mortality was assessed with Kaplan-Meier plots, Cox proportional hazards modeling, propensity score–<strong><span style="color:yellowgreen">match</span></strong>ed analysis, and sensitivity and subgroup analyses, as well, to reduce confounding.</p></sec><sec><title>Results:</title><p>In 155 647 patients with incident PAD, more than a quarter (28%) were not on statins. Use of high-intensity statins was lowest in patients with PAD only (6.4%) in <strong><span style="color:yellowgreen">comparison</span></strong> with comorbid coronary/carotid disease (18.4%). Incident amputation and mortality risk declined significantly with any statin use in <strong><span style="color:yellowgreen">comparison</span></strong> with the antiplatelet therapy–only group. In adjusted Cox models, the high-intensity statin users were associated with lower amputation risk and mortality in <strong><span style="color:yellowgreen">comparison</span></strong> with antiplatelet therapy–only users (hazard ratio, 0.67; 95% confidence interval, 0.61–0.74 and hazard ratio, 0.74; 95% confidence interval, 0.70–0.77, respectively). Low-to-moderate–intensity statins also had significant reductions in the risk of amputation and mortality (hazard ratio amputation, 0.81; 95% confidence interval, 0.75– 0.86; hazard ratio death, 0.83; 95% confidence interval, 0.81–0.86) in <strong><span style="color:yellowgreen">comparison</span></strong> with no statins (antiplatelet therapy only), but effect size was significantly weaker than the high-intensity statins (<i>P</i><0.001). The association of high-intensity statins with lower amputation and death risk remained significant and robust in propensity score–<strong><span style="color:yellowgreen">match</span></strong>ed, sensitivity, and subgroup analyses.</p></sec><sec><title>Conclusions:</title><p>Statins, especially high-intensity formulations, are underused in patients with PAD. This is the first population-based study to show that high-intensity statin use at the time of PAD diagnosis is associated with a significant reduction in limb loss and mortality in <strong><span style="color:yellowgreen">comparison</span></strong> with low-to-moderate–intensity statin users, and patients treated only with antiplatelet medications but not with statins, as well.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/14/1435
10.1161/CIRCULATIONAHA.117.032361
None

5
Systematic Biology
Resolving Ambiguity of Species Limits and Concatenation in Multilocus Sequence Data for the Construction of Phylogenetic Supermatrices
<p>Public DNA databases are becoming too large and too complex for manual methods to generate phylogenetic supermatrices from multiple gene sequences. Delineating the terminals based on taxonomic labels is no longer practical because species identifications are frequently incomplete and gene trees are incongruent with Linnaean binomials, which results in uncertainty about how to combine species units among unlinked loci. We developed a procedure that minimizes the problem of forming multilocus species units in a large phylogenetic data set using algorithms from graph theory. An initial step established sequence clusters for each locus that broadly correspond to the species level. These clusters frequently include sequences labeled with various binomials and specimen identifiers that create multiple alternatives for concatenation. To choose among these possibilities, we minimize taxonomic conflict among the species units globally in the data set using a multipartite heuristic algorithm. The procedure was applied to all available GenBank data for Coleoptera (beetles) including > 10 500 taxon labels and > 23 500 sequences of 4 loci, which were grouped into 11 241 clusters or divergent singletons by the BlastClust software. Within each cluster, unidentified sequences could be assigned to a species name through the association with fully identified sequences, resulting in 510 new identifications (13.9% of total unidentified sequences) of which nearly half were “trans-locus” identifications by clustering of sequences at a secondary locus. The limits of DNA-based clusters were inconsistent with the Linnaean binomials for 1518 clusters (13.5%) that contained more than one binomial or split a single binomial among multiple clusters. By applying a scoring scheme for full and partial name <strong><span style="color:yellowgreen">match</span></strong>es in pairs of clusters, a maximum weight set of 7366 global species units was produced. Varying the <strong><span style="color:yellowgreen">match</span></strong> weights for partial <strong><span style="color:yellowgreen">match</span></strong>es had little effect on the number of units, although if partial <strong><span style="color:yellowgreen">match</span></strong>es were disallowed, the number increased greatly. Trees from the resulting supermatrices generally produced tree topologies in good agreement with the higher taxonomy of Coleoptera, with fewer terminals compared with trees generated according to standard filtering of sequences using species labels. The study illustrates a strategy for assembling the tree-of-life from an ever more complex primary database. [BlastClust; data mining; graph theory; incongruence; multipartite <strong><span style="color:yellowgreen">match</span></strong>ing; species delimitation; supermatrix.]</p>
http://sysbio.oxfordjournals.org/cgi/content/abstract/62/3/456
10.1093/sysbio/syt011
['Coleoptera', 'beetles']

5
Circulation
Higher Risk of Vascular Dementia in Myocardial Infarction Survivors
<sec><title>Background:</title><p>Increased risk of dementia after myocardial infarction (MI) may be mediated by shared risk factors (eg, atherosclerosis) and post-MI stroke. We examined risk of dementia in 1-year survivors of MI.</p></sec><sec><title>Methods:</title><p>Using Danish medical registries, we conducted a nationwide population-based cohort study of all patients with first-time MI and a sex-, birth year–, and calendar year–<strong><span style="color:yellowgreen">match</span></strong>ed general population <strong><span style="color:yellowgreen">comparison</span></strong> cohort without MI (1980–2012). Cox regression analysis was used to compute 1- to 35-year adjusted hazard ratios (aHRs) for dementia, controlled for <strong><span style="color:yellowgreen">match</span></strong>ing factors and adjusted for comorbidities and socioeconomic status.</p></sec><sec><title>Results:</title><p>We identified 314 911 patients with MI and 1 573 193 <strong><span style="color:yellowgreen">match</span></strong>ed <strong><span style="color:yellowgreen">comparison</span></strong> cohort members randomly sampled from the general population (median age, 70 years; 63% male). After 35 years of follow-up, the cumulative incidence of all-cause dementia in the MI cohort was 9% (2.8% for Alzheimer disease, 1.6% for vascular dementia, and 4.5% for other dementias). Compared with the general population cohort, MI was not associated with all-cause dementia (aHR, 1.01; 95% confidence interval [CI], 0.98–1.03). Risk of Alzheimer disease (aHR, 0.92; 95% CI, 0.88–0.95) and other dementias (aHR, 0.98; 95% CI, 0.95–1.01) also approximated unity. However, MI was associated with higher risk of vascular dementia (aHR, 1.35; 95% CI, 1.28–1.43), which was substantially strengthened for patients experiencing stroke after MI (aHR, 4.48; 95% CI, 3.29–6.12).</p></sec><sec><title>Conclusions:</title><p>MI was associated with higher risk of vascular dementia throughout follow-up, and this association was stronger in patients with stroke. The risk of Alzheimer disease and other dementias was not higher in patients with MI.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/6/567
10.1161/CIRCULATIONAHA.117.029127
None

5
Circulation
Validity of Cardiovascular Data From Electronic Sources
<sec><title>Background:</title><p>Understanding the validity of data from electronic data research networks is critical to national research initiatives and learning healthcare systems for cardiovascular care. Our goal was to evaluate the degree of agreement of electronic data research networks in <strong><span style="color:yellowgreen">comparison</span></strong> with data collected by standardized research approaches in a cohort study.</p></sec><sec><title>Methods:</title><p>We linked individual-level data from MESA (Multi-Ethnic Study of Atherosclerosis), a community-based cohort, with HealthLNK, a 2006 to 2012 database of electronic health records from 6 Chicago health systems. To evaluate the correlation and agreement of blood pressure in HealthLNK in <strong><span style="color:yellowgreen">comparison</span></strong> with in-person MESA examinations, and body mass index in HealthLNK in <strong><span style="color:yellowgreen">comparison</span></strong> with MESA, we used Pearson correlation coefficients and Bland-Altman plots. Using diagnoses in MESA as the criterion standard, we calculated the performance of HealthLNK for hypertension, obesity, and diabetes mellitus diagnosis by using <i>International Classification of Diseases, Ninth Revision</i> codes and clinical data. We also identified potential myocardial infarctions, strokes, and heart failure events in HealthLNK and compared them with adjudicated events in MESA.</p></sec><sec><title>Results:</title><p>Of the 1164 MESA participants enrolled at the Chicago Field Center, 802 (68.9%) participants had data in HealthLNK. The correlation was low for systolic blood pressure (0.39; <i>P</i><0.0001). In <strong><span style="color:yellowgreen">comparison</span></strong> with MESA, HealthLNK overestimated systolic blood pressure by 6.5 mm Hg (95% confidence interval, 4.2–7.8). There was a high correlation between body mass index in MESA and HealthLNK (0.94; <i>P</i><0.0001). HealthLNK underestimated body mass index by 0.3 kg/m<sup>2</sup> (95% confidence interval, –0.4 to –0.1). With the use of <i>International Classification of Diseases, Ninth Revision</i> codes and clinical data, the sensitivity and specificity of HealthLNK queries for hypertension were 82.4% and 59.4%, for obesity were 73.0% and 89.8%, and for diabetes mellitus were 79.8% and 93.3%. In <strong><span style="color:yellowgreen">comparison</span></strong> with adjudicated cardiovascular events in MESA, the concordance rates for myocardial infarction, stroke, and heart failure were, respectively, 41.7% (5/12), 61.5% (8/13), and 62.5% (10/16).</p></sec><sec><title>Conclusions:</title><p>These findings illustrate the limitations and strengths of electronic data repositories in <strong><span style="color:yellowgreen">comparison</span></strong> with information collected by traditional standardized epidemiological approaches for the ascertainment of cardiovascular risk factors and events.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/13/1207
10.1161/CIRCULATIONAHA.117.027436
None

5
Circulation
Atrial Fibrillation and Ventricular Arrhythmias
<p>Sex-specific differences in the epidemiology, pathophysiology, clinical presentation, clinical treatment, and clinical outcomes of atrial fibrillation (AF), sustained ventricular arrhythmias, and sudden cardiac death are recognized. Sex hormones cause differences in cardiac electrophysiological parameters between men and women that may affect the risk for arrhythmias. The incidence and prevalence of AF is lower in women than in men. However, because women live longer and AF prevalence increases with age, the absolute number of women with AF exceeds that of men. Women with AF are more symptomatic, present with more atypical symptoms, and report worse quality of life in <strong><span style="color:yellowgreen">comparison</span></strong> with men. Female sex is an independent risk factor for death or stroke attributable to AF. Oral anticoagulation therapy for stroke prevention has similar efficacy for men and women, but older women treated with warfarin have a higher residual risk of stroke in <strong><span style="color:yellowgreen">comparison</span></strong> with men. Women with AF are less likely to receive rhythm control antiarrhythmic drug therapy, electric cardioversion, or catheter ablation in <strong><span style="color:yellowgreen">comparison</span></strong> with men. The incidence and prevalence of sustained ventricular arrhythmias and sudden cardiac death are lower in women than in men. Women receiving implantable cardioverter defibrillators for primary prevention of sudden cardiac death are less likely to experience sustained ventricular arrhythmias in <strong><span style="color:yellowgreen">comparison</span></strong> with men. In contrast, women receiving a cardiac resynchronization therapy implantable cardioverter defibrillator for the treatment of heart failure are more likely to benefit than men. Women are less likely to be referred for implantable cardioverter defibrillator therapy despite current guideline recommendations. Women are more likely to experience a significant complication related to implantable cardioverter defibrillator implantation in <strong><span style="color:yellowgreen">comparison</span></strong> with men. Whether sex differences in treatment decisions reflect patient preferences or treatment biases requires further study.</p>
http://circ.ahajournals.org/cgi/content/abstract/135/6/593
10.1161/CIRCULATIONAHA.116.025312
None

4
The Bone & Joint Journal
Long-term outcomes of cemented <i>versus</i> cementless humeral components in arthroplasty of the shoulder
<sec><title>Aims</title><p>In the initial development of total shoulder arthroplasty (TSA),   the humeral component was usually fixed with cement. Cementless   components were subsequently introduced. The aim of this study was   to compare the long-term outcome of cemented and cementless humeral   components in arthroplasty of the shoulder.</p></sec><sec><title>Patients and Methods</title><p>All patients who underwent primary arthroplasty of the shoulder   at our institution between 1970 and 2012 were included in the study.   There were 4636 patients with 1167 cemented humeral components and   3469 cementless components. Patients with the two types of fixation   were <strong><span style="color:yellowgreen">match</span></strong>ed for nine different covariates using a propensity score   analysis. A total of 551 well-balanced pairs of patients with cemented   and cementless components were available after <strong><span style="color:yellowgreen">match</span></strong>ing for <strong><span style="color:yellowgreen">comparison</span></strong>   of the outcomes. The clinical outcomes which were analysed included loosening   of the humeral component determined at revision surgery, periprosthetic   fractures, post-operative infection and operating time.</p></sec><sec><title>Results</title><p>The overall five-, ten-, 15- and 20-year rates of survival were   98.9%, 97.2%, 95.5%, and 94.4%, respectively. Survival without loosening   at 20 years was 98% for cemented components and 92.4% for cementless   components. After propensity score <strong><span style="color:yellowgreen">match</span></strong>ing including fixation as   determined by the design of the component, humeral loosening was   also found to be significantly higher in the cementless group. Survival   without humeral loosening at 20 years was 98.7% for cemented components   and 91.0% for cementless components. There was no significant difference   in the risk of intra- or post-operative fracture. The rate of survival   without deep infection and the mean operating time were significantly   higher in the cemented group.</p></sec><sec><title>Conclusion</title><p>Both types of fixation give rates of long-term survival of >   90%. Cemented components have better rates of survival without loosening   but this should be weighed against increased operating time and   the risk of bony destruction of the proximal humerus at the time   of revision of a cemented humeral component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:666–73.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/666
10.1302/0301-620X.99B5.BJJ-2016-0910.R1
None

4
The Bone & Joint Journal
The impact of external fixation on mortality in patients with an unstable pelvic ring fracture
<sec><title>Aim</title><p>There is not adequate evidence to establish whether external   fixation (EF) of pelvic fractures leads to a reduced mortality.   We used the Japan Trauma Data Bank database to identify isolated   unstable pelvic ring fractures to exclude the possibility of blood   loss from other injuries, and analyzed the effectiveness of EF on   mortality in this group of patients.</p></sec><sec><title>Patients and Methods</title><p>This was a registry-based <strong><span style="color:yellowgreen">comparison</span></strong> of 1163 patients who had   been treated for an isolated unstable pelvic ring fracture with   (386 patients) or without (777 patients) EF. An isolated pelvic   ring fracture was defined by an Abbreviated Injury Score (AIS) for   other injuries of < 3. An unstable pelvic ring fracture was defined   as having an AIS ≥ 4. The primary outcome of this study was mortality.   A subgroup analysis was carried out for patients who required blood   transfusion within 24 hours of arrival in the Emergency Department   and those who had massive blood loss (AIS code: 852610.5). Propensity-score   <strong><span style="color:yellowgreen">match</span></strong>ing was used to identify a cohort like the EF and non-EF groups.</p></sec><sec><title>Results</title><p>With the use of propensity-score <strong><span style="color:yellowgreen">match</span></strong>ing using the completed   data, 346 patients were <strong><span style="color:yellowgreen">match</span></strong>ed. When the propensity-score <strong><span style="color:yellowgreen">match</span></strong>ing   was adjusted, EF was associated with a significantly lower risk   of death (p = 0.047). In the subgroup analysis of patients who needed   blood transfusion within 24 hours and those who had massive blood loss,   EF was associated with a significantly lower risk of death in patients   who needed blood transfusion within 24 hours (p = 0.014) and in   those with massive blood loss (p = 0.016).</p></sec><sec><title>Conclusion</title><p>The use of EF to treat unstable pelvic ring fractures was associated   with a significantly lower risk of death, especially in patients   with severe fractures.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:233–41.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/233
10.1302/0301-620X.100B2.BJJ-2017-0852.R1
None

4
Circulation
Second Arterial Versus Venous Conduits for Multivessel Coronary Artery Bypass Surgery in California
<sec><title>Background:</title><p>Whether a second arterial conduit improves outcomes after multivessel coronary artery bypass grafting remains unclear. Consequently, arterial conduits other than the left internal thoracic artery are seldom used in the United States.</p></sec><sec><title>Methods:</title><p>Using a state-maintained clinical registry including all 126 nonfederal hospitals in California, we compared all-cause mortality and rates of stroke, myocardial infarction, repeat revascularization, and sternal wound infection between propensity score–<strong><span style="color:yellowgreen">match</span></strong>ed cohorts who underwent primary, isolated multivessel coronary artery bypass grafting with the left internal thoracic artery, and who received a second arterial conduit (right internal thoracic artery or radial artery, n=5866) or a venous conduit (n=53 566) between 2006 and 2011. Propensity score <strong><span style="color:yellowgreen">match</span></strong>ing using 34 preoperative characteristics yielded 5813 <strong><span style="color:yellowgreen">match</span></strong>ed sets. A subgroup analysis compared outcomes between propensity score–<strong><span style="color:yellowgreen">match</span></strong>ed recipients of a right internal thoracic artery (n=1576) or a radial artery (n=4290).</p></sec><sec><title>Results:</title><p>Second arterial conduit use decreased from 10.7% in 2006 to 9.1% in 2011 (<i>P</i><0.0001). However, receipt of a second arterial conduit was associated with significantly lower mortality (13.1% versus 10.6% at 7 years; hazard ratio, 0.79; 95% confidence interval [CI], 0.72–0.87), and lower risks of myocardial infarction (hazard ratio, 0.78; 95% CI, 0.70–0.87) and repeat revascularization (hazard ratio, 0.82; 95% CI, 0.76–0.88). In <strong><span style="color:yellowgreen">comparison</span></strong> with radial artery grafts, right internal thoracic artery grafts were associated with similar mortality rates (right internal thoracic artery 10.3% versus radial artery 10.7% at 7 years; hazard ratio, 1.10; 95% CI, 0.89–1.37) and individual risks of cardiovascular events, but the risk of sternal wound infection was increased (risk difference, 1.07%; 95% CI, 0.15–2.07).</p></sec><sec><title>Conclusions:</title><p>Second arterial conduit use in California is low and declining, but arterial grafts were associated with significantly lower mortality and fewer cardiovascular events. A right internal thoracic artery graft offered no benefit over that of a radial artery, but did increase risk of sternal wound infection. These findings suggest surgeons should consider lowering their threshold for using arterial grafts, and the radial artery may be the preferred second conduit.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/16/1698
10.1161/CIRCULATIONAHA.117.030959
None

4
Circulation
Does Use of Bilateral Internal Mammary Artery Grafting Reduce Long-Term Risk of Repeat Coronary Revascularization?
<sec><title>Background:</title><p>Although previous studies have demonstrated that patients receiving bilateral internal mammary artery (BIMA) conduits during coronary artery bypass grafting have better long-term survival than those receiving a single internal mammary artery (SIMA), data on risk of repeat revascularization are more limited. In this analysis, we compare the timing, frequency, and type of repeat coronary revascularization among patients receiving BIMA and SIMA.</p></sec><sec><title>Methods:</title><p>We conducted a multicenter, retrospective analysis of 47 984 consecutive coronary artery bypass grafting surgeries performed from 1992 to 2014 among 7 medical centers reporting to a prospectively maintained clinical registry. Among the study population, 1482 coronary artery bypass grafting surgeries with BIMA were identified, and 1297 patients receiving BIMA were propensity-<strong><span style="color:yellowgreen">match</span></strong>ed to 1297 patients receiving SIMA. The primary end point was freedom from repeat coronary revascularization.</p></sec><sec><title>Results:</title><p>The median duration of follow-up was 13.2 (IQR, 7.4–17.7) years. Patients were well <strong><span style="color:yellowgreen">match</span></strong>ed by age, body mass index, major comorbidities, and cardiac function. There was a higher freedom from repeat revascularization among patients receiving BIMA than among patients receiving SIMA (hazard ratio [HR], 0.78 [95% CI, 0.65–0.94]; <i>P</i>=0.009). Among the <strong><span style="color:yellowgreen">match</span></strong>ed cohort, 19.4% (n=252) of patients receiving SIMA underwent repeat revascularization, whereas this frequency was 15.1% (n=196) among patients receiving BIMA (<i>P</i>=0.004). The majority of repeat revascularization procedures were percutaneous coronary interventions (94.2%), and this did not differ between groups (<i>P</i>=0.274). Groups also did not differ in the ratio of native versus graft vessel percutaneous coronary intervention (<i>P</i>=0.899), or regarding percutaneous coronary intervention target vessels; the most common targets in both groups were the right coronary (<i>P</i>=0.133) and circumflex arteries (<i>P</i>=0.093). In <strong><span style="color:yellowgreen">comparison</span></strong> with SIMA, BIMA grafting was associated with a reduction in all-cause mortality at 12 years of follow-up (HR, 0.79 [95% CI, 0.69–0.91]; <i>P</i>=0.001), and there was no difference in in-hospital morbidity.</p></sec><sec><title>Conclusions:</title><p>BIMA grafting was associated with a reduced risk of repeat revascularization and an improvement in long-term survival and should be considered more frequently during coronary artery bypass grafting.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1676
10.1161/CIRCULATIONAHA.117.027405
None

4
Circulation
Patients With Long-QT Syndrome Caused by Impaired <i>hERG</i>-Encoded K<sub>v</sub>11.1 Potassium Channel Have Exaggerated Endocrine Pancreatic and Incretin Function Associated With Reactive Hypoglycemia
<sec><title>Background:</title><p>Loss-of-function mutations in <i>hERG</i> (encoding the K<sub>v</sub>11.1 voltage-gated potassium channel) cause long-QT syndrome type 2 (LQT2) because of prolonged cardiac repolarization. However, K<sub>v</sub>11.1 is also present in pancreatic α and β cells and intestinal L and K cells, secreting glucagon, insulin, and the incretins glucagon-like peptide-1 (GLP-1) and GIP (glucose-dependent insulinotropic polypeptide), respectively. These hormones are crucial for glucose regulation, and long-QT syndrome may cause disturbed glucose regulation. We measured secretion of these hormones and cardiac repolarization in response to glucose ingestion in LQT2 patients with functional mutations in <i>hERG</i> and <strong><span style="color:yellowgreen">match</span></strong>ed healthy participants, testing the hypothesis that LQT2 patients have increased incretin and β-cell function and decreased α-cell function, and thus lower glucose levels.</p></sec><sec><title>Methods:</title><p>Eleven patients with LQT2 and 22 sex-, age-, and body mass index–<strong><span style="color:yellowgreen">match</span></strong>ed control participants underwent a 6-hour 75-g oral glucose tolerance test with ECG recording and blood sampling for measurements of glucose, insulin, C-peptide, glucagon, GLP-1, and GIP.</p></sec><sec><title>Results:</title><p>In <strong><span style="color:yellowgreen">comparison</span></strong> with <strong><span style="color:yellowgreen">match</span></strong>ed control participants, LQT2 patients had 56% to 78% increased serum insulin, serum C-peptide, plasma GLP-1, and plasma GIP responses (<i>P</i>=0.03–0.001) and decreased plasma glucose levels after glucose ingestion (<i>P</i>=0.02) with more symptoms of hypoglycemia (<i>P</i>=0.04). Sixty-three percent of LQT2 patients developed hypoglycemic plasma glucose levels (<70 mg/dL) versus 36% control participants (<i>P</i>=0.16), and 18% patients developed serious hypoglycemia (<50 mg/dL) versus none of the controls. LQT2 patients had defective glucagon responses to low glucose, <i>P</i>=0.008. β-Cell function (Insulin Secretion Sensitivity Index-2) was 2-fold higher in LQT2 patients than in controls (4398 [95% confidence interval, 2259–8562] versus 2156 [1961–3201], <i>P</i>=0.03). Pharmacological K<sub>v</sub>11.1 blockade (dofetilide) in rats had similar effect, and small interfering RNA inhibition of <i>hERG</i> in β and L cells increased insulin and GLP-1 secretion up to 50%. Glucose ingestion caused cardiac repolarization disturbances with increased QTc intervals in both patients and controls, but with a 122% greater increase in QTcF interval in LQT2 patients (<i>P</i>=0.004).</p></sec><sec><title>Conclusions:</title><p>Besides a prolonged cardiac repolarization phase, LQT2 patients display increased GLP-1, GIP, and insulin secretion and defective glucagon secretion, causing decreased plasma glucose and thus increased risk of hypoglycemia. Furthermore, glucose ingestion increased QT interval and aggravated the cardiac repolarization disturbances in LQT2 patients.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT02775513.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/18/1705
10.1161/CIRCULATIONAHA.116.024279
None

3
Molecular Biology and Evolution
Expansion of Secretin-Like G Protein-Coupled Receptors and Their Peptide Ligands via Local Duplications Before and After Two Rounds of Whole-Genome Duplication
<p>In humans, the secretin-like G protein-coupled receptor (GPCR) family comprises 15 members with 18 corresponding peptide ligand genes. Although members have been identified in a large variety of vertebrate and nonvertebrate species, the origin and relationship of these proteins remain unresolved. To address this issue, we employed large-scale genome <strong><span style="color:yellowgreen">comparison</span></strong>s to identify genome fragments with conserved synteny and <strong><span style="color:yellowgreen">match</span></strong>ed these fragments to linkage groups in reconstructed early gnathostome ancestral chromosomes (<i>GAC</i>). This genome <strong><span style="color:yellowgreen">comparison</span></strong> revealed that most receptor and peptide genes were clustered in three <i>GAC</i> linkage groups and suggested that the ancestral forms of five peptide subfamilies (corticotropin-releasing hormone-like, calcitonin-like, parathyroid hormone-like, glucagon-like, and growth hormone-releasing hormone-like) and their cognate receptor families emerged through tandem local gene duplications before two rounds (2R) of whole-genome duplication. These subfamily genes have, then, been amplified by 2R whole-genome duplication, followed by additional local duplications and gene loss prior to the divergence of land vertebrates and teleosts. This study delineates a possible evolutionary scenario for whole secretin-like peptide and receptor family members and may shed light on evolutionary mechanisms for expansion of a gene family with a large number of paralogs.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1119
10.1093/molbev/mst031
['vertebrates']

3
Journal of Experimental Biology
Trans-generational plasticity in physiological thermal tolerance is modulated by maternal pre-reproductive environment in the polychaete <i>Ophryotrocha labronica</i>
<p>Maternal temperature is known to affect many aspects of offspring phenotype, but its effect on offspring physiological thermal tolerance has received less attention, despite the importance of physiological traits in defining organismal ability to cope with temperature changes. To fill this gap, we used the marine polychaete <i>Ophryotrocha labronica</i> to investigate the influence of maternal temperature on offspring upper and lower thermal tolerance limits, and assess whether maternal influence changed according to the stage of offspring pre-zygotic development at which a thermal cue was provided. Measurements were taken on adult offspring acclimated to 18 or 30°C, produced by mothers previously reared at 24°C and then exposed to 18 or 30°C at an early and late stage of oogenesis. When the shift from 24°C was provided early during oogenesis, mothers produced offspring with greater cold and heat tolerance whenever mother–offspring temperatures did not <strong><span style="color:yellowgreen">match</span></strong>, with respect to when they <strong><span style="color:yellowgreen">match</span></strong>ed, suggesting the presence of an anticipatory maternal effect triggered by the thermal variation. Conversely, when the cue was provided later during oogenesis, more tolerant offspring were observed when temperatures persisted across generations. In this case, maternal exposure to 18 or 30°C may have benefited offspring performance, while limitations in the transmission of the thermal cue may account for the lack of correlation between maternal experiences and offspring performance when mother–offspring environments did not <strong><span style="color:yellowgreen">match</span></strong>. Our results provided evidence for a trans-generational effect of temperature on physiological performance characterised by a high context dependency, and are discussed in the light of maternal pre-reproductive experiences.</p>
http://jeb.biologists.org/cgi/content/abstract/217/11/2004
10.1242/jeb.094474
['Ophryotrocha', 'Ophryotrocha labronica']

3
The Bone & Joint Journal
Risk of early mortality after cemented compared with cementless total hip arthroplasty
<sec><title>Aims</title><p>It has been suggested that cemented fixation of total hip arthroplasty   (THA) is associated with an increased peri-operative mortality compared   with cementless THA. Our aim was to investigate this through a nationwide   <strong><span style="color:yellowgreen">match</span></strong>ed cohort study adjusting for age, comorbidity, and socioeconomic   background.</p></sec><sec><title>Patients and Methods</title><p>A total of 178 784 patients with osteoarthritis who underwent   either cemented or cementless THA from the Swedish Hip Arthroplasty   Register were <strong><span style="color:yellowgreen">match</span></strong>ed with 862 294 controls from the general population.   Information about the causes of death, comorbidities, and socioeconomic   background was obtained. Mortality within the first 90 days after   the operation was the primary outcome measure.</p></sec><sec><title>Results</title><p>Patients who underwent cemented THA had an increased risk of   death during the first 14 days compared with the controls (hazard   ratio (HR) 1.3, confidence interval (CI) 1.11 to 1.44), corresponding   to an absolute increase in risk of five deaths per 10 000 observations.   No such early increase of risk was seen in those who underwent cementless THA.   Between days 15 and 29 the risk of mortality was decreased for those   with cemented THA (HR 0.7, CI 0.62 to 0.87). Between days 30 and   90 all patients undergoing THA, irrespective of the mode of fixation,   had a lower risk of death than controls. Patients selected for cementless   fixation were younger, healthier and had a higher level of education   and income than those selected for cemented THA. A supplementary   analysis of 16 556 hybrid THAs indicated that cementation of the   femoral component was associated with a slight increase in mortality   up to 15 days, whereas no such increase in mortality was seen in   those with a cemented acetabular component combined with a cementless   femoral component.</p></sec><sec><title>Conclusion</title><p>This nationwide <strong><span style="color:yellowgreen">match</span></strong>ed cohort study indicates that patients   receiving cemented THA have a minimally increased relative risk   of early mortality that is reversed from day 15 and thereafter.   The absolute increase in risk is very small. Our findings lend support   to the idea that cementation of the femoral component is more dangerous   than cementation of the acetabular component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:37–43.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/1/37
10.1302/0301-620X.99B1.BJJ-2016-0304.R1
None

3
The Bone & Joint Journal
Metal-on-metal total hip arthroplasty is not associated with cardiac disease
<sec><title>Aims</title><p>Many case reports and small studies have suggested that cobalt   ions are a potential cause of cardiac complications, specifically   cardiomyopathy, after metal-on-metal (MoM) total hip arthroplasty   (THA). The impact of metal ions on the incidence of cardiac disease   after MoM THA has not been evaluated in large studies. The aim of   this study was to compare the rate of onset of new cardiac symptoms   in patients who have undergone MoM THA with those who have undergone   metal-on-polyethylene (MoP) THA.</p></sec><sec><title>Patients and Methods</title><p>Data were extracted from the Standard Analytics Files database   for patients who underwent MoM THA between 2005 and 2012. Bearing   surface was selected using International Classification of Diseases   ninth revision codes. Patients with a minimum five-year follow-up   were selected. An age and gender-<strong><span style="color:yellowgreen">match</span></strong>ed cohort of patients who underwent   MoP THA served as a <strong><span style="color:yellowgreen">comparison</span></strong> group. New diagnoses of cardiac disease   were collected during the follow-up period. Comorbidities and demographics   were identified and routine descriptive statistics were used.</p></sec><sec><title>Results</title><p>We identified 29 483 patients who underwent MoM THA and 24 175   <strong><span style="color:yellowgreen">match</span></strong>ed patients who underwent MoP THA. Both groups had a mean Charlson   comorbidity index score of 4. There were no statistically significant   differences in 30 of 31 pre-existing comorbidities. Patients undergoing   MoM THA had a slightly lower incidence of cardiac failure compared   with those undergoing MoP THA at three years (6.60% <i>versus</i> 7.06%,   odds ratio (OR) 0.93, 95% confidence interval (CI) 0.87 to 0.99)   and four years (8.73% <i>versus</i> 9.49%, OR 0.91, 95%   CI 0.86 to 0.97) postoperatively, with no difference in the incidence   of new cardiac failure in between the groups at five years. There   was no statistically significant difference in the incidence of   arrhythmia, myocardial infarction and cardiomyopathy at any time   between the two groups.</p></sec><sec><title>Conclusion</title><p>MoM THA is not associated with cardiac complications. Initial   reports may have represented individual instances of cardiac disease   in patients with a failing MoM articulation rather than an emerging   epidemiological trend.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:28–32.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1/28
10.1302/0301-620X.100B1.BJJ-2017-0366.R1
None

3
Circulation
Atrial Fibrillation Burden in Young Patients With Congenital Heart Disease
<sec><title>Background:</title><p>Patients with congenital heart disease (CHD) are assumed to be vulnerable to atrial fibrillation (AF) as a result of residual shunts, anomalous vessel anatomy, progressive valvulopathy, hypertension, and atrial scars from previous heart surgery. However, the risk of developing AF and the complications associated with AF in children and young adults with CHD have not been compared with those in control subjects.</p></sec><sec><title>Methods:</title><p>Data from the Swedish Patient and Cause of Death registers were used to identify all patients with a diagnosis of CHD who were born from 1970 to 1993. Each patient with CHD was <strong><span style="color:yellowgreen">match</span></strong>ed by birth year, sex, and county with 10 control subjects from the Total Population Register in Sweden. Follow-up data were collected until 2011.</p></sec><sec><title>Results:</title><p>Among 21 982 patients (51.6% men) with CHD and 219 816 <strong><span style="color:yellowgreen">match</span></strong>ed control subjects, 654 and 328 developed AF, respectively. The mean follow-up was 27 years. The risk of developing AF was 21.99 times higher (95% confidence interval, 19.26–25.12) in patients with CHD than control subjects. According to a hierarchical CHD classification, patients with conotruncal defects had the highest risk (hazard ratio, 84.27; 95% confidence interval, 56.86–124.89). At the age of 42 years, 8.3% of all patients with CHD had a recorded diagnosis of AF. Heart failure was the quantitatively most important complication in patients with CHD and AF, with a 10.7% (70 of 654) recorded diagnosis of heart failure.</p></sec><sec><title>Conclusions:</title><p>The risk of AF in children and young adults with CHD was 22 times higher than that in <strong><span style="color:yellowgreen">match</span></strong>ed control subjects. Up to the age of 42 years, 1 of 12 patients with CHD had developed AF, and 1 of 10 patients with CHD with AF had developed heart failure. The patient groups with the most complex congenital defects carried the greatest risk of AF and could be considered for targeted monitoring.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/9/928
10.1161/CIRCULATIONAHA.117.029590
None

3
Circulation
Surgical Enlargement of the Aortic Root Does Not Increase the Operative Risk of Aortic Valve Replacement
<sec><title>Background:</title><p>Surgical aortic root enlargement (ARE) during aortic valve replacement (AVR) allows for larger prosthesis implantation and may be an important adjunct to surgical AVR in the transcatheter valve-in-valve era. The incremental operative risk of adding ARE to AVR has not been established. We aimed to evaluate the early outcomes of patients undergoing AVR with or without ARE.</p></sec><sec><title>Methods:</title><p>From January 1990 to August 2014, 7039 patients underwent AVR (AVR+ARE, n=1854; AVR, n=5185) at a single institution. Patients with aortic dissection and active endocarditis were excluded. Mean age was 65±14 years and 63% were male. Logistic regression and propensity score <strong><span style="color:yellowgreen">match</span></strong>ing were used to adjust for unbalanced variables in group <strong><span style="color:yellowgreen">comparison</span></strong>s.</p></sec><sec><title>Results:</title><p>Patients undergoing AVR+ARE were more likely to be female (46% versus 34%, <i>P</i><0.001) and had higher rates of previous cardiac surgery (18% versus 12%, <i>P</i><0.001), chronic obstructive pulmonary disease (5% versus 3%, <i>P</i>=0.004), urgent/emergent status (6% versus 4%, <i>P</i>=0.01), and worse New York Heart Association status (<i>P</i><0.001). Most patients received bioprosthetic valves (AVR+ARE: 73.4% versus AVR: 73.3%, <i>P</i>=0.98) and also underwent concomitant cardiac procedures (AVR+ARE: 68% versus AVR: 67%, <i>P</i>=0.31). Mean prosthesis size implanted was slightly smaller in patients requiring AVR+ARE versus AVR (23.4±2.1 versus 24.1±2.3, <i>P</i><0.001). In-hospital mortality was higher after AVR+ARE (4.3% versus 3.0%, <i>P</i>=0.008), although when the cohort was restricted to patients undergoing isolated aortic valve replacement with or without root enlargement, mortality was not statistically different (AVR+ARE: 1.7% versus AVR: 1.1%, <i>P</i>=0.29). After adjustment for baseline characteristics, AVR+ARE was not associated with an increased risk of in-hospital mortality when compared with AVR (odds ratio, 1.03; 95% confidence interval, 0.75–1.41; <i>P</i>=0.85). Furthermore, AVR+ARE was not associated with an increased risk of postoperative adverse events. Results were similar if propensity <strong><span style="color:yellowgreen">match</span></strong>ing was used instead of multivariable adjustments for baseline characteristics.</p></sec><sec><title>Conclusions:</title><p>In the largest analysis to date, ARE was not associated with increased risk of mortality or adverse events. Surgical ARE is a safe adjunct to AVR in the modern era.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/15/1585
10.1161/CIRCULATIONAHA.117.030525
None

3
Circulation
Impact of Left Atrial Appendage Closure During Cardiac Surgery on the Occurrence of Early Postoperative Atrial Fibrillation, Stroke, and Mortality
<sec><title>Background:</title><p>Prophylactic exclusion of the left atrial appendage (LAA) is often performed during cardiac surgery ostensibly to reduce the risk of stroke. However, the clinical impact of LAA closure in humans remains inconclusive.</p></sec><sec><title>Methods:</title><p>Of 10 633 adults who underwent coronary artery bypass grafting and valve surgery between January 2000 and December 2005, 9792 patients with complete baseline characteristics, surgery procedure, and follow-up data were included in this analysis. A propensity score–<strong><span style="color:yellowgreen">match</span></strong>ing analysis based on 28 pretreatment covariates was performed and 461 <strong><span style="color:yellowgreen">match</span></strong>ing pairs were derived and analyzed to estimate the association of LAA closure with early postoperative atrial fibrillation (POAF) (atrial fibrillation ≤30 days of surgery), ischemic stroke, and mortality.</p></sec><sec><title>Results:</title><p>In the propensity-<strong><span style="color:yellowgreen">match</span></strong>ed cohort, the overall incidence of POAF was 53.9%. In this group, the rate of early POAF among the patients who underwent LAA closure was 68.6% versus 31.9% for those who did not undergo the procedure (<i>P</i><0.001). LAA closure was independently associated with an increased risk of early POAF (adjusted odds ratio, 3.88; 95% confidence interval, 2.89–5.20), but did not significantly influence the risk of stroke (adjusted hazard ratio, 1.07; 95% confidence interval, 0.72–1.58) or mortality (adjusted hazard ratio, 0.92; 95% confidence interval, 0.75–1.13).</p></sec><sec><title>Conclusions:</title><p>After adjustment for treatment allocation bias, LAA closure during routine cardiac surgery was significantly associated with an increased risk of early POAF, but it did not influence the risk of stroke or mortality. It remains uncertain whether prophylactic exclusion of the LAA is warranted for stroke prevention during non–atrial fibrillation-related cardiac surgery.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/4/366
10.1161/CIRCULATIONAHA.116.021952
None

2
PLANT PHYSIOLOGY
Regeneration of <i>Solanum tuberosum</i> Plants from Protoplasts Induces Widespread Genome Instability
<p>Nontransgenic genome editing in regenerable protoplasts, plant cells free of their cell wall, could revolutionize crop improvement because it reduces regulatory and technical complexity. However, plant tissue culture is known to engender frequent unwanted variation, termed somaclonal variation. To evaluate the contribution of large-scale genome instability to this phenomenon, we analyzed potatoes (<i>Solanum tuberosum</i>) regenerated from either protoplasts or stem explants for copy number changes by <strong><span style="color:yellowgreen">comparison</span></strong> of Illumina read depth. Whereas a control set of eight plants that had been propagated by cuttings displayed no changes, all 15 protoplast regenerants tested were affected by aneuploidy or structural chromosomal changes. Certain chromosomes displayed segmental deletions and duplications ranging from one to many. Resampling different leaves of the same plant found differences in three regenerants, indicating frequent persistence of instability. By <strong><span style="color:yellowgreen">comparison</span></strong>, 33 regenerants from stem explants used for <i>Agrobacterium</i>-mediated transformation displayed less frequent but still considerable (18%) large-scale copy number changes. Repetition of certain instability patterns suggested greater susceptibility in specific genomic sites. These results indicate that tissue culture, depending on the protocol used, can induce genomic instability resulting in large-scale changes likely to compromise final plant phenotype.</p>
http://plantphysiol.org/cgi/content/abstract/180/1/78
10.1104/pp.18.00906
['Solanum', 'Solanum tuberosum', 'plants']

2
PLANT PHYSIOLOGY
Plant Phenotyping: An Active Vision Cell for Three-Dimensional Plant Shoot Reconstruction
<p>Three-dimensional (3D) computer-generated models of plants are urgently needed to support both phenotyping and simulation-based studies such as photosynthesis modeling. However, the construction of accurate 3D plant models is challenging, as plants are complex objects with an intricate leaf structure, often consisting of thin and highly reflective surfaces that vary in shape and size, forming dense, complex, crowded scenes. We address these issues within an image-based method by taking an active vision approach, one that investigates the scene to intelligently capture images, to image acquisition. Rather than use the same camera positions for all plants, our technique is to acquire the images needed to reconstruct the target plant, tuning camera placement to <strong><span style="color:yellowgreen">match</span></strong> the plant’s individual structure. Our method also combines volumetric- and surface-based reconstruction methods and determines the necessary images based on the analysis of voxel clusters. We describe a fully automatic plant modeling/phenotyping cell (or module) comprising a six-axis robot and a high-precision turntable. By using a standard color camera, we overcome the difficulties associated with laser-based plant reconstruction methods. The 3D models produced are compared with those obtained from fixed cameras and evaluated by <strong><span style="color:yellowgreen">comparison</span></strong> with data obtained by x-ray microcomputed tomography across different plant structures. Our results show that our method is successful in improving the accuracy and quality of data obtained from a variety of plant types.</p>
http://plantphysiol.org/cgi/content/abstract/178/2/524
10.1104/pp.18.00664
['plants']

2
PLANT PHYSIOLOGY
Reproductive Long Intergenic Noncoding RNAs Exhibit Male Gamete Specificity and Polycomb Repressive Complex 2-Mediated Repression
<p>Long noncoding RNAs (lncRNAs) have been characterized extensively in animals and are involved in several processes, including homeobox gene expression and X-chromosome inactivation. In <strong><span style="color:yellowgreen">comparison</span></strong>, there has been much less detailed characterization of plant lncRNAs, and the number of distinct lncRNAs encoded in plant genomes and their regulation by developmental and epigenetic mechanisms remain largely unknown. Here, we analyzed transcriptome data from Asian rice (<i>Oryza sativa</i>) and identified 6,309 long intergenic noncoding RNAs (lincRNAs), focusing on their expression in reproductive tissues and organs. Most <i>O. sativa</i> lincRNAs were expressed in a highly tissue-specific manner, with an unexpectedly high fraction specifically expressed in male gametes. Mutation of a component of the Polycomb Repressive Complex2 (PRC2) resulted in derepression of another large class of lincRNAs, whose expression is correlated with H3K27 trimethylation in developing panicles. Overlap with the sperm cell-specific lincRNAs suggests that epigenetic repression of lincRNAs in the panicles was partially relieved in the male germline. Expression of a subset of lincRNAs also showed modulation by drought in reproductive tissues. <strong><span style="color:yellowgreen">comparison</span></strong> with other cereal genomes showed that the lincRNAs generally have low levels of conservation at both the sequence and structural levels. Use of a novelty detection support vector machine model enabled the detection of nucleotide sequence and structural homology in ∼10% and ∼4% of the lincRNAs in genomes of purple false brome (<i>Brachypodium distachyon</i>) and maize (<i>Zea mays</i>), respectively. This is the first study to report on a large number of lncRNAs that are targets of repression by PRC2 rather than mediating regulation via PRC2. That the vast majority of the lincRNAs reported here do not overlap with those of other rice studies indicates that these are a significant addition to the known lincRNAs in rice.</p>
http://plantphysiol.org/cgi/content/abstract/177/3/1198
10.1104/pp.17.01269
['Brachypodium', 'Brachypodium distachyon', 'Oryza', 'Oryza sativa', 'Zea', 'Zea mays', 'animals', 'maize', 'rice']

2
PLANT PHYSIOLOGY
OsbZIP48, a HY5 Transcription Factor Ortholog, Exerts Pleiotropic Effects in Light-Regulated Development
<p>Plants have evolved an intricate network of sensory photoreceptors and signaling components to regulate their development. Among the light signaling components identified to date, HY5, a basic leucine zipper (bZIP) transcription factor, has been investigated extensively. However, most of the work on HY5 has been carried out in Arabidopsis (<i>Arabidopsis thaliana</i>), a dicot. In this study, based on homology search and phylogenetic analysis, we identified three homologs of AtHY5 in monocots; however, AtHYH (HY5 homolog) homologs are absent in the monocots analyzed. Out of the three homologs identified in rice (<i>Oryza sativa</i>), we have functionally characterized <i>OsbZIP48</i>. <i>OsbZIP48</i> was able to complement the <i>Athy5</i> mutant. OsbZIP48 protein levels are developmentally regulated in rice. Moreover, the OsbZIP48 protein does not degrade in dark-grown rice and <i>Athy5</i> seedlings complemented with <i>OsbZIP48</i>, which is in striking contrast to AtHY5. In <strong><span style="color:yellowgreen">comparison</span></strong> with <i>AtHY5</i>, which does not cause any change in hypocotyl length when overexpressed in Arabidopsis, the overexpression of full-length <i>OsbZIP48</i> in rice transgenics reduced the plant height considerably. Microarray analysis revealed that <i>OsKO2</i>, which encodes <i>ent</i>-kaurene oxidase 2 of the gibberellin biosynthesis pathway, is down-regulated in <i>OsbZIP48<sup>OE</sup></i> and up-regulated in <i>OsbZIP48<sup>KD</sup></i> transgenics as compared with the wild type. Electrophoretic mobility shift assay showed that OsbZIP48 binds directly to the <i>OsKO2</i> promoter. The RNA interference lines and the T-DNA insertional mutant of <i>OsbZIP48</i> showed seedling-lethal phenotypes despite the fact that roots were more proliferative during early stages of development in the T-DNA insertional mutant. These data provide credible evidence that OsbZIP48 performs more diverse functions in a monocot system like rice in <strong><span style="color:yellowgreen">comparison</span></strong> with its Arabidopsis ortholog, HY5.</p>
http://plantphysiol.org/cgi/content/abstract/176/2/1262
10.1104/pp.17.00478
['Arabidopsis', 'Arabidopsis thaliana', 'Oryza', 'Oryza sativa', 'rice']

2
PLANT PHYSIOLOGY
A High-Throughput, Field-Based Phenotyping Technology for Tall Biomass Crops
<p>Recent advances in omics technologies have not been accompanied by equally efficient, cost-effective, and accurate phenotyping methods required to dissect the genetic architecture of complex traits. Even though high-throughput phenotyping platforms have been developed for controlled environments, field-based aerial and ground technologies have only been designed and deployed for short-stature crops. Therefore, we developed and tested Phenobot 1.0, an auto-steered and self-propelled field-based high-throughput phenotyping platform for tall dense canopy crops, such as sorghum (<i>Sorghum bicolor</i>). Phenobot 1.0 was equipped with laterally positioned and vertically stacked stereo RGB cameras. Images collected from 307 diverse sorghum lines were reconstructed in 3D for feature extraction. User interfaces were developed, and multiple algorithms were evaluated for their accuracy in estimating plant height and stem diameter. Tested feature extraction methods included the following: (1) User-interactive Individual Plant Height Extraction (UsIn-PHe) based on dense stereo three-dimensional reconstruction; (2) Automatic Hedge-based Plant Height Extraction (Auto-PHe) based on dense stereo 3D reconstruction; (3) User-interactive Dense Stereo Matching Stem Diameter Extraction; and (4) User-interactive Image Patch Stereo Matching Stem Diameter Extraction (IPaS-Di). Comparative genome-wide association analysis and ground-truth validation demonstrated that both UsIn-PHe and Auto-PHe were accurate methods to estimate plant height, while Auto-PHe had the additional advantage of being a completely automated process. For stem diameter, IPaS-Di generated the most accurate estimates of this biomass-related architectural trait. In summary, our technology was proven robust to obtain ground-based high-throughput plant architecture parameters of sorghum, a tall and densely planted crop species.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2008
10.1104/pp.17.00707
['Sorghum', 'Sorghum bicolor', 'sorghum']

2
PLANT PHYSIOLOGY
Processes Underlying a Reproductive Barrier in <i>indica</i>-<i>japonica</i> Rice Hybrids Revealed by Transcriptome Analysis<xref><sup>1</sup></xref>
<p>In rice (<i>Oryza sativa</i>), hybrids between <i>indica</i> and <i>japonica</i> subspecies are usually highly sterile, which provides a model system for studying postzygotic reproductive isolation. A killer-protector system, <i>S5</i>, composed of three adjacent genes (<i>ORF3</i>, <i>ORF4</i>, and <i>ORF5</i>), regulates female gamete fertility of <i>indica-japonica</i> hybrids. To characterize the processes underlying this system, we performed transcriptomic analyses of pistils from rice variety Balilla (BL), Balilla with transformed <i>ORF5+</i> (BL<i>5+</i>) producing sterile female gametes, and Balilla with transformed <i>ORF3+</i> and <i>ORF5+</i> (BL<i>3+5+</i>) producing fertile gametes. RNA sequencing of tissues collected before (MMC), during (MEI), and after (AME) meiosis of the megaspore mother cell detected 19,269 to 20,928 genes as expressed. <strong><span style="color:yellowgreen">comparison</span></strong> between BL<i>5+</i> and BL showed that <i>ORF5+</i> induced differential expression of 8,339, 6,278, and 530 genes at MMC, MEI, and AME, respectively. At MMC, large-scale differential expression of cell wall-modifying genes and biotic and abiotic response genes indicated that cell wall integrity damage induced severe biotic and abiotic stresses. The processes continued to MEI and induced endoplasmic reticulum (ER) stress as indicated by differential expression of ER stress-responsive genes, leading to programmed cell death at MEI and AME, resulting in abortive female gametes. In the BL<i>3+5+</i>/BL <strong><span style="color:yellowgreen">comparison</span></strong>, 3,986, 749, and 370 genes were differentially expressed at MMC, MEI, and AME, respectively. Large numbers of cell wall modification and biotic and abiotic response genes were also induced at MMC but largely suppressed at MEI without inducing ER stress and programed cell death , producing fertile gametes. These results have general implications for the understanding of biological processes underlying reproductive barriers.</p>
http://plantphysiol.org/cgi/content/abstract/174/3/1683
10.1104/pp.17.00093
['Oryza', 'Oryza sativa', 'rice']

2
Molecular Biology and Evolution
Phylogenetic Tools for Generalized HIV-1 Epidemics: Findings from the PANGEA-HIV Methods Comparison
<p>Viral phylogenetic methods contribute to understanding how HIV spreads in populations, and thereby help guide the design of prevention interventions. So far, most analyses have been applied to well-sampled concentrated HIV-1 epidemics in wealthy countries. To direct the use of phylogenetic tools to where the impact of HIV-1 is greatest, the Phylogenetics And Networks for Generalized HIV Epidemics in Africa (PANGEA-HIV) consortium generates full-genome viral sequences from across sub-Saharan Africa. Analyzing these data presents new challenges, since epidemics are principally driven by heterosexual transmission and a smaller fraction of cases is sampled. Here, we show that viral phylogenetic tools can be adapted and used to estimate epidemiological quantities of central importance to HIV-1 prevention in sub-Saharan Africa. We used a community-wide methods <strong><span style="color:yellowgreen">comparison</span></strong> exercise on simulated data, where participants were blinded to the true dynamics they were inferring. Two distinct simulations captured generalized HIV-1 epidemics, before and after a large community-level intervention that reduced infection levels. Five research groups participated. Structured coalescent modeling approaches were most successful: phylogenetic estimates of HIV-1 incidence, incidence reductions, and the proportion of transmissions from individuals in their first 3 months of infection correlated with the true values (Pearson correlation > 90%), with small bias. However, on some simulations, true values were markedly outside reported confidence or credibility intervals. The blinded <strong><span style="color:yellowgreen">comparison</span></strong> revealed current limits and strengths in using HIV phylogenetics in challenging settings, provided benchmarks for future methods’ development, and supports using the latest generation of phylogenetic tools to advance HIV surveillance and prevention.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/185
10.1093/molbev/msw217
None

2
Molecular Biology and Evolution
AGP: A Multimethods Web Server for Alignment-Free Genome Phylogeny
<p>Phylogenetic analysis based on alignment method meets huge challenges when dealing with whole-genome sequences, for example, recombination, shuffling, and rearrangement of sequences. Thus, various alignment-free methods for phylogeny construction have been proposed. However, most of these methods have not been implemented as tools or web servers. Researchers cannot use these methods easily with their data sets. To facilitate the usage of various alignment-free methods, we implemented most of the popular alignment-free methods and constructed a user-friendly web server for alignment-free genome phylogeny (AGP). AGP integrated the phylogenetic tree construction, visualization, and <strong><span style="color:yellowgreen">comparison</span></strong> functions together. Both AGP and all source code of the methods are available at <ext-link>http://www.herbbol.org:8000/agp</ext-link> (last accessed February 26, 2013). AGP will facilitate research in the field of whole-genome phylogeny and <strong><span style="color:yellowgreen">comparison</span></strong>.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1032
10.1093/molbev/mst021
None

2
Journal of Experimental Biology
Octopaminergic modulation of the visual flight speed regulator of <i>Drosophila</i>
<p>Recent evidence suggests that flies' sensitivity to large-field optic flow is increased by the release of octopamine during flight. This increase in gain presumably enhances visually mediated behaviors such as the active regulation of forward speed, a process that involves the <strong><span style="color:yellowgreen">comparison</span></strong> of a vision-based estimate of velocity with an internal set point. To determine where in the neural circuit this <strong><span style="color:yellowgreen">comparison</span></strong> is made, we selectively silenced the octopamine neurons in the fruit fly <i>Drosophila</i>, and examined the effect on vision-based velocity regulation in free-flying flies. We found that flies with inactivated octopamine neurons accelerated more slowly in response to visual motion than control flies, but maintained nearly the same baseline flight speed. Our results are parsimonious with a circuit architecture in which the internal control signal is injected into the visual motion pathway upstream of the interneuron network that estimates groundspeed.</p>
http://jeb.biologists.org/cgi/content/abstract/217/10/1737
10.1242/jeb.098665
['Drosophila', 'fruit fly']

2
Journal of Experimental Biology
Pheromones exert top-down effects on visual recognition in the jumping spider <i>Lyssomanes viridis</i>
<p>In diverse and productive habitats, predaceous arthropods are expected to frequently encounter dangerous conspecifics and heterospecifics. This should make quick and accurate discriminations between species and sexes adaptive. By simultaneously sampling both visual cues and pheromones, and by utilizing stringent species- and sex-specific visual recognition templates, an individual should be able to increase both its speed and accuracy in making such discriminations. We tested for the use and stringency of visual recognition templates in the jumping spider <i>Lyssomanes viridis</i> by presenting males with animated images of conspecifics, heterospecifics and composite images that combined the facial coloration and morphology of one sex or species with the leg coloration of another. Males' courtship <i>versus</i> threat displays indicated whether a stimulus was perceived as a potential mate or a threat. By comparing males' visual inspection times of, and display types towards, the various images in the presence <i>versus</i> absence of female pheromones, we were able to deduce whether males tend to inspect a subset of the color pattern and morphological features that make up their conspecific recognition templates (i.e. those on just the face or just the legs), or all features, and whether this changes in the presence of pheromones. We found that the male recognition template for conspecific female was surprisingly coarse, whereas the recognition template for conspecific male, and especially the male face, was more specific. Pheromones hastened the recognition of images with coloration and morphology closely <strong><span style="color:yellowgreen">match</span></strong>ing those of conspecifics, presumably by activating conspecific visual recognition templates. When males were presented with an image that was, overall, a poor <strong><span style="color:yellowgreen">match</span></strong> to a conspecific female, but that contained a subset of female or female-like features, female pheromones usually did not hasten recognition, but did increase the likelihood that the image would be identified as a female. Taken together, our data suggest that males examined features on both the face and the legs in both the presence and absence of pheromones, and that female pheromones tipped the balance in favor of a female identification when a male was unsure how to categorize an incongruous set of visual features.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1744
10.1242/jeb.071118
['Lyssomanes', 'Lyssomanes viridis', 'arthropods']

2
The Bone & Joint Journal
Cemented total hip arthroplasty following acetabular fracture
<sec><title>Aims</title><p>To evaluate the outcomes of cemented total hip arthroplasty (THA)   following a fracture of the acetabulum, with evaluation of risk   factors and <strong><span style="color:yellowgreen">comparison</span></strong> with a patient group with no history of fracture. </p></sec><sec><title>Patients and Methods</title><p>Between 1992 and 2016, 49 patients (33 male) with mean age of   57 years (25 to 87) underwent cemented THA at a mean of 6.5 years   (0.1 to 25) following acetabular fracture. A total of 38 had undergone   surgical fixation and 11 had been treated non-operatively; 13 patients   died at a mean of 10.2 years after THA (0.6 to 19). Patients were   assessed pre-operatively, at one year and at final follow-up (mean   9.1 years, 0.5 to 23) using the Oxford Hip Score (OHS). Implant   survivorship was assessed. An age and gender-<strong><span style="color:yellowgreen">match</span></strong>ed cohort of THAs   performed for non-traumatic osteoarthritis (OA) or avascular necrosis   (AVN) (n = 98) were used to compare complications and patient-reported outcome   measures (PROMs).</p></sec><sec><title>Results</title><p>The mean time from fracture to THA was significantly shorter   for patients with AVN    (2.2 years) or protrusio (2.2 years) than those with post-traumatic   OA (9.4 years) or infection (8.0 years) (p = 0.03). Nine contained   and four uncontained defects were managed with autograft (n = 11),   bulk allograft (n = 1), or trabecular metal augment (n = 1). Initial   fracture management (open reduction and internal fixation or non-operative),   timing of THA    (>/< one year), and age (>/< 55 years) had no significant   effect on OHS or ten-year survival. Six THAs were revised at mean   of 12 years (5 to 23) with ten-year all-cause survival of 92% (95%   confidence interval 80.8 to 100). THA complication rates (all complications,   heterotopic ossification, leg length discrepancy > 10 mm) were significantly higher   following acetabular fracture compared with atraumatic OA/AVN and   OHSs were inferior: one-year OHS    (35.7 v<i>ersus</i> 40.2, p = 0.026); and final follow-up   OHS (33.6 v<i>ersus</i> 40.9, p = 0.008). </p></sec><sec><title>Conclusion </title><p>Cemented THA is a reasonable option for the sequelae of acetabular   fracture. Higher complication rates and poorer PROMs, compared with   patients undergoing THA for atraumatic causes, reflects the complex   nature of these cases.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1399–1408.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/10/1399
10.1302/0301-620X.99B10.BJJ-2016-1261.R2
None

2
The Bone & Joint Journal
Comparative study of computer-assisted total knee arthroplasty after opening wedge osteotomy <i>versus</i> after unicompartmental arthroplasty
<sec><title>Aims</title><p>The role of high tibial osteotomy (HTO) is being questioned by   the use of unicompartmental knee arthroplasty (UKA) in the treatment   of medial compartment femorotibial osteoarthritis. Our aim was to   compare the outcomes of revision HTO or UKA to a total knee arthroplasty   (TKA) using computer-assisted surgery in <strong><span style="color:yellowgreen">match</span></strong>ed groups of patients.</p></sec><sec><title>Patients and Methods</title><p>We conducted a retrospective study to compare the clinical and   radiological outcome of patients who underwent revision of a HTO   to a TKA (group 1) with those who underwent revision of a medial   UKA to a TKA (group 2). All revision procedures were performed using   computer-assisted surgery. We extracted these groups of patients   from our database. They were <strong><span style="color:yellowgreen">match</span></strong>ed by age, gender, body mass index,   follow-up and pre-operative functional score. The outcomes included   the Knee Society Scores (KSS), radiological outcomes and the rate   of further revision.</p></sec><sec><title>Results</title><p>There were 20 knees in 20 patients in each group. The mean follow-up   was 4.1 years (2 to 18.7). The mean total KSS at last follow-up   was 185.7 (standard deviation (<sc>sd</sc>) 5) in group 1 compared   with 176.5 (<sc>sd</sc> 11) for group 2 (p = 0.003). The mean hip-knee-ankle   angle was 180.2° (<sc>sd</sc> 3.2°) in group 1 and 179.0° (<sc>sd</sc> 2.2°)   in group 2. No revision was required.</p></sec><sec><title>Conclusion</title><p>We found that good functional and radiological outcomes followed   revision of both HTO and UKA to TKA. Revision of HTO showed significantly   better functional outcomes. These results need to be further investigated   by a prospective randomised controlled trial involving a larger   group of patients.</p><p>Cite this article: <i>Bone Joint J</i> 2016;98-B:1620–4.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/98-B/12/1620
10.1302/0301-620X.98B12.38064
None

2
The Bone & Joint Journal
Mid-term outcomes of routine proximal row carpectomy compared with proximal row carpectomy with dorsal capsular interposition arthroplasty for the treatment of late-stage arthropathy of the wrist
<sec><title>Aims</title><p>The aims of this study were to compare the mid-term outcomes   of patients with late-stage arthritis of the wrist treated with   proximal row carpectomy (PRC) and dorsal capsular interposition   (DCI) arthroplasty with a <strong><span style="color:yellowgreen">match</span></strong>ed cohort treated with routine PRC   alone.</p></sec><sec><title>Patients and Methods</title><p>A total of 25 arthritic wrists (24 patients) with pre-existing   degenerative changes of the proximal capitate and/or the lunate   fossa of the radius were treated with PRC + DCI over a ten-year   period. This group of patients were <strong><span style="color:yellowgreen">match</span></strong>ed 1:2 with a group of   50 wrists (48 patients) without degenerative changes in the capitate   or lunate fossa that were treated with a routine PRC alone during   the same period. The mean age of the patients at the time of surgery   was 56.8 years (25 to 81), and the demographics and baseline range   of movement of the wrist, grip strength, Quick Disabilities of the   Arm, Shoulder, and Hand (QuickDASH) score, and Patient-Rated Wrist   Evaluation (PRWE) score were similar in both groups. </p></sec><sec><title>Results</title><p>At a mean follow-up of 5.9 years (1.8 to 11.8), significant improvements   in mean grip strength, the flexion-extension arc of movement of   the wrist, QuickDASH, and PRWE scores were seen in both groups.   There was no diifference between the groups for any of the outcomes.   One patient in the PRC + DCI group required additional surgery for   a deep infection, while two in the PRC group had complications (one   wound dehiscence requiring revision closure, one transient radial   sensory neuritis). One patient in each group required total arthrodesis   of the wrist for progressive degenerative radiocarpal changes. A   total of 70 patients (93%) were satisfied with the outcomes.</p></sec><sec><title>Conclusion</title><p>PRC with DCI is an effective form of treatment for late-stage   arthritis of the wrist involving the capitolunate joint, with mid-term   outcomes that are similar to those in patients without degenerative   changes affecting the capitate or lunate fossa who are treated with   a routine PRC alone.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:197–204.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/197
10.1302/0301-620X.100B2.BJJ-2017-0816.R2
None

2
The Bone & Joint Journal
The risk of cardiac failure following metal-on-metal hip arthroplasty
<sec><title>Aims</title><p>The aim of this study was to determine whether patients with   metal-on-metal (MoM) arthroplasties of the hip have an increased   risk of cardiac failure compared with those with alternative types   of arthroplasties (non-MoM).</p></sec><sec><title>Patients and Methods</title><p>A linkage study between the National Joint Registry, Hospital   Episodes Statistics and records of the Office for National Statistics   on deaths was undertaken. Patients who underwent elective total   hip arthroplasty between January 2003 and December 2014 with no   past history of cardiac failure were included and stratified as   having either a MoM (n = 53 529) or a non-MoM (n = 482 247) arthroplasty.   The primary outcome measure was the time to an admission to hospital   for cardiac failure or death. Analysis was carried out using data   from all patients and from those <strong><span style="color:yellowgreen">match</span></strong>ed by propensity score.</p></sec><sec><title>Results</title><p>The risk of cardiac failure was lower in the MoM cohort compared   with the non-MoM cohort (adjusted hazard ratio (aHR) 0.901; 95%   confidence interval (CI) 0.853 to 0.953). The risk of cardiac failure   was similar following <strong><span style="color:yellowgreen">match</span></strong>ing (aHR 0.909; 95% CI 0.838 to 0.987)   and the findings were consistent in subgroup analysis.</p></sec><sec><title>Conclusion</title><p>The risk of cardiac failure following total hip arthroplasty   was not increased in those in whom MoM implants were used, compared   with those in whom other types of prostheses were used, in the first   seven years after surgery.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:20–7.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1/20
10.1302/0301-620X.100B1.BJJ-2017-1065.R1
None

2
Circulation
Metabolic Predictors of Incident Coronary Heart Disease in Women
<sec><title>Background:</title><p>Although metabolomic profiling offers promise for the prediction of coronary heart disease (CHD), and metabolic risk factors are more strongly associated with CHD in women than men, limited data are available for women.</p></sec><sec><title>Methods:</title><p>We applied a liquid chromatography–tandem mass spectrometry metabolomics platform to measure 371 metabolites in a discovery set of postmenopausal women (472 incident CHD cases, 472 controls) with validation in an independent set of postmenopausal women (312 incident CHD cases, 315 controls).</p></sec><sec><title>Results:</title><p>Eight metabolites, primarily oxidized lipids, were significantly dysregulated in cases after the adjustment for <strong><span style="color:yellowgreen">match</span></strong>ing and CHD risk factors in both the discovery and validation data sets. One oxidized phospholipid, C34:2 hydroxy-phosphatidylcholine, remained associated with CHD after further adjustment for other validated metabolites. Subjects with C34:2 hydroxy-phosphatidylcholine levels in the highest quartile had a 4.7-fold increase in CHD odds in <strong><span style="color:yellowgreen">comparison</span></strong> with the lowest quartile; C34:2 hydroxy-phosphatidylcholine also significantly improved the area under the curve (<i>P</i><0.01) for CHD. The C34:2 hydroxy-phosphatidylcholine findings were replicated in a third replication data set of 980 men and women (230 cardiovascular events) with a stronger association observed in women.</p></sec><sec><title>Conclusions:</title><p>These data replicate known metabolite predictors, identify novel markers, and support the relationship between lipid oxidation and subsequent CHD.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/8/841
10.1161/CIRCULATIONAHA.117.029468
None

2
Circulation
Genetics, Lifestyle, and Low-Density Lipoprotein Cholesterol in Young and Apparently Healthy Women
<sec><title>Background:</title><p>Atherosclerosis starts in childhood but low-density lipoprotein cholesterol (LDL-C), a causal risk factor, is mostly studied and dealt with when clinical events have occurred. Women are usually affected later in life than men and are underdiagnosed, undertreated, and understudied in cardiovascular trials and research. This study aims at a better understanding of lifestyle and genetic factors that affect LDL-C in young women.</p></sec><sec><title>Methods:</title><p>We randomly selected for every year of age 8 women with LDL-C ≤1st percentile (≤50 mg/dL) and 8 women with LDL-C ≥99th percentile (≥186 mg/dL) from 28 000 female participants aged between 25 to 40 years of a population-based cohort study. The resulting groups include 119 and 121 women, respectively, of an average 33 years of age. A gene-sequencing panel was used to assess established monogenic and polygenic origins of these phenotypes. Information on lifestyle was extracted from questionnaires. A healthy lifestyle score was allocated based on a recently developed algorithm.</p></sec><sec><title>Results:</title><p>Of the women with LDL-C ≤1st percentile, 19 (15.7%) carried mutations that are causing monogenic hypocholesterolemia and 60 (49.6%) were genetically predisposed to low LDL-C on the basis of an extremely low weighted genetic risk score. In <strong><span style="color:yellowgreen">comparison</span></strong> with control groups, a healthier lifestyle was not associated with low LDL-C in women without genetic predispositions. Among women with LDL-C ≥99th percentile, 20 women (16.8%) carried mutations that cause familial hypercholesterolemia, whereas 25 (21%) were predisposed to high LDL-C on the basis of a high-weighted genetic risk score. The women in whom no genetic origin for hypercholesterolemia could be identified were found to exhibit a significantly unfavorable lifestyle in <strong><span style="color:yellowgreen">comparison</span></strong> with controls.</p></sec><sec><title>Conclusions:</title><p>This study highlights the need for early assessment of the cardiovascular risk profile in apparently healthy young women to identify those with LDL-C ≥99th percentile for their age: first, because, in this study, 17% of the cases were molecularly diagnosed with familial hypercholesterolemia, which needs further attention; second, because our data indicate that an unfavorable lifestyle is significantly associated with severe hypercholesterolemia in genetically unaffected women, which may also need further attention.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/8/820
10.1161/CIRCULATIONAHA.117.032479
None

2
Circulation
Genetic Predisposition to High Blood Pressure and Lifestyle Factors
<sec><title>Background:</title><p>High blood pressure (BP) is a major risk factor for cardiovascular diseases (CVDs), the leading cause of mortality worldwide. Both heritable and lifestyle risk factors contribute to elevated BP levels. We aimed to investigate the extent to which lifestyle factors could offset the effect of an adverse BP genetic profile and its effect on CVD risk.</p></sec><sec><title>Methods:</title><p>We constructed a genetic risk score for high BP by using 314 published BP loci in 277 005 individuals without previous CVD from the UK Biobank study, a prospective cohort of individuals aged 40 to 69 years, with a median of 6.11 years of follow-up. We scored participants according to their lifestyle factors including body mass index, healthy diet, sedentary lifestyle, alcohol consumption, smoking, and urinary sodium excretion levels measured at recruitment. We examined the association between tertiles of genetic risk and tertiles of lifestyle score with BP levels and incident CVD by using linear regression and Cox regression models, respectively.</p></sec><sec><title>Results:</title><p>Healthy lifestyle score was strongly associated with BP (<i>P</i><10<sup>–320</sup>) for systolic and diastolic BP and CVD events regardless of the underlying BP genetic risk. Participants with a favorable in <strong><span style="color:yellowgreen">comparison</span></strong> with an unfavorable lifestyle (bottom versus top tertile lifestyle score) had 3.6, 3.5, and 3.6 mm Hg lower systolic BP in low, middle, and high genetic risk groups, respectively (<i>P</i> for interaction=0.0006). Similarly, favorable in <strong><span style="color:yellowgreen">comparison</span></strong> with unfavorable lifestyle showed 30%, 31%, and 33% lower risk of CVD among participants in low, middle, and high genetic risk groups, respectively (<i>P</i> for interaction=0.99).</p></sec><sec><title>Conclusions:</title><p>Our data further support population-wide efforts to lower BP in the population via lifestyle modification. The advantages and disadvantages of disclosing genetic predisposition to high BP for risk stratification needs careful evaluation.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/7/653
10.1161/CIRCULATIONAHA.117.030898
None

2
Circulation
Comparison Between Patent Ductus Arteriosus Stent and Modified Blalock-Taussig Shunt as Palliation for Infants With Ductal-Dependent Pulmonary Blood Flow
<sec><title>Background:</title><p>Infants with ductal-dependent pulmonary blood flow may undergo palliation with either a patent ductus arteriosus (PDA) stent or a modified Blalock-Taussig (BT) shunt. A balanced multicenter <strong><span style="color:yellowgreen">comparison</span></strong> of these 2 approaches is lacking.</p></sec><sec><title>Methods:</title><p>Infants with ductal-dependent pulmonary blood flow palliated with either a PDA stent or a BT shunt from January 2008 to November 2015 were reviewed from the 4 member centers of the Congenital Catheterization Research Collaborative. Outcomes were compared by use of propensity score adjustment to account for baseline differences between groups.</p></sec><sec><title>Results:</title><p>One hundred six patients with a PDA stent and 251 patients with a BT shunt were included. The groups differed in underlying anatomy (expected 2-ventricle circulation in 60% of PDA stents versus 45% of BT shunts; <i>P</i>=0.001) and presence of antegrade pulmonary blood flow (61% of PDA stents versus 38% of BT shunts; <i>P</i><0.001). After propensity score adjustment, there was no difference in the hazard of the primary composite outcome of death or unplanned reintervention to treat cyanosis (hazard ratio, 0.8; 95% confidence interval [CI], 0.52–1.23; <i>P</i>=0.31). Other reinterventions were more common in the PDA stent group (hazard ratio, 29.8; 95% CI, 9.8–91.1; <i>P</i><0.001). However, the PDA stent group had a lower adjusted intensive care unit length of stay (5.3 days [95% CI, 4.2–6.7] versus 9.19 days [95% CI, 7.9–10.6]; <i>P</i><0.001), a lower risk of diuretic use at discharge (odds ratio, 0.4; 95% CI, 0.25–0.64; <i>P</i><0.001) and procedural complications (odds ratio, 0.4; 95% CI, 0.2–0.77; <i>P</i>=0.006), and larger (152 mm<sup>2</sup>/m<sup>2</sup> [95% CI, 132–176] versus 125 mm<sup>2</sup>/m<sup>2</sup> [95% CI, 113–138]; <i>P</i>=0.029) and more symmetrical (symmetry index, 0.84 [95% CI, 0.8–0.89] versus 0.77 [95% CI, 0.75–0.8]; <i>P</i>=0.008] pulmonary arteries at the time of subsequent surgical repair or last follow-up.</p></sec><sec><title>Conclusions:</title><p>In this multicenter <strong><span style="color:yellowgreen">comparison</span></strong> of palliative PDA stent and BT shunt for infants with ductal-dependent pulmonary blood flow adjusted for differences in patient factors, there was no difference in the primary end point, death or unplanned reintervention to treat cyanosis. However, other markers of morbidity and pulmonary artery size favored the PDA stent group, supporting PDA stent as a reasonable alternative to BT shunt in select patients.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/6/589
10.1161/CIRCULATIONAHA.117.029987
None

2
Circulation
Chronic Rejection of Cardiac Allografts Is Associated With Increased Lymphatic Flow and Cellular Trafficking
<sec><title>Background:</title><p>Cardiac transplantation is an excellent treatment for end-stage heart disease. However, rejection of the donor graft, in particular, by chronic rejection leading to cardiac allograft vasculopathy, remains a major cause of graft loss. The lymphatic system plays a crucial role in the alloimmune response, facilitating trafficking of antigen-presenting cells to draining lymph nodes. The encounter of antigen-presenting cells with T lymphocytes in secondary lymphoid organs is essential for the initiation of alloimmunity. Donor lymphatic vessels are not anastomosed to that of the recipient during transplantation. The pathophysiology of lymphatic disruption is unknown, and whether this disruption enhances or hinders the alloimmune responses is unclear. Although histological analysis of lymphatic vessels in donor grafts can yield information on the structure of the lymphatics, the function following cardiac transplantation is poorly understood.</p></sec><sec><title>Methods:</title><p>Using single-photon emission computed tomography/computed tomography lymphoscintigraphy, we quantified the lymphatic flow index following heterotrophic cardiac transplantation in a murine model of chronic rejection.</p></sec><sec><title>Results:</title><p>Ten weeks following transplantation of a minor antigen (HY) sex-mis<strong><span style="color:yellowgreen">match</span></strong>ed heart graft, the lymphatic flow index was significantly increased in <strong><span style="color:yellowgreen">comparison</span></strong> with sex-<strong><span style="color:yellowgreen">match</span></strong>ed controls. Furthermore, the enhanced lymphatic flow index correlated with an increase in donor cells in the mediastinal draining lymph nodes; increased lymphatic vessel area; and graft infiltration of CD4<sup>+</sup>, CD8<sup>+</sup> T cells, and CD68<sup>+</sup> macrophages.</p></sec><sec><title>Conclusions:</title><p>Chronic rejection results in increased lymphatic flow from the donor graft to draining lymph nodes, which may be a factor in promoting cellular trafficking, alloimmunity, and cardiac allograft vasculopathy.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/5/488
10.1161/CIRCULATIONAHA.117.028533
None

2
Circulation
Risk of Dementia in Adults With Congenital Heart Disease
<sec><title>Background:</title><p>More children with congenital heart disease (CHD) are surviving to adulthood, and CHD is associated with risk factors for dementia. We compared the risk of dementia in CHD adults to that of the general population.</p></sec><sec><title>Methods:</title><p>In this cohort study, we used medical registries and a medical record review covering all Danish hospitals to identify adults with CHD diagnosed between 1963 and 2012. These individuals with CHD were followed from January 1, 1981, 30 years of age, or date of first CHD registration (index date for <strong><span style="color:yellowgreen">match</span></strong>ed members of the general population cohort) until hospital diagnosis of dementia, death, emigration, or end of study (December 31, 2012). For each individual with CHD, we identified 10 members of the general population utilizing the Danish Civil Registration System <strong><span style="color:yellowgreen">match</span></strong>ed on sex and birth year. We computed cumulative incidences and hazard ratios (HRs) of dementia, adjusting for sex and birth year.</p></sec><sec><title>Results:</title><p>The cumulative incidence of dementia was 4% by 80 years of age in 10 632 adults with CHD (46% male). The overall HR comparing adults with CHD with the general population cohort was 1.6 (95% confidence interval [CI], 1.3−2.0). The HR among individuals with CHD without extracardiac defects was 1.4 (95% CI, 1.1−1.8). Adults with mild-to-moderate CHD had an HR of 1.5 (95% CI, 1.1−2.0), whereas the HR was 2.0 (95% CI, 1.2−3.3) for severe CHD, including univentricular hearts. The HR for early onset dementia (<65 years of age) was 2.6 (95% CI, 1.8−3.8), whereas the late-onset HR was 1.3 (95% CI, 1.0−1.8).</p></sec><sec><title>Conclusions:</title><p>CHD was associated with an increased risk of dementia compared with the general population, in particular for early onset dementia. Further understanding of dementia risk in the population with CHD is a potential target for future investigation.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/18/1912
10.1161/CIRCULATIONAHA.117.029686
None

2
Circulation
Cardiovascular Outcomes and Risks After Initiation of a Sodium Glucose Cotransporter 2 Inhibitor
<sec><title>Background:</title><p>Clinical trials have shown cardiovascular benefits and potential risks from sodium glucose cotransporter 2 inhibitors (SGLT2i). Trials may have limited ability to address individual end points or safety concerns.</p></sec><sec><title>Methods:</title><p>We performed a population-based cohort study among patients with type 2 diabetes mellitus with established cardiovascular disease newly initiated on antihyperglycemic agents within the US Department of Defense Military Health System between April 1, 2013, and December 31, 2016. Incidence rates, hazard ratios (HRs), and 95% confidence intervals (CIs) for time to first composite end point of all-cause mortality and hospitalization for heart failure event, major adverse cardiovascular events (defined as all-cause mortality, nonfatal myocardial infarction, and nonfatal stroke), and individual end points were evaluated using conditional Cox models comparing new SGLT2i users with other antihyperglycemic agents. The exploratory safety end point was below-knee lower extremity amputation. Intent-to-treat and on-treatment analyses were performed.</p></sec><sec><title>Results:</title><p>After propensity <strong><span style="color:yellowgreen">match</span></strong>ing, 25 258 patients were followed for a median of 1.6 years. Compared with non-SGLT2i, initiation of SGLT2i was associated with a lower rate of all-cause mortality and hospitalization for heart failure (1.73 versus 3.01 events per 100 person-years; HR, 0.57; 95% CI, 0.50–0.65) and major adverse cardiovascular events (2.31 versus 3.45 events per 100 person-years; HR, 0.67; 95% CI, 0.60–0.75). SGLT2i initiation was also associated with an ≈2-fold higher risk of below-knee lower extremity amputation (0.17 versus 0.09 events per 100 person-years; HR, 1.99; 95% CI, 1.12–3.51). Because of the disproportionate canagliflozin exposure in the database, the majority of amputations were observed on canagliflozin. Results were consistent in the on-treatment analysis.</p></sec><sec><title>Conclusions:</title><p>In this high-risk cohort, initiation of SGLT2i was associated with lower risk of all-cause mortality, hospitalization for heart failure, and major adverse cardiovascular events and higher risk of below-knee lower extremity amputation. Findings underscore the potential benefit and risks to be aware of when initiating SGLT2i. It remains unclear whether the below-knee lower extremity amputation risk extends across the class of medication, because the study was not powered to make <strong><span style="color:yellowgreen">comparison</span></strong>s among individual treatments.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/14/1450
10.1161/CIRCULATIONAHA.117.031227
None

2
Circulation
Lower Risk of Heart Failure and Death in Patients Initiated on Sodium-Glucose Cotransporter-2 Inhibitors Versus Other Glucose-Lowering Drugs
<sec><title>Background:</title><p>Reduction in cardiovascular death and hospitalization for heart failure (HHF) was recently reported with the sodium-glucose cotransporter-2 inhibitor (SGLT-2i) empagliflozin in patients with type 2 diabetes mellitus who have atherosclerotic cardiovascular disease. We compared HHF and death in patients newly initiated on any SGLT-2i versus other glucose-lowering drugs in 6 countries to determine if these benefits are seen in real-world practice and across SGLT-2i class.</p></sec><sec><title>Methods:</title><p>Data were collected via medical claims, primary care/hospital records, and national registries from the United States, Norway, Denmark, Sweden, Germany, and the United Kingdom. Propensity score for SGLT-2i initiation was used to <strong><span style="color:yellowgreen">match</span></strong> treatment groups. Hazard ratios for HHF, death, and their combination were estimated by country and pooled to determine weighted effect size. Death data were not available for Germany.</p></sec><sec><title>Results:</title><p>After propensity <strong><span style="color:yellowgreen">match</span></strong>ing, there were 309 056 patients newly initiated on either SGLT-2i or other glucose-lowering drugs (154 528 patients in each treatment group). Canagliflozin, dapagliflozin, and empagliflozin accounted for 53%, 42%, and 5% of the total exposure time in the SGLT-2i class, respectively. Baseline characteristics were balanced between the 2 groups. There were 961 HHF cases during 190 164 person-years follow-up (incidence rate, 0.51/100 person-years). Of 215 622 patients in the United States, Norway, Denmark, Sweden, and the United Kingdom, death occurred in 1334 (incidence rate, 0.87/100 person-years), and HHF or death in 1983 (incidence rate, 1.38/100 person-years). Use of SGLT-2i, versus other glucose-lowering drugs, was associated with lower rates of HHF (hazard ratio, 0.61; 95% confidence interval, 0.51–0.73; <i>P</i><0.001); death (hazard ratio, 0.49; 95% confidence interval, 0.41–0.57; <i>P</i><0.001); and HHF or death (hazard ratio, 0.54; 95% confidence interval, 0.48–0.60; <i>P</i><0.001) with no significant heterogeneity by country.</p></sec><sec><title>Conclusions:</title><p>In this large multinational study, treatment with SGLT-2i versus other glucose-lowering drugs was associated with a lower risk of HHF and death, suggesting that the benefits seen with empagliflozin in a randomized trial may be a class effect applicable to a broad population of patients with type 2 diabetes mellitus in real-world practice.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02993614.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/3/249
10.1161/CIRCULATIONAHA.117.029190
None

2
Circulation
Pericarditis as a Marker of Occult Cancer and a Prognostic Factor for Cancer Mortality
<sec><title>Background:</title><p>Pericarditis may be a serious complication of malignancy. Its significance as a first symptom of occult cancer and as a prognostic factor for cancer survival is unknown.</p></sec><sec><title>Methods:</title><p>Using Danish medical databases, we conducted a nationwide cohort study of all patients with a first-time diagnosis of pericarditis during 1994 to 2013. We excluded patients with previous cancer and followed up the remaining patients for subsequent cancer diagnosis until November 30, 2013. We calculated risks and standardized incidence ratios of cancer for patients with pericarditis compared with the general population. We assessed whether pericarditis predicts cancer survival by the Kaplan-Meier method and Cox regression using a <strong><span style="color:yellowgreen">match</span></strong>ed <strong><span style="color:yellowgreen">comparison</span></strong> cohort of cancer patients without pericarditis.</p></sec><sec><title>Results:</title><p>Among 13 759 patients with acute pericarditis, 1550 subsequently were diagnosed with cancer during follow-up. The overall cancer standardized incidence ratio was 1.5 (95% confidence interval [CI], 1.4–1.5), driven predominantly by increased rates of lung, kidney, and bladder cancer, lymphoma, leukemia, and unspecified metastatic cancer. The <3-month cancer risk among patients with pericarditis was 2.7%, and the standardized incidence ratio was 12.4 (95% CI, 11.2–13.7). The 3- to <12-month standardized incidence ratio of cancer was 1.5 (95% CI, 1.2–1.7), subsequently decreasing to 1.1 (95% CI, 1.0–1.2). Three-month survival after the cancer diagnosis was 80% and 86% among those with and without pericarditis, respectively, and the hazard ratio was 1.5 (95% CI, 1.3–1.8). One-year survival was 65% and 70%, respectively, corresponding to a 3- to <12-month hazard ratio of 1.3 (95% CI, 1.1–1.5).</p></sec><sec><title>Conclusions:</title><p>Pericarditis may be a marker of occult cancer and augurs increased mortality after a cancer diagnosis.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/11/996
10.1161/CIRCULATIONAHA.116.024041
None

2
Circulation
Excess Cardiovascular Risk in Women Relative to Men Referred for Coronary Angiography Is Associated With Severely Impaired Coronary Flow Reserve, Not Obstructive Disease
<sec><title>Background:</title><p>Cardiovascular disease (CVD) fatality rates are higher for women than for men, yet obstructive coronary artery disease (CAD) is less prevalent in women. Coronary flow reserve (CFR), an integrated measure of large- and small-vessel CAD and myocardial ischemia, identifies patients at risk for CVD death, but is not routinely measured in clinical practice. We sought to investigate the impact of sex, CFR, and angiographic CAD severity on adverse cardiovascular events.</p></sec><sec><title>Methods:</title><p>Consecutive patients (n=329, 43% women) referred for invasive coronary angiography after stress testing with myocardial perfusion positron emission tomography and with left ventricular ejection fraction >40% were followed (median, 3.0 years) for a composite end point of major adverse cardiovascular events, including cardiovascular death and hospitalization for nonfatal myocardial infarction or heart failure. The extent and severity of angiographic CAD were estimated by using the CAD prognostic index, and CFR was quantified by using positron emission tomography.</p></sec><sec><title>Results:</title><p>Although women in <strong><span style="color:yellowgreen">comparison</span></strong> with men had lower pretest clinical scores, rates of prior myocardial infarction, and burden of angiographic CAD (<i>P</i><0.001), they demonstrated greater risk of CVD events, even after adjustment for traditional risk factors, imaging findings, and early revascularization (adjusted hazard ratio, 2.05; 95% confidence interval, 1.05–4.02; <i>P</i>=0.03). Impaired CFR was similarly present among women and men, but in patients with low CFR (<1.6, n=163), women showed a higher frequency of nonobstructive CAD, whereas men showed a higher frequency of severely obstructive CAD (<i>P</i>=0.002). After also adjusting for CFR, the effect of sex on outcomes was no longer significant. When stratified by sex and CFR, only women with severely impaired CFR demonstrated significantly increased adjusted risk of CVD events (<i>P</i><0.0001, <i>P</i> for interaction=0.04).</p></sec><sec><title>Conclusions:</title><p>Women referred for coronary angiography had a significantly lower burden of obstructive CAD in <strong><span style="color:yellowgreen">comparison</span></strong> with men but were not protected from CVD events. Excess cardiovascular risk in women was independently associated with impaired CFR, representing a hidden biological risk, and a phenotype less amenable to revascularization. Impaired CFR, particularly absent severely obstructive CAD, may represent a novel target for CVD risk reduction.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/6/566
10.1161/CIRCULATIONAHA.116.023266
None

2
Circulation
Twenty-Year Outcome After Mitral Repair Versus Replacement for Severe Degenerative Mitral Regurgitation
<sec><title>Background:</title><p>Mitral valve (MV) repair is preferred over replacement in clinical guidelines and is an important determinant of the indication for surgery in degenerative mitral regurgitation. However, the level of evidence supporting current recommendations is low, and recent data cast doubts on its validity in the current era. Accordingly, the aim of the present study was to analyze very long-term outcome after MV repair and replacement for degenerative mitral regurgitation with a flail leaflet.</p></sec><sec><title>Methods:</title><p>MIDA (Mitral Regurgitation International Database) is a multicenter registry enrolling patients with degenerative mitral regurgitation with a flail leaflet in 6 tertiary European and US centers. We analyzed the outcome after MV repair (n=1709) and replacement (n=213) overall, by propensity score <strong><span style="color:yellowgreen">match</span></strong>ing, and by inverse probability-of-treatment weighting.</p></sec><sec><title>Results:</title><p>At baseline, patients undergoing MV repair were younger, had more comorbidities, and were more likely to present with a posterior leaflet prolapse than those undergoing MV replacement. After propensity score <strong><span style="color:yellowgreen">match</span></strong>ing and inverse probability-of-treatment weighting, the 2 treatments groups were balanced, and absolute standardized differences were usually <10%, indicating adequate <strong><span style="color:yellowgreen">match</span></strong>. Operative mortality (defined as a death occurring within 30 days from surgery or during the same hospitalization) was lower after MV repair than after replacement in both the entire population (1.3% versus 4.7%; <i>P</i><0.001) and the propensity-<strong><span style="color:yellowgreen">match</span></strong>ed population (0.2% versus 4.4%; <i>P</i><0.001). During a mean follow-up of 9.2 years, 552 deaths were observed, of which 207 were of cardiovascular origin. Twenty-year survival was better after MV repair than after MV replacement in both the entire population (46% versus 23%; <i>P</i><0.001) and the <strong><span style="color:yellowgreen">match</span></strong>ed population (41% versus 24%; <i>P</i><0.001). Similar superiority of MV repair was obtained in patient subsets on the basis of age, sex, or any stratification criteria (all <i>P</i><0.001). MV repair was also associated with reduced incidence of reoperations and valve-related complications.</p></sec><sec><title>Conclusions:</title><p>Among patients with degenerative mitral regurgitation with a flail leaflet referred to mitral surgery, MV repair was associated with lower operative mortality, better long-term survival, and fewer valve-related complications compared with MV replacement.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/5/410
10.1161/CIRCULATIONAHA.116.023340
None

2
Circulation
Hemocompatibility-Related Outcomes in the MOMENTUM 3 Trial at 6 Months
<sec><title>Background:</title><p>The HeartMate 3 (HM3) Left Ventricular Assist System (LVAS) (Abbott) is a centrifugal, fully magnetically levitated, continuous-flow blood pump engineered to enhance hemocompatibility and reduce shear stress on blood components. The MOMENTUM 3 trial (Multicenter Study of MagLev Technology in Patients Undergoing Mechanical Circulatory Support Therapy With HeartMate 3) compares the HM3 LVAS with the HeartMate II (HMII) LVAS (Abbott) in advanced heart failure refractory to medical management, irrespective of therapeutic intention (bridge to transplant versus destination therapy). This investigation reported its primary outcome in the short-term cohort (n=294; 6-month follow-up), demonstrating superiority of the HM3 for the trial primary end point (survival free of a disabling stroke or reoperation to replace the pump for malfunction), driven by a reduced need for reoperations. The aim of this analysis was to evaluate the aggregate of hemocompatibility-related clinical adverse events (HRAEs) between the 2 LVAS.</p></sec><sec><title>Methods:</title><p>We conducted a secondary end point evaluation of HRAE (survival free of any nonsurgical bleeding, thromboembolic event, pump thrombosis, or neurological event) in the short-term cohort (as-treated cohort n=289) at 6 months. The net burden of HRAE was also assessed by using a previously described hemocompatibility score, which uses 4 escalating tiers of hierarchal severity to derive a total score for events encountered during the entire follow-up experience for each patient.</p></sec><sec><title>Results:</title><p>In 289 patients in the as-treated group (151 the HM3 and 138 the HMII), survival free of any HRAE was achieved in 69% of the HM3 group and in 55% of the HMII group (hazard ratio, 0.62; confidence interval, 0.42–0.91; <i>P</i>=0.012). Using the hemocompatibility score, the HM3 group demonstrated less pump thrombosis requiring reoperation (0 versus 36 points, <i>P</i><0.001) or medically managed pump thrombosis (0 versus 5 points, <i>P</i>=0.02), and fewer nondisabling strokes (6 versus 24 points, <i>P</i>=0.026) than the control HMII LVAS. The net hemocompatibility score in the HM3 in <strong><span style="color:yellowgreen">comparison</span></strong> with the HMII patients was 101 (0.67±1.50 points/patient) versus 137 (0.99±1.79 points/patient) (odds ratio, 0.64; confidence interval, 0.39–1.03; <i>P</i>=0.065).</p></sec><sec><title>Conclusions:</title><p>In this secondary analysis of the MOMENTUM 3 trial, the HM3 LVAS demonstrated greater freedom from HRAEs in <strong><span style="color:yellowgreen">comparison</span></strong> with the HMII LVAS at 6 months.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT02224755.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/21/2003
10.1161/CIRCULATIONAHA.117.028303
None

2
Circulation
Depression Treatment and 1-Year Mortality After Acute Myocardial Infarction
<sec><title>Background:</title><p>Depression among patients with acute myocardial infarction (AMI) is prevalent and associated with an adverse quality of life and prognosis. Despite recommendations from some national organizations to screen for depression, it is unclear whether treatment of depression in patients with AMI is associated with better outcomes. We aimed to determine whether the prognosis of patients with treated versus untreated depression differs.</p></sec><sec><title>Methods:</title><p>The TRIUMPH study (Translational Research Investigating Underlying Disparities in Acute Myocardial Infarction Patients’ Health Status) is an observational multicenter cohort study that enrolled 4062 patients aged ≥18 years with AMI between April 11, 2005, and December 31, 2008, from 24 US hospitals. Research coordinators administered the Patient Health Questionnaire-9 (PHQ-9) during the index AMI admission. Depression was defined by a PHQ-9 score of ≥10. Depression was categorized as treated if there was documentation of a discharge diagnosis, medication prescribed for depression, or referral for counseling, and as untreated if none of these 3 criteria was documented in the medical records despite a PHQ score ≥10. One-year mortality was compared between patients with AMI having: (1) no depression (PHQ-9<10; reference); (2) treated depression; and (3) untreated depression adjusting for demographics, AMI severity, and clinical factors.</p></sec><sec><title>Results:</title><p>Overall, 759 (18.7%) patients met PHQ-9 criteria for depression and 231 (30.4%) were treated. In <strong><span style="color:yellowgreen">comparison</span></strong> with 3303 patients without depression, the 231 patients with treated depression had 1-year mortality rates that were not different (6.1% versus 6.7%; adjusted hazard ratio, 1.12; 95% confidence interval, 0.63–1.99). In contrast, the 528 patients with untreated depression had higher 1-year mortality in <strong><span style="color:yellowgreen">comparison</span></strong> with patients without depression (10.8% versus 6.1%; adjusted hazard ratio, 1.91; 95% confidence interval, 1.39–2.62).</p></sec><sec><title>Conclusions:</title><p>Although depression in patients with AMI is associated with increased long-term mortality, this association may be confined to patients with untreated depression.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/18/1681
10.1161/CIRCULATIONAHA.116.025140
None

2
Circulation
Risk of Heart Failure With Preserved Ejection Fraction in Older Women After Contemporary Radiotherapy for Breast Cancer
<sec><title>Background:</title><p>Cardiomyocytes are resistant to radiation. However, cardiac radiation exposure causes coronary microvascular endothelial inflammation, a perturbation implicated in the pathogenesis of heart failure (HF) and particularly HF with preserved ejection fraction (HFpEF). Radiotherapy for breast cancer results in variable cardiac radiation exposure and may increase the risk of HF.</p></sec><sec><title>Methods:</title><p>We conducted a population-based case-control study of incident HF in 170 female residents of Olmsted County, Minnesota (59 cases and 111 controls), who underwent contemporary (1998–2013) radiotherapy for breast cancer with computed tomography–assisted radiotherapy planning. Controls were <strong><span style="color:yellowgreen">match</span></strong>ed to cases for age, tumor side, chemotherapy use, diabetes mellitus, and hypertension. Mean cardiac radiation dose (MCRD) in each patient was calculated from the patient’s computed tomography images and radiotherapy plan.</p></sec><sec><title>Results:</title><p>Mean age at radiotherapy was 69±9 years. Of HF cases, 38 (64%) had EF≥50% (HFpEF), 18 (31%) had EF<50% (HF with reduced EF), and 3 (5%) did not have EF measured. The EF was ≥40% in 50 of the 56 HF cases (89%) with an EF measurement. The mean interval from radiotherapy to HF was 5.8±3.4 years. The odds of HF was higher in patients with a history of ischemic heart disease or atrial fibrillation. The MCRD was 2.5 Gy (range, 0.2–13.1 Gy) and higher in cases (3.3±2.7 Gy) than controls (2.1±2.0 Gy; <i>P</i>=0.004). The odds ratio (95% confidence interval) for HF per log MCRD was 9.1 (3.4–24.4) for any HF, 16.9 (3.9–73.7) for HFpEF, and 3.17 (0.8–13.0) for HF with reduced EF. The increased odds of any HF or HFpEF with increasing MCRD remained significant after adjustment for HF risk factors and in sensitivity analyses <strong><span style="color:yellowgreen">match</span></strong>ing by cancer stage rather than tumor side. Only 18.6% of patients experienced new or recurrent ischemic events between radiotherapy and the onset of HF.</p></sec><sec><title>Conclusions:</title><p>The relative risk of HFpEF increases with increasing cardiac radiation exposure during contemporary conformal breast cancer radiotherapy. These data emphasize the importance of radiotherapy techniques that limit MCRD during breast cancer treatment. Moreover, these data provide further support for the importance of coronary microvascular compromise in the pathophysiology of HFpEF.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/15/1388
10.1161/CIRCULATIONAHA.116.025434
None

2
Circulation
Use of Intravenous Recombinant Tissue Plasminogen Activator in Patients With Acute Ischemic Stroke Who Take Non–Vitamin K Antagonist Oral Anticoagulants Before Stroke
<sec><title>Background:</title><p>Intravenous rt-PA (recombinant tissue-type plasminogen activator) is effective in improving outcomes in ischemic stroke; however, there are few data on the use of rt-PA in patients who are receiving a non–vitamin K antagonist oral anticoagulant (NOAC).</p></sec><sec><title>Methods:</title><p>Using data from the American Heart Association Get With The Guidelines-Stroke Registry, we examined the outcomes of use of thrombolytic therapy in patients with ischemic stroke who received anticoagulation with NOACs versus those on warfarin (international normalized ratio <1.7) or not on anticoagulation from 1289 registry hospitals between October 2012 and March 2015.</p></sec><sec><title>Results:</title><p>Of 42 887 patients with ischemic stroke treated with intravenous rt-PA within 4.5 hours, 251 were taking NOACs (dabigatran 87, rivaroxaban 129, and apixaban 35) before their stroke, 1500 were taking warfarin, and 41 136 were on neither. Patients on NOACs or warfarin were older, had more comorbid conditions, and experienced more severe strokes than did those who were not on anticoagulation (median National Institutes of Health Stroke Scale 12, 13, and 9, respectively). Unadjusted rates of symptomatic intracranial hemorrhage in the NOAC, warfarin, and none groups were 4.8%, 4.9%, and 3.9%, respectively (<i>P</i>=0.11). In <strong><span style="color:yellowgreen">comparison</span></strong> with those not on anticoagulation, the adjusted odds ratio for symptomatic intracranial hemorrhage for those on NOACs was 0.92 (95% confidence interval, 0.51–1.65) and for those on warfarin the adjusted odds ratio was 0.85 (95% confidence interval, 0.66–1.10). There were also no significant differences in the risk for life-threatening/serious systemic hemorrhage, any rt-PA complication, in-hospital mortality, and modified Rankin Scale at discharge across 3 groups. Similar results were also found after propensity score <strong><span style="color:yellowgreen">match</span></strong>ing.</p></sec><sec><title>Conclusions:</title><p>Although experience of using rt-PA in patients with ischemic stroke on a NOAC is limited, these preliminary observations suggest that rt-PA appears to be reasonably well tolerated without prohibitive risks for adverse events among selected NOAC-treated patients. Future studies should evaluate the safety and efficacy of intravenous rt-PA in patients with ischemic stroke who are taking NOACs.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/11/1024
10.1161/CIRCULATIONAHA.116.023940
None

2
Circulation
Hospital Variation in Time to Epinephrine for Nonshockable In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>For patients with in-hospital cardiac arrests attributable to nonshockable rhythms, delays in epinephrine administration beyond 5 minutes is associated with worse survival. However, the extent of hospital variation in delayed epinephrine administration and its effect on hospital-level outcomes is unknown.</p></sec><sec><title>Methods:</title><p>Within Get With The Guidelines-Resuscitation, we identified 103 932 adult patients (≥18 years) at 548 hospitals with an in-hospital cardiac arrest attributable to a nonshockable rhythm who received at least 1 dose of epinephrine between 2000 and 2014. We constructed 2-level hierarchical regression models to quantify hospital variation in rates of delayed epinephrine administration (>5 minutes) and its association with hospital rates of survival to discharge and survival with functional recovery.</p></sec><sec><title>Results:</title><p>Overall, 13 213 (12.7%) patients had delays to epinephrine, and this rate varied markedly across hospitals (range, 0%–53.8%). The odds of delay in epinephrine administration were 58% higher at 1 randomly selected hospital in <strong><span style="color:yellowgreen">comparison</span></strong> with a similar patient at another randomly selected hospital (median odds ratio, 1.58; 95% confidence interval, 1.51–1.64). The median risk-standardized survival rate was 12.0% (range, 5.4%–31.9%), and the risk-standardized survival with functional recovery was 7.4% (range, 0.9%–30.8%). There was an inverse correlation between a hospital’s rate of delayed epinephrine administration and its risk-standardized rate of survival to discharge (ρ=–0.22, <i>P</i><0.0001) and survival with functional recovery (ρ=–0.14, <i>P</i>=0.001). In <strong><span style="color:yellowgreen">comparison</span></strong> with a median survival rate of 12.9% (interquartile range, 11.1%–15.4%) at hospitals in the lowest quartile of epinephrine delay, risk-standardized survival was 16% lower at hospitals in the quartile with the highest rate of epinephrine delays (10.8%; interquartile range, 9.7%–12.7%).</p></sec><sec><title>Conclusions:</title><p>Delays in epinephrine administration following in-hospital cardiac arrest are common and variy across hospitals. Hospitals with high rates of delayed epinephrine administration had lower rates of overall survival for in-hospital cardiac arrest attributable to nonshockable rhythm. Further studies are needed to determine whether improving hospital performance on time to epinephrine administration, especially at hospitals with poor performance on this metric, will lead to improved outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2105
10.1161/CIRCULATIONAHA.116.025459
None

2
Circulation
Conventional Versus Compression-Only Versus No-Bystander Cardiopulmonary Resuscitation for Pediatric Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Conventional cardiopulmonary resuscitation (CPR) (chest compression and rescue breathing) has been recommended for pediatric out-of-hospital cardiac arrest (OHCA) because of the asphyxial nature of the majority of pediatric cardiac arrest events. However, the clinical effectiveness of additional rescue breathing (conventional CPR) compared with compression-only CPR in children is uncertain.</p></sec><sec><title>Methods:</title><p>This nationwide population-based study of pediatric OHCA patients was based on data from the All-Japan Utstein Registry. We included all pediatric patients who experienced OHCA in Japan from January 1, 2011, to December 31, 2012. The primary outcome was a favorable neurological state 1 month after OHCA defined as a Glasgow-Pittsburgh Cerebral Performance Category score of 1 to 2 (corresponding to a Pediatric Cerebral Performance Category score of 1–3). Outcomes were compared with logistic regression with uni- and multivariable modeling in the overall cohort and for a propensity-<strong><span style="color:yellowgreen">match</span></strong>ed subset of patients.</p></sec><sec><title>Results:</title><p>A total of 2157 patients were included; 417 received conventional CPR, 733 received compression-only CPR, and 1007 did not receive any bystander CPR. Among these patients, 213 (9.9%) survived with a favorable neurological status 1 month after OHCA, including 108/417 (25.9%) for conventional, 68/733 (9.3%) for compression-only, and 37/1007 (3.7%) for no-bystander CPR. In unadjusted analyses, conventional CPR was superior to compression-only CPR in neurologically favorable survival (odds ratio [OR] 3.42, 95% confidence interval [CI] 2.45–4.76; <i>P</i><0.0001), with a trend favoring conventional CPR that was no longer statistically significant after multivariable adjustment (OR<sub>adjusted</sub> 1.52, 95% CI 0.93–2.49), and with further attenuation of the difference in a propensity-<strong><span style="color:yellowgreen">match</span></strong>ed subset (OR 1.20, 95% CI 0.81–1.77). Both conventional and compression-only CPR were associated with higher odds for neurologically favorable survival compared with no-bystander CPR (OR<sub>adjusted</sub> 5.01, 95% CI 2.98–8.57, and OR<sub>adjusted</sub> 3.29, 95% CI 1.93–5.71), respectively.</p></sec><sec><title>Conclusions:</title><p>In this population-based study of pediatric OHCA in Japan, both conventional and compression-only CPR were associated with superior outcomes compared with no-bystander CPR. Unadjusted outcomes with conventional CPR were superior to compression-only CPR, with the magnitude of difference attenuated and no longer statistically significant after statistical adjustments. These findings support randomized clinical trials comparing conventional versus compression-only CPR in children, with conventional CPR preferred until such controlled comparative data are available, and either method preferred over no-bystander CPR.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2060
10.1161/CIRCULATIONAHA.116.023831
None

