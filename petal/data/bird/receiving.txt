9
Circulation
Does Use of Bilateral Internal Mammary Artery Grafting Reduce Long-Term Risk of Repeat Coronary Revascularization?
<sec><title>Background:</title><p>Although previous studies have demonstrated that patients <strong><span style="color:yellowgreen">receiv</span></strong>ing bilateral internal mammary artery (BIMA) conduits during coronary artery bypass grafting have better long-term survival than those <strong><span style="color:yellowgreen">receiv</span></strong>ing a single internal mammary artery (SIMA), data on risk of repeat revascularization are more limited. In this analysis, we compare the timing, frequency, and type of repeat coronary revascularization among patients <strong><span style="color:yellowgreen">receiv</span></strong>ing BIMA and SIMA.</p></sec><sec><title>Methods:</title><p>We conducted a multicenter, retrospective analysis of 47 984 consecutive coronary artery bypass grafting surgeries performed from 1992 to 2014 among 7 medical centers reporting to a prospectively maintained clinical registry. Among the study population, 1482 coronary artery bypass grafting surgeries with BIMA were identified, and 1297 patients <strong><span style="color:yellowgreen">receiv</span></strong>ing BIMA were propensity-matched to 1297 patients <strong><span style="color:yellowgreen">receiv</span></strong>ing SIMA. The primary end point was freedom from repeat coronary revascularization.</p></sec><sec><title>Results:</title><p>The median duration of follow-up was 13.2 (IQR, 7.4–17.7) years. Patients were well matched by age, body mass index, major comorbidities, and cardiac function. There was a higher freedom from repeat revascularization among patients <strong><span style="color:yellowgreen">receiv</span></strong>ing BIMA than among patients <strong><span style="color:yellowgreen">receiv</span></strong>ing SIMA (hazard ratio [HR], 0.78 [95% CI, 0.65–0.94]; <i>P</i>=0.009). Among the matched cohort, 19.4% (n=252) of patients <strong><span style="color:yellowgreen">receiv</span></strong>ing SIMA underwent repeat revascularization, whereas this frequency was 15.1% (n=196) among patients <strong><span style="color:yellowgreen">receiv</span></strong>ing BIMA (<i>P</i>=0.004). The majority of repeat revascularization procedures were percutaneous coronary interventions (94.2%), and this did not differ between groups (<i>P</i>=0.274). Groups also did not differ in the ratio of native versus graft vessel percutaneous coronary intervention (<i>P</i>=0.899), or regarding percutaneous coronary intervention target vessels; the most common targets in both groups were the right coronary (<i>P</i>=0.133) and circumflex arteries (<i>P</i>=0.093). In comparison with SIMA, BIMA grafting was associated with a reduction in all-cause mortality at 12 years of follow-up (HR, 0.79 [95% CI, 0.69–0.91]; <i>P</i>=0.001), and there was no difference in in-hospital morbidity.</p></sec><sec><title>Conclusions:</title><p>BIMA grafting was associated with a reduced risk of repeat revascularization and an improvement in long-term survival and should be considered more frequently during coronary artery bypass grafting.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1676
10.1161/CIRCULATIONAHA.117.027405
None

8
Journal of Experimental Biology
Pheromones exert top-down effects on visual recognition in the jumping spider <i>Lyssomanes viridis</i>
<p>In diverse and productive habitats, predaceous arthropods are expected to frequently encounter dangerous conspecifics and heterospecifics. This should make quick and accurate discriminations between species and sexes adaptive. By simultaneously sampling both visual cues and pheromones, and by utilizing stringent species- and sex-specific visual <strong><span style="color:yellowgreen">recognit</span></strong>ion templates, an individual should be able to increase both its speed and accuracy in making such discriminations. We tested for the use and stringency of visual <strong><span style="color:yellowgreen">recognit</span></strong>ion templates in the jumping spider <i>Lyssomanes viridis</i> by presenting males with animated images of conspecifics, heterospecifics and composite images that combined the facial coloration and morphology of one sex or species with the leg coloration of another. Males' courtship <i>versus</i> threat displays indicated whether a stimulus was perceived as a potential mate or a threat. By comparing males' visual inspection times of, and display types towards, the various images in the presence <i>versus</i> absence of female pheromones, we were able to deduce whether males tend to inspect a subset of the color pattern and morphological features that make up their conspecific <strong><span style="color:yellowgreen">recognit</span></strong>ion templates (i.e. those on just the face or just the legs), or all features, and whether this changes in the presence of pheromones. We found that the male <strong><span style="color:yellowgreen">recognit</span></strong>ion template for conspecific female was surprisingly coarse, whereas the <strong><span style="color:yellowgreen">recognit</span></strong>ion template for conspecific male, and especially the male face, was more specific. Pheromones hastened the <strong><span style="color:yellowgreen">recognit</span></strong>ion of images with coloration and morphology closely matching those of conspecifics, presumably by activating conspecific visual <strong><span style="color:yellowgreen">recognit</span></strong>ion templates. When males were presented with an image that was, overall, a poor match to a conspecific female, but that contained a subset of female or female-like features, female pheromones usually did not hasten <strong><span style="color:yellowgreen">recognit</span></strong>ion, but did increase the likelihood that the image would be identified as a female. Taken together, our data suggest that males examined features on both the face and the legs in both the presence and absence of pheromones, and that female pheromones tipped the balance in favor of a female identification when a male was unsure how to categorize an incongruous set of visual features.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1744
10.1242/jeb.071118
['Lyssomanes', 'Lyssomanes viridis', 'arthropods']

6
PLANT PHYSIOLOGY
Myosins XI Are Involved in Exocytosis of Cellulose Synthase Complexes
<p>In plants, cellulose is synthesized at the cell surface by plasma membrane (PM)-localized cellulose synthase (CESA) complexes (CSCs). The molecular and cellular mechanisms that underpin delivery of CSCs to the PM, however, are poorly understood. Cortical microtubules have been shown to interact with CESA-containing compartments and mark the site for CSC delivery, but are not required for the delivery itself. Here, we demonstrate that myosin XI and the actin cytoskeleton mediate CSC delivery to the PM by coordinating the exocytosis of CESA-containing compartments. Measurement of cellulose content indicated that cellulose biosynthesis was significantly reduced in a <i>myosin xik xi1 xi2</i> triple-knockout mutant. By combining genetic and pharmacological disruption of myosin activity with quantitative live-cell imaging, we observed decreased abundance of PM-localized CSCs and reduced delivery rate of CSCs in myosin-deficient cells. These phenotypes correlated with a significant increase in failed vesicle secretion events at the PM as well as an abnormal accumulation of CESA-containing compartments at the cell cortex. Through high-resolution spatiotemporal assays of cortical vesicle behavior, we identified defects in CSC vesicle tethering and fusion at the PM. Furthermore, disruption of myosin activity reduced the delivery of several other secretory markers to the PM and reduced constitutive and <strong><span style="color:yellowgreen">recept</span></strong>or-mediated endocytosis. These findings reveal a previously undescribed role for myosin in vesicle secretion and cellulose production at the cytoskeleton-PM-cell wall nexus.</p>
http://plantphysiol.org/cgi/content/abstract/179/4/1537
10.1104/pp.19.00018
['plants']

6
PLANT PHYSIOLOGY
MILDEW RESISTANCE LOCUS O Function in Pollen Tube Reception Is Linked to Its Oligomerization and Subcellular Distribution
<p>Sexual reproduction in flowering plants requires communication between synergid cells and a tip-elongating pollen tube (PT) for the successful delivery of sperm cells to the embryo sac. The <strong><span style="color:yellowgreen">recept</span></strong>ion of the PT relies on signaling within the synergid cell that ultimately leads to the degeneration of the <strong><span style="color:yellowgreen">recept</span></strong>ive synergid and PT rupture, releasing the sperm cells for double fertilization. In Arabidopsis (<i>Arabidopsis thaliana</i>), NORTIA, a member of the MILDEW RESISTANCE LOCUS O (MLO) family of proteins, plays a critical role in the communication processes regulating PT <strong><span style="color:yellowgreen">recept</span></strong>ion. In this study, we determined that MLO function in PT <strong><span style="color:yellowgreen">recept</span></strong>ion is dependent on MLO protein localization into a Golgi-associated compartment before PT arrival, indicating that PT-triggered regulation of the synergid secretory system is important for synergid function during pollination. Additionally, a structure-function analysis revealed that MLO homooligomerization, mediated by the amino-terminal region of the protein, and carboxyl-terminal tail identity both contribute to MLO activity during PT <strong><span style="color:yellowgreen">recept</span></strong>ion.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/172
10.1104/pp.17.00523
['Arabidopsis', 'Arabidopsis thaliana', 'plants']

5
Science
Supracellular contraction at the rear of neural crest cell groups drives collective chemotaxis
<p><strong><span style="color:yellowgreen">collect</span></strong>ive cell chemotaxis, the directed migration of cell groups along gradients of soluble chemical cues, underlies various developmental and pathological processes. We use neural crest cells, a migratory embryonic stem cell population whose behavior has been likened to malignant invasion, to study <strong><span style="color:yellowgreen">collect</span></strong>ive chemotaxis in vivo. Studying <i>Xenopus</i> and zebrafish, we have shown that the neural crest exhibits a tensile actomyosin ring at the edge of the migratory cell group that contracts in a supracellular fashion. This contractility is polarized during <strong><span style="color:yellowgreen">collect</span></strong>ive cell chemotaxis: It is inhibited at the front but persists at the rear of the cell cluster. The differential contractility drives directed <strong><span style="color:yellowgreen">collect</span></strong>ive cell migration ex vivo and in vivo through the intercalation of rear cells. Thus, in neural crest cells, <strong><span style="color:yellowgreen">collect</span></strong>ive chemotaxis works by rear-wheel drive.</p>
http://sciencemag.org/cgi/content/abstract/362/6412/339
10.1126/science.aau3301
['Xenopus', 'zebrafish']

5
Circulation
Preterm Delivery and Maternal Cardiovascular Disease in Young and Middle-Aged Adult Women
<sec><title>Background:</title><p>Preterm delivery has been shown to be associated with increased risk of cardiovascular disease (CVD), but it is unknown whether this risk remains after adjustment for prepregnancy lifestyle and CVD risk factors.</p></sec><sec><title>Methods:</title><p>We examined the association between history of having delivered an infant preterm (<37 weeks) and CVD in 70 182 parous women in the Nurses’ Health Study II. Multivariable Cox proportional-hazards models were used to estimate hazards ratios (HRs) and 95% confidence intervals (CIs) for CVD events (myocardial infarction and stroke, n=949); we also adjusted for intermediates to determine the proportion of the association between preterm and CVD accounted for by postpartum development of CVD risk factors.</p></sec><sec><title>Results:</title><p>After adjusting for age, race, parental education, and prepregnancy lifestyle and CVD risk factors, preterm delivery in the first pregnancy was associated with an increased risk of CVD (HR, 1.42; 95% CI, 1.16–1.72) in comparison with women with a term delivery (≥37 weeks) in the first pregnancy. When preterm delivery was split into moderate preterm (≥32 to <37 weeks) and very preterm (<32 weeks), the HRs were 1.22 (95% CI, 0.96–1.54) and 2.01 (95% CI, 1.47–2.75), respectively. The increased rate of CVD in the very preterm group persisted even among women whose first pregnancy was not complicated by hypertensive disorders of pregnancy (HR, 2.01; 95% CI, 1.38–2.93). In comparison with women with at least 2 pregnancies, all of which were delivered at term, women with a preterm first birth and at least 1 later preterm birth had a HR of CVD of 1.65 (95% CI, 1.20–2.28). The association between moderate preterm first birth and CVD was accounted for in part by the development of postpartum chronic hypertension, hypercholesterolemia, type 2 diabetes mellitus, and changes in body mass index (proportion accounted for, 14.5%; 95% CI, 4.0–41.1), as was the very-preterm-CVD relationship (13.1%; 95% CI, 9.0–18.7).</p></sec><sec><title>Conclusions:</title><p>Preterm delivery is independently predictive of CVD and may be useful for CVD prevention efforts. Because only a modest proportion of the preterm-CVD association was accounted for by development of conventional CVD risk factors, further research may identify additional pathways.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/6/578
10.1161/CIRCULATIONAHA.116.025954
None

5
Circulation
Detailed Echocardiographic Phenotyping in Breast Cancer Patients
<sec><title>Background:</title><p>Cardiovascular disease in patients with breast cancer is of growing concern. The longitudinal effects of commonly used therapies, including doxorubicin and trastuzumab, on cardiac remodeling and function remain unknown in this population. We aimed to define the changes in echocardiographic parameters of structure, function, and ventricular-arterial coupling, and their associations with left ventricular ejection fraction (LVEF) and heart failure symptoms.</p></sec><sec><title>Methods:</title><p>In a longitudinal prospective cohort study of 277 breast cancer participants <strong><span style="color:yellowgreen">receiv</span></strong>ing doxorubicin (Dox), trastuzumab (Tras), or both (Dox+Tras), we obtained 1249 echocardiograms over a median follow-up of 2.0 (interquartile range, 1.0–3.0) years. Left ventricular structure, diastolic and contractile function, and ventricular-arterial coupling measures were quantified in a core laboratory blinded to participant characteristics. We evaluated changes in echocardiographic parameters over time, and used repeated-measures regression models to define their association with LVEF decline and recovery. Linear regression models defined the association between early changes in these parameters and subsequent changes in LVEF and heart failure symptoms.</p></sec><sec><title>Results:</title><p>Overall, 177 (64%) <strong><span style="color:yellowgreen">receiv</span></strong>ed Dox, 51 (18%) <strong><span style="color:yellowgreen">receiv</span></strong>ed Tras, and 49 (18%) <strong><span style="color:yellowgreen">receiv</span></strong>ed Dox+Tras. With Dox, there was a sustained, modest decrease in LVEF over the follow-up duration (1-year change in LVEF –3.6%; 95% confidence interval [CI], –4.4% to –2.8%; 3-year change –3.8%; 95% CI, –5.1% to –2.5%). With Tras, a similar LVEF decline was observed at 1 year (–4.5%; 95% CI, –6.0% to –2.9%) and 3 years (–2.8%; 95%CI, –5.3 to –0.4%). Participants <strong><span style="color:yellowgreen">receiv</span></strong>ing Dox+Tras demonstrated the greatest declines at 1 year (–6.6%; 95% CI, –8.2 to –5.0%), with partial recovery at 3 years (–2.8%; 95% CI, –4.8 to –0.8%). LVEF declines and recovery were associated primarily with changes in systolic volumes, longitudinal and circumferential strain, and ventricular-arterial coupling indices, effective arterial elastance (Ea) and the coupling ratio Ea/Ees<sub>sb</sub>, without evidence for effect modification across therapies. Early changes in volumes, strain, and Ea/Ees<sub>sb</sub> at 4 to 6 months were associated with 1- and 2-year LVEF changes. Similarly, early changes in strain and Ea were associated with worsening heart failure symptoms at 1 year.</p></sec><sec><title>Conclusions:</title><p>Doxorubicin and trastuzumab resulted in modest, persistent declines in LVEF at 3 years. Changes in volumes, strain, and ventricular-arterial coupling were consistently associated with concurrent and subsequent LVEF declines and recovery across therapies.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/15/1397
10.1161/CIRCULATIONAHA.116.023463
None

5
Circulation
Point-of-Care Hemostatic Testing in Cardiac Surgery
<sec><title>Background:</title><p>Cardiac surgery is frequently complicated by coagulopathic bleeding that is difficult to optimally manage using standard hemostatic testing. We hypothesized that point-of-care hemostatic testing within the context of an integrated transfusion algorithm would improve the management of coagulopathy in cardiac surgery and thereby reduce blood transfusions.</p></sec><sec><title>Methods:</title><p>We conducted a pragmatic multicenter stepped-wedge cluster randomized controlled trial of a point-of-care–based transfusion algorithm in consecutive patients undergoing cardiac surgery with cardiopulmonary bypass at 12 hospitals from October 6, 2014, to May 1, 2015. Following a 1-month data <strong><span style="color:yellowgreen">collect</span></strong>ion at all participating hospitals, a transfusion algorithm incorporating point-of-care hemostatic testing was sequentially implemented at 2 hospitals at a time in 1-month intervals, with the implementation order randomly assigned. No other aspects of care were modified. The primary outcome was red blood cell transfusion from surgery to postoperative day 7. Other outcomes included transfusion of other blood products, major bleeding, and major complications. The analysis adjusted for secular time trends, within-hospital clustering, and patient-level risk factors. All outcomes and analyses were prespecified before study initiation.</p></sec><sec><title>Results:</title><p>Among the 7402 patients studied, 3555 underwent surgery during the control phase and 3847 during the intervention phase. Overall, 3329 (45.0%) <strong><span style="color:yellowgreen">receiv</span></strong>ed red blood cells, 1863 (25.2%) <strong><span style="color:yellowgreen">receiv</span></strong>ed platelets, 1645 (22.2%) <strong><span style="color:yellowgreen">receiv</span></strong>ed plasma, and 394 (5.3%) <strong><span style="color:yellowgreen">receiv</span></strong>ed cryoprecipitate. Major bleeding occurred in 1773 (24.1%) patients, and major complications occurred in 740 (10.2%) patients. The trial intervention reduced rates of red blood cell transfusion (adjusted relative risk, 0.91; 95% confidence interval, 0.85–0.98; <i>P</i>=0.02; number needed to treat, 24.7), platelet transfusion (relative risk, 0.77; 95% confidence interval, 0.68–0.87; <i>P</i><0.001; number needed to treat, 16.7), and major bleeding (relative risk, 0.83; 95% confidence interval, 0.72–0.94; <i>P</i>=0.004; number needed to treat, 22.6), but had no effect on other blood product transfusions or major complications.</p></sec><sec><title>Conclusions:</title><p>Implementation of point-of-care hemostatic testing within the context of an integrated transfusion algorithm reduces red blood cell transfusions, platelet transfusions, and major bleeding following cardiac surgery. Our findings support the broader adoption of point-of-care hemostatic testing into clinical practice.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02200419.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/16/1152
10.1161/CIRCULATIONAHA.116.023956
None

4
Science
Role of AcrAB-TolC multidrug efflux pump in drug-resistance acquisition by plasmid transfer
<p>Drug-resistance dissemination by horizontal gene transfer remains poorly understood at the cellular scale. Using live-cell microscopy, we reveal the dynamics of resistance <strong><span style="color:yellowgreen">acquisit</span></strong>ion by transfer of the <i>Escherichia coli</i> fertility factor–conjugation plasmid encoding the tetracycline-efflux pump TetA. The entry of the single-stranded DNA plasmid into the recipient cell is rapidly followed by complementary-strand synthesis, plasmid-gene expression, and production of TetA. In the presence of translation-inhibiting antibiotics, resistance <strong><span style="color:yellowgreen">acquisit</span></strong>ion depends on the AcrAB-TolC multidrug efflux pump, because it reduces tetracycline concentrations in the cell. Protein synthesis can thus persist and TetA expression can be initiated immediately after plasmid <strong><span style="color:yellowgreen">acquisit</span></strong>ion. AcrAB-TolC efflux activity can also preserve resistance <strong><span style="color:yellowgreen">acquisit</span></strong>ion by plasmid transfer in the presence of antibiotics with other modes of action.</p>
http://sciencemag.org/cgi/content/abstract/364/6442/778
10.1126/science.aav6390
['Escherichia', 'Escherichia coli']

4
Science
Gene editing restores dystrophin expression in a canine model of Duchenne muscular dystrophy
<p>Mutations in the gene encoding dystrophin, a protein that maintains muscle integrity and function, cause Duchenne muscular dystrophy (DMD). The deltaE50-MD dog model of DMD harbors a mutation corresponding to a mutational “hotspot” in the human <i>DMD</i> gene. We used adeno-associated viruses to deliver CRISPR gene editing components to four dogs and examined dystrophin protein expression 6 weeks after intramuscular delivery (<i>n</i> = 2) or 8 weeks after systemic delivery (<i>n</i> = 2). After systemic delivery in skeletal muscle, dystrophin was restored to levels ranging from 3 to 90% of normal, depending on muscle type. In cardiac muscle, dystrophin levels in the dog <strong><span style="color:yellowgreen">receiv</span></strong>ing the highest dose reached 92% of normal. The treated dogs also showed improved muscle histology. These large-animal data support the concept that, with further development, gene editing approaches may prove clinically useful for the treatment of DMD.</p>
http://sciencemag.org/cgi/content/abstract/362/6410/86
10.1126/science.aau1549
['human']

4
Science
Two areas for familiar face recognition in the primate brain
<p>Familiarity alters face <strong><span style="color:yellowgreen">recognit</span></strong>ion: Familiar faces are recognized more accurately than unfamiliar ones and under difficult viewing conditions when unfamiliar face <strong><span style="color:yellowgreen">recognit</span></strong>ion fails. The neural basis for this fundamental difference remains unknown. Using whole-brain functional magnetic resonance imaging, we found that personally familiar faces engage the macaque face-processing network more than unfamiliar faces. Familiar faces also recruited two hitherto unknown face areas at anatomically conserved locations within the perirhinal cortex and the temporal pole. These two areas, but not the core face-processing network, responded to familiar faces emerging from a blur with a characteristic nonlinear surge, akin to the abruptness of familiar face <strong><span style="color:yellowgreen">recognit</span></strong>ion. In contrast, responses to unfamiliar faces and objects remained linear. Thus, two temporal lobe areas extend the core face-processing network into a familiar face-<strong><span style="color:yellowgreen">recognit</span></strong>ion system.</p>
http://sciencemag.org/cgi/content/abstract/357/6351/591
10.1126/science.aan1139
None

4
Science
Causal neural network of metamemory for retrospection in primates
<p>We know how confidently we know: Metacognitive self-monitoring of memory states, so-called “metamemory,” enables strategic and efficient information <strong><span style="color:yellowgreen">collect</span></strong>ion based on past experiences. However, it is unknown how metamemory is implemented in the brain. We explored causal neural mechanism of metamemory in macaque monkeys performing metacognitive confidence judgments on memory. By whole-brain searches via functional magnetic resonance imaging, we discovered a neural correlate of metamemory for temporally remote events in prefrontal area 9 (or 9/46d), along with that for recent events within area 6. Reversible inactivation of each of these identified loci induced doubly dissociated selective impairments in metacognitive judgment performance on remote or recent memory, without impairing <strong><span style="color:yellowgreen">recognit</span></strong>ion performance itself. The findings reveal that parallel metamemory streams supervise <strong><span style="color:yellowgreen">recognit</span></strong>ion networks for remote and recent memory, without contributing to <strong><span style="color:yellowgreen">recognit</span></strong>ion itself.</p>
http://sciencemag.org/cgi/content/abstract/355/6321/188
10.1126/science.aal0162
['primates']

4
Journal of Experimental Biology
Prior experience with conspecific signals enhances auditory midbrain responsiveness to conspecific vocalizations
<p>There is a long history in neuroethology of investigating how communication signals influence the brain and behavior. It has become increasingly clear that brain areas associated with sensory processing are plastic in adults and that this plasticity is related to reproductive condition. However, the role of communication signal <strong><span style="color:yellowgreen">recept</span></strong>ion in adult auditory plasticity has <strong><span style="color:yellowgreen">receiv</span></strong>ed relatively little attention. Here, we investigated whether the <strong><span style="color:yellowgreen">recept</span></strong>ion of communication signals (a frog chorus) could enhance the responsiveness of the auditory system to future <strong><span style="color:yellowgreen">recept</span></strong>ion of communication signals (a single male call). We found that animals that had been exposed to 10 days of a male chorus had stronger auditory midbrain immediate early gene expression than animals that had been exposed to 10 days of random tones when tested with 30 min of male calls or 30 min of tones. Our results suggest that exposure to dynamic social stimuli, like frog choruses, may play an important role in shaping the neural and behavioral responses to communication signals.</p>
http://jeb.biologists.org/cgi/content/abstract/217/11/1977
10.1242/jeb.096883
['animals']

4
Circulation
Counseling African Americans to Control Hypertension
<sec><title>Background—</title><p>Data are limited on the implementation of evidence-based multilevel interventions targeted at blood pressure (BP) control in hypertensive blacks who <strong><span style="color:yellowgreen">receiv</span></strong>e care in low-resource primary care practices.</p></sec><sec><title>Methods and Results—</title><p>Counseling African Americans to Control Hypertension is a cluster-randomized clinical trial in which 30 community health centers were randomly assigned to the intervention condition (IC) or usual care (UC). Patients at the IC sites <strong><span style="color:yellowgreen">receiv</span></strong>ed patient education, home BP monitoring, and monthly lifestyle counseling, whereas physicians attended monthly hypertension case rounds and <strong><span style="color:yellowgreen">receiv</span></strong>ed feedback on their patients’ home BP readings and chart audits. Patients and physicians at the UC sites <strong><span style="color:yellowgreen">receiv</span></strong>ed printed patient education material and hypertension treatment guidelines, respectively. The primary outcome was BP control, and secondary outcomes were mean changes in systolic and diastolic BPs at 12 months, assessed with an automated BP device. A total of 1059 patients (mean age, 56 years; 28% men, 59% obese, and 36% with diabetes mellitus) were enrolled. The BP control rate was similar in both groups (IC=49.3% versus UC=44.5%; odds ratio, 1.21 [95% confidence interval, 0.90–1.63]; <i>P</i>=0.21). In prespecified subgroup analyses, the intervention was associated with greater BP control in patients without diabetes mellitus (IC=54.0% versus UC=44.7%; odds ratio, 1.45 [confidence interval, 1.02–2.06]); and small-sized community health centers (IC=51.1% versus UC=39.6%; odds ratio, 1.45 [confidence interval, 1.04–2.45]).</p></sec><sec><title>Conclusions—</title><p>A practice-based, multicomponent intervention was no better than UC in improving BP control among hypertensive blacks. Future research on the implementation of behavioral modification strategies for hypertension control in low-resource settings should focus on the development of more efficient and tailored interventions in this high-risk population.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00233220.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/20/2044
10.1161/CIRCULATIONAHA.113.006650
None

3
Science Signaling
A Nanoparticle-Based Combination Chemotherapy Delivery System for Enhanced Tumor Killing by Dynamic Rewiring of Signaling Pathways
<sec><title>Timing the One-Two Punch</title><p>Morton <i>et al</i>. developed a dual-drug, time-delayed nanoparticle delivery system for treating cancer. The nanoparticles contained two drugs (one in the membrane and one in the center) and were coated to target the nanoparticles to cancer cells. Cancer cells took up the nanoparticles. The first drug quickly escaped the nanoparticle, sensitizing the cells to the second drug, which escaped more slowly. In mice, tumors from cells that respond to the first drug were reduced when the mice were treated with the dual-drug nanoparticles, but the tumors continued to grow in mice <strong><span style="color:yellowgreen">receiv</span></strong>ing only single-drug therapy. This time-delayed, nanoparticle-mediated drug delivery may avoid the resistance that cancer cells develop to chemotherapy.</p></sec>
http://stke.sciencemag.org/cgi/content/summary/7/325/ra44
10.1126/scisignal.2005261
None

3
Science
Supracellular contractions propel migration
<p>Constructing multicellular bodies, starting from a single-cell zygote, often requires the movement of cells across considerable distances, which is achieved through cell migration. During embryonic development, as well as in healing and regeneration, cells travel across diverse terrains, which dictates the character of navigation (<i>1</i>). Cancer cells metastasize and migrate into healthy organs, and knowledge of their migration strategies could be important to identify targets to treat advanced disease (<i>2</i>). Some migratory cells cover large distances individually (<i>3</i>), whereas others migrate in groups, with leaders and followers being directed by chemical signals (chemotaxis) (<i>4</i>, <i>5</i>). The exchange of information and resulting motility of such groups has been enigmatic. Moreover, the driving force of <strong><span style="color:yellowgreen">collect</span></strong>ive cell migration has been considered a sum of migratory and signaling activities of individually participating cells. However, according to a study on page 339 of this issue by Shellard <i>et al.</i> (<i>6</i>), <strong><span style="color:yellowgreen">collect</span></strong>ive cell migration requires formation of cytoskeletal structures that span through adjoining cells at the rear of a cell group to coordinate, orient, and propel the entire group. This mechanism of <strong><span style="color:yellowgreen">collect</span></strong>ive cell migration could be applicable to cancer metastasis and wound healing and might change our understanding of developmental migration.</p>
http://sciencemag.org/cgi/content/summary/362/6412/290
10.1126/science.aav3376
None

3
Science
Induction of CD4 T cell memory by local cellular collectivity
<p>Cell differentiation is directed by signals driving progenitors into specialized cell types. This process can involve <strong><span style="color:yellowgreen">collect</span></strong>ive decision-making, when differentiating cells determine their lineage choice by interacting with each other. We used live-cell imaging in microwell arrays to study <strong><span style="color:yellowgreen">collect</span></strong>ive processes affecting differentiation of naive CD4<sup>+</sup> T cells into memory precursors. We found that differentiation of precursor memory T cells sharply increases above a threshold number of locally interacting cells. These homotypic interactions involve the cytokines interleukin-2 (IL-2) and IL-6, which affect memory differentiation orthogonal to their effect on proliferation and survival. Mathematical modeling suggests that the differentiation rate is continuously modulated by the instantaneous number of locally interacting cells. This cellular <strong><span style="color:yellowgreen">collect</span></strong>ivity can prioritize allocation of immune memory to stronger responses.</p>
http://sciencemag.org/cgi/content/abstract/360/6394/eaaj1853
10.1126/science.aaj1853
None

3
Science
Plant-soil feedback and the maintenance of diversity in Mediterranean-climate shrublands
<p>Soil biota influence plant performance through plant-soil feedback, but it is unclear whether the strength of such feedback depends on plant traits and whether plant-soil feedback drives local plant diversity. We grew 16 co-occurring plant species with contrasting nutrient-<strong><span style="color:yellowgreen">acquisit</span></strong>ion strategies from hyperdiverse Australian shrublands and exposed them to soil biota from under their own or other plant species. Plant responses to soil biota varied according to their nutrient-<strong><span style="color:yellowgreen">acquisit</span></strong>ion strategy, including positive feedback for ectomycorrhizal plants and negative feedback for nitrogen-fixing and nonmycorrhizal plants. Simulations revealed that such strategy-dependent feedback is sufficient to maintain the high taxonomic and functional diversity characterizing these Mediterranean-climate shrublands. Our study identifies nutrient-<strong><span style="color:yellowgreen">acquisit</span></strong>ion strategy as a key trait explaining how different plant responses to soil biota promote local plant diversity.</p>
http://sciencemag.org/cgi/content/abstract/355/6321/173
10.1126/science.aai8291
['plants']

3
PLANT PHYSIOLOGY
Genetics of Variable Disease Expression Conferred by Inverse Gene-For-Gene Interactions in the Wheat-<i>Parastagonospora nodorum</i> Pathosystem
<p>The wheat-<i>Parastagonospora nodorum</i> pathosystem involves the <strong><span style="color:yellowgreen">recognit</span></strong>ion of pathogen-secreted necrotrophic effectors (NEs) by corresponding wheat NE sensitivity genes. This inverse gene-for-gene <strong><span style="color:yellowgreen">recognit</span></strong>ion leads to necrotrophic effector-triggered susceptibility and ultimately septoria nodorum blotch disease. Here, we used multiple pathogen isolates to individually evaluate the effects of the host gene-NE interactions <i>Tan spot necrosis1</i>-Stagonospora nodorum ToxinA (<i>Tsn1</i>-SnToxA), <i>Stagonospora nodorum necrosis1</i>-Stagonospora nodorum Toxin1 (<i>Snn1</i>-SnTox1), and <i>Stagonospora nodorum necrosis3-B genome homeolog1</i>-Stagonospora nodorum Toxin3 (<i>Snn3-B1</i>-SnTox3), alone and in various combinations, to determine the relative importance of these interactions in causing disease. Genetic analysis of a recombinant inbred wheat population inoculated separately with three <i>P. nodorum</i> isolates, all of which produce all three NEs, indicated that the <i>Tsn1</i>-SnToxA and <i>Snn3-B1</i>-SnTox3 interactions contributed to disease caused by all four isolates, but their effects varied and ranged from epistatic to additive. The <i>Snn1</i>-SnTox1 interaction was associated with increased disease for one isolate, but for other isolates, there was evidence that this interaction inhibited the expression of other host gene-NE interactions. RNA sequencing analysis in planta showed that <i>SnTox1</i> was differentially expressed between these three isolates after infection. Further analysis of NE gene-knockout isolates showed that the effect of some interactions could be masked or inhibited by other compatible interactions, and the regulation of this occurs at the level of NE gene transcription. Collectively, these results show that the inverse gene-for-gene interactions leading to necrotrophic effector-triggered susceptibility in the wheat-<i>P. nodorum</i> pathosystem vary in their effects depending on the genetic backgrounds of the pathogen and host, and interplay among the interactions is complex and intricately regulated.</p>
http://plantphysiol.org/cgi/content/abstract/180/1/420
10.1104/pp.19.00149
['Stagonospora', 'wheat']

3
PLANT PHYSIOLOGY
Multiplexed Gene Editing and Protein Overexpression Using a <i>Tobacco mosaic virus</i> Viral Vector
<p>Development of CRISPR/Cas9 transient gene editing screening tools in plant biology has been hindered by difficulty of <strong><span style="color:yellowgreen">deliveri</span></strong>ng high quantities of biologically active single guide RNAs (sgRNAs). Furthermore, it has been largely accepted that in vivo generated sgRNAs need to be devoid of extraneous nucleotides, which has limited sgRNA expression by delivery vectors. Here, we increased cellular concentrations of sgRNA by transiently <strong><span style="color:yellowgreen">deliveri</span></strong>ng sgRNAs using a <i>Tobacco mosaic virus</i>-derived vector (TRBO) designed with 5′ and 3′ sgRNA proximal nucleotide-processing capabilities. To demonstrate proof-of-principle, we used the TRBO-sgRNA delivery platform to target GFP in <i>Nicotiana benthamiana</i> (16c) plants, and gene editing was accompanied by loss of GFP expression. Surprisingly, indel (insertions and deletions) percentages averaged nearly 70% within 7 d postinoculation using the TRBO-sgRNA constructs, which retained 5′ nucleotide overhangs. In contrast, and in accordance with current models, in vitro Cas9 cleavage assays only edited DNA when 5′ sgRNA nucleotide overhangs were removed, suggesting a novel processing mechanism is occurring in planta. Since the Cas9/TRBO-sgRNA platform demonstrated sgRNA flexibility, we targeted the <i>N. benthamiana NbAGO1</i> paralogs with one sgRNA and also multiplexed two sgRNAs using a single TRBO construct, resulting in indels in three genes. TRBO-mediated expression of an RNA transcript consisting of an sgRNA adjoining a GFP protein coding region produced indels and viral-based GFP overexpression. In conclusion, multiplexed delivery of sgRNAs using the TRBO system offers flexibility for gene expression and editing and uncovered novel aspects of CRISPR/Cas9 biology.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/23
10.1104/pp.17.00411
['Nicotiana', 'plants']

3
PLANT PHYSIOLOGY
Generation of a Collection of Mutant Tomato Lines Using Pooled CRISPR Libraries
<p>The high efficiency of clustered regularly interspaced short palindromic repeats (CRISPR)-mediated mutagenesis in plants enables the development of high-throughput mutagenesis strategies. By transforming pooled CRISPR libraries into tomato (<i>Solanum lycopersicum</i>), <strong><span style="color:yellowgreen">collect</span></strong>ions of mutant lines were generated with minimal transformation attempts and in a relatively short period of time. Identification of the targeted gene(s) was easily determined by sequencing the incorporated guide RNA(s) in the primary transgenic events. From a single transformation with a CRISPR library targeting the immunity-associated leucine-rich repeat subfamily XII genes, heritable mutations were recovered in 15 of the 54 genes targeted. To increase throughput, a second CRISPR library was made containing three guide RNAs per construct to target 18 putative transporter genes. This resulted in stable mutations in 15 of the 18 targeted genes, with some primary transgenic plants having as many as five mutated genes. Furthermore, the redundancy in this <strong><span style="color:yellowgreen">collect</span></strong>ion of plants allowed for the association of aberrant T0 phenotypes with the underlying targeted genes. Plants with mutations in a homolog of an Arabidopsis (<i>Arabidopsis thaliana</i>) boron efflux transporter displayed boron deficiency phenotypes. The strategy described here provides a technically simple yet high-throughput approach for generating a <strong><span style="color:yellowgreen">collect</span></strong>ion of lines with targeted mutations and should be applicable to any plant transformation system.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2023
10.1104/pp.17.00489
['Arabidopsis', 'Arabidopsis thaliana', 'Solanum', 'Solanum lycopersicum', 'plants']

3
Molecular Biology and Evolution
Source of CpG Depletion in the HIV-1 Genome
<p>The dinucleotide CpG is highly underrepresented in the genome of human immunodeficiency virus type 1 (HIV-1). To identify the source of CpG depletion in the HIV-1 genome, we investigated two biological mechanisms: (1) CpG methylation-induced transcriptional silencing and (2) CpG <strong><span style="color:yellowgreen">recognit</span></strong>ion by Toll-like <strong><span style="color:yellowgreen">recept</span></strong>ors (TLRs). We hypothesized that HIV-1 has been under selective evolutionary pressure by these mechanisms leading to the reduction of CpG in its genome. A CpG depleted genome would enable HIV-1 to avoid methylation-induced transcriptional silencing and/or to avoid <strong><span style="color:yellowgreen">recognit</span></strong>ion by TLRs that identify foreign CpG sequences. We investigated these two hypotheses by determining the sequence context dependency of CpG depletion and comparing it with that of CpG methylation and TLR <strong><span style="color:yellowgreen">recognit</span></strong>ion. We found that in both human and HIV-1 genomes the CpG motifs flanked by T/A were depleted most and those flanked by C/G were depleted least. Similarly, our analyses of human methylome data revealed that the CpG motifs flanked by T/A were methylated most and those flanked by C/G were methylated least. Given that a similar CpG depletion pattern was observed for the human genome within which CpGs are not likely to be recognized by TLRs, we argue that the main source of CpG depletion in HIV-1 is likely host-induced methylation. Analyses of CpG motifs in over 100 viruses revealed that this unique CpG representation pattern is specific to the human and simian immunodeficiency viruses.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3205
10.1093/molbev/msw205
['human']

3
The Bone & Joint Journal
Tuberculosis of the spine with severe angular kyphosis
<sec><title>Aims</title><p>To address the natural history of severe post-tuberculous (TB)   kyphosis, with focus upon the long-term neurological outcome, occurrence   of restrictive lung disease, and the effect on life expectancy. </p></sec><sec><title>Patients and Methods</title><p>This is a retrospective clinical review of prospectively <strong><span style="color:yellowgreen">collect</span></strong>ed   imaging data based at a single institute. A total of 24 patients   of Southern Chinese origin who presented with spinal TB with a mean   of 113° of kyphosis (65° to 159°) who fulfilled inclusion criteria   were reviewed. Plain radiographs were used to assess the degree   of spinal deformity. Myelography, CT and MRI were used when available   to assess the integrity of the spinal cord and canal. Patient demographics,   age of onset of spinal TB and interventions, types of surgical procedure,   intra- and post-operative complications, and neurological status   were assessed. </p></sec><sec><title>Results</title><p>All except one of the 24 patients were treated with anti-TB chemotherapy   when they were first diagnosed with spinal TB. They subsequently   <strong><span style="color:yellowgreen">receiv</span></strong>ed surgery either for neurological deterioration, or deformity   correction in later life. The mean follow-up was 34 years (11 to   59) since these surgical interventions. Some 16 patients (66.7%) suffered   from late neurological deterioration at a mean of 26 years (8 to   49) after the initial drug treatment. The causes of neurological   deterioration were healed disease in nine patients (56.2%),    re-activation in six patients (37.5%) and adjacent level spinal   stenosis in one patient (6.3%). The result of surgery was worse   in healed disease. Eight patients without neurological deterioration   <strong><span style="color:yellowgreen">receiv</span></strong>ed surgery to correct the kyphosis. The mean correction ranged   from 97° to 72°. Three patients who were clinically quiescent with   no neurological deterioration were found to have active TB of the   spine. Solid fusion was achieved in all cases and no patient suffered   from neurological deterioration after 42 years of follow-up. On   final follow-up, six patients were noted to have deceased (age range:   47 years to 75 years).</p></sec><sec><title>Conclusion</title><p>Our study presents one of the longest assessments of spinal TB   with severe kyphosis. Severe post-TB kyphosis may lead to significant   health problems many years following the initial drug treatment.   Early surgical correction of the kyphosis, solid fusion and regular   surveillance may avoid late complications. Paraplegia, restrictive   lung disease and early onset kyphosis might relate to early death.   Clinically quiescent disease does not mean cure. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1381–8.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/10/1381
10.1302/0301-620X.99B10.BJJ-2017-0148.R1
None

3
Circulation
Association Between Urinary Sodium and Potassium Excretion and Blood Pressure Among Adults in the United States
<sec><title>Background:</title><p>Higher levels of sodium and lower levels of potassium intake are associated with higher blood pressure. However, the shape and magnitude of these associations can vary by study participant characteristics or intake assessment method. Twenty-four–hour urinary excretion of sodium and potassium are unaffected by recall errors and represent all sources of intake, and were <strong><span style="color:yellowgreen">collect</span></strong>ed for the first time in a nationally representative US survey. Our objective was to assess the associations of blood pressure and hypertension with 24-hour urinary excretion of sodium and potassium among US adults.</p></sec><sec><title>Methods:</title><p>Cross-sectional data were obtained from 766 participants age 20 to 69 years with complete blood pressure and 24-hour urine <strong><span style="color:yellowgreen">collect</span></strong>ions in the 2014 National Health and Nutrition Examination Survey, a nationally representative survey of the US noninstitutionalized population. Usual 24-hour urinary electrolyte excretion (sodium, potassium, and their ratio) was estimated from ≤2 <strong><span style="color:yellowgreen">collect</span></strong>ions on nonconsecutive days, adjusting for day-to-day variability in excretion. Outcomes included systolic and diastolic blood pressure from the average of 3 measures and hypertension status, based on average blood pressure ≥140/90 and antihypertensive medication use.</p></sec><sec><title>Results:</title><p>After multivariable adjustment, each 1000-mg difference in usual 24-hour sodium excretion was directly associated with systolic (4.58 mm Hg; 95% confidence interval [CI], 2.64–6.51) and diastolic (2.25 mm Hg; 95% CI, 0.83–3.67) blood pressures. Each 1000-mg difference in potassium excretion was inversely associated with systolic blood pressure (–3.72 mm Hg; 95% CI, –6.01 to –1.42). Each 0.5 U difference in sodium-to-potassium ratio was directly associated with systolic blood pressure (1.72 mm Hg; 95% CI, 0.76–2.68). Hypertension was linearly associated with progressively higher sodium and lower potassium excretion; in comparison with the lowest quartile of excretion, the adjusted odds of hypertension for the highest quartile was 4.22 (95% CI, 1.36–13.15) for sodium, and 0.38 (95% CI, 0.17–0.87) for potassium (<i>P</i><0.01 for trends).</p></sec><sec><title>Conclusions:</title><p>These cross-sectional results show a strong dose-response association between urinary sodium excretion and blood pressure, and an inverse association between urinary potassium excretion and blood pressure, in a nationally representative sample of US adults.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/3/237
10.1161/CIRCULATIONAHA.117.029193
None

3
Circulation
Associations Between Adding a Radial Artery Graft to Single and Bilateral Internal Thoracic Artery Grafts and Outcomes
<sec><title>Background:</title><p>Whether the use of the radial artery (RA) can improve clinical outcomes in coronary artery bypass graft surgery remains unclear. The ART (Arterial Revascularization Trial) was designed to compare survival after bilateral internal thoracic artery (BITA) over single left internal thoracic artery (SITA). In the ART, a large proportion of patients (≈20%) also <strong><span style="color:yellowgreen">receiv</span></strong>ed an RA graft instead of a saphenous vein graft (SVG). We aimed to investigate the associations between using the RA instead of an SVG to supplement SITA or BITA grafts and outcomes by performing a post hoc analysis of the ART.</p></sec><sec><title>Methods:</title><p>Patients enrolled in the ART (n=3102) were classified on the basis of conduits actually <strong><span style="color:yellowgreen">receiv</span></strong>ed (as treated). The analysis included 2737 patients who <strong><span style="color:yellowgreen">receiv</span></strong>ed an RA graft (RA group; n=632) or SVG only (SVG group; n=2105) in addition to SITA or BITA grafts. The primary end point was the composite of myocardial infarction, cardiovascular death, and repeat revascularization at 5 years. Propensity score matching and stratified Cox regression were used to compare the 2 strategies.</p></sec><sec><title>Results:</title><p>Myocardial infarction, cardiovascular death, and repeat revascularization cumulative incidence was 2.3% (95% confidence interval [CI], 1.1–3.4), 3.5% (95% CI, 2.1–5.0), and 4.4% (95% CI, 2.8–6.0) in the RA group and 3.4% (95% CI, 2.0–4.8), 4.0% (95% CI, 2.5–5.6), and 7.6% (95% CI, 5.5–9.7) in the SVG group, respectively. The composite end point was significantly lower in the RA group (8.8%; 95% CI, 6.5–11.0) compared with the SVG group (13.6%; 95% CI, 10.8–16.3; <i>P</i>=0.005). This association was present when an RA graft was used to supplement both SITA and BITA grafts (interaction <i>P</i>=0.62).</p></sec><sec><title>Conclusions:</title><p>This post hoc ART analysis showed that an additional RA was associated with lower risk for midterm major adverse cardiac events when used to supplement SITA or BITA grafts.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.situ.ox.ac.uk/surgical-trials/art</ext-link>. Unique identifier: ISRCTN46552265.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/5/454
10.1161/CIRCULATIONAHA.117.027659
None

3
Circulation
Antiarrhythmic Drugs for Nonshockable-Turned-Shockable Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Out-of-hospital cardiac arrest (OHCA) commonly presents with nonshockable rhythms (asystole and pulseless electric activity). It is unknown whether antiarrhythmic drugs are safe and effective when nonshockable rhythms evolve to shockable rhythms (ventricular fibrillation/pulseless ventricular tachycardia [VF/VT]) during resuscitation.</p></sec><sec><title>Methods:</title><p>Adults with nontraumatic OHCA, vascular access, and VF/VT anytime after ≥1 shock(s) were prospectively randomized, double-blind, to <strong><span style="color:yellowgreen">receiv</span></strong>e amiodarone, lidocaine, or placebo by paramedics. Patients presenting with initial shock-refractory VF/VT were previously reported. The current study was a prespecified analysis in a separate cohort that initially presented with nonshockable OHCA and was randomized on subsequently developing shock-refractory VF/VT. The primary outcome was survival to hospital discharge. Secondary outcomes included discharge functional status and adverse drug-related effects.</p></sec><sec><title>Results:</title><p>Of 37 889 patients with OHCA, 3026 with initial VF/VT and 1063 with initial nonshockable-turned-shockable rhythms were treatment-eligible, were randomized, and <strong><span style="color:yellowgreen">receiv</span></strong>ed their assigned drug. Baseline characteristics among patients with nonshockable-turned-shockable rhythms were balanced across treatment arms, except that recipients of a placebo included fewer men and were less likely to <strong><span style="color:yellowgreen">receiv</span></strong>e bystander cardiopulmonary resuscitation. Active-drug recipients in this cohort required fewer shocks, supplemental doses of their assigned drug, and ancillary antiarrhythmic drugs than recipients of a placebo (<i>P</i><0.05). In all, 16 (4.1%) amiodarone, 11 (3.1%) lidocaine, and 6 (1.9%) placebo-treated patients survived to hospital discharge (<i>P</i>=0.24). No significant interaction between treatment assignment and discharge survival occurred with the initiating OHCA rhythm (asystole, pulseless electric activity, or VF/VT). Survival in each of these categories was consistently higher with active drugs, although the trends were not statistically significant. Adjusted absolute differences (95% confidence interval) in survival from nonshockable-turned-shockable arrhythmias with amiodarone versus placebo were 2.3% (−0.3, 4.8), <i>P</i>=0.08, and for lidocaine versus placebo 1.2% (−1.1, 3.6), <i>P</i>=0.30. More than 50% of these survivors were functionally independent or required minimal assistance. Drug-related adverse effects were infrequent.</p></sec><sec><title>Conclusions:</title><p>Outcome from nonshockable-turned-shockable OHCA is poor but not invariably fatal. Although not statistically significant, point estimates for survival were greater after amiodarone or lidocaine than placebo, without increased risk of adverse effects or disability and consistent with previously observed favorable trends from treatment of initial shock-refractory VF/VT with these drugs. Together the findings may signal a clinical benefit that invites further investigation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01401647.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2119
10.1161/CIRCULATIONAHA.117.028624
None

3
Circulation
Use of a Single Baseline Versus Multiyear 24-Hour Urine Collection for Estimation of Long-Term Sodium Intake and Associated Cardiovascular and Renal Risk
<sec><title>Background:</title><p>A decrease in sodium intake has been shown to lower blood pressure, but data from cohort studies on the association with cardiovascular and renal outcomes are inconsistent. In these studies, sodium intake was often estimated with a single baseline measurement, which may be inaccurate considering day-to-day changes in sodium intake and sodium excretion. We compared the effects of single versus repetitive follow-up 24-hour urine samples on the relation between sodium intake and long-term cardiorenal outcomes.</p></sec><sec><title>Methods:</title><p>We selected adult subjects with an estimated glomerular filtration rate >60 mL/min/1.73m<sup>2</sup>, an outpatient 24-hour urine sample between 1998 and 1999, and at least 1 <strong><span style="color:yellowgreen">collect</span></strong>ion during a 17-year follow-up. Sodium intake was estimated with a single baseline <strong><span style="color:yellowgreen">collect</span></strong>ion and the average of samples <strong><span style="color:yellowgreen">collect</span></strong>ed during a 1-, 5-, and 15-year follow-up. We used Cox regression analysis and the landmark approach to investigate the relation between sodium intake and cardiovascular (cardiovascular events or mortality) and renal (end-stage renal disease: dialysis, transplantation, and/or >60% estimated glomerular filtration rate decline, or mortality) outcomes.</p></sec><sec><title>Results:</title><p>We included 574 subjects with 9776 twenty-four–hour urine samples. Average age was 47 years, and 46% were male. Median follow-up was 16.2 years. Average 24-hour sodium excretion, ranging from 3.8 to 3.9 g (165–170 mmol), was equal among all methods (<i>P</i>=0.88). However, relative to a single baseline measurement, 50% of the subjects had a >0.8-g (>34-mmol) difference in sodium intake with long-term estimations. As a result, 45%, 49%, and 50% of all subjects switched between tertiles of sodium intake when the 1-, 5-, or 15-year average was used, respectively. Consequently, hazard ratios for cardiorenal outcome changed up to 85% with the use of sodium intake estimations from short-term (1-year) and long-term (5-year) follow-up instead of baseline estimations.</p></sec><sec><title>Conclusions:</title><p>Relative to a single baseline 24-hour sodium measurement, the use of subsequent 24-hour urine samples resulted in different estimations of an individual’s sodium intake, whereas population averages remained similar. This finding had significant consequences for the association between sodium intake and long-term cardiovascular and renal outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/10/917
10.1161/CIRCULATIONAHA.117.029028
None

3
Circulation
Atrial Fibrillation and Ventricular Arrhythmias
<p>Sex-specific differences in the epidemiology, pathophysiology, clinical presentation, clinical treatment, and clinical outcomes of atrial fibrillation (AF), sustained ventricular arrhythmias, and sudden cardiac death are recognized. Sex hormones cause differences in cardiac electrophysiological parameters between men and women that may affect the risk for arrhythmias. The incidence and prevalence of AF is lower in women than in men. However, because women live longer and AF prevalence increases with age, the absolute number of women with AF exceeds that of men. Women with AF are more symptomatic, present with more atypical symptoms, and report worse quality of life in comparison with men. Female sex is an independent risk factor for death or stroke attributable to AF. Oral anticoagulation therapy for stroke prevention has similar efficacy for men and women, but older women treated with warfarin have a higher residual risk of stroke in comparison with men. Women with AF are less likely to <strong><span style="color:yellowgreen">receiv</span></strong>e rhythm control antiarrhythmic drug therapy, electric cardioversion, or catheter ablation in comparison with men. The incidence and prevalence of sustained ventricular arrhythmias and sudden cardiac death are lower in women than in men. Women <strong><span style="color:yellowgreen">receiv</span></strong>ing implantable cardioverter defibrillators for primary prevention of sudden cardiac death are less likely to experience sustained ventricular arrhythmias in comparison with men. In contrast, women <strong><span style="color:yellowgreen">receiv</span></strong>ing a cardiac resynchronization therapy implantable cardioverter defibrillator for the treatment of heart failure are more likely to benefit than men. Women are less likely to be referred for implantable cardioverter defibrillator therapy despite current guideline recommendations. Women are more likely to experience a significant complication related to implantable cardioverter defibrillator implantation in comparison with men. Whether sex differences in treatment decisions reflect patient preferences or treatment biases requires further study.</p>
http://circ.ahajournals.org/cgi/content/abstract/135/6/593
10.1161/CIRCULATIONAHA.116.025312
None

3
Circulation
Conventional Versus Compression-Only Versus No-Bystander Cardiopulmonary Resuscitation for Pediatric Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Conventional cardiopulmonary resuscitation (CPR) (chest compression and rescue breathing) has been recommended for pediatric out-of-hospital cardiac arrest (OHCA) because of the asphyxial nature of the majority of pediatric cardiac arrest events. However, the clinical effectiveness of additional rescue breathing (conventional CPR) compared with compression-only CPR in children is uncertain.</p></sec><sec><title>Methods:</title><p>This nationwide population-based study of pediatric OHCA patients was based on data from the All-Japan Utstein Registry. We included all pediatric patients who experienced OHCA in Japan from January 1, 2011, to December 31, 2012. The primary outcome was a favorable neurological state 1 month after OHCA defined as a Glasgow-Pittsburgh Cerebral Performance Category score of 1 to 2 (corresponding to a Pediatric Cerebral Performance Category score of 1–3). Outcomes were compared with logistic regression with uni- and multivariable modeling in the overall cohort and for a propensity-matched subset of patients.</p></sec><sec><title>Results:</title><p>A total of 2157 patients were included; 417 <strong><span style="color:yellowgreen">receiv</span></strong>ed conventional CPR, 733 <strong><span style="color:yellowgreen">receiv</span></strong>ed compression-only CPR, and 1007 did not <strong><span style="color:yellowgreen">receiv</span></strong>e any bystander CPR. Among these patients, 213 (9.9%) survived with a favorable neurological status 1 month after OHCA, including 108/417 (25.9%) for conventional, 68/733 (9.3%) for compression-only, and 37/1007 (3.7%) for no-bystander CPR. In unadjusted analyses, conventional CPR was superior to compression-only CPR in neurologically favorable survival (odds ratio [OR] 3.42, 95% confidence interval [CI] 2.45–4.76; <i>P</i><0.0001), with a trend favoring conventional CPR that was no longer statistically significant after multivariable adjustment (OR<sub>adjusted</sub> 1.52, 95% CI 0.93–2.49), and with further attenuation of the difference in a propensity-matched subset (OR 1.20, 95% CI 0.81–1.77). Both conventional and compression-only CPR were associated with higher odds for neurologically favorable survival compared with no-bystander CPR (OR<sub>adjusted</sub> 5.01, 95% CI 2.98–8.57, and OR<sub>adjusted</sub> 3.29, 95% CI 1.93–5.71), respectively.</p></sec><sec><title>Conclusions:</title><p>In this population-based study of pediatric OHCA in Japan, both conventional and compression-only CPR were associated with superior outcomes compared with no-bystander CPR. Unadjusted outcomes with conventional CPR were superior to compression-only CPR, with the magnitude of difference attenuated and no longer statistically significant after statistical adjustments. These findings support randomized clinical trials comparing conventional versus compression-only CPR in children, with conventional CPR preferred until such controlled comparative data are available, and either method preferred over no-bystander CPR.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2060
10.1161/CIRCULATIONAHA.116.023831
None

3
Circulation
Diagnosis and Treatment of Fetal Cardiac Disease
<sec><title>Background—</title><p>The goal of this statement is to review available literature and to put forth a scientific statement on the current practice of fetal cardiac medicine, including the diagnosis and management of fetal cardiovascular disease.</p></sec><sec><title>Methods and Results—</title><p>A writing group appointed by the American Heart Association reviewed the available literature pertaining to topics relevant to fetal cardiac medicine, including the diagnosis of congenital heart disease and arrhythmias, assessment of cardiac function and the cardiovascular system, and available treatment options. The American College of Cardiology/American Heart Association classification of recommendations and level of evidence for practice guidelines were applied to the current practice of fetal cardiac medicine. Recommendations relating to the specifics of fetal diagnosis, including the timing of referral for study, indications for referral, and experience suggested for performance and interpretation of studies, are presented. The components of a fetal echocardiogram are described in detail, including descriptions of the assessment of cardiac anatomy, cardiac function, and rhythm. Complementary modalities for fetal cardiac assessment are reviewed, including the use of advanced ultrasound techniques, fetal magnetic resonance imaging, and fetal magnetocardiography and electrocardiography for rhythm assessment. Models for parental counseling and a discussion of parental stress and depression assessments are reviewed. Available fetal therapies, including medical management for arrhythmias or heart failure and closed or open intervention for diseases affecting the cardiovascular system such as twin–twin transfusion syndrome, lung masses, and vascular tumors, are highlighted. Catheter-based intervention strategies to prevent the progression of disease in utero are also discussed. Recommendations for delivery planning strategies for fetuses with congenital heart disease including models based on classification of disease severity and delivery room treatment will be highlighted. Outcome assessment is reviewed to show the benefit of prenatal diagnosis and management as they affect outcome for babies with congenital heart disease.</p></sec><sec><title>Conclusions—</title><p>Fetal cardiac medicine has evolved considerably over the past 2 decades, predominantly in response to advances in imaging technology and innovations in therapies. The diagnosis of cardiac disease in the fetus is mostly made with ultrasound; however, new technologies, including 3- and 4-dimensional echocardiography, magnetic resonance imaging, and fetal electrocardiography and magnetocardiography, are available. Medical and interventional treatments for select diseases and strategies for delivery room care enable stabilization of high-risk fetuses and contribute to improved outcomes. This statement highlights what is currently known and recommended on the basis of evidence and experience in the rapidly advancing and highly specialized field of fetal cardiac care.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/21/2183
10.1161/01.cir.0000437597.44550.5d
None

3
Circulation
Survey of a Protocol to Increase Appropriate Implementation of Dispatcher-Assisted Cardiopulmonary Resuscitation for Out-of-Hospital Cardiac Arrest
<sec><title>Background—</title><p>Dispatcher-assisted cardiopulmonary resuscitation (DA-CPR) attempts to improve the management of out-of-hospital cardiac arrest by laypersons who are unable to recognize cardiac arrest and are unfamiliar with CPR. Therefore, we investigated the sensitivity and specificity of our new DA-CPR protocol for achieving implementation of bystander CPR in out-of-hospital cardiac arrest victims not already <strong><span style="color:yellowgreen">receiv</span></strong>ing bystander CPR.</p></sec><sec><title>Methods and Results—</title><p>Since 2007, we have applied a new DA-CPR protocol that uses supplementary key words. Fire departments prospectively <strong><span style="color:yellowgreen">collect</span></strong>ed baseline data on DA-CPR from January 2009 to December 2011. DA-CPR was attempted in 2747 patients; of these, 417 (15.2%) did not experience cardiac arrest. The sensitivity and specificity of the 2007 protocol versus estimated values of the previous standard protocol were 72.9% versus 50.3% and 99.6% versus 99.8%, respectively. We identified key words that may be useful for detecting out-of-hospital cardiac arrest. Multiple logistic regression analysis revealed that the occurrence of cardiac arrest after an emergency call (odds ratio, 16.85) and placing an emergency call away from the scene of the arrest (odds ratio, 11.04) were potentially associated with failure to provide DA-CPR. Furthermore, at-home cardiac arrest (odds ratio, 1.61) and family members as bystanders (odds ratio, 1.55) were associated with bystander noncompliance with DA-CPR. No complications were reported in the 417 patients who <strong><span style="color:yellowgreen">receiv</span></strong>ed DA-CPR but did not have cardiac arrest.</p></sec><sec><title>Conclusions—</title><p>Our 2007 protocol is safe and highly specific and may be more sensitive than the standard protocol. Understanding the factors associated with failure of bystanders to provide DA-CPR and implementing public education are necessary to increase the benefit of DA-CPR.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/17/1751
10.1161/CIRCULATIONAHA.113.004409
None

2
PLANT PHYSIOLOGY
Biosynthesis of Diterpenoids in <i>Tripterygium</i> Adventitious Root Cultures
<p>Adventitious root cultures were developed from <i>Tripterygium regelii</i>, and growth conditions were optimized for the abundant production of diterpenoids, which can be <strong><span style="color:yellowgreen">collect</span></strong>ed directly from the medium. An analysis of publicly available transcriptome data sets <strong><span style="color:yellowgreen">collect</span></strong>ed with <i>T. regelii</i> roots and root cultures indicated the presence of a large gene family (with 20 members) for terpene synthases (TPSs). Nine candidate diterpene synthase genes were selected for follow-up functional evaluation, of which two belonged to the TPS-c, three to the TPS-e/f, and four to the TPS-b subfamilies. These genes were characterized by heterologous expression in a modular metabolic engineering system in <i>Escherichia coli</i>. Members of the TPS-c subfamily were characterized as copalyl diphosphate (diterpene) synthases, and those belonging to the TPS-e/f subfamily catalyzed the formation of precursors of kaurane diterpenoids. The TPS-b subfamily encompassed genes coding for enzymes involved in abietane diterpenoid biosynthesis and others with activities as monoterpene synthases. The structural characterization of diterpenoids accumulating in the medium of <i>T. regelii</i> adventitious root cultures, facilitated by searching the Spektraris online spectral database, enabled us to formulate a biosynthetic pathway for the biosynthesis of triptolide, a diterpenoid with pharmaceutical potential. Considering the significant enrichment of diterpenoids in the culture medium, fast-growing adventitious root cultures may hold promise as a sustainable resource for the large-scale production of triptolide.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/92
10.1104/pp.17.00659
['Escherichia', 'Escherichia coli']

2
PLANT PHYSIOLOGY
Sequence Exchange between Homologous NB-LRR Genes Converts Virus Resistance into Nematode Resistance, and Vice Versa
<p>Plants have evolved a limited repertoire of NB-LRR disease resistance (<i>R</i>) genes to protect themselves against myriad pathogens. This limitation is thought to be counterbalanced by the rapid evolution of NB-LRR proteins, as only a few sequence changes have been shown to be sufficient to alter resistance specificities toward novel strains of a pathogen. However, little is known about the flexibility of NB-LRR <i>R</i> genes to switch resistance specificities between phylogenetically unrelated pathogens. To investigate this, we created domain swaps between the close homologs <i>Gpa2</i> and <i>Rx1</i>, which confer resistance in potato (<i>Solanum tuberosum</i>) to the cyst nematode <i>Globodera pallida</i> and <i>Potato virus X</i>, respectively. The genetic fusion of the CC-NB-ARC of Gpa2 with the LRR of Rx1 (Gpa2<sub>CN</sub>/Rx1<sub>L</sub>) results in autoactivity, but lowering the protein levels restored its specific activation response, including extreme resistance to <i>Potato virus X</i> in potato shoots. The reciprocal chimera (Rx1<sub>CN</sub>/Gpa2<sub>L</sub>) shows a loss-of-function phenotype, but exchange of the first three LRRs of Gpa2 by the corresponding region of Rx1 was sufficient to regain a wild-type resistance response to <i>G. pallida</i> in the roots. These data demonstrate that exchanging the <strong><span style="color:yellowgreen">recognit</span></strong>ion moiety in the LRR is sufficient to convert extreme virus resistance in the leaves into mild nematode resistance in the roots, and vice versa. In addition, we show that the CC-NB-ARC can operate independently of the <strong><span style="color:yellowgreen">recognit</span></strong>ion specificities defined by the LRR domain, either aboveground or belowground. These data show the versatility of NB-LRR genes to generate resistance to unrelated pathogens with completely different lifestyles and routes of invasion.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/498
10.1104/pp.17.00485
['Solanum', 'Solanum tuberosum']

2
PLANT PHYSIOLOGY
Root Cortical Senescence Improves Growth under Suboptimal Availability of N, P, and K
<p>Root cortical senescence (RCS) in Triticeae reduces nutrient uptake, nutrient content, respiration, and radial hydraulic conductance of root tissue. We used the functional-structural model <i>SimRoot</i> to evaluate the functional implications of RCS in barley (<i>Hordeum vulgare</i>) under suboptimal nitrate, phosphorus, and potassium availability. The utility of RCS was evaluated using sensitivity analyses in contrasting nutrient regimes. At flowering (80 d), RCS increased simulated plant growth by up to 52%, 73%, and 41% in nitrate-, phosphorus-, and potassium-limiting conditions, respectively. Plants with RCS had reduced nutrient requirement of root tissue for optimal plant growth, reduced total cumulative cortical respiration, and increased total carbon reserves. Nutrient reallocation during RCS had a greater effect on simulated plant growth than reduced respiration or nutrient uptake. Under low nutrient availability, RCS had greater benefit in plants with fewer tillers. RCS had greater benefit in phenotypes with fewer lateral roots at low nitrate availability, but the opposite was true in low phosphorus or potassium availability. Additionally, RCS was quantified in field-grown barley in different nitrogen regimes. Field and virtual soil coring simulation results demonstrated that living cortical volume per root length (an indicator of RCS) decreased with depth in younger plants, while roots of older plants had very little living cortical volume per root length. RCS may be an adaptive trait for nutrient <strong><span style="color:yellowgreen">acquisit</span></strong>ion by reallocating nutrients from senescing tissue and secondarily by reducing root respiration. These simulated results suggest that RCS merits investigation as a breeding target for enhanced soil resource <strong><span style="color:yellowgreen">acquisit</span></strong>ion and edaphic stress tolerance.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2333
10.1104/pp.17.00648
['Hordeum', 'Hordeum vulgare', 'barley', 'plants']

2
PLANT PHYSIOLOGY
A Legume TOR Protein Kinase Regulates <i>Rhizobium</i> Symbiosis and Is Essential for Infection and Nodule Development
<p>The target of rapamycin (<i>TOR</i>) protein kinase regulates metabolism, growth, and life span in yeast, animals, and plants in coordination with nutrient status and environmental conditions. The nutrient-dependent nature of <i>TOR</i> functionality makes this kinase a putative regulator of symbiotic associations involving nutrient <strong><span style="color:yellowgreen">acquisit</span></strong>ion. However, <i>TOR</i>’s role in these processes remains to be understood. Here, we uncovered the role of <i>TOR</i> during the bean (<i>Phaseolus vulgaris</i>)-<i>Rhizobium tropici</i> (<i>Rhizobium</i>) symbiotic interaction. <i>TOR</i> was expressed in all tested bean tissues, with higher transcript levels in the root meristems and senesced nodules. We showed <i>TOR</i> promoter expression along the progressing infection thread and in the infected cells of mature nodules. Posttranscriptional gene silencing of <i>TOR</i> using RNA interference (RNAi) showed that this gene is involved in lateral root elongation and root cell organization and also alters the density, size, and number of root hairs. The suppression of <i>TOR</i> transcripts also affected infection thread progression and associated cortical cell divisions, resulting in a drastic reduction of nodule numbers. <i>TOR</i>-RNAi resulted in reduced reactive oxygen species accumulation and altered <i>CyclinD1</i> and <i>CyclinD3</i> expression, which are crucial factors for infection thread progression and nodule organogenesis. Enhanced expression of <i>TOR</i>-regulated <i>ATG</i> genes in <i>TOR</i>-RNAi roots suggested that <i>TOR</i> plays a role in the <strong><span style="color:yellowgreen">recognit</span></strong>ion of <i>Rhizobium</i> as a symbiont. Together, these data suggest that <i>TOR</i> plays a vital role in the establishment of root nodule symbiosis in the common bean.</p>
http://plantphysiol.org/cgi/content/abstract/172/3/2002
10.1104/pp.16.00844
['Phaseolus', 'Phaseolus vulgaris', 'Rhizobium', 'Rhizobium tropici', 'animals', 'plants']

2
Molecular Biology and Evolution
Ultrafast Approximation for Phylogenetic Bootstrap
<p>Nonparametric bootstrap has been a widely used tool in phylogenetic analysis to assess the clade support of phylogenetic trees. However, with the rapidly growing amount of data, this task remains a computational bottleneck. Recently, approximation methods such as the RAxML rapid bootstrap (RBS) and the Shimodaira–Hasegawa-like approximate likelihood ratio test have been introduced to speed up the bootstrap. Here, we suggest an ultrafast bootstrap approximation approach (UFBoot) to compute the support of phylogenetic groups in maximum likelihood (ML) based trees. To achieve this, we combine the resampling estimated log-likelihood method with a simple but effective <strong><span style="color:yellowgreen">collect</span></strong>ion scheme of candidate trees. We also propose a stopping rule that assesses the convergence of branch support values to automatically determine when to stop <strong><span style="color:yellowgreen">collect</span></strong>ing candidate trees. UFBoot achieves a median speed up of 3.1 (range: 0.66–33.3) to 10.2 (range: 1.32–41.4) compared with RAxML RBS for real DNA and amino acid alignments, respectively. Moreover, our extensive simulations show that UFBoot is robust against moderate model violations and the support values obtained appear to be relatively unbiased compared with the conservative standard bootstrap. This provides a more direct interpretation of the bootstrap support. We offer an efficient and easy-to-use software (available at <ext-link>http://www.cibiv.at/software/iqtree</ext-link>) to perform the UFBoot analysis with ML tree inference.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1188
10.1093/molbev/mst024
None

2
Journal of Experimental Biology
<i>In vivo</i> cranial bone strain and bite force in the agamid lizard <i>Uromastyx geyri</i>
<p><i>In vivo</i> bone strain data are the most direct evidence of deformation and strain regimes in the vertebrate cranium during feeding and can provide important insights into skull morphology. Strain data have been <strong><span style="color:yellowgreen">collect</span></strong>ed during feeding across a wide range of mammals; in contrast, <i>in vivo</i> cranial bone strain data have been <strong><span style="color:yellowgreen">collect</span></strong>ed from few sauropsid taxa. Here we present bone strain data recorded from the jugal of the herbivorous agamid lizard <i>Uromastyx geyri</i> along with simultaneously recorded bite force. Principal and shear strain magnitudes in <i>Uromastyx geyri</i> were lower than cranial bone strains recorded in <i>Alligator mississippiensis</i>, but higher than those reported from herbivorous mammals. Our results suggest that variations in principal strain orientations in the facial skeleton are largely due to differences in feeding behavior and bite location, whereas food type has little impact on strain orientations. Furthermore, mean principal strain orientations differ between male and female <i>Uromastyx</i> during feeding, potentially because of sexual dimorphism in skull morphology.</p>
http://jeb.biologists.org/cgi/content/abstract/217/11/1983
10.1242/jeb.096362
['Alligator', 'Alligator mississippiensis', 'Uromastyx', 'Uromastyx geyri', 'mammals']

2
Journal of Experimental Biology
Adaptive evolution of fish hatching enzyme: one amino acid substitution results in differential salt dependency of the enzyme
<p>Embryos of medaka <i>Oryzias latipes</i> hatch in freshwater, while those of killifish <i>Fundulus heteroclitus</i> hatch in brackish water. Medaka and <i>Fundulus</i> possess two kinds of hatching enzymes, high choriolytic enzyme (HCE) and low choriolytic enzyme (LCE), which cooperatively digest their egg envelope at the time of hatching. Optimal salinity of medaka HCE was found in 0 mol l<sup>−1</sup> NaCl, and activity decreased with increasing salt concentrations. One of the two <i>Fundulus</i> HCEs, FHCE1, showed the highest activity in 0 mol l<sup>−1</sup> NaCl, and the other, FHCE2, showed the highest activity in 0.125 mol l<sup>−1</sup> NaCl. The results suggest that the salt dependencies of HCEs are well adapted to each salinity at the time of hatching. Different from HCE, LCEs of both species maintained the activity sufficient for egg envelope digestion in various salinities. The difference in amino acid sequence between FHCE1 and FHCE2 was found at only a single site at position 36 (Gly/Arg), suggesting that this single substitution causes the different salt dependency between the two enzymes. Superimposition of FHCE1 and FHCE2 with the 3-D structure model of medaka HCE revealed that position 36 was located on the surface of HCE molecule, far from its active site cleft. The results suggest a hypothesis that position 36 influences salt-dependent activity of HCE, not with <strong><span style="color:yellowgreen">recognit</span></strong>ion of primary structure around the cleavage site, but with <strong><span style="color:yellowgreen">recognit</span></strong>ion of higher ordered structure of egg envelope protein.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1609
10.1242/jeb.069716
['Fundulus', 'Fundulus heteroclitus', 'Oryzias', 'Oryzias latipes', 'fish']

2
The Bone & Joint Journal
Unconstrained metacarpophalangeal joint arthroplasties
<sec><title>Aims</title><p>We performed a systematic review of the current literature regarding   the outcomes of unconstrained metacarpophalangeal joint (MCPJ) arthroplasty.</p></sec><sec><title>Materials and Methods</title><p>We initially identified 1305 studies, and 406 were found to be   duplicates. After exclusion criteria were applied, seven studies   were included. Outcomes extracted included pre- and post-operative   pain visual analogue scores, range of movement (ROM), strength of   pinch and grip, satisfaction and patient reported outcome measures   (PROMs). Clinical and radiological complications were recorded.   The results are presented in three groups based on the design of   the arthroplasty and the aetiology (pyrocarbon-osteoarthritis (pyro-OA),   pyrocarbon-inflammatory arthritis (pyro-IA), metal-on-polyethylene   (MoP)).</p></sec><sec><title>Results</title><p>Results show that pyrocarbon implants provide an 85% reduction   in pain, 144% increase of pinch grip and 13° improvements in ROM   for both OA and IA combined. Patients <strong><span style="color:yellowgreen">receiv</span></strong>ing MoP arthroplasties   had a reduction in pinch strength. Satisfaction rates were 91% and   92% for pyrocarbon-OA and pyrocarbon-IA groups, respectively. There were   nine failures in 87 joints (10.3%) over a mean follow-up of 5.5   years (1.0 to 14.3) for pyro-OA. There were 18 failures in 149 joints   (12.1%) over a mean period of 6.6 years (1.0 to 16.0) for pyro-IA.   Meta-analysis was not possible due to the heterogeneity of the studies   and the limited presentation of data.</p></sec><sec><title>Conclusion</title><p>We would recommend prospective data <strong><span style="color:yellowgreen">collect</span></strong>ion for small joint   arthroplasties of the hand consisting of PROMs that would allow   clinicians to come to stronger conclusions about the impact on function   of replacing the MCPJs. A national joint registry may be the best   way to achieve this.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:100–6.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/1/100
10.1302/0301-620X.99B1.37237
None

2
The Bone & Joint Journal
Assessing treatment outcomes using a single question
<p>Satisfaction with care is important to both patients   and to those who pay for it. The Net Promoter Score (NPS), widely   used in the service industries, has been introduced into the NHS   as the ‘friends and family test’; an overarching measure of patient   satisfaction. It assesses the likelihood of the patient recommending   the healthcare <strong><span style="color:yellowgreen">receiv</span></strong>ed to another, and is seen as a discriminator   of healthcare performance. We prospectively assessed 6186 individuals   undergoing primary lower limb joint replacement at a single university   hospital to determine the Net Promoter Score for joint replacements   and to evaluate which factors contributed to the response. </p><p>Achieving pain relief (odds ratio (OR) 2.13, confidence interval   (CI) 1.83 to 2.49), the meeting of pre-operative expectation (OR   2.57, CI 2.24 to 2.97), and the hospital experience (OR 2.33, CI   2.03 to 2.68) are the domains that explain whether a patient would   recommend joint replacement services. These three factors, combined   with the type of surgery undertaken (OR 2.31, CI 1.68 to 3.17),   drove a predictive model that was able to explain 95% of the variation   in the patient’s recommendation response. Though intuitively similar,   this ‘recommendation’ metric was found to be materially different   to satisfaction responses. The difference between THR (NPS 71) and   TKR (NPS 49) suggests that no overarching score for a department   should be used without an adjustment for case mix. However, the   Net Promoter Score does measure a further important dimension to   our existing metrics: the patient experience of healthcare delivery.</p><p>Cite this article: <i>Bone Joint J</i> 2014;96-B:622–8.</p>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/96-B/5/622
10.1302/0301-620X.96B5.32434
None

2
Development
The secreted <i>AdamTS-A</i> metalloprotease is required for collective cell migration
<p>Members of the ADAMTS family of secreted metalloproteases play crucial roles in modulating the extracellular matrix (ECM) in development and disease. Here, we show that ADAMTS-A, the <i>Drosophila</i> ortholog of human ADAMTS 9 and ADAMTS 20, and of <i>C. elegans</i> GON-1, is required for cell migration during embryogenesis. <i>AdamTS-A</i> is expressed in multiple migratory cell types, including hemocytes, caudal visceral mesoderm (CVM), the visceral branch of the trachea (VBs) and the secretory portion of the salivary gland (SG). Loss of <i>AdamTS-A</i> causes defects in germ cell, CVM and VB migration and, depending on the tissue, <i>AdamTS-A</i> functions both autonomously and non-autonomously. In the highly polarized <strong><span style="color:yellowgreen">collect</span></strong>ive of the SG epithelium, loss of <i>AdamTS-A</i> causes apical surface irregularities and cell elongation defects. We provide evidence that ADAMTS-A is secreted into the SG lumen where it functions to release cells from the apical ECM, consistent with the defects observed in <i>AdamTS-A</i> mutant SGs. We show that loss of the apically localized protocadherin <i>Cad99C</i> rescues the SG defects, suggesting that Cad99C serves as a link between the SG apical membrane and the secreted apical ECM component(s) cleaved by ADAMTS-A. Our analysis of <i>AdamTS-A</i> function in the SG suggests a novel role for ADAMTS proteins in detaching cells from the apical ECM, facilitating tube elongation during <strong><span style="color:yellowgreen">collect</span></strong>ive cell migration.</p>
http://dev.biologists.org/cgi/content/abstract/140/9/1981
10.1242/dev.087908
['Drosophila', 'human']

2
Circulation
Residual Inflammatory Risk on Treatment With PCSK9 Inhibition and Statin Therapy
<sec><title>Background:</title><p>The combination of statin therapy and PCSK9 (proprotein convertase subtilisin/kexin type 9) inhibition markedly lowers low-density lipoprotein cholesterol (LDL-C) and reduces cardiovascular event rates. Whether residual inflammatory risk as measured by on-treatment high sensitivity C-reactive protein (hsCRP) remains an important clinical issue in such patients is uncertain.</p></sec><sec><title>Methods:</title><p>We evaluated residual inflammatory risk among 9738 patients participating in the SPIRE-1 and SPIRE-2 cardiovascular outcomes trials (Studies of PCSK9 Inhibition and the Reduction in Vascular Events), who were <strong><span style="color:yellowgreen">receiv</span></strong>ing both statin therapy and bococizumab, according to on-treatment levels of hsCRP (hsCRP<sub>OT</sub>) and LDL-C<sub>OT</sub> measured 14 weeks after drug initiation. The primary end point was nonfatal myocardial infarction, nonfatal stroke, hospitalization for unstable angina requiring urgent revascularization, or cardiovascular death.</p></sec><sec><title>Results:</title><p>At 14 weeks, the mean percentage change in LDL-C among statin-treated patients who additionally <strong><span style="color:yellowgreen">receiv</span></strong>ed bococizumab was −60.5% (95% confidence interval [CI], −61.2 to −59.8; <i>P</i><0.001; median change, −65.4%) as compared to 6.6% (95% CI, −1.0 to 14.1; <i>P</i>=0.09; median change, 0.0%) for hsCRP. Incidence rates for future cardiovascular events for patients treated with both statin therapy and bococizumab according to hsCRP<sub>OT</sub> <1, 1 to 3, and >3 mg/L were 1.96, 2.50, and 3.59 events per 100 person-years, respectively, corresponding to multivariable adjusted hazard ratios of 1.0, 1.16 (95% CI, 0.81–1.66), and 1.62 (95% CI, 1.14–2.30) (<i>P</i>-trend=0.001) after adjustment for traditional cardiovascular risk factors and LDL-C<sub>OT</sub>. Comparable adjusted hazard ratios for LDL-C<sub>OT</sub> (<30, 30–50, >50 mg/dL) were 1.0, 0.87, and 1.21, respectively (<i>P</i>-trend=0.16). Relative risk reductions with bococizumab were similar across hsCRP<sub>OT</sub> groups (<i>P</i>-interaction=0.87).</p></sec><sec><title>Conclusions:</title><p>In this post hoc analysis of the SPIRE trials of bococizumab in a stable outpatient population, evidence of residual inflammatory risk persisted among patients treated with both statin therapy and proprotein convertase subtilisin-kexin type 9 inhibition.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifiers: NCT01975376, NCT01975389.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/2/141
10.1161/CIRCULATIONAHA.118.034645
None

2
Circulation
Empagliflozin and Clinical Outcomes in Patients With Type 2 Diabetes Mellitus, Established Cardiovascular Disease, and Chronic Kidney Disease
<sec><title>Background:</title><p>Empagliflozin, a sodium-glucose cotransporter 2 inhibitor, reduced cardiovascular morbidity and mortality in patients with type 2 diabetes mellitus and established cardiovascular disease in the EMPA-REG OUTCOME trial (Empagliflozin Cardiovascular Outcome Event Trial in Type 2 Diabetes Mellitus Patients). Urinary glucose excretion with empagliflozin decreases with declining renal function, resulting in less potency for glucose lowering in patients with kidney disease. We investigated the effects of empagliflozin on clinical outcomes in patients with type 2 diabetes mellitus, established cardiovascular disease, and chronic kidney disease.</p></sec><sec><title>Methods:</title><p>Patients with type 2 diabetes mellitus, established cardiovascular disease, and estimated glomerular filtration rate (eGFR) ≥30 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> at screening were randomized to <strong><span style="color:yellowgreen">receiv</span></strong>e empagliflozin 10 mg, empagliflozin 25 mg, or placebo once daily in addition to standard of care. We analyzed cardiovascular death, hospitalization for heart failure, all-cause hospitalization, and all-cause mortality in patients with prevalent kidney disease (defined as eGFR <60 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> and/or urine albumin-creatinine ratio >300 mg/g) at baseline. Additional analyses were performed in subgroups by baseline eGFR (<45, 45–<60, 60–<90, ≥90 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup>) and baseline urine albumin-creatinine ratio (>300, 30–≤300, <30 mg/g).</p></sec><sec><title>Results:</title><p>Of 7020 patients treated, 2250 patients had prevalent kidney disease at baseline, of whom 67% had a diagnosis of type 2 diabetes mellitus for >10 years, 58% were <strong><span style="color:yellowgreen">receiv</span></strong>ing insulin, and 84% were taking angiotensin-converting enzyme inhibitors or angiotensin <strong><span style="color:yellowgreen">recept</span></strong>or blockers. In patients with prevalent kidney disease at baseline, empagliflozin reduced the risk of cardiovascular death by 29% compared with placebo (hazard ratio [HR], 0.71; 95% confidence interval [CI], 0.52–0.98), the risk of all-cause mortality by 24% (HR, 0.76; 95% CI, 0.59–0.99), the risk of hospitalization for heart failure by 39% (HR, 0.61; 95% CI, 0.42–0.87), and the risk of all-cause hospitalization by 19% (HR, 0.81; 95% CI, 0.72–0.92). Effects of empagliflozin on these outcomes were consistent across categories of eGFR and urine albumin-creatinine ratio at baseline and across the 2 doses studied. The adverse event profile of empagliflozin in patients with eGFR <60 mL·min<sup>−1</sup>·1.73 m<sup>−2</sup> was consistent with the overall trial population.</p></sec><sec><title>Conclusions:</title><p>Empagliflozin improved clinical outcomes and reduced mortality in vulnerable patients with type 2 diabetes mellitus, established cardiovascular disease, and chronic kidney disease.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01131676.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/2/119
10.1161/CIRCULATIONAHA.117.028268
None

2
Circulation
Effect of Losartan on Right Ventricular Dysfunction
<sec><title>Background:</title><p>The effect of angiotensin II <strong><span style="color:yellowgreen">recept</span></strong>or blockers on right ventricular (RV) function is still unknown. Angiotensin II <strong><span style="color:yellowgreen">recept</span></strong>or blockers are beneficial in patients with acquired left ventricular dysfunction, and recent findings have suggested a favorable effect in symptomatic patients with systemic RV dysfunction. The current study aimed to determine the effect of losartan, an angiotensin II <strong><span style="color:yellowgreen">recept</span></strong>or blocker, on subpulmonary RV dysfunction in adults after repaired tetralogy of Fallot.</p></sec><sec><title>Methods:</title><p>The REDEFINE trial (Right Ventricular Dysfunction in Tetralogy of Fallot: Inhibition of the Renin-Angiotensin-Aldosterone System) is an investigator-initiated, multicenter, prospective, 1:1 randomized, double-blind, placebo-controlled study. Adults with repaired tetralogy of Fallot and RV dysfunction (RV ejection fraction [EF] <50%) but without severe valvular dysfunction were eligible. Patients were randomly assigned between losartan (150 mg daily) and placebo with target treatment duration between 18 and 24 months. The primary outcome was RV EF change, determined by cardiovascular MRI in intention-to-treat analysis.</p></sec><sec><title>Results:</title><p>Of 95 included patients, 47 patients <strong><span style="color:yellowgreen">receiv</span></strong>ed 150 mg losartan daily (age, 38.0±12.4 years; 74% male), and 48 patients <strong><span style="color:yellowgreen">receiv</span></strong>ed placebo (age, 40.6±11.4 years; 63% male). Overall, RV EF did not change in patients allocated to losartan (n=42) (44.4±5.1% to 45.2±5.0%) and placebo (n=46) (43.2±6.3% to 43.6±6.9%). Losartan did not significantly improve RV EF in comparison with placebo (+0.51%; 95% confidence interval, –1.0 to +2.0; <i>P</i>=0.50). No significant treatment effects were found on secondary outcomes: left ventricular EF, peak aerobic exercise capacity, and N-terminal pro–brain natriuretic peptide (<i>P</i>>0.30 for all). In predefined subgroup analyses, losartan did not have a statistically significant impact on RV EF in subgroups with symptoms, restrictive RV, RV EF<40%, pulmonary valve replacement, or QRS fragmentation. However, in a post hoc analysis, losartan was associated with improved RV EF in a subgroup (n=30) with nonrestrictive RV and incomplete remodeling (QRS fragmentation and previous pulmonary valve replacement) (+2.7%; 95% confidence interval, +0.1 to +5.4; <i>P</i>=0.045).</p></sec><sec><title>Conclusions:</title><p>Losartan had no significant effect on RV dysfunction or secondary outcome parameters in repaired tetralogy of Fallot. Future larger studies may determine whether there might be a role for losartan in specific vulnerable subgroups.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02010905.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/14/1463
10.1161/CIRCULATIONAHA.117.031438
None

2
Circulation
Genetic and Functional Profiling of CD16-Dependent Natural Killer Activation Identifies Patients at Higher Risk of Cardiac Allograft Vasculopathy
<sec><title>Background:</title><p>Cardiac transplantation is an effective therapy for end-stage heart failure. Because cardiac allograft vasculopathy (CAV) is the major cause of late mortality after heart transplant (HT), there is a need to identify markers that reflect inflammatory or cytotoxic immune mechanisms contributing to its onset. Noninvasive and early stratification of patients at risk remains a challenge for adapting individualized therapy. The CD16 (Fc-gamma <strong><span style="color:yellowgreen">recept</span></strong>or 3A [FCGR3A]) <strong><span style="color:yellowgreen">recept</span></strong>or was recently identified as a major determinant of antibody-mediated natural killer (NK) cell activation in HT biopsies; however, little is known about the role of CD16 in promoting allograft vasculopathy. This study aimed to investigate whether markers that reflect CD16-dependent circulating NK cell activation may identify patients at higher risk of developing CAV after HT.</p></sec><sec><title>Methods:</title><p>Blood samples were <strong><span style="color:yellowgreen">collect</span></strong>ed from 103 patients undergoing routine coronarography angiography for CAV diagnosis (median 5 years since HT). Genomic and phenotypic analyses of FCGR3A/CD16 Fc-<strong><span style="color:yellowgreen">recept</span></strong>or profiles were compared in CAV-positive (n=52) and CAV-free patients (n=51). The levels of CD16 expression and rituximab-dependent cell cytotoxic activity of peripheral NK cells in HT recipients were evaluated using a noninvasive NK-cellular humoral activation test.</p></sec><sec><title>Results:</title><p>Enhanced levels of CD16 expression and antibody-dependent NK cell cytotoxic function of HT recipients were associated with the FCGR3A-VV genotype. The frequency of the FCGR3A-VV genotype was significantly higher in the CAV<sup>+</sup> group (odds ratio, 3.9; <i>P</i>=0.0317) than in the CAV<sup>-</sup> group. The FCGR3A-VV genotype was identified as an independent marker correlated with the presence of CAV at the time of coronary angiography by using multivariate logistic regression models. The FCGR3A-VV genotype was also identified as a baseline-independent predictor of CAV risk (odds ratio, 4.7; <i>P</i>=0.023).</p></sec><sec><title>Conclusions:</title><p>This study unravels a prominent role for the CD16-dependent NK cell activation pathway in the complex array of factors that favor the progression of transplant arteriosclerosis. It highlights the clinical potential of a noninvasive evaluation of FCGR3A/CD16 in the early stratification of CAV risk. The <strong><span style="color:yellowgreen">recognit</span></strong>ion of CD16 as a major checkpoint that controls immune surveillance may promote the design of individualized NK cell–targeted therapies to limit vascular damage in highly responsive sensitized patients.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01569334.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/10/1049
10.1161/CIRCULATIONAHA.117.030435
None

2
Circulation
Validity of Cardiovascular Data From Electronic Sources
<sec><title>Background:</title><p>Understanding the validity of data from electronic data research networks is critical to national research initiatives and learning healthcare systems for cardiovascular care. Our goal was to evaluate the degree of agreement of electronic data research networks in comparison with data <strong><span style="color:yellowgreen">collect</span></strong>ed by standardized research approaches in a cohort study.</p></sec><sec><title>Methods:</title><p>We linked individual-level data from MESA (Multi-Ethnic Study of Atherosclerosis), a community-based cohort, with HealthLNK, a 2006 to 2012 database of electronic health records from 6 Chicago health systems. To evaluate the correlation and agreement of blood pressure in HealthLNK in comparison with in-person MESA examinations, and body mass index in HealthLNK in comparison with MESA, we used Pearson correlation coefficients and Bland-Altman plots. Using diagnoses in MESA as the criterion standard, we calculated the performance of HealthLNK for hypertension, obesity, and diabetes mellitus diagnosis by using <i>International Classification of Diseases, Ninth Revision</i> codes and clinical data. We also identified potential myocardial infarctions, strokes, and heart failure events in HealthLNK and compared them with adjudicated events in MESA.</p></sec><sec><title>Results:</title><p>Of the 1164 MESA participants enrolled at the Chicago Field Center, 802 (68.9%) participants had data in HealthLNK. The correlation was low for systolic blood pressure (0.39; <i>P</i><0.0001). In comparison with MESA, HealthLNK overestimated systolic blood pressure by 6.5 mm Hg (95% confidence interval, 4.2–7.8). There was a high correlation between body mass index in MESA and HealthLNK (0.94; <i>P</i><0.0001). HealthLNK underestimated body mass index by 0.3 kg/m<sup>2</sup> (95% confidence interval, –0.4 to –0.1). With the use of <i>International Classification of Diseases, Ninth Revision</i> codes and clinical data, the sensitivity and specificity of HealthLNK queries for hypertension were 82.4% and 59.4%, for obesity were 73.0% and 89.8%, and for diabetes mellitus were 79.8% and 93.3%. In comparison with adjudicated cardiovascular events in MESA, the concordance rates for myocardial infarction, stroke, and heart failure were, respectively, 41.7% (5/12), 61.5% (8/13), and 62.5% (10/16).</p></sec><sec><title>Conclusions:</title><p>These findings illustrate the limitations and strengths of electronic data repositories in comparison with information <strong><span style="color:yellowgreen">collect</span></strong>ed by traditional standardized epidemiological approaches for the ascertainment of cardiovascular risk factors and events.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/13/1207
10.1161/CIRCULATIONAHA.117.027436
None

2
Circulation
Optical Coherence Tomography Findings in Patients With Coronary Stent Thrombosis
<sec><title>Background:</title><p>Stent thrombosis (ST) is a serious complication following coronary stenting. Intravascular optical coherence tomography (OCT) may provide insights into mechanistic processes leading to ST. We performed a prospective, multicenter study to evaluate OCT findings in patients with ST.</p></sec><sec><title>Methods:</title><p>Consecutive patients presenting with ST were prospectively enrolled in a registry by using a centralized telephone registration system. After angiographic confirmation of ST, OCT imaging of the culprit vessel was performed with frequency domain OCT. Clinical data were <strong><span style="color:yellowgreen">collect</span></strong>ed according to a standardized protocol. OCT <strong><span style="color:yellowgreen">acquisit</span></strong>ions were analyzed at a core laboratory. Dominant and contributing findings were adjudicated by an imaging adjudication committee.</p></sec><sec><title>Results:</title><p>Two hundred thirty-one patients presenting with ST underwent OCT imaging; 14 (6.1%) had image quality precluding further analysis. Of the remaining patients, 62 (28.6%) and 155 (71.4%) presented with early and late/very late ST, respectively. The underlying stent type was a new-generation drug-eluting stent in 50.3%. Mean reference vessel diameter was 2.9±0.6 mm and mean reference vessel area was 6.8±2.6 mm<sup>2</sup>. Stent underexpansion (stent expansion index <0.8) was observed in 44.4% of patients. The predicted average probability (95% confidence interval) that any frame had uncovered (or thrombus-covered) struts was 99.3% (96.1–99.9), 96.6% (92.4–98.5), 34.3% (15.0–60.7), and 9.6% (6.2–14.5) and malapposed struts was 21.8% (8.4–45.6), 8.5% (4.6–15.3), 6.7% (2.5–16.3), and 2.0% (1.2–3.3) for acute, subacute, late, and very late ST, respectively. The most common dominant finding adjudicated for acute ST was uncovered struts (66.7% of cases); for subacute ST, the most common dominant finding was uncovered struts (61.7%) and underexpansion (25.5%); for late ST, the most common dominant finding was uncovered struts (33.3%) and severe restenosis (19.1%); and for very late ST, the most common dominant finding was neoatherosclerosis (31.3%) and uncovered struts (20.2%). In patients presenting very late ST, uncovered stent struts were a common dominant finding in drug-eluting stents, and neoatherosclerosis was a common dominant finding in bare metal stents.</p></sec><sec><title>Conclusions:</title><p>In patients with ST, uncovered and malapposed struts were frequently observed with the incidence of both decreasing with longer time intervals between stent implantation and presentation. The most frequent dominant observation varied according to time intervals from index stenting: uncovered struts and underexpansion in acute/subacute ST and neoatherosclerosis and uncovered struts in late/very late ST.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/11/1007
10.1161/CIRCULATIONAHA.117.026788
None

2
Circulation
Neurological Injury and Cerebral Blood Flow in Single Ventricles Throughout Staged Surgical Reconstruction
<sec><title>Background:</title><p>Patients with a single ventricle experience a high rate of brain injury and adverse neurodevelopmental outcome; however, the incidence of brain abnormalities throughout surgical reconstruction and their relationship with cerebral blood flow, oxygen delivery, and carbon dioxide reactivity remain unknown.</p></sec><sec><title>Methods:</title><p>Patients with a single ventricle were studied with magnetic resonance imaging scans immediately prior to bidirectional Glenn (pre-BDG), before Fontan (BDG), and then 3 to 9 months after Fontan reconstruction.</p></sec><sec><title>Results:</title><p>One hundred sixty-eight consecutive subjects recruited into the project underwent 235 scans: 63 pre-BDG (mean age, 4.8±1.7 months), 118 BDG (2.9±1.4 years), and 54 after Fontan (2.4±1.0 years). Nonacute ischemic white matter changes on T2-weighted imaging, focal tissue loss, and ventriculomegaly were all more commonly detected in BDG and Fontan compared with pre-BDG patients (<i>P</i><0.05). BDG patients had significantly higher cerebral blood flow than did Fontan patients. The odds of discovering brain injury with adjustment for surgical stage as well as ≥2 coexisting lesions within a patient decreased (63%–75% and 44%, respectively) with increasing amount of cerebral blood flow (<i>P</i><0.05). In general, there was no association of oxygen delivery (except for ventriculomegaly in the BDG group) or carbon dioxide reactivity with neurological injury.</p></sec><sec><title>Conclusions:</title><p>Significant brain abnormalities are commonly present in patients with a single ventricle, and detection of these lesions increases as children progress through staged surgical reconstruction, with multiple coexisting lesions more common earlier than later. In addition, this study demonstrated that BDG patients had greater cerebral blood flow than did Fontan patients and that an inverse association exists of various indexes of cerebral blood flow with these brain lesions. However, CO<sub>2</sub> reactivity and oxygen delivery (with 1 exception) were not associated with brain lesion development.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02135081.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/7/671
10.1161/CIRCULATIONAHA.116.021724
None

2
Circulation
Impact of Computed Tomography Perfusion Imaging on the Response to Tenecteplase in Ischemic Stroke
<sec><title>Background:</title><p>We pooled 2 clinical trials of tenecteplase compared with alteplase for the treatment of acute ischemic stroke, 1 that demonstrated superiority of tenecteplase and the other that showed no difference between the treatments in patient clinical outcomes. We tested the hypotheses that reperfusion therapy with tenecteplase would be superior to alteplase in improving functional outcomes in the group of patients with target mismatch as identified with advanced imaging.</p></sec><sec><title>Methods:</title><p>We investigated whether tenecteplase-treated patients had a different 24-hour reduction in the National Institutes of Health Stroke Scale and a favorable odds ratio of a modified Rankin scale score of 0 to 1 versus 2 to 6 compared with alteplase-treated patients using linear regression to generate odds ratios. Imaging outcomes included rates of vessel recanalization and infarct growth at 24 hours and occurrence of large parenchymal hematoma. Baseline computed tomography perfusion was analyzed to assess whether patients met the target mismatch criteria (absolute mismatch volume >15 mL, mismatch ratio >1.8, baseline ischemic core <70 mL, and volume of severely hypoperfused tissue <100 mL). Patients meeting target mismatch criteria were analyzed as a subgroup to identify whether they had different treatment responses from the pooled group.</p></sec><sec><title>Results:</title><p>Of 146 pooled patients, 71 <strong><span style="color:yellowgreen">receiv</span></strong>ed alteplase and 75 <strong><span style="color:yellowgreen">receiv</span></strong>ed tenecteplase. Tenecteplase-treated patients had greater early clinical improvement (median National Institutes of Health Stroke Scale score change: tenecteplase, 7; alteplase, 2; <i>P</i>=0.018) and less parenchymal hematoma (2 of 75 versus 10 of 71; <i>P</i>=0.02). The pooled group did not show improved patient outcomes when treated with tenecteplase (modified Rankin scale score 0–1: odds ratio, 1.77; 95% confidence interval, 0.89–3.51; <i>P</i>=0.102) compared with alteplase therapy. However, in patients with target mismatch (33 tenecteplase, 35 alteplase), treatment with tenecteplase was associated with greater early clinical improvement (median National Institutes of Health Stroke Scale score change: tenecteplase, 6; alteplase, 1; <i>P</i><0.001) and better late independent recovery (modified Rankin scale score 0–1: odds ratio, 2.33; 95% confidence interval, 1.13–5.94; <i>P</i>=0.032) than those treated with alteplase.</p></sec><sec><title>Conclusions:</title><p>Tenecteplase may offer an improved efficacy and safety profile compared with alteplase, benefits possibly exaggerated in patients with baseline computed tomography perfusion–defined target mismatch.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01472926. URL: <ext-link>https://www.anzctr.org.au</ext-link>. Unique identifier: ACTRN12608000466347.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/5/440
10.1161/CIRCULATIONAHA.116.022582
None

2
Circulation
Optimizing a Drone Network to Deliver Automated External Defibrillators
<sec><title>Background:</title><p>Public access defibrillation programs can improve survival after out-of-hospital cardiac arrest, but automated external defibrillators (AEDs) are rarely available for bystander use at the scene. Drones are an emerging technology that can deliver an AED to the scene of an out-of-hospital cardiac arrest for bystander use. We hypothesize that a drone network designed with the aid of a mathematical model combining both optimization and queuing can reduce the time to AED arrival.</p></sec><sec><title>Methods:</title><p>We applied our model to 53 702 out-of-hospital cardiac arrests that occurred in the 8 regions of the Toronto Regional RescuNET between January 1, 2006, and December 31, 2014. Our primary analysis quantified the drone network size required to deliver an AED 1, 2, or 3 minutes faster than historical median 911 response times for each region independently. A secondary analysis quantified the reduction in drone resources required if RescuNET was treated as a large coordinated region.</p></sec><sec><title>Results:</title><p>The region-specific analysis determined that 81 bases and 100 drones would be required to deliver an AED ahead of median 911 response times by 3 minutes. In the most urban region, the 90th percentile of the AED arrival time was reduced by 6 minutes and 43 seconds relative to historical 911 response times in the region. In the most rural region, the 90th percentile was reduced by 10 minutes and 34 seconds. A single coordinated drone network across all regions required 39.5% fewer bases and 30.0% fewer drones to achieve similar AED delivery times.</p></sec><sec><title>Conclusions:</title><p>An optimized drone network designed with the aid of a novel mathematical model can substantially reduce the AED delivery time to an out-of-hospital cardiac arrest event.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/25/2454
10.1161/CIRCULATIONAHA.116.026318
None

