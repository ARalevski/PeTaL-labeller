12
The Bone & Joint Journal
The validity and reproducibility of cross table radiographs compared with CT scans for the measurement of anteversion of the acetabular component after total hip arthroplasty
<sec><title>Aims</title><p>The aim of this study was to assess the reproducibility and validity   of cross table radiographs for measuring the anteversion of the   acetabular component after total hip arthroplasty (THA) and to compare   it with measurements using CT scans.</p></sec><sec><title>Patients and <strong><span style="color:yellowgreen">method</span></strong>s</title><p>A total of 29 patients who underwent THA between June 2010 and   January 2016 were included. There were 17 men and 12 women. Their   mean age was 43 years (26 to 65). Seven patients underwent a bilateral   procedure. Thus, 36 THAs were included in the study. Lateral radiographs   and CT scans were obtained post-operatively and radiographs repeated   three weeks later. The anteversion of the acetabular component was   measured using the <strong><span style="color:yellowgreen">method</span></strong> described by Woo and Morrey and the ischiolateral   <strong><span style="color:yellowgreen">method</span></strong> described by Pulos et al and these were compared with the   results obtained from CT scans.</p></sec><sec><title>Results</title><p>The mean anteversion was 18.35° (3° to 38°) using Woo and Morrey’s   <strong><span style="color:yellowgreen">method</span></strong>, 51.45° (30° to 85°) using the ischiolateral <strong><span style="color:yellowgreen">method</span></strong> and 21.22°   (2° to 48°) using CT scans. The Pearson correlation coefficient   was 0.754 for Woo and Morrey’s <strong><span style="color:yellowgreen">method</span></strong> and 0.925 for the ischiolateral   <strong><span style="color:yellowgreen">method</span></strong>. There was a linear correlation between the measurements   using the ischiolateral <strong><span style="color:yellowgreen">method</span></strong> and those using CT scans. We derived   a simple linear equation between the value of the CT scan and that   of ischiolateral <strong><span style="color:yellowgreen">method</span></strong> to deduce the CT scan value from that of ischiolateral   <strong><span style="color:yellowgreen">method</span></strong> and <i>vice versa</i>. </p></sec><sec><title>Conclusion</title><p>The anteversion of the acetabular component measured using both   plain radiographic <strong><span style="color:yellowgreen">method</span></strong>s was consistently valid with good interobserver   reproducibility, but the ischiolateral <strong><span style="color:yellowgreen">method</span></strong> which is independent   of pelvic tilt was more accurate. As CT is costly, associated with   a high dose of radiation and not readily available, the ischiolateral <strong><span style="color:yellowgreen">method</span></strong>   can be used for assessing the anteversion of the acetabular component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1006–11.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/8/1006
10.1302/0301-620X.99B8.BJJ-2016-1158.R2
None

7
Molecular Biology and Evolution
AGP: A Multimethods Web Server for Alignment-Free Genome Phylogeny
<p>Phylogenetic analysis based on alignment <strong><span style="color:yellowgreen">method</span></strong> meets huge challenges when dealing with whole-genome sequences, for example, recombination, shuffling, and rearrangement of sequences. Thus, various alignment-free <strong><span style="color:yellowgreen">method</span></strong>s for phylogeny construction have been proposed. However, most of these <strong><span style="color:yellowgreen">method</span></strong>s have not been implemented as tools or web servers. Researchers cannot use these <strong><span style="color:yellowgreen">method</span></strong>s easily with their data sets. To facilitate the usage of various alignment-free <strong><span style="color:yellowgreen">method</span></strong>s, we implemented most of the popular alignment-free <strong><span style="color:yellowgreen">method</span></strong>s and constructed a user-friendly web server for alignment-free genome phylogeny (AGP). AGP integrated the phylogenetic tree construction, visualization, and comparison functions together. Both AGP and all source code of the <strong><span style="color:yellowgreen">method</span></strong>s are available at <ext-link>http://www.herbbol.org:8000/agp</ext-link> (last accessed February 26, 2013). AGP will facilitate research in the field of whole-genome phylogeny and comparison.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1032
10.1093/molbev/mst021
None

7
The Bone & Joint Journal
An analysis of the best method for evaluating anteversion of the acetabular component after total hip replacement on plain radiographs
<p>Several radiological <strong><span style="color:yellowgreen">method</span></strong>s of measuring anteversion   of the acetabular component after total hip replacement (THR) have   been described. These studies used different definitions and reference   planes to compare <strong><span style="color:yellowgreen">method</span></strong>s, allowing for misinterpretation of the   results. We compared the reliability and accuracy of five current   <strong><span style="color:yellowgreen">method</span></strong>s using plain radiographs (those of Lewinnek, Widmer, Liaw,   Pradhan, and Woo and Morrey) with CT measurements, using the same   definition and reference plane. We retrospectively studied the plain   radiographs and CT scans in 84 hips of 84 patients who underwent   primary THR. Intra- and inter-observer reliability were high for   the measurement of inclination and anteversion with all <strong><span style="color:yellowgreen">method</span></strong>s   on plain radiographs and CT scans. The measurements of inclination on   plain radiographs were similar to the measurements using CT (p =   0.043). The mean difference between CT measurements was 0.6° (-5.9°   to 6.8°).</p><p>Measurements using Widmer’s <strong><span style="color:yellowgreen">method</span></strong> were the most similar to those   using CT (p = 0.088), with a mean difference between CT measurements   of -0.9° (-10.4° to 9.1°), whereas the other four <strong><span style="color:yellowgreen">method</span></strong>s differed   significantly from those using CT (p < 0.001).</p><p>This study has shown that Widmer’s <strong><span style="color:yellowgreen">method</span></strong> is the best for evaluating   the anteversion of the acetabular component on plain radiographs.</p><p>Cite this article: <i>Bone Joint J</i> 2014; 96-B:597–603.</p>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/96-B/5/597
10.1302/0301-620X.96B.33013
None

6
PLANT PHYSIOLOGY
Construction and Optimization of a Large Gene Coexpression Network in Maize Using RNA-Seq Data
<p>With the emergence of massively parallel sequencing, genomewide expression data production has reached an unprecedented level. This abundance of data has greatly facilitated maize research, but may not be amenable to traditional analysis techniques that were optimized for other data types. Using publicly available data, a gene coexpression network (GCN) can be constructed and used for gene function prediction, candidate gene selection, and improving understanding of regulatory pathways. Several GCN studies have been done in maize (<i>Zea mays</i>), mostly using microarray datasets. To build an optimal GCN from plant materials RNA-Seq data, parameters for expression data normalization and network inference were evaluated. A comprehensive evaluation of these two parameters and a ranked aggregation strategy on network performance, using libraries from 1266 maize samples, were conducted. Three normalization <strong><span style="color:yellowgreen">method</span></strong>s and 10 inference <strong><span style="color:yellowgreen">method</span></strong>s, including six correlation and four mutual information <strong><span style="color:yellowgreen">method</span></strong>s, were tested. The three normalization <strong><span style="color:yellowgreen">method</span></strong>s had very similar performance. For network inference, correlation <strong><span style="color:yellowgreen">method</span></strong>s performed better than mutual information <strong><span style="color:yellowgreen">method</span></strong>s at some genes. Increasing sample size also had a positive effect on GCN. Aggregating single networks together resulted in improved performance compared to single networks.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/568
10.1104/pp.17.00825
['Zea', 'Zea mays', 'maize']

6
Molecular Biology and Evolution
Quartet-Net: A Quartet-Based Method to Reconstruct Phylogenetic Networks
<p>Phylogenetic networks can model reticulate evolutionary events such as hybridization, recombination, and horizontal gene transfer. However, reconstructing such networks is not trivial. Popular character-based <strong><span style="color:yellowgreen">method</span></strong>s are computationally inefficient, whereas distance-based <strong><span style="color:yellowgreen">method</span></strong>s cannot guarantee reconstruction accuracy because pairwise genetic distances only reflect partial information about a reticulate phylogeny. To balance accuracy and computational efficiency, here we introduce a quartet-based <strong><span style="color:yellowgreen">method</span></strong> to construct a phylogenetic network from a multiple sequence alignment. Unlike distances that only reflect the relationship between a pair of taxa, quartets contain information on the relationships among four taxa; these quartets provide adequate capacity to infer a more accurate phylogenetic network. In applications to simulated and biological data sets, we demonstrate that this novel <strong><span style="color:yellowgreen">method</span></strong> is robust and effective in reconstructing reticulate evolutionary events and it has the potential to infer more accurate phylogenetic distances than other conventional phylogenetic network construction <strong><span style="color:yellowgreen">method</span></strong>s such as Neighbor-Joining, Neighbor-Net, and Split Decomposition. This <strong><span style="color:yellowgreen">method</span></strong> can be used in constructing phylogenetic networks from simple evolutionary events involving a few reticulate events to complex evolutionary histories involving a large number of reticulate events. A software called “Quartet-Net” is implemented and available at <ext-link>http://sysbio.cvm.msstate.edu/QuartetNet/</ext-link>.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1206
10.1093/molbev/mst040
None

5
PLANT PHYSIOLOGY
Visualizing Embolism Propagation in Gas-Injected Leaves
<p>Because the xylem in leaves is thought to be at the greatest risk of cavitation, reliable and efficient <strong><span style="color:yellowgreen">method</span></strong>s to characterize leaf xylem vulnerability are of interest. We report a <strong><span style="color:yellowgreen">method</span></strong> to generate leaf xylem vulnerability curves (VCs) by gas injection. Using optical light transmission, we visualized embolism propagation in grapevine (<i>Vitis vinifera</i>) and red oak (<i>Quercus rubra</i>) leaves injected with positive gas pressure. This resulted in a rapid, stepwise reduction of transmitted light, identical to that observed during leaf dehydration, confirming that the optical <strong><span style="color:yellowgreen">method</span></strong> detects gas bubbles and provides insights into the air-seeding hypothesis. In red oak, xylem VCs generated using gas injection were similar to those generated using bench dehydration, but indicated 50% loss of conductivity at lower tension (∼0.4 MPa) in grapevine. In determining VC, this <strong><span style="color:yellowgreen">method</span></strong> eliminates the need to ascertain xylem tension, thus avoiding potential errors in water potential estimations. It is also much faster (1 h per VC). However, severing the petiole and applying high-pressure gas could affect air-seeding and the generated VC. We discuss potential artifacts arising from gas injection and recommend comparison of this <strong><span style="color:yellowgreen">method</span></strong> with a more standard procedure before it is assumed to be suitable for a given species.</p>
http://plantphysiol.org/cgi/content/abstract/180/2/874
10.1104/pp.18.01284
['Quercus', 'Quercus rubra', 'Vitis', 'Vitis vinifera', 'oak']

5
PLANT PHYSIOLOGY
A Simple Method for Measuring Apoplast Hydration and Collecting Apoplast Contents
<p>The plant leaf apoplast is a dynamic environment subject to a variety of both internal and external stimuli. In addition to being a conduit for water vapor and gas exchange involved in transpiration and photosynthesis, the apoplast also accumulates many nutrients transported from the soil as well as those produced through photosynthesis. The internal leaf also provides a protective environment for endophytic and pathogenic microbes alike. Given the diverse array of physiological processes occurring in the apoplast, it is expedient to develop <strong><span style="color:yellowgreen">method</span></strong>s to study its contents. Many established <strong><span style="color:yellowgreen">method</span></strong>s rely on vacuum infiltration of an apoplast wash solution followed by centrifugation. In this study, we describe a refined <strong><span style="color:yellowgreen">method</span></strong> optimized for maize (<i>Zea mays</i>) seedling leaves, which not only provides a simple procedure for obtaining apoplast fluid, but also allows direct calculation of apoplast hydration at the time of harvest for every sample. In addition, we describe an abbreviated <strong><span style="color:yellowgreen">method</span></strong> for estimating apoplast hydration if the full apoplast extraction is not necessary. Finally, we show the applicability of this optimized apoplast extraction procedure for plants infected with the maize pathogen <i>Pantoea stewartii</i> ssp <i>stewartii</i>, including the efficient isolation of bacteria previously residing in the apoplast. The approaches to establishing this <strong><span style="color:yellowgreen">method</span></strong> should make it generally applicable to other types of plants.</p>
http://plantphysiol.org/cgi/content/abstract/179/4/1265
10.1104/pp.18.01076
['Pantoea', 'Pantoea stewartii', 'Zea', 'Zea mays', 'maize', 'plants']

5
PLANT PHYSIOLOGY
Plant Phenotyping: An Active Vision Cell for Three-Dimensional Plant Shoot Reconstruction
<p>Three-dimensional (3D) computer-generated models of plants are urgently needed to support both phenotyping and simulation-based studies such as photosynthesis modeling. However, the construction of accurate 3D plant models is challenging, as plants are complex objects with an intricate leaf structure, often consisting of thin and highly reflective surfaces that vary in shape and size, forming dense, complex, crowded scenes. We address these issues within an image-based <strong><span style="color:yellowgreen">method</span></strong> by taking an active vision approach, one that investigates the scene to intelligently capture images, to image acquisition. Rather than use the same camera positions for all plants, our technique is to acquire the images needed to reconstruct the target plant, tuning camera placement to match the plant’s individual structure. Our <strong><span style="color:yellowgreen">method</span></strong> also combines volumetric- and surface-based reconstruction <strong><span style="color:yellowgreen">method</span></strong>s and determines the necessary images based on the analysis of voxel clusters. We describe a fully automatic plant modeling/phenotyping cell (or module) comprising a six-axis robot and a high-precision turntable. By using a standard color camera, we overcome the difficulties associated with laser-based plant reconstruction <strong><span style="color:yellowgreen">method</span></strong>s. The 3D models produced are compared with those obtained from fixed cameras and evaluated by comparison with data obtained by x-ray microcomputed tomography across different plant structures. Our results show that our <strong><span style="color:yellowgreen">method</span></strong> is successful in improving the accuracy and quality of data obtained from a variety of plant types.</p>
http://plantphysiol.org/cgi/content/abstract/178/2/524
10.1104/pp.18.00664
['plants']

5
Molecular Biology and Evolution
FUBAR: A Fast, Unconstrained Bayesian AppRoximation for Inferring Selection
<p>Model-based analyses of natural selection often categorize sites into a relatively small number of site classes. Forcing each site to belong to one of these classes places unrealistic constraints on the distribution of selection parameters, which can result in misleading inference due to model misspecification. We present an approximate hierarchical Bayesian <strong><span style="color:yellowgreen">method</span></strong> using a Markov chain Monte Carlo (MCMC) routine that ensures robustness against model misspecification by averaging over a large number of predefined site classes. This leaves the distribution of selection parameters essentially unconstrained, and also allows sites experiencing positive and purifying selection to be identified orders of magnitude faster than by existing <strong><span style="color:yellowgreen">method</span></strong>s. We demonstrate that popular random effects likelihood <strong><span style="color:yellowgreen">method</span></strong>s can produce misleading results when sites assigned to the same site class experience different levels of positive or purifying selection—an unavoidable scenario when using a small number of site classes. Our Fast Unconstrained Bayesian AppRoximation (FUBAR) is unaffected by this problem, while achieving higher power than existing unconstrained (fixed effects likelihood) <strong><span style="color:yellowgreen">method</span></strong>s. The speed advantage of FUBAR allows us to analyze larger data sets than other <strong><span style="color:yellowgreen">method</span></strong>s: We illustrate this on a large influenza hemagglutinin data set (3,142 sequences). FUBAR is available as a batch file within the latest HyPhy distribution (<ext-link>http://www.hyphy.org</ext-link>), as well as on the Datamonkey web server (<ext-link>http://www.datamonkey.org/</ext-link>).</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1196
10.1093/molbev/mst030
None

4
Science
Retrieval practice protects memory against acute stress
<p>More than a decade of research has supported a robust consensus: Acute stress impairs memory retrieval. We aimed to determine whether a highly effective learning technique could strengthen memory against the negative effects of stress. To bolster memory, we used retrieval <strong><span style="color:yellowgreen">practic</span></strong>e, or the act of taking <strong><span style="color:yellowgreen">practic</span></strong>e tests. Participants first learned stimuli by either restudying or engaging in retrieval <strong><span style="color:yellowgreen">practic</span></strong>e. Twenty-four hours later, we induced stress in half of the participants and assessed subsequent memory performance. Participants who learned by restudying demonstrated the typical stress-related memory impairment, whereas those who learned by retrieval <strong><span style="color:yellowgreen">practic</span></strong>e were immune to the deleterious effects of stress. These results suggest that the effects of stress on memory retrieval may be contingent on the strength of the memory representations themselves.</p>
http://sciencemag.org/cgi/content/abstract/354/6315/1046
10.1126/science.aah5067
None

4
PLANT PHYSIOLOGY
Micro Imaging Displays the Sucrose Landscape within and along Its Allocation Pathways
<p>Sucrose (Suc) is the major transport sugar in plants and plays a primary role as an energy source and signal in adaptive and stress responses. An ability to quantify Suc over time and space would serve to advance our understanding of these important processes. Current technologies used for Suc mapping are unable to quantitatively visualize its distribution within tissues. Here, we present an infrared-based microspectroscopic <strong><span style="color:yellowgreen">method</span></strong> that allows for the quantitative visualization of Suc at a microscopic level of resolution (∼12 µm). This <strong><span style="color:yellowgreen">method</span></strong> can successfully model the sugar concentration in individual vascular bundles and within a complex organ such as the stem, leaf, or seed. The sensitivity of the assay ranges from 20 to 1,000 m<sc>m</sc>. We applied this <strong><span style="color:yellowgreen">method</span></strong> to the cereal crop barley (<i>Hordeum vulgare</i>) and the model plant Arabidopsis (<i>Arabidopsis thaliana</i>) to highlight the potential of the procedure for resolving the spatial distribution of metabolites. We also discuss the relevance of the <strong><span style="color:yellowgreen">method</span></strong> for studies on carbon allocation and storage in the context of crop improvement.</p>
http://plantphysiol.org/cgi/content/abstract/178/4/1448
10.1104/pp.18.00947
['Arabidopsis', 'Arabidopsis thaliana', 'Hordeum', 'Hordeum vulgare', 'barley', 'plants']

4
PLANT PHYSIOLOGY
The Persistent Homology Mathematical Framework Provides Enhanced Genotype-to-Phenotype Associations for Plant Morphology
<p>Efforts to understand the genetic and environmental conditioning of plant morphology are hindered by the lack of flexible and effective tools for quantifying morphology. Here, we demonstrate that persistent-homology-based topological <strong><span style="color:yellowgreen">method</span></strong>s can improve measurement of variation in leaf shape, serrations, and root architecture. We apply these <strong><span style="color:yellowgreen">method</span></strong>s to 2D images of leaves and root systems in field-grown plants of a domesticated introgression line population of tomato (<i>Solanum pennellii</i>). We find that compared with some commonly used conventional traits, (1) persistent-homology-based <strong><span style="color:yellowgreen">method</span></strong>s can more comprehensively capture morphological variation; (2) these techniques discriminate between genotypes with a larger normalized effect size and detect a greater number of unique quantitative trait loci (QTLs); (3) multivariate traits, whether statistically derived from univariate or persistent-homology-based traits, improve our ability to understand the genetic basis of phenotype; and (4) persistent-homology-based techniques detect unique QTLs compared to conventional traits or their multivariate derivatives, indicating that previously unmeasured aspects of morphology are now detectable. The QTL results further imply that genetic contributions to morphology can affect both the shoot and root, revealing a pleiotropic basis to natural variation in tomato. Persistent homology is a versatile framework to quantify plant morphology and developmental processes that complements and extends existing <strong><span style="color:yellowgreen">method</span></strong>s.</p>
http://plantphysiol.org/cgi/content/abstract/177/4/1382
10.1104/pp.18.00104
['Solanum', 'Solanum pennellii', 'plants']

4
PLANT PHYSIOLOGY
Optical Measurement of Stem Xylem Vulnerability
<p>The vulnerability of plant water transport tissues to a loss of function by cavitation during water stress is a key indicator of the survival capabilities of plant species during drought. Quantifying this important metric has been greatly advanced by noninvasive techniques that allow embolisms to be viewed directly in the vascular system. Here, we present a new <strong><span style="color:yellowgreen">method</span></strong> for evaluating the spatial and temporal propagation of embolizing bubbles in the stem xylem during imposed water stress. We demonstrate how the optical <strong><span style="color:yellowgreen">method</span></strong>, used previously in leaves, can be adapted to measure the xylem vulnerability of stems. Validation of the technique is carried out by measuring the xylem vulnerability of 13 conifers and two short-vesseled angiosperms and comparing the results with measurements made using the cavitron centrifuge <strong><span style="color:yellowgreen">method</span></strong>. Very close agreement between the two <strong><span style="color:yellowgreen">method</span></strong>s confirms the reliability of the new optical technique and opens the way to simple, efficient, and reliable assessment of stem vulnerability using standard flatbed scanners, cameras, or microscopes.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2054
10.1104/pp.17.00552
['conifers']

4
Molecular Biology and Evolution
Inference of Natural Selection from Interspersed Genomic Elements Based on Polymorphism and Divergence
<p>Complete genome sequences contain valuable information about natural selection, but this information is difficult to access for short, widely scattered noncoding elements such as transcription factor binding sites or small noncoding RNAs. Here, we introduce a new computational <strong><span style="color:yellowgreen">method</span></strong>, called <i>I</i>nference of <i>N</i>atural <i>S</i>election from <i>I</i>nterspersed <i>G</i>enomically co<i>H</i>erent elemen<i>T</i>s (INSIGHT), for measuring the influence of natural selection on such elements. INSIGHT uses a generative probabilistic model to contrast patterns of polymorphism and divergence in the elements of interest with those in flanking neutral sites, pooling weak information from many short elements in a manner that accounts for variation among loci in mutation rates and coalescent times. The <strong><span style="color:yellowgreen">method</span></strong> is able to disentangle the contributions of weak negative, strong negative, and positive selection based on their distinct effects on patterns of polymorphism and divergence. It obtains information about divergence from multiple outgroup genomes using a general statistical phylogenetic approach. The INSIGHT model is efficiently fitted to genome-wide data using an approximate expectation maximization algorithm. Using simulations, we show that the <strong><span style="color:yellowgreen">method</span></strong> can accurately estimate the parameters of interest even in complex demographic scenarios, and that it significantly improves on <strong><span style="color:yellowgreen">method</span></strong>s based on summary statistics describing polymorphism and divergence. To demonstrate the usefulness of INSIGHT, we apply it to several classes of human noncoding RNAs and to GATA2-binding sites in the human genome.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1159
10.1093/molbev/mst019
['human']

4
Molecular Biology and Evolution
Maximum Likelihood Estimation of Frequencies of Known Haplotypes from Pooled Sequence Data
<p>DNA samples are often pooled, either by experimental design or because the sample itself is a mixture. For example, when population allele frequencies are of primary interest, individual samples may be pooled together to lower the cost of sequencing. Alternatively, the sample itself may be a mixture of multiple species or strains (e.g., bacterial species comprising a microbiome or pathogen strains in a blood sample). We present an expectation–maximization algorithm for estimating haplotype frequencies in a pooled sample directly from mapped sequence reads, in the case where the possible haplotypes are known. This <strong><span style="color:yellowgreen">method</span></strong> is relevant to the analysis of pooled sequencing data from selection experiments, as well as the calculation of proportions of different species within a metagenomics sample. Our <strong><span style="color:yellowgreen">method</span></strong> outperforms existing <strong><span style="color:yellowgreen">method</span></strong>s based on single-site allele frequencies, as well as simple approaches using sequence read data. We have implemented the <strong><span style="color:yellowgreen">method</span></strong> in a freely available open-source software tool.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1145
10.1093/molbev/mst016
None

4
Circulation
Time to Endovascular Treatment and Outcome in Acute Ischemic Stroke
<sec><title>Background:</title><p>Randomized, clinical trials in selected acute ischemic stroke patients reported that for every hour delay of endovascular treatment (EVT), chances of functional independence diminish by up to 3.4%. These findings may not be fully generalizable to clinical <strong><span style="color:yellowgreen">practic</span></strong>e because of strict in- and exclusion criteria in these trials. Therefore, we aim to assess the association of time to EVT with functional outcome in current, everyday clinical <strong><span style="color:yellowgreen">practic</span></strong>e.</p></sec><sec><title>Methods:</title><p>The MR CLEAN Registry (Multicenter Randomized Clinical Trial of Endovascular Treatment for Acute Ischemic Stroke in The Netherlands) is an ongoing, prospective, observational study in all centers that perform EVT in The Netherlands. Data were analyzed from patients treated between March 2014 and June 2016. In the primary analysis we assessed the association of time from stroke onset to start of EVT and time from stroke onset to successful reperfusion with functional outcome (measured with the modified Rankin Scale), by means of ordinal logistic regression.</p></sec><sec><title>Results:</title><p>We analyzed 1488 patients with acute ischemic stroke who underwent EVT. An increased time to start of EVT was associated with worse functional outcome (adjusted common odds ratio, 0.83 per hour; 95% confidence interval, 0.77–0.89) and a 2.2% increase in mortality. Every hour increase from stroke onset to EVT start resulted in a 5.3% decreased probability of functional independence (modified Rankin Scale, 0–2). In the 742 patients with successful reperfusion, every hour increase from stroke onset to reperfusion was associated with a 7.7% decreased probability of functional independence.</p></sec><sec><title>Conclusions:</title><p>Time to EVT for acute ischemic stroke in current clinical <strong><span style="color:yellowgreen">practic</span></strong>e is strongly associated with functional outcome. Our data suggest that this association might be even stronger than previously suggested in reports on more selected patient populations from randomized, controlled trials. These findings emphasize that functional outcome of EVT patients can be greatly improved by shortening onset to treatment times.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/3/232
10.1161/CIRCULATIONAHA.117.032600
None

4
Circulation
Fasting Versus Nonfasting and Low-Density Lipoprotein Cholesterol Accuracy
<sec><title>Background:</title><p>Recent recommendations favoring nonfasting lipid assessment may affect low-density lipoprotein cholesterol (LDL-C) estimation. The novel <strong><span style="color:yellowgreen">method</span></strong> of LDL-C estimation (LDL-C<sub>N</sub>) uses a flexible approach to derive patient-specific ratios of triglycerides to very low-density lipoprotein cholesterol. This adaptability may confer an accuracy advantage in nonfasting patients over the fixed approach of the classic Friedewald <strong><span style="color:yellowgreen">method</span></strong> (LDL-C<sub>F</sub>).</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>We used a US cross-sectional sample of 1 545  634 patients (959 153 fasting ≥10–12 hours; 586 481 nonfasting) from the second harvest of the Very Large Database of Lipids study to assess for the first time the impact of fasting status on novel LDL-C accuracy. Rapid ultracentrifugation was used to directly measure LDL-C content (LDL-C<sub>D</sub>). Accuracy was defined as the percentage of LDL-C<sub>D</sub> falling within an estimated LDL-C (LDL-C<sub>N</sub> or LDL-C<sub>F</sub>) category by clinical cut points. For low estimated LDL-C (<70 mg/dL), we evaluated accuracy by triglyceride levels. The magnitude of absolute and percent differences between LDL-C<sub>D</sub> and estimated LDL-C (LDL-C<sub>N</sub> or LDL-C<sub>F</sub>) was stratified by LDL-C and triglyceride categories.</p></sec><sec><title>Results:</title><p>In both fasting and nonfasting samples, accuracy was higher with the novel <strong><span style="color:yellowgreen">method</span></strong> across all clinical LDL-C categories (range, 87%–94%) compared with the Friedewald estimation (range, 71%–93%; <i>P</i>≤0.001). With LDL-C <70 mg/dL, nonfasting LDL-C<sub>N</sub> accuracy (92%) was superior to LDL-C<sub>F</sub> accuracy (71%; <i>P</i><0.001). In this LDL-C range, 19% of fasting and 30% of nonfasting patients had differences ≥10 mg/dL between LDL-C<sub>F</sub> and LDL-C<sub>D</sub>, whereas only 2% and 3% of patients, respectively, had similar differences with novel estimation. Accuracy of LDL-C <70 mg/dL further decreased as triglycerides increased, particularly for Friedewald estimation (range, 37%–96%) versus the novel <strong><span style="color:yellowgreen">method</span></strong> (range, 82%–94%). With triglycerides of 200 to 399 mg/dL in nonfasting patients, LDL-C<sub>N</sub> <70 mg/dL accuracy (82%) was superior to LDL-C<sub>F</sub> (37%; <i>P</i><0.001). In this triglyceride range, 73% of fasting and 81% of nonfasting patients had ≥10 mg/dL differences between LDL-C<sub>F</sub> and LDL-C<sub>D</sub> compared with 25% and 20% of patients, respectively, with LDL-C<sub>N</sub>.</p></sec><sec><title>Conclusions:</title><p>Novel adaptable LDL-C estimation performs better in nonfasting samples than the fixed Friedewald estimation, with a particular accuracy advantage in settings of low LDL-C and high triglycerides. In addition to stimulating further study, these results may have immediate relevance for guideline committees, laboratory leadership, clinicians, and patients.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01698489.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/1/10
10.1161/CIRCULATIONAHA.117.030677
None

4
Circulation
Diagnosis and Treatment of Fetal Cardiac Disease
<sec><title>Background—</title><p>The goal of this statement is to review available literature and to put forth a scientific statement on the current <strong><span style="color:yellowgreen">practic</span></strong>e of fetal cardiac medicine, including the diagnosis and management of fetal cardiovascular disease.</p></sec><sec><title>Methods and Results—</title><p>A writing group appointed by the American Heart Association reviewed the available literature pertaining to topics relevant to fetal cardiac medicine, including the diagnosis of congenital heart disease and arrhythmias, assessment of cardiac function and the cardiovascular system, and available treatment options. The American College of Cardiology/American Heart Association classification of recommendations and level of evidence for <strong><span style="color:yellowgreen">practic</span></strong>e guidelines were applied to the current <strong><span style="color:yellowgreen">practic</span></strong>e of fetal cardiac medicine. Recommendations relating to the specifics of fetal diagnosis, including the timing of referral for study, indications for referral, and experience suggested for performance and interpretation of studies, are presented. The components of a fetal echocardiogram are described in detail, including descriptions of the assessment of cardiac anatomy, cardiac function, and rhythm. Complementary modalities for fetal cardiac assessment are reviewed, including the use of advanced ultrasound techniques, fetal magnetic resonance imaging, and fetal magnetocardiography and electrocardiography for rhythm assessment. Models for parental counseling and a discussion of parental stress and depression assessments are reviewed. Available fetal therapies, including medical management for arrhythmias or heart failure and closed or open intervention for diseases affecting the cardiovascular system such as twin–twin transfusion syndrome, lung masses, and vascular tumors, are highlighted. Catheter-based intervention strategies to prevent the progression of disease in utero are also discussed. Recommendations for delivery planning strategies for fetuses with congenital heart disease including models based on classification of disease severity and delivery room treatment will be highlighted. Outcome assessment is reviewed to show the benefit of prenatal diagnosis and management as they affect outcome for babies with congenital heart disease.</p></sec><sec><title>Conclusions—</title><p>Fetal cardiac medicine has evolved considerably over the past 2 decades, predominantly in response to advances in imaging technology and innovations in therapies. The diagnosis of cardiac disease in the fetus is mostly made with ultrasound; however, new technologies, including 3- and 4-dimensional echocardiography, magnetic resonance imaging, and fetal electrocardiography and magnetocardiography, are available. Medical and interventional treatments for select diseases and strategies for delivery room care enable stabilization of high-risk fetuses and contribute to improved outcomes. This statement highlights what is currently known and recommended on the basis of evidence and experience in the rapidly advancing and highly specialized field of fetal cardiac care.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/21/2183
10.1161/01.cir.0000437597.44550.5d
None

4
Circulation
Identifying Locations for Public Access Defibrillators Using Mathematical Optimization
<sec><title>Background—</title><p>Geospatial <strong><span style="color:yellowgreen">method</span></strong>s using mathematical optimization to identify clusters of cardiac arrests and prioritize public locations for defibrillator deployment have not been studied. Our objective was to develop such a <strong><span style="color:yellowgreen">method</span></strong> and test its performance against a population-guided approach.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s and Results—</title><p>All public location cardiac arrests in Toronto, Ontario, Canada, from December 16, 2005, to July 15, 2010, and all automated external defibrillator (AED) locations registered with Toronto Emergency Medical Services as of September 2009 were plotted geographically. Current AED coverage was quantified by determining the number of cardiac arrests occurring within 100 m of a registered AED. Clusters of cardiac arrests without a registered AED within 100 m were identified. With the use of mathematical optimization techniques, cardiac arrest coverage improvements were computed and shown to be superior to results from a population-guided deployment <strong><span style="color:yellowgreen">method</span></strong>. There were 1310 eligible public location cardiac arrests and 1669 registered AEDs. Of the eligible cardiac arrests, 304 were within 100 m of at least 1 registered AED (23% coverage). The average distance from a cardiac arrest to the closest AED was 281 m. With AEDs deployed in the top 30 locations, an additional 112 historical cardiac arrests would be covered (32% total coverage), and the average distance to the closest AED would be 262 m.</p></sec><sec><title>Conclusions—</title><p>Geographic clusters of cardiac arrests can be easily identified and prioritized with the use of mathematical modeling. Optimized AED deployment can increase cardiac arrest coverage and decrease the distance to the closest AED. Mathematical modeling can augment public AED deployment programs.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/17/1801
10.1161/CIRCULATIONAHA.113.001953
None

3
Science
Using neuroscience to develop artificial intelligence
<p>When the mathematician Alan Turing posed the question “Can machines think?” in the first line of his seminal 1950 paper that ushered in the quest for artificial intelligence (AI) (<i>1</i>), the only known systems carrying out complex computations were biological nervous systems. It is not surprising, therefore, that scientists in the nascent field of AI turned to brain circuits as a source for guidance. One path that was taken since the early attempts to perform intelligent computation by brain-like circuits (<i>2</i>), and which led recently to remarkable successes, can be described as a highly reductionist approach to model cortical circuitry. In its basic current form, known as a “deep network” (or deep net) architecture, this brain-inspired model is built from successive layers of neuron-like elements, connected by adjustable weights, called “synapses” after their biological counterparts (<i>3</i>). The application of deep nets and related <strong><span style="color:yellowgreen">method</span></strong>s to AI systems has been transformative. They proved superior to previously known <strong><span style="color:yellowgreen">method</span></strong>s in central areas of AI research, including computer vision, speech recognition and production, and playing complex games. Practical applications are already in broad use, in areas such as computer vision and speech and text translation, and large-scale efforts are under way in many other areas. Here, I discuss how additional aspects of brain circuitry could supply cues for guiding network models toward broader aspects of cognition and general AI.</p>
http://sciencemag.org/cgi/content/summary/363/6428/692
10.1126/science.aau6595
None

3
Science
Giant polarization in super-tetragonal thin films through interphase strain
<p>Strain engineering has emerged as a powerful tool to enhance the performance of known functional materials. Here we demonstrate a general and <strong><span style="color:yellowgreen">practic</span></strong>al <strong><span style="color:yellowgreen">method</span></strong> to obtain super-tetragonality and giant polarization using interphase strain. We use this <strong><span style="color:yellowgreen">method</span></strong> to create an out-of-plane–to–in-plane lattice parameter ratio of 1.238 in epitaxial composite thin films of tetragonal lead titanate (PbTiO<sub>3</sub>), compared to 1.065 in bulk. These thin films with super-tetragonal structure possess a giant remanent polarization, 236.3 microcoulombs per square centimeter, which is almost twice the value of known ferroelectrics. The super-tetragonal phase is stable up to 725°C, compared to the bulk transition temperature of 490°C. The interphase-strain approach could enhance the physical properties of other functional materials.</p>
http://sciencemag.org/cgi/content/abstract/361/6401/494
10.1126/science.aan2433
None

3
Science
Catalytic enantioselective Minisci-type addition to heteroarenes
<p>Basic heteroarenes are a ubiquitous feature of pharmaceuticals and bioactive molecules, and Minisci-type additions of radical nucleophiles are a leading <strong><span style="color:yellowgreen">method</span></strong> for their elaboration. Despite many Minisci-type protocols that result in the formation of stereocenters, exerting control over the absolute stereochemistry at these centers remains an unmet challenge. We report a process for addition of prochiral radicals, generated from amino acid derivatives, to pyridines and quinolines. Our <strong><span style="color:yellowgreen">method</span></strong> offers excellent control of both enantioselectivity and regioselectivity. An enantiopure chiral Brønsted acid catalyst serves both to activate the substrate and induce asymmetry, while an iridium photocatalyst mediates the required electron transfer processes. We anticipate that this <strong><span style="color:yellowgreen">method</span></strong> will expedite access to enantioenriched small-molecule building blocks bearing versatile basic heterocycles.</p>
http://sciencemag.org/cgi/content/abstract/360/6387/419
10.1126/science.aar6376
None

3
Science
Single-cell whole-genome analyses by Linear Amplification via Transposon Insertion (LIANTI)
<p>Single-cell genomics is important for biology and medicine. However, current whole-genome amplification (WGA) <strong><span style="color:yellowgreen">method</span></strong>s are limited by low accuracy of copy-number variation (CNV) detection and low amplification fidelity. Here we report an improved single-cell WGA <strong><span style="color:yellowgreen">method</span></strong>, Linear Amplification via Transposon Insertion (LIANTI), which outperforms existing <strong><span style="color:yellowgreen">method</span></strong>s, enabling micro-CNV detection with kilobase resolution. This allowed direct observation of stochastic firing of DNA replication origins, which differs from cell to cell. We also show that the predominant cytosine-to-thymine mutations observed in single-cell genomics often arise from the artifact of cytosine deamination upon cell lysis. However, identifying single-nucleotide variations (SNVs) can be accomplished by sequencing kindred cells. We determined the spectrum of SNVs in a single human cell after ultraviolet radiation, revealing their nonrandom genome-wide distribution.</p>
http://sciencemag.org/cgi/content/abstract/356/6334/189
10.1126/science.aak9787
['human']

3
Science
Formaldehyde stabilization facilitates lignin monomer production during biomass depolymerization
<p>Practical, high-yield lignin depolymerization <strong><span style="color:yellowgreen">method</span></strong>s could greatly increase biorefinery productivity and profitability. However, development of these <strong><span style="color:yellowgreen">method</span></strong>s is limited by the presence of interunit carbon-carbon bonds within native lignin, and further by formation of such linkages during lignin extraction. We report that adding formaldehyde during biomass pretreatment produces a soluble lignin fraction that can be converted to guaiacyl and syringyl monomers at near theoretical yields during subsequent hydrogenolysis (47 mole % of Klason lignin for beech and 78 mole % for a high-syringyl transgenic poplar). These yields were three to seven times those obtained without formaldehyde, which prevented lignin condensation by forming 1,3-dioxane structures with lignin side-chain hydroxyl groups. By depolymerizing cellulose, hemicelluloses, and lignin separately, monomer yields were between 76 and 90 mole % for these three major biomass fractions.</p>
http://sciencemag.org/cgi/content/abstract/354/6310/329
10.1126/science.aaf7810
['beech', 'poplar']

3
PLANT PHYSIOLOGY
MAPINS, a Highly Efficient Detection Method That Identifies Insertional Mutations and Complex DNA Rearrangements
<p>Insertional mutagenesis, in which a piece of exogenous DNA is integrated randomly into the genomic DNA of the recipient cell, is a useful <strong><span style="color:yellowgreen">method</span></strong> to generate new mutants with phenotypes of interest. The unicellular green alga <i>Chlamydomonas reinhardtii</i> is an outstanding model for studying many biological processes. We developed a new computational algorithm, MAPINS (mapping insertions), to efficiently identify insertion sites created by the integration of an <i>APHVIII</i> (<i>aminoglycoside 3′-phosphotransferase VIII</i>) cassette that confers paromomycin resistance. Using whole-genome sequencing data, this <strong><span style="color:yellowgreen">method</span></strong> eliminates the need for genomic DNA manipulation and retains all the sequencing information provided by paired-end sequencing. We experimentally verified 38 insertion sites out of 41 sites (93%) identified by MAPINS from 20 paromomycin-resistant strains. Using meiotic analysis of 18 of these strains, we identified insertion sites that completely cosegregate with paromomycin resistance. In six of the seven strains with a mutant phenotype, we demonstrated complete cosegregation of the mutant phenotype and the verified insertion site. In addition, we provide direct evidence of complex rearrangements of genomic DNA in five strains, three of which involve the <i>APHVIII</i> insertion site. We suggest that strains obtained by insertional mutagenesis are more complicated than expected from previous analyses in <i>Chlamydomonas</i>. To map the locations of some complex insertions, we designed 49 molecular markers based on differences identified via whole-genome sequencing between wild-type strains CC-124 and CC-125. Overall, MAPINS provides a low-cost, efficient <strong><span style="color:yellowgreen">method</span></strong> to characterize insertional mutants in <i>Chlamydomonas</i>.</p>
http://plantphysiol.org/cgi/content/abstract/178/4/1436
10.1104/pp.18.00474
['Chlamydomonas', 'Chlamydomonas reinhardtii']

3
PLANT PHYSIOLOGY
A High-Throughput, Field-Based Phenotyping Technology for Tall Biomass Crops
<p>Recent advances in omics technologies have not been accompanied by equally efficient, cost-effective, and accurate phenotyping <strong><span style="color:yellowgreen">method</span></strong>s required to dissect the genetic architecture of complex traits. Even though high-throughput phenotyping platforms have been developed for controlled environments, field-based aerial and ground technologies have only been designed and deployed for short-stature crops. Therefore, we developed and tested Phenobot 1.0, an auto-steered and self-propelled field-based high-throughput phenotyping platform for tall dense canopy crops, such as sorghum (<i>Sorghum bicolor</i>). Phenobot 1.0 was equipped with laterally positioned and vertically stacked stereo RGB cameras. Images collected from 307 diverse sorghum lines were reconstructed in 3D for feature extraction. User interfaces were developed, and multiple algorithms were evaluated for their accuracy in estimating plant height and stem diameter. Tested feature extraction <strong><span style="color:yellowgreen">method</span></strong>s included the following: (1) User-interactive Individual Plant Height Extraction (UsIn-PHe) based on dense stereo three-dimensional reconstruction; (2) Automatic Hedge-based Plant Height Extraction (Auto-PHe) based on dense stereo 3D reconstruction; (3) User-interactive Dense Stereo Matching Stem Diameter Extraction; and (4) User-interactive Image Patch Stereo Matching Stem Diameter Extraction (IPaS-Di). Comparative genome-wide association analysis and ground-truth validation demonstrated that both UsIn-PHe and Auto-PHe were accurate <strong><span style="color:yellowgreen">method</span></strong>s to estimate plant height, while Auto-PHe had the additional advantage of being a completely automated process. For stem diameter, IPaS-Di generated the most accurate estimates of this biomass-related architectural trait. In summary, our technology was proven robust to obtain ground-based high-throughput plant architecture parameters of sorghum, a tall and densely planted crop species.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2008
10.1104/pp.17.00707
['Sorghum', 'Sorghum bicolor', 'sorghum']

3
Molecular Biology and Evolution
Phylogenetic Tools for Generalized HIV-1 Epidemics: Findings from the PANGEA-HIV Methods Comparison
<p>Viral phylogenetic <strong><span style="color:yellowgreen">method</span></strong>s contribute to understanding how HIV spreads in populations, and thereby help guide the design of prevention interventions. So far, most analyses have been applied to well-sampled concentrated HIV-1 epidemics in wealthy countries. To direct the use of phylogenetic tools to where the impact of HIV-1 is greatest, the Phylogenetics And Networks for Generalized HIV Epidemics in Africa (PANGEA-HIV) consortium generates full-genome viral sequences from across sub-Saharan Africa. Analyzing these data presents new challenges, since epidemics are principally driven by heterosexual transmission and a smaller fraction of cases is sampled. Here, we show that viral phylogenetic tools can be adapted and used to estimate epidemiological quantities of central importance to HIV-1 prevention in sub-Saharan Africa. We used a community-wide <strong><span style="color:yellowgreen">method</span></strong>s comparison exercise on simulated data, where participants were blinded to the true dynamics they were inferring. Two distinct simulations captured generalized HIV-1 epidemics, before and after a large community-level intervention that reduced infection levels. Five research groups participated. Structured coalescent modeling approaches were most successful: phylogenetic estimates of HIV-1 incidence, incidence reductions, and the proportion of transmissions from individuals in their first 3 months of infection correlated with the true values (Pearson correlation > 90%), with small bias. However, on some simulations, true values were markedly outside reported confidence or credibility intervals. The blinded comparison revealed current limits and strengths in using HIV phylogenetics in challenging settings, provided benchmarks for future <strong><span style="color:yellowgreen">method</span></strong>s’ development, and supports using the latest generation of phylogenetic tools to advance HIV surveillance and prevention.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/185
10.1093/molbev/msw217
None

3
Molecular Biology and Evolution
Efficient Inference of Recombination Hot Regions in Bacterial Genomes
<p>In eukaryotes, detailed surveys of recombination rates have shown variation at multiple genomic scales and the presence of “hotspots” of highly elevated recombination. In bacteria, studies of recombination rate variation are less developed, in part because there are few analysis <strong><span style="color:yellowgreen">method</span></strong>s that take into account the clonal context within which bacterial evolution occurs. Here, we focus in particular on identifying “hot regions” of the genome where DNA is transferred frequently between isolates. We present a computationally efficient algorithm based on the recently developed “chromosome painting” algorithm, which characterizes patterns of haplotype sharing across a genome. We compare the average genome wide painting, which principally reflects clonal descent, with the painting for each site which additionally reflects the specific deviations at the site due to recombination. Using simulated data, we show that hot regions have consistently higher deviations from the genome wide average than normal regions. We applied our approach to previously analyzed <i>Escherichia coli</i> genomes and revealed that the new <strong><span style="color:yellowgreen">method</span></strong> is highly correlated with the number of recombination events affecting each site inferred by ClonalOrigin, a <strong><span style="color:yellowgreen">method</span></strong> that is only applicable to small numbers of genomes. Furthermore, we analyzed recombination hot regions in <i>Campylobacter jejuni</i> by using 200 genomes. We identified three recombination hot regions, which are enriched for genes related to membrane proteins. Our approach and its implementation, which is downloadable from <ext-link>https://github.com/bioprojects/orderedPainting</ext-link>, will help to develop a new phase of population genomic studies of recombination in prokaryotes.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/31/6/1593
10.1093/molbev/msu082
['Campylobacter', 'Campylobacter jejuni', 'Escherichia', 'Escherichia coli']

3
Molecular Biology and Evolution
Building Phylogenetic Trees from Molecular Data with MEGA
<p>Phylogenetic analysis is sometimes regarded as being an intimidating, complex process that requires expertise and years of experience. In fact, it is a fairly straightforward process that can be learned quickly and applied effectively. This Protocol describes the several steps required to produce a phylogenetic tree from molecular data for novices. In the example illustrated here, the program MEGA is used to implement all those steps, thereby eliminating the need to learn several programs, and to deal with multiple file formats from one step to another (Tamura K, Peterson D, Peterson N, Stecher G, Nei M, Kumar S. 2011. MEGA5: molecular evolutionary genetics analysis using maximum likelihood, evolutionary distance, and maximum parsimony <strong><span style="color:yellowgreen">method</span></strong>s. <i>Mol Biol Evol</i>. 28:2731–2739). The first step, identification of a set of homologous sequences and downloading those sequences, is implemented by MEGA's own browser built on top of the Google Chrome toolkit. For the second step, alignment of those sequences, MEGA offers two different algorithms: ClustalW and MUSCLE. For the third step, construction of a phylogenetic tree from the aligned sequences, MEGA offers many different <strong><span style="color:yellowgreen">method</span></strong>s. Here we illustrate the maximum likelihood <strong><span style="color:yellowgreen">method</span></strong>, beginning with MEGA's Models feature, which permits selecting the most suitable substitution model. Finally, MEGA provides a powerful and flexible interface for the final step, actually drawing the tree for publication. Here a step-by-step protocol is presented in sufficient detail to allow a novice to start with a sequence of interest and to build a publication-quality tree illustrating the evolution of an appropriate set of homologs of that sequence. MEGA is available for use on PCs and Macs from <ext-link>www.megasoftware.net</ext-link>.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1229
10.1093/molbev/mst012
None

3
The Bone & Joint Journal
Plate fixation <i>versus</i> intramedullary nailing of completely displaced midshaft fractures of the clavicle
<sec><title>Aims</title><p>This is a prospective randomised controlled trial comparing the   functional outcomes of plate fixation and elastic stable intramedullary   nailing (ESIN) of completely displaced mid-shaft fractures of the   clavicle in the active adult population.</p></sec><sec><title>Patients and <strong><span style="color:yellowgreen">method</span></strong>s</title><p>We prospectively recruited 123 patients and randomised them to   either plate fixation or ESIN. Patients completed the Quick Disabilities   of the Arm, Shoulder and Hand (DASH) score at one to six weeks post-operatively.   They were followed up at six weeks, three and six months and one   year with radiographs, and their clinical outcome was assessed using   both the DASH and the Constant Score.</p></sec><sec><title>Results</title><p>Plate fixation provided a faster functional recovery during the   first six months compared with ESIN, but there was no difference   after one year. The duration of surgery was shorter for ESIN (mean   53.4 minutes, 22 to 120) than for plate fixation (mean 69.7 minutes,   35 to 106, p < 0.001). The recovery after ESIN was slower with   increasing fracture comminution and with open reduction (p <   0.05).</p></sec><sec><title>Conclusion</title><p>Both <strong><span style="color:yellowgreen">method</span></strong>s return the patients to their pre-injury functional   levels, but plate fixation has a faster recovery period in comminuted   fractures than ESIN. ESIN has a shorter operative time and lower   infection and implant rates of failure when using 2.5 mm nails or   wider, suggesting that this is the preferred <strong><span style="color:yellowgreen">method</span></strong> in mid-shaft   fractures with no comminution, whereas plate fixation is the superior   <strong><span style="color:yellowgreen">method</span></strong> in comminuted fractures.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1095–1101</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/8/1095
10.1302/0301-620X.99B8.BJJ-2016-1318.R1
None

3
Circulation
Lower Risk of Heart Failure and Death in Patients Initiated on Sodium-Glucose Cotransporter-2 Inhibitors Versus Other Glucose-Lowering Drugs
<sec><title>Background:</title><p>Reduction in cardiovascular death and hospitalization for heart failure (HHF) was recently reported with the sodium-glucose cotransporter-2 inhibitor (SGLT-2i) empagliflozin in patients with type 2 diabetes mellitus who have atherosclerotic cardiovascular disease. We compared HHF and death in patients newly initiated on any SGLT-2i versus other glucose-lowering drugs in 6 countries to determine if these benefits are seen in real-world <strong><span style="color:yellowgreen">practic</span></strong>e and across SGLT-2i class.</p></sec><sec><title>Methods:</title><p>Data were collected via medical claims, primary care/hospital records, and national registries from the United States, Norway, Denmark, Sweden, Germany, and the United Kingdom. Propensity score for SGLT-2i initiation was used to match treatment groups. Hazard ratios for HHF, death, and their combination were estimated by country and pooled to determine weighted effect size. Death data were not available for Germany.</p></sec><sec><title>Results:</title><p>After propensity matching, there were 309 056 patients newly initiated on either SGLT-2i or other glucose-lowering drugs (154 528 patients in each treatment group). Canagliflozin, dapagliflozin, and empagliflozin accounted for 53%, 42%, and 5% of the total exposure time in the SGLT-2i class, respectively. Baseline characteristics were balanced between the 2 groups. There were 961 HHF cases during 190 164 person-years follow-up (incidence rate, 0.51/100 person-years). Of 215 622 patients in the United States, Norway, Denmark, Sweden, and the United Kingdom, death occurred in 1334 (incidence rate, 0.87/100 person-years), and HHF or death in 1983 (incidence rate, 1.38/100 person-years). Use of SGLT-2i, versus other glucose-lowering drugs, was associated with lower rates of HHF (hazard ratio, 0.61; 95% confidence interval, 0.51–0.73; <i>P</i><0.001); death (hazard ratio, 0.49; 95% confidence interval, 0.41–0.57; <i>P</i><0.001); and HHF or death (hazard ratio, 0.54; 95% confidence interval, 0.48–0.60; <i>P</i><0.001) with no significant heterogeneity by country.</p></sec><sec><title>Conclusions:</title><p>In this large multinational study, treatment with SGLT-2i versus other glucose-lowering drugs was associated with a lower risk of HHF and death, suggesting that the benefits seen with empagliflozin in a randomized trial may be a class effect applicable to a broad population of patients with type 2 diabetes mellitus in real-world <strong><span style="color:yellowgreen">practic</span></strong>e.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02993614.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/3/249
10.1161/CIRCULATIONAHA.117.029190
None

3
Circulation
Increase in Endovascular Therapy in Get With The Guidelines-Stroke After the Publication of Pivotal Trials
<sec><title>Background:</title><p>Beginning in December 2014, a series of pivotal trials showed that endovascular thrombectomy (EVT) was highly effective, prompting calls to reorganize stroke systems of care. However, there are few data on how these trials influenced the frequency of EVT in clinical <strong><span style="color:yellowgreen">practic</span></strong>e. We used data from the Get With The Guidelines-Stroke program to determine how the frequency of EVT changed in US <strong><span style="color:yellowgreen">practic</span></strong>e.</p></sec><sec><title>Methods:</title><p>We analyzed prospectively collected data from a cohort of 2 437 975 patients with ischemic stroke admitted to 2222 participating hospitals between April 2003 and the third quarter of 2016. Weighted linear regression with 2 linear splines and a knot at January 2015 was used to compare the slope of the change in EVT use before and after the pivotal trials were published. Potentially eligible patients were defined as last known well to arrival time ≤4.5 hours and National Institutes of Health Stroke Scale score ≥6.</p></sec><sec><title>Results:</title><p>The frequency of EVT use was slowly increasing before January 2015 but then sharply accelerated thereafter. In the third quarter 2016, EVT was provided to 3.3% of all patients with ischemic stroke at all hospitals, representing 15.1% of all patients who were potentially eligible for EVT based on stroke duration and severity. At EVT-capable hospitals, 7.5% of all patients with ischemic stroke were treated in the third quarter of 2016, including 27.3% of the potentially eligible patients. From 2013 to 2016, case volumes nearly doubled at EVT-capable hospitals. Mean case volume per EVT-capable hospital was 37.6 per year in the last 4 quarters. EVT case volumes increased in nearly all US states from 2014 to the last 4 quarters, but with persistent geographic variation unexplained by differences in potential patient eligibility.</p></sec><sec><title>Conclusions:</title><p>EVT use is increasing rapidly; however, there are still opportunities to treat more patients. Reorganizing stroke systems to route patients to adequately resourced EVT-capable hospitals might increase treatment of eligible patients, improve outcomes, and reduce disparities.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/24/2303
10.1161/CIRCULATIONAHA.117.031097
None

3
Circulation
Conscious Sedation Versus General Anesthesia for Transcatheter Aortic Valve Replacement
<sec><title>Background:</title><p>Conscious sedation is used during transcatheter aortic valve replacement (TAVR) with limited evidence as to the safety and efficacy of this <strong><span style="color:yellowgreen">practic</span></strong>e.</p></sec><sec><title>Methods:</title><p>The National Cardiovascular Data Registry Society of Thoracic Surgeons/American College of Cardiology Transcatheter Valve Therapy Registry was used to characterize the anesthesia choice and clinical outcomes of all US patients undergoing elective percutaneous transfemoral TAVR between April 1, 2014, and June 30, 2015. Raw and inverse probability of treatment-weighted analyses were performed to compare patients undergoing TAVR with general anesthesia with patients undergoing TAVR with conscious sedation on an intention-to-treat basis for the primary outcome of in-hospital mortality, and secondary outcomes including 30-day mortality, in-hospital and 30-day death/stroke, procedural success, intensive care unit and hospital length-of-stay, and rates of discharge to home. Post hoc falsification end point analyses were performed to evaluate for residual confounding.</p></sec><sec><title>Results:</title><p>Conscious sedation was used in 1737/10 997 (15.8%) cases with a significant trend of increasing usage over the time period studied (<i>P</i> for trend<0.001). In raw analyses, intraprocedural success with conscious sedation and general anesthesia was similar (98.2% versus 98.5%, <i>P</i>=0.31). The conscious sedation group was less likely to experience in-hospital (1.6% versus 2.5%, <i>P</i>=0.03) and 30-day death (2.9% versus 4.1%, <i>P</i>=0.03). Conversion from conscious sedation to general anesthesia was noted in 102 of 1737 (5.9%) of conscious sedation cases. After inverse probability of treatment-weighted adjustment for 51 covariates, conscious sedation was associated with lower procedural success (97.9% versus 98.6%, <i>P</i><0.001) and a reduced rate of mortality at the in-hospital (1.5% versus 2.4%, <i>P</i><0.001) and 30-day (2.3% versus 4.0%, <i>P</i><0.001) time points. Conscious sedation was associated with reductions in procedural inotrope requirement, intensive care unit and hospital length of stay (6.0 versus 6.5 days, <i>P</i><0.001), and combined 30-day death/stroke rates (4.8% versus 6.4%, <i>P</i><0.001). Falsification end point analyses of vascular complications, bleeding, and new pacemaker/defibrillator implantation demonstrated no significant differences between groups after adjustment.</p></sec><sec><title>Conclusions:</title><p>In US <strong><span style="color:yellowgreen">practic</span></strong>e, conscious sedation is associated with briefer length of stay and lower in-hospital and 30-day mortality in comparison with TAVR with general anesthesia in both unadjusted and adjusted analyses. These results suggest the safety of conscious sedation in this population, although comparative effectiveness analyses using observational data cannot definitively establish the superiority of one technique over another.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2132
10.1161/CIRCULATIONAHA.116.026656
None

3
Circulation
Counseling African Americans to Control Hypertension
<sec><title>Background—</title><p>Data are limited on the implementation of evidence-based multilevel interventions targeted at blood pressure (BP) control in hypertensive blacks who receive care in low-resource primary care <strong><span style="color:yellowgreen">practic</span></strong>es.</p></sec><sec><title>Methods and Results—</title><p>Counseling African Americans to Control Hypertension is a cluster-randomized clinical trial in which 30 community health centers were randomly assigned to the intervention condition (IC) or usual care (UC). Patients at the IC sites received patient education, home BP monitoring, and monthly lifestyle counseling, whereas physicians attended monthly hypertension case rounds and received feedback on their patients’ home BP readings and chart audits. Patients and physicians at the UC sites received printed patient education material and hypertension treatment guidelines, respectively. The primary outcome was BP control, and secondary outcomes were mean changes in systolic and diastolic BPs at 12 months, assessed with an automated BP device. A total of 1059 patients (mean age, 56 years; 28% men, 59% obese, and 36% with diabetes mellitus) were enrolled. The BP control rate was similar in both groups (IC=49.3% versus UC=44.5%; odds ratio, 1.21 [95% confidence interval, 0.90–1.63]; <i>P</i>=0.21). In prespecified subgroup analyses, the intervention was associated with greater BP control in patients without diabetes mellitus (IC=54.0% versus UC=44.7%; odds ratio, 1.45 [confidence interval, 1.02–2.06]); and small-sized community health centers (IC=51.1% versus UC=39.6%; odds ratio, 1.45 [confidence interval, 1.04–2.45]).</p></sec><sec><title>Conclusions—</title><p>A <strong><span style="color:yellowgreen">practic</span></strong>e-based, multicomponent intervention was no better than UC in improving BP control among hypertensive blacks. Future research on the implementation of behavioral modification strategies for hypertension control in low-resource settings should focus on the development of more efficient and tailored interventions in this high-risk population.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00233220.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/20/2044
10.1161/CIRCULATIONAHA.113.006650
None

3
Biology Open
Beyond the whole-mount phenotype: high-resolution imaging in fluorescence-based applications on zebrafish
<p><bold>Summary:</bold> We propose a GMA embedding <strong><span style="color:yellowgreen">method</span></strong> that preserves fluorescent signals without the need for antibodies. The <strong><span style="color:yellowgreen">method</span></strong> complements whole-mount <strong><span style="color:yellowgreen">method</span></strong>s especially if advanced imaging technology is not readily available.</p>
http://bio.biologists.org/cgi/content/abstract/8/5/bio042374
10.1242/bio.042374
['zebrafish']

2
Circulation
Derivation and Validation of the CREST Model for Very Early Prediction of Circulatory Etiology Death in Patients Without ST-Segment–Elevation Myocardial Infarction After Cardiac Arrest
<sec><title>Background:</title><p>No <strong><span style="color:yellowgreen">practic</span></strong>al tool quantitates the risk of circulatory-etiology death (CED) immediately after successful cardiopulmonary resuscitation in patients without ST-segment–elevation myocardial infarction. We developed and validated a prediction model to rapidly determine that risk and facilitate triage to individualized treatment pathways.</p></sec><sec><title>Methods:</title><p>With the use of INTCAR (International Cardiac Arrest Registry), an 87-question data set representing 44 centers in the United States and Europe, patients were classified as having had CED or a combined end point of neurological-etiology death or survival. Demographics and clinical factors were modeled in a derivation cohort, and backward stepwise logistic regression was used to identify factors independently associated with CED. We demonstrated model performance using area under the curve and the Hosmer-Lemeshow test in the derivation and validation cohorts, and assigned a simplified point-scoring system.</p></sec><sec><title>Results:</title><p>Among 638 patients in the derivation cohort, 121 (18.9%) had CED. The final model included preexisting coronary artery disease (odds ratio [OR], 2.86; confidence interval [CI], 1.83–4.49; <i>P</i>≤0.001), nonshockable rhythm (OR, 1.75; CI, 1.10–2.77; P=0.017), initial ejection fraction<30% (OR, 2.11; CI, 1.32–3.37; <i>P</i>=0.002), shock at presentation (OR, 2.27; CI, 1.42–3.62; P<0.001), and ischemic time >25 minutes (OR, 1.42; CI, 0.90–2.23; P=0.13). The derivation model area under the curve was 0.73, and Hosmer-Lemeshow test P=0.47. Outcomes were similar in the 318-patient validation cohort (area under the curve 0.68, Hosmer-Lemeshow test P=0.41). When assigned a point for each associated factor in the derivation model, the average predicted versus observed probability of CED with a CREST score (coronary artery disease, initial heart rhythm, low ejection fraction, shock at the time of admission, and ischemic time >25 minutes) of 0 to 5 was: 7.1% versus 10.2%, 9.5% versus 11%, 22.5% versus 19.6%, 32.4% versus 29.6%, 38.5% versus 30%, and 55.7% versus 50%.</p></sec><sec><title>Conclusions:</title><p>The CREST model stratified patients immediately after resuscitation according to risk of a circulatory-etiology death. The tool may allow for estimation of circulatory risk and improve the triage of survivors of cardiac arrest without ST-segment–elevation myocardial infarction at the point of care.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/3/273
10.1161/CIRCULATIONAHA.116.024332
None

2
Circulation
Association Between Urinary Sodium and Potassium Excretion and Blood Pressure Among Adults in the United States
<sec><title>Background:</title><p>Higher levels of sodium and lower levels of potassium intake are associated with higher blood pressure. However, the shape and magnitude of these associations can vary by study participant characteristics or intake assessment <strong><span style="color:yellowgreen">method</span></strong>. Twenty-four–hour urinary excretion of sodium and potassium are unaffected by recall errors and represent all sources of intake, and were collected for the first time in a nationally representative US survey. Our objective was to assess the associations of blood pressure and hypertension with 24-hour urinary excretion of sodium and potassium among US adults.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>Cross-sectional data were obtained from 766 participants age 20 to 69 years with complete blood pressure and 24-hour urine collections in the 2014 National Health and Nutrition Examination Survey, a nationally representative survey of the US noninstitutionalized population. Usual 24-hour urinary electrolyte excretion (sodium, potassium, and their ratio) was estimated from ≤2 collections on nonconsecutive days, adjusting for day-to-day variability in excretion. Outcomes included systolic and diastolic blood pressure from the average of 3 measures and hypertension status, based on average blood pressure ≥140/90 and antihypertensive medication use.</p></sec><sec><title>Results:</title><p>After multivariable adjustment, each 1000-mg difference in usual 24-hour sodium excretion was directly associated with systolic (4.58 mm Hg; 95% confidence interval [CI], 2.64–6.51) and diastolic (2.25 mm Hg; 95% CI, 0.83–3.67) blood pressures. Each 1000-mg difference in potassium excretion was inversely associated with systolic blood pressure (–3.72 mm Hg; 95% CI, –6.01 to –1.42). Each 0.5 U difference in sodium-to-potassium ratio was directly associated with systolic blood pressure (1.72 mm Hg; 95% CI, 0.76–2.68). Hypertension was linearly associated with progressively higher sodium and lower potassium excretion; in comparison with the lowest quartile of excretion, the adjusted odds of hypertension for the highest quartile was 4.22 (95% CI, 1.36–13.15) for sodium, and 0.38 (95% CI, 0.17–0.87) for potassium (<i>P</i><0.01 for trends).</p></sec><sec><title>Conclusions:</title><p>These cross-sectional results show a strong dose-response association between urinary sodium excretion and blood pressure, and an inverse association between urinary potassium excretion and blood pressure, in a nationally representative sample of US adults.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/3/237
10.1161/CIRCULATIONAHA.117.029193
None

2
Circulation
Targeting Chondroitin Sulfate Glycosaminoglycans to Treat Cardiac Fibrosis in Pathological Remodeling
<sec><title>Background:</title><p>Heart failure is a leading cause of mortality and morbidity, and the search for novel therapeutic approaches continues. In the monogenic disease mucopolysaccharidosis VI, loss-of-function mutations in arylsulfatase B lead to myocardial accumulation of chondroitin sulfate (CS) glycosaminoglycans, manifesting as myriad cardiac symptoms. Here, we studied changes in myocardial CS in nonmucopolysaccharidosis failing hearts and assessed its generic role in pathological cardiac remodeling.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>Healthy and diseased human and rat left ventricles were subjected to histological and immunostaining <strong><span style="color:yellowgreen">method</span></strong>s to analyze glycosaminoglycan distribution. Glycosaminoglycans were extracted and analyzed for quantitative and compositional changes with Alcian blue assay and liquid chromatography–mass spectrometry. Expression changes in 20 CS-related genes were studied in 3 primary human cardiac cell types and THP-1–derived macrophages under each of 9 in vitro stimulatory conditions. In 2 rat models of pathological remodeling induced by transverse aortic constriction or isoprenaline infusion, recombinant human arylsulfatase B (rhASB), clinically used as enzyme replacement therapy in mucopolysaccharidosis VI, was administered intravenously for 7 or 5 weeks, respectively. Cardiac function, myocardial fibrosis, and inflammation were assessed by echocardiography and histology. CS-interacting molecules were assessed with surface plasmon resonance, and a mechanism of action was verified in vitro.</p></sec><sec><title>Results:</title><p>Failing human hearts displayed significant perivascular and interstitial CS accumulation, particularly in regions of intense fibrosis. Relative composition of CS disaccharides remained unchanged. Transforming growth factor–β induced CS upregulation in cardiac fibroblasts. CS accumulation was also observed in both the pressure-overload and the isoprenaline models of pathological remodeling in rats. Early treatment with rhASB in the transverse aortic constriction model and delayed treatment in the isoprenaline model proved rhASB to be effective at preventing cardiac deterioration and augmenting functional recovery. Functional improvement was accompanied by reduced myocardial inflammation and overall fibrosis. Tumor necrosis factor–α was identified as a direct binding partner of CS glycosaminoglycan chains, and rhASB reduced tumor necrosis factor–α—induced inflammatory gene activation in vitro in endothelial cells and macrophages.</p></sec><sec><title>Conclusions:</title><p>CS glycosaminoglycans accumulate during cardiac pathological remodeling and mediate myocardial inflammation and fibrosis. rhASB targets CS effectively as a novel therapeutic approach for the treatment of heart failure.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/23/2497
10.1161/CIRCULATIONAHA.117.030353
['human']

2
Circulation
Pharmacodynamic Effects of Switching From Ticagrelor to Clopidogrel in Patients With Coronary Artery Disease
<sec><title>Background:</title><p>Switching between different classes of P2Y<sub>12</sub> inhibitors, including de-escalation from ticagrelor to clopidogrel, commonly occurs in clinical <strong><span style="color:yellowgreen">practic</span></strong>e. However, the pharmacodynamic profiles of this strategy have been poorly explored.</p></sec><sec><title>Methods:</title><p>This was a prospective, randomized, open-label study conducted in patients on maintenance dosing (MD) of aspirin (81 mg/d) and clopidogrel (75 mg/d). After a 7-day run-in with ticagrelor (180 mg loading dose [LD] followed by 90 mg twice daily MD), patients (n=80) were randomized into 1 of 4 groups: group A, clopidogrel 600 mg LD 24 hours after the last MD of ticagrelor (C-600 mg-24h); group B, clopidogrel 600 mg LD 12 hours after the last MD of ticagrelor (C-600 mg-12h); group C, clopidogrel 75 mg/d MD 24 hours after the last MD of ticagrelor (C-75 mg-24h); and group D, ticagrelor 90 mg twice daily MD (T-90 mg twice daily). MD of the randomized treatment was maintained for 10±3 days. Pharmacodynamic assessments were performed at baseline, after run-in, and at 2, 24, 48, and 72 hours and 10 days with P2Y<sub>12</sub> reaction units by VerifyNow; platelet reactivity index was assessed by vasodilator-stimulated phosphoprotein; and maximal platelet aggregation was determined by light transmittance aggregometry.</p></sec><sec><title>Results:</title><p>T-90 mg twice daily led to lower platelet reactivity than any clopidogrel regimen using all assays at all time points. P2Y<sub>12</sub> reaction unit levels were similar between the C-600 mg-24h (group A) and the C-75 mg-24h (group C) (<i>P</i>=0.29), including at 48 hours (primary end point; least mean difference, −6.9; 95% confidence interval, −38.1 to 24.3; <i>P</i>=0.66). P2Y<sub>12</sub> reaction unit levels were lower with C-600 mg-12h (group B) than with C-75 mg-24h (group C; <i>P</i>=0.024). Maximal platelet aggregation over time was lower with both C-600 mg-24h (group A; <i>P</i>=0.041) and C-600 mg-12h (group B; <i>P</i>=0.028) compared with C-75 mg-24h (group C). Platelet reactivity index profiles paralleled those observed with P2Y<sub>12</sub> reaction units. There were no pharmacodynamic differences for all tests between C-600 mg-24h (group A) and C-600 mg-12h (group B). In group C (C-75 mg-24h), platelet reactivity increased compared with baseline as early as 24 hours, reaching statistical significance at 48 and 72 hours and up to 10 days. These pharmacodynamic findings were delayed and blunted in magnitude with the administration of an LD, regardless of the timing of administration.</p></sec><sec><title>Conclusions:</title><p>De-escalation from ticagrelor to clopidogrel therapy is associated with an increase in platelet reactivity. The use of an LD before the initiation of an MD regimen of clopidogrel mitigates these observations, although this is not affected by the timing of its administration after ticagrelor discontinuation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02287909.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/23/2450
10.1161/CIRCULATIONAHA.118.033983
None

2
Circulation
Status of Hypertension in China
<sec><title>Background:</title><p>Although the prevalence of hypertension (HTN) continues to increase in developing countries, including China, recent data are lacking. A nationwide survey was conducted from October 2012 to December 2015 to assess the prevalence of HTN in China.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>A stratified multistage random sampling <strong><span style="color:yellowgreen">method</span></strong> was used to obtain a nationally representative sample of 451 755 residents ≥18 years of age from 31 provinces in mainland China from October 2012 to December 2015. Blood pressure (BP) was measured after resting for 5 minutes by trained staff using a validated oscillometric BP monitor. HTN was defined as systolic BP (SBP) ≥140 mm Hg/or diastolic BP (DBP) ≥90 mm Hg or use of antihypertensive medication within 2 weeks. Pre-HTN was defined as SBP 120 to 139 mm Hg and DBP 80 to 89 mm Hg without antihypertensive medication. HTN control was defined as SBP <140 mm Hg and DBP<90 mm Hg. In addition, the prevalence of HTN (SBP ≥130 or DBP ≥80 mm Hg) and control rate (SBP <130 and DBP <80 mm Hg) of HTN were also estimated according to the 2017 American College of Cardiology/American Heart Association High Blood Pressure Guideline.</p></sec><sec><title>Results:</title><p>Overall, 23.2% (≈244.5 million) of the Chinese adult population ≥18 years of age had HTN, and another 41.3% (≈435.3 million) had pre-HTN according to the Chinese guideline. There were no significant differences of HTN prevalence between urban and rural residents (23.4% versus 23.1%, <i>P</i>=0.819). Among individuals with HTN, 46.9% were aware of their condition, 40.7% were taking prescribed antihypertensive medications, and 15.3% had controlled HTN. Calcium channel blockers were the most commonly used antihypertensive medication (46.5%) as monotherapy, and 31.7% of treated hypertensive patients used ≥2 medications. The prevalence of HTN based on the 2017 American College of Cardiology/American Heart Association guideline was twice as high as that based on 2010 Chinese guideline (46.4%), whereas the control rate fell to 3.0%.</p></sec><sec><title>Conclusions:</title><p>In China, there is a high prevalence of HTN and pre-HTN, and awareness, treatment, and control of HTN were low. Management of medical therapy for HTN needs to improve.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/22/2344
10.1161/CIRCULATIONAHA.117.032380
None

2
Circulation
Geographic Variation in Cardiac Rehabilitation Participation in Medicare and Veterans Affairs Populations
<sec><title>Background:</title><p>Cardiac rehabilitation is strongly recommended after myocardial infarction, percutaneous coronary intervention, or coronary artery bypass surgery, but it is historically underused. We sought to evaluate variation in cardiac rehabilitation participation across the United States.</p></sec><sec><title>Methods:</title><p>From administrative data from the Veterans Affairs (VA) healthcare system and a 5% Medicare sample, we used International Classification of Diseases, 9th Revision codes to identify patients hospitalized for myocardial infarction, percutaneous coronary intervention, or coronary artery bypass surgery from 2007 to 2011. After excluding patients who died in ≤30 days of hospitalization, we calculated the percentage of patients who participated in ≥1 outpatient visits for cardiac rehabilitation during the 12 months after hospitalization. We estimated adjusted and standardized rates of participation in cardiac rehabilitation by state using hierarchical logistic regression models.</p></sec><sec><title>Results:</title><p>Overall, participation in cardiac rehabilitation was 16.3% (23 403/143 756) in Medicare and 10.3% (9123/88 826) in VA. However, participation rates varied widely across states, ranging from 3.2% to 41.8% in Medicare and 1.2% to 47.6% in VA. Similar regional variation was observed in both populations. Patients in the West North Central region (Iowa, Kansas, Minnesota, Missouri, Nebraska, North Dakota, and South Dakota) had the highest participation, whereas those in the Pacific region (Alaska, California, Hawaii, Oregon, and Washington) had the lowest participation in both Medicare (33.7% versus 10.6%) and VA (16.6% versus 5.1%) populations. Significant hospital-level variation was also present, with participation ranging from 3% to 75% in Medicare and 1% to 43% in VA.</p></sec><sec><title>Conclusions:</title><p>Cardiac rehabilitation participation remains low overall in both Medicare and VA populations. However, remarkably similar regional variation exists, with some regions and hospitals achieving high rates of participation in both populations. This provides an opportunity to identify best <strong><span style="color:yellowgreen">practic</span></strong>es from higher performing hospitals and regions that could be used to improve cardiac rehabilitation participation in lower performing hospitals and regions.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/18/1899
10.1161/CIRCULATIONAHA.117.029471
None

2
Circulation
Prognostic Implications of Magnetic Resonance–Derived Quantification in Asymptomatic Patients With Organic Mitral Regurgitation
<sec><title>Background:</title><p>Magnetic resonance imaging (MRI) is an accurate <strong><span style="color:yellowgreen">method</span></strong> for the quantitative assessment of organic mitral regurgitation (OMR). The aim of the present study was to compare the discriminative power of MRI quantification and the recommended Doppler echocardiography (ECHO)–derived integrative approach to identify asymptomatic patients with OMR and adverse outcome.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>The study population consisted of 258 asymptomatic patients (63±14 years, 60% men) with preserved left ventricular ejection fraction (>60%) and chronic moderate and severe OMR (flail 25%, prolapse 75%) defined by using the ECHO-derived integrative approach. All patients underwent MRI to quantify regurgitant volume (RV) of OMR by subtracting the aortic forward flow volume from the total left ventricular stroke volume. Severe OMR was defined as RV≥60 mL.</p></sec><sec><title>Results:</title><p>Mean ECHO-derived RV was on average 17.1 mL larger than the MRI-derived RV (<i>P</i><0.05). Concordant grading of OMR severity with both techniques was observed in 197 (76%) individuals with 62 (31%) patients having severe OMR (MRI SEV-ECHO SEV) and 135 (69%) patients having moderate OMR (MRI MOD-ECHO MOD). The remaining 61 (24%) individuals had discordant findings (MRI SEV-ECHO MOD or MRI MOD-ECHO SEV) between the 2 techniques. The majority of these differences in OMR classification were observed in patients with late systolic or multiple jets (both κ<0.2). Patients with eccentric jets showed moderate agreement (κ=0.53; 95% confidence interval, 0.41–0.64). In contrast, a very good agreement (κ=0.90; 95% confidence interval, 0.82–0.98) was observed in a combination of holosystolic, central, and single jet. During a median follow-up of 5.0 years (interquartile range, 3.5–6.0 years), 38 (15%) patients died and 106 (41%) either died or developed indication for mitral valve surgery. In separate Cox regression analyses, the MRI-derived left ventricular end-systolic volume index, RV, and OMR category (severe versus moderate), and the ECHO-derived OMR category were independent predictors of all-cause mortality (all <i>P</i><0.05). The MRI-derived RV showed the largest area under the curve to predict mortality (0.72) or its combination with the development of indication for mitral valve surgery (0.83).</p></sec><sec><title>Conclusions:</title><p>The findings of the present study suggest that the MRI-derived assessment of OMR can better identify patients with severe OMR and adverse outcome than ECHO-derived integrative approach warranting close follow-up and perhaps, early mitral valve surgery.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/13/1349
10.1161/CIRCULATIONAHA.117.029332
None

2
Circulation
Long-Term Potassium Monitoring and Dynamics in Heart Failure and Risk of Mortality
<sec><title>Background:</title><p>The prognostic value of long-term potassium monitoring and dynamics in heart failure has not been characterized completely. We sought to determine the association between serum potassium values collected at follow-up with all-cause mortality in a prospective and consecutive cohort of patients discharged from a previous acute heart failure admission.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>Serum potassium was measured at every physician-patient encounter, including hospital admissions and ambulatory settings. The multivariable-adjusted association of serum potassium with mortality was assessed by using comprehensive state-of-the-art regression <strong><span style="color:yellowgreen">method</span></strong>s that can accommodate time-dependent exposure modeling.</p></sec><sec><title>Results:</title><p>The study sample included 2164 patients with a total of 16 116 potassium observations. Mean potassium at discharge was 4.3±0.48 mEq/L. Hypokalemia (<3.5 mEq/L), normokalemia (3.5–5.0 mEq/L), and hyperkalemia (>5 mEq/L) were observed at the index admission in 77 (3.6%), 1965 (90.8%), and 122 (5.6%) patients, respectively. At a median follow-up of 2.8 years (range, 0.03–12.8 years), 1090 patients died (50.4%). On a continuous scale, the multivariable-adjusted association of potassium values and mortality revealed a nonlinear association (U-shaped) with higher risk at both ends of its distribution (omnibus <i>P</i>=0.001). Likewise, the adjusted hazard ratios for hypokalemia and hyperkalemia, normokalemia as reference, were 2.35 (95% confidence interval, 1.40–3.93; <i>P</i>=0.001) and 1.55 (95% confidence interval, 1.11–2.16; <i>P</i>=0.011), respectively (omnibus <i>P</i>=0.0003). Furthermore, dynamic changes in potassium were independently associated with substantial differences in mortality risk. Potassium normalization was independently associated with lower mortality risk (<i>P</i>=0.001).</p></sec><sec><title>Conclusions:</title><p>Either modeled continuously or categorically, serum potassium levels during long-term monitoring were independently associated with mortality in patients with heart failure. Likewise, persistence of abnormal potassium levels was linked to a higher risk of death in comparison with patients who maintained or returned to normal values.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/13/1320
10.1161/CIRCULATIONAHA.117.030576
None

2
Circulation
Application of Large-Scale Aptamer-Based Proteomic Profiling to Planned Myocardial Infarctions
<sec><title>Background:</title><p>Emerging proteomic technologies using novel affinity-based reagents allow for efficient multiplexing with high-sample throughput. To identify early biomarkers of myocardial injury, we recently applied an aptamer-based proteomic profiling platform that measures 1129 proteins to samples from patients undergoing septal alcohol ablation for hypertrophic cardiomyopathy, a human model of planned myocardial injury. Here, we examined the scalability of this approach using a markedly expanded platform to study a far broader range of human proteins in the context of myocardial injury.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>We applied a highly multiplexed, expanded proteomic technique that uses single-stranded DNA aptamers to assay 4783 human proteins (4137 distinct human gene targets) to derivation and validation cohorts of planned myocardial injury, individuals with spontaneous myocardial infarction, and at-risk controls.</p></sec><sec><title>Results:</title><p>We found 376 target proteins that significantly changed in the blood after planned myocardial injury in a derivation cohort (n=20; <i>P</i><1.05E-05, 1-way repeated measures analysis of variance, Bonferroni threshold). Two hundred forty-seven of these proteins were validated in an independent planned myocardial injury cohort (n=15; <i>P</i><1.33E-04, 1-way repeated measures analysis of variance); >90% were directionally consistent and reached nominal significance in the validation cohort. Among the validated proteins that were increased within 1 hour after planned myocardial injury, 29 were also elevated in patients with spontaneous myocardial infarction (n=63; <i>P</i><6.17E-04). Many of the novel markers identified in our study are intracellular proteins not previously identified in the peripheral circulation or have functional roles relevant to myocardial injury. For example, the cardiac LIM protein, cysteine- and glycine-rich protein 3, is thought to mediate cardiac mechanotransduction and stress responses, whereas the mitochondrial ATP synthase F<sub>0</sub> subunit component is a vasoactive peptide on its release from cells. Last, we performed aptamer-affinity enrichment coupled with mass spectrometry to technically verify aptamer specificity for a subset of the new biomarkers.</p></sec><sec><title>Conclusions:</title><p>Our results demonstrate the feasibility of large-scale aptamer multiplexing at a level that has not previously been reported and with sample throughput that greatly exceeds other existing proteomic <strong><span style="color:yellowgreen">method</span></strong>s. The expanded aptamer-based proteomic platform provides a unique opportunity for biomarker and pathway discovery after myocardial injury.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/12/1270
10.1161/CIRCULATIONAHA.117.029443
['human']

2
Circulation
Long-Term Outcomes in Patients With Type 2 Myocardial Infarction and Myocardial Injury
<sec><title>Background:</title><p>Type 2 myocardial infarction and myocardial injury are common in clinical <strong><span style="color:yellowgreen">practic</span></strong>e, but long-term consequences are uncertain. We aimed to define long-term outcomes and explore risk stratification in patients with type 2 myocardial infarction and myocardial injury.</p></sec><sec><title>Methods:</title><p>We identified consecutive patients (n=2122) with elevated cardiac troponin I concentrations (≥0.05 µg/L) at a tertiary cardiac center. All diagnoses were adjudicated as per the universal definition of myocardial infarction. The primary outcome was all-cause death. Secondary outcomes included major adverse cardiovascular events (eg, nonfatal myocardial infarction or cardiovascular death) and noncardiovascular death. To explore competing risks, cause-specific hazard ratios were obtained using Cox regression models.</p></sec><sec><title>Results:</title><p>The adjudicated index diagnosis was type 1 or 2 myocardial infarction or myocardial injury in 1171 (55.2%), 429 (20.2%), and 522 (24.6%) patients, respectively. At 5 years, all-cause death rates were higher in those with type 2 myocardial infarction (62.5%) or myocardial injury (72.4%) compared with type 1 myocardial infarction (36.7%). The majority of excess deaths in those with type 2 myocardial infarction or myocardial injury were because of noncardiovascular causes (hazard ratio, 2.32; 95% confidence interval, 1.92–2.81 versus type 1 myocardial infarction). Despite this finding, the observed crude major adverse cardiovascular event rates were similar between groups (30.6% versus 32.6%), with differences apparent after adjustment for covariates (hazard ratio, 0.82; 95% confidence interval, 0.69–0.96). Coronary heart disease was an independent predictor of major adverse cardiovascular events in those with type 2 myocardial infarction or myocardial injury (hazard ratio, 1.71; 95% confidence interval, 1.31–2.24).</p></sec><sec><title>Conclusions:</title><p>Despite an excess in noncardiovascular death, patients with type 2 myocardial infarction or myocardial injury have a similar crude rate of major adverse cardiovascular events as those with type 1 myocardial infarction. Identifying underlying coronary heart disease in this vulnerable population may help target therapies that could modify future risk.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/12/1236
10.1161/CIRCULATIONAHA.117.031806
None

2
Circulation
International External Validation Study of the 2014 European Society of Cardiology Guidelines on Sudden Cardiac Death Prevention in Hypertrophic Cardiomyopathy (EVIDENCE-HCM)
<sec><title>Background:</title><p>Identification of people with hypertrophic cardiomyopathy (HCM) who are at risk of sudden cardiac death (SCD) and require a prophylactic implantable cardioverter defibrillator is challenging. In 2014, the European Society of Cardiology proposed a new risk stratification <strong><span style="color:yellowgreen">method</span></strong> based on a risk prediction model (HCM Risk-SCD) that estimates the 5-year risk of SCD. The aim was to externally validate the 2014 European Society of Cardiology recommendations in a geographically diverse cohort of patients recruited from the United States, Europe, the Middle East, and Asia.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>This was an observational, retrospective, longitudinal cohort study.</p></sec><sec><title>Results:</title><p>The cohort consisted of 3703 patients. Seventy three (2%) patients reached the SCD end point within 5 years of follow-up (5-year incidence, 2.4% [95% confidence interval {CI}, 1.9–3.0]). The validation study revealed a calibration slope of 1.02 (95% CI, 0.93–1.12), C-index of 0.70 (95% CI, 0.68–0.72), and D-statistic of 1.17 (95% CI, 1.05–1.29). In a complete case analysis (n= 2147; 44 SCD end points at 5 years), patients with a predicted 5-year risk of <4% (n=1524; 71%) had an observed 5-year SCD incidence of 1.4% (95% CI, 0.8–2.2); patients with a predicted risk of ≥6% (n=297; 14%) had an observed SCD incidence of 8.9% (95% CI, 5.96–13.1) at 5 years. For every 13 (297/23) implantable cardioverter defibrillator implantations in patients with an estimated 5-year SCD risk ≥6%, 1 patient can potentially be saved from SCD.</p></sec><sec><title>Conclusions:</title><p>This study confirms that the HCM Risk-SCD model provides accurate prognostic information that can be used to target implantable cardioverter defibrillator therapy in patients at the highest risk of SCD.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/10/1015
10.1161/CIRCULATIONAHA.117.030437
None

2
Circulation
Latent Rheumatic Heart Disease
<sec><title>Background:</title><p>Screening echocardiography has emerged as a potentially powerful tool for early diagnosis of rheumatic heart disease (RHD). The utility of screening echocardiography hinges on the rate of RHD progression and the ability of penicillin prophylaxis to improve outcome. We report the longitudinal outcomes of a cohort of children with latent RHD and identify risk factors for unfavorable outcomes.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>This was a prospective natural history study conducted under the Ugandan RHD registry. Children with latent RHD and ≥1 year of follow-up were included. All echocardiograms were re-reviewed by experts (2012 World Heart Federation criteria) for inclusion and evidence of change. Bi- and multivariable logistic regression, Kaplan-Meier analysis, and Cox proportional hazards models, as well, were developed to search for risk factors for unfavorable outcome and compare progression-free survival between those treated and not treated with penicillin. Propensity and other matching <strong><span style="color:yellowgreen">method</span></strong>s with sensitivity analysis were implemented for the evaluation of the penicillin effect.</p></sec><sec><title>Results:</title><p>Blinded review confirmed 227 cases of latent RHD: 164 borderline and 63 definite (42 mild, 21 moderate/severe). Median age at diagnosis was 12 years and median follow-up was 2.3 years (interquartile range, 2.0–2.9). Penicillin prophylaxis was prescribed in 49.3% with overall adherence of 84.7%. Of children with moderate-to-severe definite RHD, 47.6% had echocardiographic progression (including 2 deaths), and 9.5% had echocardiographic regression. Children with mild definite and borderline RHD showed 26% and 9.8% echocardiographic progression and 45.2% and 46.3% echocardiographic improvement, respectively. Of those with mild definite RHD or borderline RHD, more advanced disease category, younger age, and morphological mitral valve features were risk factors for an unfavorable outcome.</p></sec><sec><title>Conclusions:</title><p>Latent RHD is a heterogeneous diagnosis with variable disease outcomes. Children with moderate to severe latent RHD have poor outcomes. Children with both borderline and mild definite RHD are at substantial risk of progression. Although long-term outcome remains unclear, the initial change in latent RHD may be evident during the first 1 to 2 years following diagnosis. Natural history data are inherently limited, and a randomized clinical trial is needed to definitively determine the impact of penicillin prophylaxis on the trajectory of latent RHD.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/23/2233
10.1161/CIRCULATIONAHA.117.029936
None

2
Circulation
Physiology of Angina and Its Alleviation With Nitroglycerin
<sec><title>Background:</title><p>The mechanisms governing exercise-induced angina and its alleviation by the most commonly used antianginal drug, nitroglycerin, are incompletely understood. The purpose of this study was to develop a <strong><span style="color:yellowgreen">method</span></strong> by which the effects of antianginal drugs could be evaluated invasively during physiological exercise to gain further understanding of the clinical impact of angina and nitroglycerin.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>Forty patients (mean age, 65.2±7.6 years) with exertional angina and coronary artery disease underwent cardiac catheterization via radial access and performed incremental exercise using a supine cycle ergometer. As they developed limiting angina, sublingual nitroglycerin was administered to half the patients, and all patients continued to exercise for 2 minutes at the same workload. Throughout exercise, distal coronary pressure and flow velocity and central aortic pressure were recorded with sensor wires.</p></sec><sec><title>Results:</title><p>Patients continued to exercise after nitroglycerin administration with less ST-segment depression (<i>P</i>=0.003) and therefore myocardial ischemia. Significant reductions in afterload (aortic pressure, <i>P</i>=0.030) and myocardial oxygen demand were seen (tension-time index, <i>P</i>=0.024; rate-pressure product, <i>P</i>=0.046), as well as an increase in myocardial oxygen supply (Buckberg index, <i>P</i>=0.017). Exercise reduced peripheral arterial wave reflection (<i>P</i><0.05), which was not further augmented by the administration of nitroglycerin (<i>P</i>=0.648). The observed increases in coronary pressure gradient, stenosis resistance, and flow velocity did not reach statistical significance; however, the diastolic velocity–pressure gradient relation was consistent with a significant increase in relative stenosis severity (k coefficient, <i>P</i><0.0001), in keeping with exercise-induced vasoconstriction of stenosed epicardial segments and dilatation of normal segments, with trends toward reversal with nitroglycerin.</p></sec><sec><title>Conclusions:</title><p>The catheterization laboratory protocol provides a model to study myocardial ischemia and the actions of novel and established antianginal drugs. Administration of nitroglycerin causes changes in the systemic and coronary circulation that combine to reduce myocardial oxygen demand and to increase supply, thereby attenuating exercise-induced ischemia. Designing antianginal therapies that exploit these mechanisms may provide new therapeutic strategies.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/1/24
10.1161/CIRCULATIONAHA.116.025856
None

2
Circulation
Exploring Coronary Circulatory Response to Stenosis and Its Association With Invasive Physiologic Indexes Using Absolute Myocardial Blood Flow and Coronary Pressure
<sec><title>Background:</title><p>Although invasive physiological assessment for coronary stenosis has become a standard <strong><span style="color:yellowgreen">practic</span></strong>e to guide treatment strategy, coronary circulatory response and changes in invasive physiological indexes, according to different anatomic and hemodynamic lesion severity, have not been fully demonstrated in patients with coronary artery disease.</p></sec><sec><title>Methods:</title><p>One hundred fifteen patients with left anterior descending artery stenosis who underwent both <sup>13</sup>N-ammonia positron emission tomography and invasive physiological measurement were analyzed. Myocardial blood flow (MBF) measured with positron emission tomography and invasively measured coronary pressures were used to calculate microvascular resistance and stenosis resistance.</p></sec><sec><title>Results:</title><p>With progressive worsening of angiographic stenosis severity, both resting and hyperemic transstenotic pressure gradient and stenosis resistance increased (<i>P</i><0.001 for all) and hyperemic MBF (<i>P</i><0.001) and resting microvascular resistance (<i>P</i>=0.012) decreased. Resting MBF (<i>P</i>=0.383) and hyperemic microvascular resistance (<i>P</i>=0.431) were not changed and maintained stable. Both fractional flow reserve and instantaneous wave-free ratio decreased as angiographic stenosis severity, stenosis resistance, and transstenotic pressure gradient increased and hyperemic MBF decreased (all <i>P</i><0.001). When the presence of myocardial ischemia was defined by both low hyperemic MBF and low coronary flow reserve, the diagnostic accuracy of fractional flow reserve and instantaneous wave-free ratio did not differ, regardless of cutoff values of hyperemic MBF and coronary flow reserve.</p></sec><sec><title>Conclusions:</title><p>This study demonstrated how the coronary circulation changes in response to increasing coronary stenosis severity using <sup>13</sup>N-ammonium positron emission tomography–derived MBF and invasively measured pressure data. Currently used resting and hyperemic pressure–derived invasive physiological indexes have similar patterns of relationships to the different anatomic and hemodynamic lesion severities.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01366404.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/19/1798
10.1161/CIRCULATIONAHA.117.029911
None

2
Circulation
A Population-Based Study of Abdominal Aortic Aneurysm Treatment in Finland 2000 to 2014
<sec><title>Background:</title><p>In the event of rupture of an abdominal aortic aneurysm (AAA), mortality is very high. AAA prevalence and incidence of ruptures have been reported to be decreasing. The treatment of AAA has also undergone a change in recent decades with a shift toward endovascular aneurysm repair (EVAR). Our aim was to evaluate how these changes have affected the elective and emergency treatment of AAA and their results in Finland.</p></sec><sec><title><strong><span style="color:yellowgreen">method</span></strong>s:</title><p>All patients treated for AAA in Finland, a country with a population of 5.5 million, during 2000 to 2014 were searched from the registry of the Finnish Institute for Health and Welfare. Data on all patients who had died of AAA during the same time period were obtained from Statistics Finland. The data were combined and analyzed.</p></sec><sec><title>Results:</title><p>The annual incidence of ruptured AAA was 16.4 per 100 000 population over 50 years and decreased significantly during the study period. Over half of the 4949 patients who had a ruptured AAA died outside the hospital. Thirty-day mortality after emergency repair was 39.4%. Intact AAA repairs numbered 4956. The absolute number of annual repairs increased during the study period, and the use of EVAR became the dominant <strong><span style="color:yellowgreen">method</span></strong> of elective repair. Thirty-day mortality in elective AAA repair dropped significantly from 6.3% in 2000 to 2004 to 2.7% in 2010 to 2014 mostly because of the increased number of EVAR procedures with lower mortality. Long-term mortality in patients treated with EVAR was higher than in patients treated with open repair. Mortality after elective AAA repair was primarily attributable to cardiovascular causes, but there was a slightly higher proportion of AAA-related late deaths in patients treated with EVAR.</p></sec><sec><title>Conclusions:</title><p>Ruptured AAA incidence for men >65 years has declined by nearly 30% in Finland, likely because of the decrease in AAA prevalence. The treatment results have improved as well for both elective and emergency repair. Increased use of EVAR has resulted in a decrease of mortality after elective AAA repair, but results of open repair have improved as well. However, late mortality from elective EVAR is surprisingly high in comparison with open repair, which may have been exaggerated by patient selection.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1726
10.1161/CIRCULATIONAHA.117.028259
None

