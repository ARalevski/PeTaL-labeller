9
Circulation
Randomized Comparisons of Double-Dose Clopidogrel or Adjunctive Cilostazol Versus Standard Dual Antiplatelet in Patients With High Posttreatment Platelet Reactivity
<sec><title>Background:</title><p>Patients undergoing percutaneous coronary intervention react differently to antiplatelet drugs. Those with low responsiveness to clopidogrel have a higher risk of cardiac ischemic events. The goal of this study is to conduct a head-to-head comparison of the safety and effectiveness of intensified antiplatelet therapies (either double-dose clopidogrel [DOUBLE] or adjunctive cilostazol [TRIPLE]) and conventional strategy (<strong><span style="color:yellowgreen">standard</span></strong>) in patients after percutaneous coronary intervention.</p></sec><sec><title>Methods:</title><p>In this single-center, randomized, controlled trial, we used thromboelastography, a platelet function test, to select 1078 patients undergoing percutaneous coronary intervention at high thrombotic risk and compared the intensified antiplatelet therapies with <strong><span style="color:yellowgreen">standard</span></strong> antiplatelet therapy. The primary outcome was the incidence of major adverse cardiac and cerebrovascular events at 18 months after percutaneous coronary intervention, defined as a composite of all-cause death, myocardial infarction, target vessel revascularization, or stroke. Bleeding Academic Research Consortium defined bleeding complications (types 1, 2, 3, or 5) were the safety end points.</p></sec><sec><title>Results:</title><p>The primary end point occurred in 52 patients (14.4%) in the <strong><span style="color:yellowgreen">standard</span></strong> group, 38 patients (10.6%) in the DOUBLE group, and 30 patients (8.5%) in the TRIPLE group (hazard ratio, 0.720; 95% confidence interval, 0.474–1.094, DOUBLE versus <strong><span style="color:yellowgreen">standard</span></strong>; hazard ratio, 0.550; 95% confidence interval, 0.349–0.866, TRIPLE versus <strong><span style="color:yellowgreen">standard</span></strong>). No significant difference in the rates of major bleeding (Bleeding Academic Research Consortium grade≥3) was found in the DOUBLE group (3.34% versus 1.93% in <strong><span style="color:yellowgreen">standard</span></strong>, <i>P</i>=0.133) and the TRIPLE group (2.53% versus 1.93% in <strong><span style="color:yellowgreen">standard</span></strong>, <i>P</i>=0.240). The rate of Bleeding Academic Research Consortium–defined minor bleeding increased in the DOUBLE group (27.4% versus 20.3% in <strong><span style="color:yellowgreen">standard</span></strong>, <i>P</i>=0.031), but not in the TRIPLE group (23.6% versus 20.3% in <strong><span style="color:yellowgreen">standard</span></strong>, <i>P</i>=0.146).</p></sec><sec><title>Conclusions:</title><p>In patients with low responsiveness to clopidogrel, as measured by thromboelastography, the intensified antiplatelet strategies with adjunctive use of cilostazol significantly improved the clinical outcomes without increasing the risk of major bleeding. Decreased trend of negative outcomes could be observed in patients with double dosage of clopidogrel, but the difference was not significant.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01779401.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/21/2231
10.1161/CIRCULATIONAHA.117.030190
None

6
DNA Research
ChloroMitoSSRDB: Open Source Repository of Perfect and Imperfect Repeats in Organelle Genomes for Evolutionary Genomics
<p>Microsatellites or simple sequence repeats (SSRs) are repetitive stretches of nucleotides (A, T, G, C) that are distributed either as single base pair stretches or as a combination of two- to six-nucleotides units that are non-randomly distributed within coding and in non-coding regions of the genome. ChloroMitoSSRDB is a complete curated web-oriented relational database of perfect and imperfect repeats in organelle genomes. The present version of the database contains perfect and imperfect SSRs of 2161 organelle genomes (1982 mitochondrial and 179 chloroplast genomes). We detected a total of 5838 chloroplast perfect SSRs, 37 297 chloroplast imperfect SSRs, 5898 mitochondrial perfect SSRs and 50 355 mitochondrial imperfect SSRs across these genomes. The repeats have been further hyperlinked to the annotated gene regions (coding or non-coding) and a link to the corresponding gene record in National Center for Biotechnology Information(<ext-link>www.ncbi.nlm.nih.gov/</ext-link>) to identify and understand the positional relationship of the repetitive tracts. ChloroMitoSSRDB is connected to a user-friendly web interface that provides useful information associated with the location of the repeats (coding and non-coding), size of repeat, motif and length polymorphism, etc. ChloroMitoSSRDB will serve as a repository for developing functional markers for molecular phylogenetics, estimating molecular variation across species. Database URL: ChloroMitoSSRDB can be accessed as an open source repository at <ext-link>www.mcr.org.in/chloromitossrdb</ext-link>.</p>
http://dnaresearch.oxfordjournals.org/cgi/content/abstract/20/2/127
10.1093/dnares/dss038
None

5
Science
Stop codon reassignments in the wild
<p>The canonical genetic <strong><span style="color:yellowgreen">code</span></strong> is assumed to be deeply conserved across all domains of life with very few exceptions. By scanning 5.6 trillion base pairs of metagenomic data for stop codon reassignment events, we detected recoding in a substantial fraction of the >1700 environmental samples examined. We observed extensive <i>opal</i> and <i>amber</i> stop codon reassignments in bacteriophages and of <i>opal</i> in bacteria. Our data indicate that bacteriophages can infect hosts with a different genetic <strong><span style="color:yellowgreen">code</span></strong> and demonstrate phage-host antagonism based on <strong><span style="color:yellowgreen">code</span></strong> differences. The abundance and diversity of genetic <strong><span style="color:yellowgreen">code</span></strong>s present in environmental organisms should be considered in the design of engineered organisms with altered genetic <strong><span style="color:yellowgreen">code</span></strong>s in order to preclude the exchange of genetic information with naturally occurring species.</p>
http://sciencemag.org/cgi/content/abstract/344/6186/909
10.1126/science.1250691
None

5
The Bone & Joint Journal
Intra-operative digital imaging
<sec><title>Aims</title><p>The aims of this study were to examine the rate at which the   positioning of the acetabular component, leg length discrepancy   and femoral offset are outside an acceptable range in total hip   arthroplasties (THAs) which either do or do not involve the use   of intra-operative <strong><span style="color:yellowgreen">digit</span></strong>al imaging.</p></sec><sec><title>Patients and Methods</title><p>A retrospective case-control study was undertaken with 50 patients   before and 50 patients after the integration of an intra-operative   <strong><span style="color:yellowgreen">digit</span></strong>al imaging system in THA. The demographics of the two groups   were comparable for body mass index, age, laterality and the indication   for surgery. The <strong><span style="color:yellowgreen">digit</span></strong>al imaging group had more men than the group without.   Surgical data and radiographic parameters, including the inclination   and anteversion of the acetabular component, leg length discrepancy,   and the difference in femoral offset compared with the contralateral   hip were collected and compared, as well as the incidence of altering   the position of a component based on the intra-operative image.</p></sec><sec><title>Results</title><p><strong><span style="color:yellowgreen">digit</span></strong>al imaging took a mean of five minutes (2.3 to 14.6) to   perform. Intra-operative changes with the use of <strong><span style="color:yellowgreen">digit</span></strong>al imaging   were made for 43 patients (86%), most commonly to adjust leg length   and femoral offset. There was a decrease in the incidence of outliers   when using intra-operative imaging compared with not using it in   regard to leg length discrepancy (20% <i>versus</i> 52%,   p = 0.001) and femoral offset inequality (18% <i>versus</i> 44%,   p = 0.004). There was also a difference in the incidence of outliers   in acetabular inclination (0% <i>versus</i> 7%, p = 0.023)   and version (0% <i>versus</i> 4%, p = 0.114) compared   with historical results of a high-volume surgeon at the same centre.</p></sec><sec><title>Conclusion</title><p>The use of intra-operative <strong><span style="color:yellowgreen">digit</span></strong>al imaging in THA improves the   accuracy of the positioning of the components at THA without adding   a substantial amount of time to the operation.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100B(1   Supple A):36–43.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1_Supple_A/36
10.1302/0301-620X.100B1.BJJ-2017-0596.R1
None

5
Circulation
Modeling Major Adverse Outcomes of Pediatric and Adult Patients With Congenital Heart Disease Undergoing Cardiac Catheterization
<sec><title>Background:</title><p>Risk <strong><span style="color:yellowgreen">standard</span></strong>ization for adverse events after congenital cardiac catheterization is needed to equitably compare patient outcomes among different hospitals as a foundation for quality improvement. The goal of this project was to develop a risk-<strong><span style="color:yellowgreen">standard</span></strong>ization methodology to adjust for patient characteristics when comparing major adverse outcomes in the NCDR’s (National Cardiovascular Data Registry) IMPACT Registry (Improving Pediatric and Adult Congenital Treatment).</p></sec><sec><title>Methods:</title><p>Between January 2011 and March 2014, 39 725 consecutive patients within IMPACT undergoing cardiac catheterization were identified. Given the heterogeneity of interventional procedures for congenital heart disease, new procedure-type risk categories were derived with empirical data and expert opinion, as were markers of hemodynamic vulnerability. A multivariable hierarchical logistic regression model to identify patient and procedural characteristics predictive of a major adverse event or death after cardiac catheterization was derived in 70% of the cohort and validated in the remaining 30%.</p></sec><sec><title>Results:</title><p>The rate of major adverse event or death was 7.1% and 7.2% in the derivation and validation cohorts, respectively. Six procedure-type risk categories and 6 independent indicators of hemodynamic vulnerability were identified. The final risk adjustment model included procedure-type risk category, number of hemodynamic vulnerability indicators, renal insufficiency, single-ventricle physiology, and coagulation disorder. The model had good discrimination, with a C-statistic of 0.76 and 0.75 in the derivation and validation cohorts, respectively. Model calibration in the validation cohort was excellent, with a slope of 0.97 (<strong><span style="color:yellowgreen">standard</span></strong> error, 0.04; <i>P</i> value [for difference from 1] =0.53) and an intercept of 0.007 (<strong><span style="color:yellowgreen">standard</span></strong> error, 0.12; <i>P</i> value [for difference from 0] =0.95).</p></sec><sec><title>Conclusions:</title><p>The creation of a validated risk-<strong><span style="color:yellowgreen">standard</span></strong>ization model for adverse outcomes after congenital cardiac catheterization can support reporting of risk-adjusted outcomes in the IMPACT Registry as a foundation for quality improvement.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/21/2009
10.1161/CIRCULATIONAHA.117.027714
None

5
Circulation
Validity of Cardiovascular Data From Electronic Sources
<sec><title>Background:</title><p>Understanding the validity of data from electronic data research networks is critical to national research initiatives and learning healthcare systems for cardiovascular care. Our goal was to evaluate the degree of agreement of electronic data research networks in comparison with data collected by <strong><span style="color:yellowgreen">standard</span></strong>ized research approaches in a cohort study.</p></sec><sec><title>Methods:</title><p>We linked individual-level data from MESA (Multi-Ethnic Study of Atherosclerosis), a community-based cohort, with HealthLNK, a 2006 to 2012 database of electronic health records from 6 Chicago health systems. To evaluate the correlation and agreement of blood pressure in HealthLNK in comparison with in-person MESA examinations, and body mass index in HealthLNK in comparison with MESA, we used Pearson correlation coefficients and Bland-Altman plots. Using diagnoses in MESA as the criterion <strong><span style="color:yellowgreen">standard</span></strong>, we calculated the performance of HealthLNK for hypertension, obesity, and diabetes mellitus diagnosis by using <i>International Classification of Diseases, Ninth Revision</i> <strong><span style="color:yellowgreen">code</span></strong>s and clinical data. We also identified potential myocardial infarctions, strokes, and heart failure events in HealthLNK and compared them with adjudicated events in MESA.</p></sec><sec><title>Results:</title><p>Of the 1164 MESA participants enrolled at the Chicago Field Center, 802 (68.9%) participants had data in HealthLNK. The correlation was low for systolic blood pressure (0.39; <i>P</i><0.0001). In comparison with MESA, HealthLNK overestimated systolic blood pressure by 6.5 mm Hg (95% confidence interval, 4.2–7.8). There was a high correlation between body mass index in MESA and HealthLNK (0.94; <i>P</i><0.0001). HealthLNK underestimated body mass index by 0.3 kg/m<sup>2</sup> (95% confidence interval, –0.4 to –0.1). With the use of <i>International Classification of Diseases, Ninth Revision</i> <strong><span style="color:yellowgreen">code</span></strong>s and clinical data, the sensitivity and specificity of HealthLNK queries for hypertension were 82.4% and 59.4%, for obesity were 73.0% and 89.8%, and for diabetes mellitus were 79.8% and 93.3%. In comparison with adjudicated cardiovascular events in MESA, the concordance rates for myocardial infarction, stroke, and heart failure were, respectively, 41.7% (5/12), 61.5% (8/13), and 62.5% (10/16).</p></sec><sec><title>Conclusions:</title><p>These findings illustrate the limitations and strengths of electronic data repositories in comparison with information collected by traditional <strong><span style="color:yellowgreen">standard</span></strong>ized epidemiological approaches for the ascertainment of cardiovascular risk factors and events.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/13/1207
10.1161/CIRCULATIONAHA.117.027436
None

5
Circulation
Adherence to Antihypertensive Treatment and the Blood Pressure–Lowering Effects of Renal Denervation in the Renal Denervation for Hypertension (DENERHTN) Trial
<sec><title>Background:</title><p>The DENERHTN trial (Renal Denervation for Hypertension) confirmed the blood pressure–lowering efficacy of renal denervation added to a <strong><span style="color:yellowgreen">standard</span></strong>ized stepped-care antihypertensive treatment for resistant hypertension at 6 months. We report the influence of adherence to antihypertensive treatment on blood pressure control.</p></sec><sec><title>Methods:</title><p>One hundred six patients with hypertension resistant to 4 weeks of treatment with indapamide 1.5 mg/d, ramipril 10 mg/d (or irbesartan 300 mg/d), and amlodipine 10 mg/d were randomly assigned to renal denervation plus <strong><span style="color:yellowgreen">standard</span></strong>ized stepped-care antihypertensive treatment, or the same antihypertensive treatment alone. For <strong><span style="color:yellowgreen">standard</span></strong>ized stepped-care antihypertensive treatment, spironolactone 25 mg/d, bisoprolol 10 mg/d, prazosin 5 mg/d, and rilmenidine 1 mg/d were sequentially added at monthly visits if home blood pressure was ≥135/85 mm Hg after randomization. We assessed adherence to antihypertensive treatment at 6 months by drug screening in urine/plasma samples from 85 patients.</p></sec><sec><title>Results:</title><p>The numbers of fully adherent (20/40 versus 21/45), partially nonadherent (13/40 versus 20/45), or completely nonadherent patients (7/40 versus 4/45) to antihypertensive treatment were not different in the renal denervation and the control groups, respectively (<i>P</i>=0.3605). The difference in the change in daytime ambulatory systolic blood pressure from baseline to 6 months between the 2 groups was –6.7 mm Hg (<i>P</i>=0.0461) in fully adherent and –7.8 mm Hg (<i>P</i>=0.0996) in nonadherent (partially nonadherent plus completely nonadherent) patients. The between-patient variability of daytime ambulatory systolic blood pressure was greater for nonadherent than for fully adherent patients.</p></sec><sec><title>Conclusions:</title><p>In the DENERHTN trial, the prevalence of nonadherence to antihypertensive drugs at 6 months was high (≈50%) but not different in the renal denervation and control groups. Regardless of adherence to treatment, renal denervation plus <strong><span style="color:yellowgreen">standard</span></strong>ized stepped-care antihypertensive treatment resulted in a greater decrease in blood pressure than <strong><span style="color:yellowgreen">standard</span></strong>ized stepped-care antihypertensive treatment alone.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01570777.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/12/847
10.1161/CIRCULATIONAHA.116.022922
None

4
Science
Quantifying the contribution of recessive coding variation to developmental disorders
<p>We estimated the genome-wide contribution of recessive coding variation in 6040 families from the Deciphering Developmental Disorders study. The proportion of cases attributable to recessive coding variants was 3.6% in patients of European ancestry, compared with 50% explained by de novo coding mutations. It was higher (31%) in patients with Pakistani ancestry, owing to elevated autozygosity. Half of this recessive burden is attributable to known genes. We identified two genes not previously associated with recessive developmental disorders, <i>KDM5B</i> and <i>EIF3F</i>, and functionally validated them with mouse and cellular models. Our results suggest that recessive coding variants account for a small fraction of currently undiagnosed nonconsanguineous individuals, and that the role of noncoding variants, incomplete penetrance, and polygenic mechanisms need further exploration.</p>
http://sciencemag.org/cgi/content/abstract/362/6419/1161
10.1126/science.aar6731
None

4
The Bone & Joint Journal
Minimising aseptic loosening in extreme bone resections
<sec><title>Aims</title><p>Following the resection of an extensive amount of bone in the   treatment of a tumour, the residual segment may be insufficient   to accept a <strong><span style="color:yellowgreen">standard</span></strong> length intramedullary cemented stem. Short-stemmed   endoprostheses conceivably have an increased risk of aseptic loosening.   Extra-cortical plates have been added to minimise this risk by supplementing   fixation. The aim of this study was to investigate the survivorship   of short-stemmed endoprostheses and extra-cortical plates.</p></sec><sec><title>Patients and Methods</title><p>The study involved 37 patients who underwent limb salvage surgery   for a primary neoplasm of bone between 1998 and 2013. Endoprosthetic   replacement involved the proximal humerus in nine, the proximal   femur in nine, the distal femur in 13 and the proximal tibia in   six patients. There were 12 primary (32%) and 25 revision procedures (68%).   Implant survivorship was compared with matched controls. The amount   of bone that was resected was > 70% of its length and statistically   greater than the <strong><span style="color:yellowgreen">standard</span></strong> control group at each anatomical site.</p></sec><sec><title>Results</title><p>The mean follow-up was seven years (one to 17). The mean length   of the stem was 33 mm (20 to 60) in the humerus and 79 mm (34 to   100) in the lower limb. Kaplan-Meier analysis of survival of the   implant according to anatomical site confirmed that there was no   statistically significant difference between the short-stemmed endoprostheses and   the <strong><span style="color:yellowgreen">standard</span></strong> stemmed controls at the proximal humeral (p = 0.84),   proximal femoral (p = 0.57), distal femoral (p = 0.21) and proximal   tibial (p = 0.61) sites.</p><p>In the short-stemmed group, no implants with extra-cortical plate   osseointegration suffered loosening at a mean of 8.5 years (range   2 to 16 years). Three of ten (30%) without osseointegration suffered   aseptic loosening at a mean of 7.7 years (range 2 to 11.5 years).</p></sec><sec><title>Conclusion</title><p>When extensive resections of bone are required in the surgical   management of tumours, and in revision cases, the addition of extra-cortical   plates to short medullary stems has shown non-inferiority to <strong><span style="color:yellowgreen">standard</span></strong>   length medullary stems and minimises aseptic failure.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1689–95.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/12/1689
10.1302/0301-620X.99B12.BJJ-2017-0213.R1
None

4
The Bone & Joint Journal
Restoration of the centre of rotation in primary total hip arthroplasty
<sec><title>Aims</title><p>One goal of total hip arthroplasty is to restore normal hip anatomy.   The aim of this study was to compare displacement of the centre   of rotation (COR) using a <strong><span style="color:yellowgreen">standard</span></strong> reaming technique with a technique   in which the acetabulum was reamed immediately peripherally and   referenced off the rim.</p></sec><sec><title>Patients and Methods</title><p>In the first cohort the acetabulum was reamed to the floor followed   by sequentially larger reamers. In the second cohort the acetabulum   was only reamed peripherally, starting with a reamer the same size   as the native femoral head. Anteroposterior pelvic radiographs were   analysed for acetabular floor depth and vertical and horizontal position   of the COR.</p></sec><sec><title>Results</title><p>Horizontally, the mean medial displacement of the COR was 0.8   mm (<strong><span style="color:yellowgreen">standard</span></strong> deviation (<sc>sd</sc>) 1.4) in the peripheral remaing   group and 5.0 mm (<sc>sd</sc> 3.30) in the <strong><span style="color:yellowgreen">standard</span></strong> reaming group   (p < 0.001). Vertically, the mean superior displacement of the   COR was 0.7 mm (<sc>sd</sc> 1.3) in the peripheral reaming group   and 3.7 mm (<sc>sd</sc> 2.6) in the <strong><span style="color:yellowgreen">standard</span></strong> reaming group (p < 0.001).   In the <strong><span style="color:yellowgreen">standard</span></strong> reaming group, there was a strong correlation between   the pre-operative acetabular floor depth and displacement of the   COR (p < 0.001).</p></sec><sec><title>Conclusion</title><p>Reaming the acetabulum to the floor can lead to significant displacement   of the COR medially and superiorly. This displacement is related   to the pre-operative acetabular floor depth and cannot always be   compensated by using a high offset stem.</p><p>Cite this article: <i>Bone Joint J</i> 2016;98-B:1597–603.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/98-B/12/1597
10.1302/0301-620X.98B12.BJJ-2016-0345.R1
None

4
Disease Models & Mechanisms
Histopathology reveals correlative and unique phenotypes in a high-throughput mouse phenotyping screen
<p>The Mouse Genetics Project (MGP) at the Wellcome Trust Sanger Institute aims to generate and phenotype over 800 genetically modified mouse lines over the next 5 years to gain a better understanding of mammalian gene function and provide an invaluable resource to the scientific community for follow-up studies. Phenotyping includes the generation of a <strong><span style="color:yellowgreen">standard</span></strong>ized biobank of paraffin-embedded tissues for each mouse line, but histopathology is not routinely performed. In collaboration with the Pathology Core of the Centre for Modeling Human Disease (CMHD) we report the utility of histopathology in a high-throughput primary phenotyping screen. Histopathology was assessed in an unbiased selection of 50 mouse lines with (<i>n</i>=30) or without (<i>n</i>=20) clinical phenotypes detected by the <strong><span style="color:yellowgreen">standard</span></strong> MGP primary phenotyping screen. Our findings revealed that histopathology added correlating morphological data in 19 of 30 lines (63.3%) in which the primary screen detected a phenotype. In addition, seven of the 50 lines (14%) presented significant histopathology findings that were not associated with or predicted by the <strong><span style="color:yellowgreen">standard</span></strong> primary screen. Three of these seven lines had no clinical phenotype detected by the <strong><span style="color:yellowgreen">standard</span></strong> primary screen. Incidental and strain-associated background lesions were present in all mutant lines with good concordance to wild-type controls. These findings demonstrate the complementary and unique contribution of histopathology to high-throughput primary phenotyping of mutant mice.</p>
http://dmm.biologists.org/cgi/content/abstract/7/5/515
10.1242/dmm.015263
None

4
Circulation
Prevalence and Predictors of Cholesterol Screening, Awareness, and Statin Treatment Among US Adults With Familial Hypercholesterolemia or Other Forms of Severe Dyslipidemia (1999–2014)
<sec><title>Background:</title><p>Familial hypercholesterolemia (FH) and other extreme elevations in low-density lipoprotein cholesterol significantly increase the risk of atherosclerotic cardiovascular disease; however, recent data suggest that prescription rates for statins remain low in these patients. National rates of screening, awareness, and treatment with statins among individuals with FH or severe dyslipidemia are unknown.</p></sec><sec><title>Methods:</title><p>Data from the 1999 to 2014 National Health and Nutrition Examination Survey were used to estimate prevalence rates of self-reported screening, awareness, and statin therapy among US adults (n=42 471 weighted to represent 212 million US adults) with FH (defined using the Dutch Lipid Clinic criteria) and with severe dyslipidemia (defined as low-density lipoprotein cholesterol levels ≥190 mg/dL). Logistic regression was used to identify sociodemographic and clinical correlates of hypercholesterolemia awareness and statin therapy.</p></sec><sec><title>Results:</title><p>The estimated US prevalence of definite/probable FH was 0.47% (<strong><span style="color:yellowgreen">standard</span></strong> error, 0.03%) and of severe dyslipidemia was 6.6% (<strong><span style="color:yellowgreen">standard</span></strong> error, 0.2%). The frequency of cholesterol screening and awareness was high (>80%) among adults with definite/probable FH or severe dyslipidemia; however, statin use was uniformly low (52.3% [<strong><span style="color:yellowgreen">standard</span></strong> error, 8.2%] of adults with definite/probable FH and 37.6% [<strong><span style="color:yellowgreen">standard</span></strong> error, 1.2%] of adults with severe dyslipidemia). Only 30.3% of patients with definite/probable FH on statins were taking a high-intensity statin. The prevalence of statin use in adults with severe dyslipidemia increased over time (from 29.4% to 47.7%) but not faster than trends in the general population (from 5.7% to 17.6%). Older age, health insurance status, having a usual source of care, diabetes mellitus, hypertension, and having a personal history of early atherosclerotic cardiovascular disease were associated with higher statin use.</p></sec><sec><title>Conclusions:</title><p>Despite the high prevalence of cholesterol screening and awareness, only ≈50% of adults with FH are on statin therapy, with even fewer prescribed a high-intensity statin; young and uninsured patients are at the highest risk for lack of screening and for undertreatment. This study highlights an imperative to improve the frequency of cholesterol screening and statin prescription rates to better identify and treat this high-risk population. Additional studies are needed to better understand how to close these gaps in screening and treatment.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/21/2218
10.1161/CIRCULATIONAHA.117.032321
None

4
Circulation
Effect of Ferric Carboxymaltose on Exercise Capacity in Patients With Chronic Heart Failure and Iron Deficiency
<sec><title>Background:</title><p>Iron deficiency is common in patients with heart failure (HF) and is associated with reduced exercise capacity and poor outcomes. Whether correction of iron deficiency with (intravenous) ferric carboxymaltose (FCM) affects peak oxygen consumption [peak V<sc>O</sc><sub>2</sub>], an objective measure of exercise intolerance in HF, has not been examined.</p></sec><sec><title>Methods:</title><p>We studied patients with systolic HF (left ventricular ejection fraction ≤45%) and mild to moderate symptoms despite optimal HF medication. Patients were randomized 1:1 to treatment with FCM for 24 weeks or <strong><span style="color:yellowgreen">standard</span></strong> of care. The primary end point was the change in peak V<sc>O</sc><sub>2</sub> from baseline to 24 weeks. Secondary end points included the effect on hematinic and cardiac biomarkers, quality of life, and safety. For the primary analysis, patients who died had a value of 0 imputed for 24-week peak V<sc>O</sc><sub>2</sub>. Additional sensitivity analyses were performed to determine the impact of imputation of missing peak V<sc>O</sc><sub>2</sub> data.</p></sec><sec><title>Results:</title><p>A total of 172 patients with HF were studied and received FCM (n=86) or <strong><span style="color:yellowgreen">standard</span></strong> of care (control group, n=86). At baseline, the groups were well matched; mean age was 64 years, 75% were male, mean left ventricular ejection fraction was 32%, and peak V<sc>O</sc><sub>2</sub> was 13.5 mL/min/kg. FCM significantly increased serum ferritin and transferrin saturation. At 24 weeks, peak V<sc>O</sc><sub>2</sub> had decreased in the control group (least square means −1.19±0.389 mL/min/kg) but was maintained on FCM (−0.16±0.387 mL/min/kg; <i>P</i>=0.020 between groups). In a sensitivity analysis, in which missing data were not imputed, peak V<sc>O</sc><sub>2</sub> at 24 weeks decreased by −0.63±0.375 mL/min/kg in the control group and by −0.16±0.373 mL/min/kg in the FCM group; <i>P</i>=0.23 between groups). Patients’ global assessment and functional class as assessed by the New York Heart Association improved on FCM versus <strong><span style="color:yellowgreen">standard</span></strong> of care.</p></sec><sec><title>Conclusions:</title><p>Treatment with intravenous FCM in patients with HF and iron deficiency improves iron stores. Although a favorable effect on peak V<sc>O</sc><sub>2</sub> was observed on FCM, compared with <strong><span style="color:yellowgreen">standard</span></strong> of care in the primary analysis, this effect was highly sensitive to the imputation strategy for peak V<sc>O</sc><sub>2</sub> among patients who died. Whether FCM is associated with an improved outcome in these high-risk patients needs further study.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01394562.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/15/1374
10.1161/CIRCULATIONAHA.117.027497
None

4
Circulation
Hospital Variation in Time to Epinephrine for Nonshockable In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>For patients with in-hospital cardiac arrests attributable to nonshockable rhythms, delays in epinephrine administration beyond 5 minutes is associated with worse survival. However, the extent of hospital variation in delayed epinephrine administration and its effect on hospital-level outcomes is unknown.</p></sec><sec><title>Methods:</title><p>Within Get With The Guidelines-Resuscitation, we identified 103 932 adult patients (≥18 years) at 548 hospitals with an in-hospital cardiac arrest attributable to a nonshockable rhythm who received at least 1 dose of epinephrine between 2000 and 2014. We constructed 2-level hierarchical regression models to quantify hospital variation in rates of delayed epinephrine administration (>5 minutes) and its association with hospital rates of survival to discharge and survival with functional recovery.</p></sec><sec><title>Results:</title><p>Overall, 13 213 (12.7%) patients had delays to epinephrine, and this rate varied markedly across hospitals (range, 0%–53.8%). The odds of delay in epinephrine administration were 58% higher at 1 randomly selected hospital in comparison with a similar patient at another randomly selected hospital (median odds ratio, 1.58; 95% confidence interval, 1.51–1.64). The median risk-<strong><span style="color:yellowgreen">standard</span></strong>ized survival rate was 12.0% (range, 5.4%–31.9%), and the risk-<strong><span style="color:yellowgreen">standard</span></strong>ized survival with functional recovery was 7.4% (range, 0.9%–30.8%). There was an inverse correlation between a hospital’s rate of delayed epinephrine administration and its risk-<strong><span style="color:yellowgreen">standard</span></strong>ized rate of survival to discharge (ρ=–0.22, <i>P</i><0.0001) and survival with functional recovery (ρ=–0.14, <i>P</i>=0.001). In comparison with a median survival rate of 12.9% (interquartile range, 11.1%–15.4%) at hospitals in the lowest quartile of epinephrine delay, risk-<strong><span style="color:yellowgreen">standard</span></strong>ized survival was 16% lower at hospitals in the quartile with the highest rate of epinephrine delays (10.8%; interquartile range, 9.7%–12.7%).</p></sec><sec><title>Conclusions:</title><p>Delays in epinephrine administration following in-hospital cardiac arrest are common and variy across hospitals. Hospitals with high rates of delayed epinephrine administration had lower rates of overall survival for in-hospital cardiac arrest attributable to nonshockable rhythm. Further studies are needed to determine whether improving hospital performance on time to epinephrine administration, especially at hospitals with poor performance on this metric, will lead to improved outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2105
10.1161/CIRCULATIONAHA.116.025459
None

3
Science
From oncogenic mutation to dynamic code
<p>Signal transduction pathways (STPs) convert biochemical reactions into precise and reproducible biological outcomes. These functions are performed reliably and reproducibly against a background of noise (variation) arising from the stochastic nature of biochemical reactions (<i>1</i>). Indeed, information theory analysis of STPs indicates that they have a limited capacity to discriminate information, including different ligands or different activation states of components (<i>2</i>). However, this discrimination is dramatically enhanced by adding dynamic information, such as signal rise time, signal duration, amplitude, and decay rate (<i>3</i>). The observation that differential activation dynamics of the extracellular signal-regulated kinase (ERK) pathway can determine whether rat pheochromocytoma cells proliferate or differentiate was reported more than 20 years ago (<i>4</i>), and evidence has since accumulated that STP dynamics control cell fate decisions. However, we are still struggling to understand how signaling dynamics is en<strong><span style="color:yellowgreen">code</span></strong>d and de<strong><span style="color:yellowgreen">code</span></strong>d and how pathological changes, such as the expression of mutant proteins, affect the dynamic STP <strong><span style="color:yellowgreen">code</span></strong>. On page 892 of this issue, Bugaj <i>et al.</i> (<i>5</i>) make use of new tools with which to decipher this <strong><span style="color:yellowgreen">code</span></strong> and reveal how certain cancer-associated BRAF mutations can corrupt the dynamic STP <strong><span style="color:yellowgreen">code</span></strong> and trick cells into unlicensed proliferation.</p>
http://sciencemag.org/cgi/content/summary/361/6405/844
10.1126/science.aau8059
None

3
Science
Dynamics of cortical dendritic membrane potential and spikes in freely behaving rats
<p>Neural activity in vivo is primarily measured using extracellular somatic spikes, which provide limited information about neural computation. Hence, it is necessary to record from neuronal dendrites, which can generate dendritic action potentials (DAPs) in vitro, which can profoundly influence neural computation and plasticity. We measured neocortical sub- and suprathreshold dendritic membrane potential (DMP) from putative distal-most dendrites using tetrodes in freely behaving rats over multiple days with a high degree of stability and submillisecond temporal resolution. DAP firing rates were several-fold larger than somatic rates. DAP rates were also modulated by subthreshold DMP fluctuations, which were far larger than DAP amplitude, indicating hybrid, analog-<strong><span style="color:yellowgreen">digit</span></strong>al coding in the dendrites. Parietal DAP and DMP exhibited egocentric spatial maps comparable to pyramidal neurons. These results have important implications for neural coding and plasticity.</p>
http://sciencemag.org/cgi/content/abstract/355/6331/eaaj1497
10.1126/science.aaj1497
None

3
PLANT PHYSIOLOGY
CyanoGate: A Modular Cloning Suite for Engineering Cyanobacteria Based on the Plant MoClo Syntax
<p>Recent advances in synthetic biology research have been underpinned by an exponential increase in available genomic information and a proliferation of advanced DNA assembly tools. The adoption of plasmid vector assembly <strong><span style="color:yellowgreen">standard</span></strong>s and parts libraries has greatly enhanced the reproducibility of research and the exchange of parts between different labs and biological systems. However, a <strong><span style="color:yellowgreen">standard</span></strong>ized modular cloning (MoClo) system is not yet available for cyanobacteria, which lag behind other prokaryotes in synthetic biology despite their huge potential regarding biotechnological applications. By building on the assembly library and syntax of the Plant Golden Gate MoClo kit, we have developed a versatile system called CyanoGate that unites cyanobacteria with plant and algal systems. Here, we describe the generation of a suite of parts and acceptor vectors for making (1) marked/unmarked knock-outs or integrations using an integrative acceptor vector, and (2) transient multigene expression and repression systems using known and previously undescribed replicative vectors. We tested and compared the CyanoGate system in the established model cyanobacterium <i>Synechocystis</i> sp. PCC 6803 and the more recently described fast-growing strain <i>Synechococcus elongatus</i> UTEX 2973. The UTEX 2973 fast-growth phenotype was only evident under specific growth conditions; however, UTEX 2973 accumulated high levels of proteins with strong native or synthetic promoters. The system is publicly available and can be readily expanded to accommodate other <strong><span style="color:yellowgreen">standard</span></strong>ized MoClo parts to accelerate the development of reliable synthetic biology tools for the cyanobacterial community.</p>
http://plantphysiol.org/cgi/content/abstract/180/1/39
10.1104/pp.18.01401
['Cyanobacteria', 'Synechococcus', 'Synechococcus elongatus', 'Synechocystis']

3
Journal of Experimental Biology
Non-linear amplification of graded voltage signals in the first-order visual interneurons of the butterfly <i>Papilio xuthus</i>
<p><bold>Summary:</bold> LMCs in the visual system of <i>Papilio xuthus</i> use two information-coding strategies: a graded coding and a mixed coding involving action-potential like spikes. Use of spikes depends on light level.</p>
http://jeb.biologists.org/cgi/content/abstract/221/12/jeb179085
10.1242/jeb.179085
['Papilio', 'Papilio xuthus', 'butterfly']

3
Circulation
Risk Factors of Sudden Cardiac Death in the Young
<sec><title>Background:</title><p>Prevention of sudden cardiac arrest (SCA) in the young remains a largely unsolved public health problem, and sports activity is an established trigger. Although the presence of <strong><span style="color:yellowgreen">standard</span></strong> cardiovascular risk factors in the young can link to future morbidity and mortality in adulthood, the potential contribution of these risk factors to SCA in the young has not been evaluated.</p></sec><sec><title>Methods:</title><p>We prospectively ascertained subjects who experienced SCA between the ages of 5 and 34 years in the Portland, Oregon, metropolitan area (2002–2015, catchment population ≈1 million). We assessed the circumstances, resuscitation outcomes, and clinical profile of subjects who had SCA by a detailed evaluation of emergency response records, lifetime clinical records, and autopsy examinations. We specifically evaluated the association of <strong><span style="color:yellowgreen">standard</span></strong> cardiovascular risk factors and SCA, and sports as a trigger for SCA in the young.</p></sec><sec><title>Results:</title><p>Of 3775 SCAs in all age groups, 186 (5%) occurred in the young (mean age 25.9±6.8, 67% male). In SCA in the young, overall prevalence of warning signs before SCA was low (29%), and 26 (14%) were associated with sports as a trigger. The remainder (n=160) occurred in other settings categorized as nonsports. Sports-related SCAs accounted for 39% of SCAs in patients aged ≤18, 13% of SCAs in patients aged 19 to 25, and 7% of SCAs in patients aged 25 to 34. Sports-related SCA cases were more likely to present with shockable rhythms, and survival from cardiac arrest was 2.5-fold higher in sports-related versus nonsports SCA (28% versus 11%; <i>P</i>=0.05). Overall, the most common SCA-related conditions were sudden arrhythmic death syndrome (31%), coronary artery disease (22%), and hypertrophic cardiomyopathy (14%). There was an unexpectedly high overall prevalence of established cardiovascular risk factors (obesity, diabetes mellitus, hypertension, hyperlipidemia, smoking) with ≥1 risk factors in 58% of SCA cases.</p></sec><sec><title>Conclusions:</title><p>Sports was a trigger of SCA in a minority of cases, and, in most patients, SCA occurred without warning symptoms. <strong><span style="color:yellowgreen">standard</span></strong> cardiovascular risk factors were found in over half of patients, suggesting the potential role of public health approaches that screen for cardiovascular risk factors at earlier ages.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/15/1561
10.1161/CIRCULATIONAHA.117.031262
None

3
Circulation
Effect of Intensive Blood Pressure Lowering on Left Ventricular Hypertrophy in Patients With Hypertension
<sec><title>Background:</title><p>It is currently unknown whether intensive blood pressure (BP) lowering beyond that recommended would lead to more lowering of the risk of left ventricular hypertrophy (LVH) in patients with hypertension and whether reducing the risk of LVH explains the reported cardiovascular disease (CVD) benefits of intensive BP lowering in this population.</p></sec><sec><title>Methods:</title><p>This analysis included 8164 participants (mean age, 67.9 years; 35.3% women; 31.2% blacks) with hypertension but no diabetes mellitus from the SPRINT trial (Systolic Blood Pressure Intervention Trial): 4086 randomly assigned to intensive BP lowering (target SBP <120 mm Hg) and 4078 assigned to <strong><span style="color:yellowgreen">standard</span></strong> BP lowering (target SBP <140 mm Hg). Progression and regression of LVH as defined by Cornell voltage criteria derived from <strong><span style="color:yellowgreen">standard</span></strong> 12-lead ECGs recorded at baseline and biannually were compared between treatment arms during a median follow-up of 3.81 years. The effect of intensive (versus <strong><span style="color:yellowgreen">standard</span></strong>) BP lowering on the SPRINT primary CVD outcome (a composite of myocardial infarction, acute coronary syndrome, stroke, heart failure, and CVD death) was compared before and after adjustment for LVH as a time-varying covariate.</p></sec><sec><title>Results:</title><p>Among SPRINT participants without baseline LVH (n=7559), intensive (versus <strong><span style="color:yellowgreen">standard</span></strong>) BP lowering was associated with a 46% lower risk of developing LVH (hazard ratio=0.54; 95% confidence interval, 0.43–0.68). Similarly, among SPRINT participants with baseline LVH (n=605, 7.4%), those assigned to the intensive (versus <strong><span style="color:yellowgreen">standard</span></strong>) BP lowering were 66% more likely to regress/improve their LVH (hazard ratio=1.66; 95% confidence interval, 1.31–2.11). Adjustment for LVH as a time-varying covariate did not substantially attenuate the effect of intensive BP therapy on CVD events (hazard ratio of intensive versus <strong><span style="color:yellowgreen">standard</span></strong> BP lowering on CVD, 0.76 [95% confidence interval, 0.64–0.90] and 0.77 [95% confidence interval, 0.65–0.91] before and after adjustment for LVH as a time-varying covariate, respectively).</p></sec><sec><title>Conclusions:</title><p>Among patients with hypertension but no diabetes mellitus, intensive BP lowering (target systolic BP <120 mm Hg) compared with <strong><span style="color:yellowgreen">standard</span></strong> BP lowering (target systolic BP <140 mm Hg) resulted in lower rates of developing new LVH in those without LVH and higher rates of regression of LVH in those with existing LVH. This favorable effect on LVH did not explain most of the reduction in CVD events associated with intensive BP lowering in the SPRINT trial.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01206062.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/5/440
10.1161/CIRCULATIONAHA.117.028441
None

3
Circulation
Potential Cardiovascular and Total Mortality Benefits of Air Pollution Control in Urban China
<sec><title>Background:</title><p>Outdoor air pollution ranks fourth among preventable causes of China’s burden of disease. We hypothesized that the magnitude of health gains from air quality improvement in urban China could compare with achieving recommended blood pressure or smoking control goals.</p></sec><sec><title>Methods:</title><p>The Cardiovascular Disease Policy Model–China projected coronary heart disease, stroke, and all-cause deaths in urban Chinese adults 35 to 84 years of age from 2017 to 2030 if recent air quality (particulate matter with aerodynamic diameter ≤2.5 µm, PM<sub>2.5</sub>) and traditional cardiovascular risk factor trends continue. We projected life-years gained if urban China were to reach 1 of 3 air quality goals: Beijing Olympic Games level (mean PM<sub>2.5</sub>, 55 μg/m<sup>3</sup>), China Class II <strong><span style="color:yellowgreen">standard</span></strong> (35 μg/m<sup>3</sup>), or World Health Organization <strong><span style="color:yellowgreen">standard</span></strong> (10 μg/m<sup>3</sup>). We compared projected air pollution reduction control benefits with potential benefits of reaching World Health Organization hypertension and tobacco control goals.</p></sec><sec><title>Results:</title><p>Mean PM<sub>2.5</sub> reduction to Beijing Olympic levels by 2030 would gain ≈241,000 (95% uncertainty interval, 189 000–293 000) life-years annually. Achieving either the China Class II or World Health Organization PM<sub>2.5</sub> <strong><span style="color:yellowgreen">standard</span></strong> would yield greater health benefits (992 000 [95% uncertainty interval, 790 000–1 180 000] or 1 827 000 [95% uncertainty interval, 1 481 00–2 129 000] annual life-years gained, respectively) than World Health Organization–recommended goals of 25% improvement in systolic hypertension control and 30% reduction in smoking combined (928 000 [95% uncertainty interval, 830 000–1 033 000] life-years).</p></sec><sec><title>Conclusions:</title><p>Air quality improvement in different scenarios could lead to graded health benefits ranging from 241 000 life-years gained to much greater benefits equal to or greater than the combined benefits of 25% improvement in systolic hypertension control and 30% smoking reduction.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/17/1575
10.1161/CIRCULATIONAHA.116.026487
['tobacco']

3
Circulation
Dynamic Edematous Response of the Human Heart to Myocardial Infarction
<sec><title>Background:</title><p>Clinical protocols aimed to characterize the post–myocardial infarction (MI) heart by cardiac magnetic resonance (CMR) need to be <strong><span style="color:yellowgreen">standard</span></strong>ized to take account of dynamic biological phenomena evolving early after the index ischemic event. Here, we evaluated the time course of edema reaction in patients with ST-segment–elevation MI by CMR and assessed its implications for myocardium-at-risk (MaR) quantification both in patients and in a large-animal model.</p></sec><sec><title>Methods:</title><p>A total of 16 patients with anterior ST-segment–elevation MI successfully treated by primary angioplasty and 16 matched controls were prospectively recruited. In total, 94 clinical CMR examinations were performed: patients with ST-segment–elevation MI were serially scanned (within the first 3 hours after reperfusion and at 1, 4, 7, and 40 days), and controls were scanned only once. T2 relaxation time in the myocardium (T2 mapping) and the extent of edema on T2-weighted short-tau triple inversion-recovery (ie, CMR-MaR) were evaluated at all time points. In the experimental study, 20 pigs underwent 40-minute ischemia/reperfusion followed by serial CMR examinations at 120 minutes and 1, 4, and 7 days after reperfusion. Reference MaR was assessed by contrast-multidetector computed tomography during the index coronary occlusion. Generalized linear mixed models were used to take account of repeated measurements.</p></sec><sec><title>Results:</title><p>In humans, T2 relaxation time in the ischemic myocardium declines significantly from early after reperfusion to 24 hours, and then increases up to day 4, reaching a plateau from which it decreases from day 7. Consequently, edema extent measured by T2-weighted short-tau triple inversion-recovery (CMR-MaR) varied with the timing of the CMR examination. These findings were confirmed in the experimental model by showing that only CMR-MaR values for day 4 and day 7 postreperfusion, coinciding with the deferred edema wave, were similar to values measured by reference contrast-multidetector computed tomography.</p></sec><sec><title>Conclusions:</title><p>Post-MI edema in patients follows a bimodal pattern that affects CMR estimates of MaR. Dynamic changes in post–ST-segment–elevation MI edema highlight the need for <strong><span style="color:yellowgreen">standard</span></strong>ization of CMR timing to retrospectively delineate MaR and quantify myocardial salvage. According to the present clinical and experimental data, a time window between days 4 and 7 post-MI seems a good compromise solution for <strong><span style="color:yellowgreen">standard</span></strong>ization. Further studies are needed to study the effect of other factors on these variables.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/14/1288
10.1161/CIRCULATIONAHA.116.025582
['pigs']

3
Circulation
Impact of Combat Deployment and Posttraumatic Stress Disorder on Newly Reported Coronary Heart Disease Among US Active Duty and Reserve Forces
<sec><title>Background—</title><p>The recent conflicts in Iraq and Afghanistan have exposed thousands of service members to intense stress, and as a result, many have developed posttraumatic stress disorder (PTSD). The role of military deployment experiences and PTSD in coronary heart disease (CHD) is not well defined, especially in young US service members with recent combat exposure.</p></sec><sec><title>Methods and Results—</title><p>We conducted a prospective cohort study to investigate the relationships between wartime experiences, PTSD, and CHD. Current and former US military personnel from all service branches participating in the Millennium Cohort Study during 2001 to 2008 (n=60 025) were evaluated for newly self-reported CHD. Electronic medical record review for <i>International Classification of Diseases, Ninth Revision, Clinical Modification</i> <strong><span style="color:yellowgreen">code</span></strong>s for CHD was conducted among a subpopulation of active duty members (n=23 794). Logistic regression models examined the associations between combat experiences and PTSD with CHD with adjustment for established CHD risk factors. A total of 627 participants (1.0%) newly reported CHD over an average of 5.6 years of follow-up. Deployers with combat experiences had an increased odds of newly reporting CHD (odds ratio, 1.63; 95% confidence interval, 1.11–2.40) and having a diagnosis <strong><span style="color:yellowgreen">code</span></strong> for new-onset CHD (odds ratio, 1.93; 95% confidence interval, 1.31–2.84) compared with noncombat deployers. Screening positive for PTSD symptoms was associated with self-reported CHD before but not after adjustment for depression and anxiety and was not associated with a new diagnosis <strong><span style="color:yellowgreen">code</span></strong> for CHD.</p></sec><sec><title>Conclusions—</title><p>Combat deployments are associated with new-onset CHD among young US service members and veterans. Experiences of intense stress may increase the risk for CHD over a relatively short period among young adults.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/18/1813
10.1161/CIRCULATIONAHA.113.005407
None

2
PLANT PHYSIOLOGY
MoChlo: A Versatile, Modular Cloning Toolbox for Chloroplast Biotechnology
<p>Plant synthetic biology is a rapidly evolving field with new tools constantly emerging to drive innovation. Of particular interest is the application of synthetic biology to chloroplast biotechnology to generate plants capable of producing new metabolites, vaccines, biofuels, and high-value chemicals. Progress made in the assembly of large DNA molecules, composing multiple transcriptional units, has significantly aided in the ability to rapidly construct novel vectors for genetic engineering. In particular, Golden Gate assembly has provided a facile molecular tool for <strong><span style="color:yellowgreen">standard</span></strong>ized assembly of synthetic genetic elements into larger DNA constructs. In this work, a complete modular chloroplast cloning system, MoChlo, was developed and validated for fast and flexible chloroplast engineering in plants. A library of 128 <strong><span style="color:yellowgreen">standard</span></strong>ized chloroplast-specific parts (47 promoters, 38 5′ untranslated regions [5′UTRs], nine promoter:5′UTR fusions, 10 3′UTRs, 14 genes of interest, and 10 chloroplast-specific destination vectors) were mined from the literature and modified for use in MoChlo assembly, along with chloroplast-specific destination vectors. The strategy was validated by assembling synthetic operons of various sizes and determining the efficiency of assembly. This method was successfully used to generate chloroplast transformation vectors containing up to seven transcriptional units in a single vector (∼10.6-kb synthetic operon). To enable researchers with limited resources to engage in chloroplast biotechnology, and to accelerate progress in the field, the entire kit, as described, is available through Addgene at minimal cost. Thus, the MoChlo kit represents a valuable tool for fast and flexible design of heterologous metabolic pathways for plastid metabolic engineering.</p>
http://plantphysiol.org/cgi/content/abstract/179/3/943
10.1104/pp.18.01220
['plants']

2
PLANT PHYSIOLOGY
Digital Imaging Combined with Genome-Wide Association Mapping Links Loci to Plant-Pathogen Interaction Traits
<p>Plant resistance to generalist pathogens with broad host ranges, such as <i>Botrytis cinerea</i> (<i>Botrytis</i>), is typically quantitative and highly polygenic. Recent studies have begun to elucidate the molecular genetic basis of plant-pathogen interactions using commonly measured traits, including lesion size and/or pathogen biomass. However, with the advent of <strong><span style="color:yellowgreen">digit</span></strong>al imaging and high-throughput phenomics, there are a large number of additional traits available to study quantitative resistance. In this study, we used high-throughput <strong><span style="color:yellowgreen">digit</span></strong>al imaging analysis to investigate previously poorly characterized visual traits of plant-pathogen interactions related to disease resistance using the Arabidopsis (<i>Arabidopsis thaliana</i>)/<i>Botrytis</i> pathosystem. From a large collection of visual lesion trait measurements, we focused on color, shape, and size to test how these aspects of the Arabidopsis/<i>Botrytis</i> interaction are genetically related. Through genome-wide association mapping in Arabidopsis, we show that lesion color and shape are genetically separable traits associated with plant disease resistance. Moreover, by employing defined mutants in 23 candidate genes identified from the genome-wide association mapping, we demonstrate links between loci and each of the different plant-pathogen interaction traits. These results expand our understanding of the functional mechanisms driving plant disease resistance.</p>
http://plantphysiol.org/cgi/content/abstract/178/3/1406
10.1104/pp.18.00851
['Arabidopsis', 'Arabidopsis thaliana', 'Botrytis']

2
PLANT PHYSIOLOGY
Multi-Omics Driven Assembly and Annotation of the Sandalwood (<i>Santalum album</i>) Genome
<p>Indian sandalwood (<i>Santalum album</i>) is an important tropical evergreen tree known for its fragrant heartwood-derived essential oil and its valuable carving wood. Here, we applied an integrated genomic, transcriptomic, and proteomic approach to assemble and annotate the Indian sandalwood genome. Our genome sequencing resulted in the establishment of a draft map of the smallest genome for any woody tree species to date (221 Mb). The genome annotation predicted 38,119 protein-coding genes and 27.42% repetitive DNA elements. In-depth proteome analysis revealed the identities of 72,325 unique peptides, which confirmed 10,076 of the predicted genes. The addition of transcriptomic and proteogenomic approaches resulted in the identification of 53 novel proteins and 34 gene-correction events that were missed by genomic approaches. Proteogenomic analysis also helped in reassigning 1,348 potential noncoding RNAs as bona fide protein-coding messenger RNAs. Gene expression patterns at the RNA and protein levels indicated that peptide sequencing was useful in capturing proteins en<strong><span style="color:yellowgreen">code</span></strong>d by nuclear and organellar genomes alike. Mass spectrometry-based proteomic evidence provided an unbiased approach toward the identification of proteins en<strong><span style="color:yellowgreen">code</span></strong>d by organellar genomes. Such proteins are often missed in transcriptome data sets due to the enrichment of only messenger RNAs that contain poly(A) tails. Overall, the use of integrated omic approaches enhanced the quality of the assembly and annotation of this nonmodel plant genome. The availability of genomic, transcriptomic, and proteomic data will enhance genomics-assisted breeding, germplasm characterization, and conservation of sandalwood trees.</p>
http://plantphysiol.org/cgi/content/abstract/176/4/2772
10.1104/pp.17.01764
['Santalum', 'Santalum album', 'sandalwood']

2
PLANT PHYSIOLOGY
The Long Intergenic Noncoding RNA (LincRNA) Landscape of the Soybean Genome
<p>Long intergenic noncoding RNAs (lincRNAs) are emerging as important regulators of diverse biological processes. However, our understanding of lincRNA abundance and function remains very limited especially for agriculturally important plants. Soybean (<i>Glycine max</i>) is a major legume crop plant providing over a half of global oilseed production. Moreover, soybean can form symbiotic relationships with <i>Rhizobium</i> bacteria to fix atmospheric nitrogen. Soybean has a complex paleopolyploid genome and exhibits many vegetative and floral development complexities. Soybean cultivars have photoperiod requirements restricting its use and productivity. Molecular regulators of these legume-specific developmental processes remain enigmatic. Long noncoding RNAs may play important regulatory roles in soybean growth and development. In this study, over one billion RNA-seq read pairs from 37 samples representing nine tissues were used to discover 6,018 lincRNA loci. The lincRNAs were shorter than protein-coding transcripts and had lower expression levels and more sample specific expression. Few of the loci were found to be conserved in two other legume species (chickpea [<i>Cicer arietinum</i>] and <i>Medicago truncatula</i>), but almost 200 homeologous lincRNAs in the soybean genome were detected. Protein-coding gene-lincRNA coexpression analysis suggested an involvement of lincRNAs in stress response, signal transduction, and developmental processes. Positional analysis of lincRNA loci implicated involvement in transcriptional regulation. lincRNA expression from centromeric regions was observed especially in actively dividing tissues, suggesting possible roles in cell division. Integration of publicly available genome-wide association data with the lincRNA map of the soybean genome uncovered 23 lincRNAs potentially associated with agronomic traits.</p>
http://plantphysiol.org/cgi/content/abstract/176/3/2133
10.1104/pp.17.01657
['Cicer', 'Cicer arietinum', 'Glycine', 'Glycine max', 'Medicago', 'Medicago truncatula', 'Rhizobium', 'plants', 'soybean']

2
PLANT PHYSIOLOGY
Pausing of Chloroplast Ribosomes Is Induced by Multiple Features and Is Linked to the Assembly of Photosynthetic Complexes<xref><sup>1</sup></xref>
<p>Many mRNAs contain pause sites that briefly interrupt the progress of translation. Specific features that induce ribosome pausing have been described; however, their individual contributions to pause-site formation, and the overall biological significance of ribosome pausing, remain largely unclear. We have taken advantage of the compact genome of chloroplasts to carry out a plastid genome-wide survey of pause sites, as a basis for studying the impact of pausing on posttranslational processes. Based on ribosomal profiling of Arabidopsis (<i>Arabidopsis thaliana</i>) chloroplast mRNAs, we demonstrate that a combination of factors—mRNA secondary structure, internal Shine-Dalgarno sequences, and positively charged amino acids in the nascent peptide chain—explains 95% of the major pause sites on plastid mRNAs, whereas codon usage has little impact. The distribution of the pause sites is nonrandom and conforms to distinct patterns in the vicinity of sequences coding for transmembrane domains, which depend on their orientation within the membrane as well as being next to sequences coding for cofactor binding sites. We found strong indications that the mechanisms causing ribosomal pausing and at least some of the ribosomes pause sites are conserved between distantly related plant species. In addition, the positions of features that cause pausing are well conserved in photoautotrophic plants, but less so in their nonphotosynthetic, parasitic relatives, implying that the synthesis and assembly of photosynthetic multiprotein complexes requires localized ribosome pausing.</p>
http://plantphysiol.org/cgi/content/abstract/176/3/2557
10.1104/pp.17.01564
['Arabidopsis', 'Arabidopsis thaliana', 'plants']

2
PLANT PHYSIOLOGY
Natural Variation Underlies Differences in ETHYLENE RESPONSE FACTOR17 Activity in Fruit Peel Degreening
<p>Through natural or human selection, many fleshy fruits have evolved vivid external or internal coloration, which often develops during ripening. Such developmental changes in color are associated with the biosynthesis of pigments as well as with degreening through chlorophyll degradation. Here, we demonstrated that natural variation in the coding region of the gene <i>ETHYLENE RESPONSE FACTOR17</i> (<i>ERF17</i>) contributes to apple (<i>Malus domestica</i>) fruit peel degreening. Specifically, <i>ERF17</i> mutant alleles with different serine (Ser) repeat insertions in the coding region exhibited enhanced transcriptional regulation activity in a dual-luciferase reporter assay when more Ser repeats were present. Notably, surface plasmon resonance analysis showed that the number of Ser repeats affected the binding activity of ERF17 to the promoter sequences of chlorophyll degradation-related genes. In addition, overexpression of <i>ERF17</i> in evergreen apples altered the accumulation of chlorophyll. Furthermore, we demonstrated that <i>ERF17</i> has been under selection since the origin of apple tree cultivation. Taken together, these results reveal allelic variation underlying an important fruit quality trait and a molecular genetic mechanism associated with apple domestication.</p>
http://plantphysiol.org/cgi/content/abstract/176/3/2292
10.1104/pp.17.01320
['Malus', 'apple', 'human']

2
PLANT PHYSIOLOGY
Novel Stress-Inducible Antisense RNAs of Protein-Coding Loci Are Synthesized by RNA-Dependent RNA Polymerase
<p>Our previous study identified approximately 6,000 abiotic stress-responsive noncoding transcripts existing on the antisense strand of protein-coding genes and implied that a type of antisense RNA was synthesized from a sense RNA template by <i>RNA-dependent RNA polymerase</i> (<i>RDR</i>). Expression analyses revealed that the expression of novel abiotic stress-induced antisense RNA on 1,136 gene loci was reduced in the <i>rdr1/2/6</i> mutants. RNase protection indicated that the <i>RD29A</i> antisense RNA and other RDR1/2/6-dependent antisense RNAs are involved in the formation of dsRNA. The accumulation of stress-inducible antisense RNA was decreased and increased in <i>dcp5</i> and <i>xrn4</i>, respectively, but not changed in <i>dcl2/3/4</i>, <i>nrpd1a</i> and <i>nrpd1b</i>. RNA-seq analyses revealed that the majority of the RDR1/2/6-dependent antisense RNA loci did not overlap with RDR1/2/6-dependent 20–30 nt RNA loci. Additionally, <i>rdr1/2/6</i> mutants decreased the degradation rate of the sense RNA and exhibited arrested root growth during the recovery stage following a drought stress, whereas <i>dcl2/3/4</i> mutants did not. Collectively, these results indicate that RDRs have stress-inducible antisense RNA synthesis activity and a novel biological function that is different from the known endogenous small RNA pathways from protein-coding genes. These data reveal a novel mechanism of RNA regulation during abiotic stress response that involves complex RNA degradation pathways.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/457
10.1104/pp.17.00787
None

2
PLANT PHYSIOLOGY
Cyst Nematode Parasitism Induces Dynamic Changes in the Root Epigenome
<p>A growing body of evidence indicates that epigenetic modifications can provide efficient, dynamic, and reversible cellular responses to a wide range of environmental stimuli. However, the significance of epigenetic modifications in plant-pathogen interactions remains largely unexplored. In this study, we provide a comprehensive analysis of epigenome changes during the compatible interaction between the beet cyst nematode <i>Heterodera schachtii</i> and Arabidopsis (<i>Arabidopsis thaliana</i>). Whole-genome bisulfite sequencing was conducted to assess the dynamic changes in the methylome of Arabidopsis roots in response to <i>H. schachtii</i> infection. <i>H. schachtii</i> induced widespread hypomethylation of protein-coding genes and transposable elements (TEs), preferentially those adjacent to protein-coding genes. The abundance of 24-nt siRNAs was associated with hypermethylation of TEs and gene promoters, with influence observed for methylation context and infection time points. mRNA sequencing revealed a significant enrichment for the differentially methylated genes among the differentially expressed genes, specifically those with functions corresponding to primary metabolic processes and responses to stimuli. The differentially methylated genes overlapped with more than one-fourth of the syncytium differentially expressed genes and are of functional significance. Together, our results provide intriguing insights into the potential regulatory role of differential DNA methylation in shaping the biological interplay between cyst nematodes and host plants.</p>
http://plantphysiol.org/cgi/content/abstract/174/1/405
10.1104/pp.16.01948
['Arabidopsis', 'Arabidopsis thaliana', 'beet', 'plants', 'Heterodera', 'Heterodera schachtii']

2
PLANT PHYSIOLOGY
The Plastid Genome of <i>Polytoma uvella</i> Is the Largest Known among Colorless Algae and Plants and Reflects Contrasting Evolutionary Paths to Nonphotosynthetic Lifestyles
<p>The loss of photosynthesis is frequently associated with parasitic or pathogenic lifestyles, but it also can occur in free-living, plastid-bearing lineages. A common consequence of becoming nonphotosynthetic is the reduction in size and gene content of the plastid genome. In exceptional circumstances, it can even result in the complete loss of the plastid DNA (ptDNA) and its associated gene expression system, as reported recently in several lineages, including the nonphotosynthetic green algal genus <i>Polytomella</i>. Closely related to <i>Polytomella</i> is the polyphyletic genus <i>Polytoma</i>, the members of which lost photosynthesis independently of <i>Polytomella</i>. Species from both genera are free-living organisms that contain nonphotosynthetic plastids, but unlike <i>Polytomella</i>, <i>Polytoma</i> members have retained a genome in their colorless plastid. Here, we present the plastid genome of <i>Polytoma uvella</i>: to our knowledge, the first report of ptDNA from a nonphotosynthetic chlamydomonadalean alga. The <i>P. uvella</i> ptDNA contains 25 protein-coding genes, most of which are related to gene expression and none are connected to photosynthesis. However, despite its reduced coding capacity, the <i>P. uvella</i> ptDNA is inflated with short repeats and is tens of kilobases larger than the ptDNAs of its closest known photosynthetic relatives, <i>Chlamydomonas leiostraca</i> and <i>Chlamydomonas applanata</i>. In fact, at approximately 230 kb, the ptDNA of <i>P. uvella</i> represents the largest plastid genome currently reported from a nonphotosynthetic alga or plant. Overall, the <i>P. uvella</i> and <i>Polytomella</i> plastid genomes reveal two very different evolutionary paths following the loss of photosynthesis: expansion and complete deletion, respectively. We hypothesize that recombination-based DNA-repair mechanisms are at least partially responsible for the different evolutionary outcomes observed in such closely related nonphotosynthetic algae.</p>
http://plantphysiol.org/cgi/content/abstract/173/2/932
10.1104/pp.16.01628
['Chlamydomonas', 'Polytoma', 'Polytoma uvella', 'Polytomella']

2
Molecular Biology and Evolution
The Evolution of Human Cells in Terms of Protein Innovation
<p>Humans are composed of hundreds of cell types. As the genomic DNA of each somatic cell is identical, cell type is determined by what is expressed and when. Until recently, little has been reported about the determinants of human cell identity, particularly from the joint perspective of gene evolution and expression. Here, we chart the evolutionary past of all documented human cell types via the collective histories of proteins, the principal product of gene expression. FANTOM5 data provide cell-type–specific <strong><span style="color:yellowgreen">digit</span></strong>al expression of human protein-coding genes and the SUPERFAMILY resource is used to provide protein domain annotation. The evolutionary epoch in which each protein was created is inferred by comparison with domain annotation of all other completely sequenced genomes. Studying the distribution across epochs of genes expressed in each cell type reveals insights into human cellular evolution in terms of protein innovation. For each cell type, its history of protein innovation is charted based on the genes it expresses. Combining the histories of all cell types enables us to create a timeline of cell evolution. This timeline identifies the possibility that our common ancestor Coelomata (cavity-forming animals) provided the innovation required for the innate immune system, whereas cells which now form the brain of human have followed a trajectory of continually accumulating novel proteins since Opisthokonta (boundary of animals and fungi). We conclude that exaptation of existing domain architectures into new contexts is the dominant source of cell-type–specific domain architectures.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/31/6/1364
10.1093/molbev/mst139
['animals', 'fungi', 'human']

2
Journal of Experimental Biology
Olfactory memories are intensity specific in larval <i>Drosophila</i>
<p>Learning can rely on stimulus quality, stimulus intensity, or a combination of these. Regarding olfaction, the coding of odour quality is often proposed to be combinatorial along the olfactory pathway, and working hypotheses are available concerning short-term associative memory trace formation of odour quality. However, it is less clear how odour intensity is <strong><span style="color:yellowgreen">code</span></strong>d, and whether olfactory memory traces include information about the intensity of the learnt odour. Using odour–sugar associative conditioning in larval <i>Drosophila</i>, we first describe the dose–effect curves of learnability across odour intensities for four different odours (<i>n</i>-amyl acetate, 3-octanol, 1-octen-3-ol and benzaldehyde). We then chose odour intensities such that larvae were trained at an intermediate odour intensity, but were tested for retention with either that trained intermediate odour intensity, or with respectively higher or lower intensities. We observed a specificity of retention for the trained intensity for all four odours used. This adds to the appreciation of the richness in ‘content’ of olfactory short-term memory traces, even in a system as simple as larval <i>Drosophila</i>, and to define the demands on computational models of associative olfactory memory trace formation. We suggest two kinds of circuit architecture that have the potential to accommodate intensity learning, and discuss how they may be implemented in the insect brain.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1552
10.1242/jeb.082222
['Drosophila']

2
The Bone & Joint Journal
Mid-term outcomes of 77 modular radial head prostheses
<sec><title>Aims</title><p>Radial head arthroplasty (RHA) may be used in the treatment of   non-reconstructable radial head fractures. The aim of this study   was to evaluate the mid-term clinical and radiographic results of   RHA.</p></sec><sec><title>Patients and Methods</title><p>Between 2002 and 2014, 77 RHAs were implanted in 54 men and 23   women with either acute injuries (54) or with traumatic sequelae   (23) of a fracture of the radial head. Four designs of RHA were   used, including the Guepar (Small Bone Innovations (SBi)/Stryker;   36), Evolutive (Aston Medical; 24), rHead RECON (SBi/Stryker; ten)   or rHead <strong><span style="color:yellowgreen">standard</span></strong> (SBi/Stryker; 7) prostheses. The mean follow-up   was 74.0 months (<strong><span style="color:yellowgreen">standard</span></strong> deviation (<sc>sd</sc>) 38.6; 24 to 141).   The indication for further surgery, range of movement, mean Mayo   Elbow Performance (MEP) score, quick Disabilities of the Arm, Shoulder   and Hand (quickDASH) score, osteolysis and positioning of the implant   were also assessed according to the design, and acute or delayed   use.</p></sec><sec><title>Results</title><p>The mean MEP and quickDASH scores were 90.2 (<sc>sd</sc> 14;   45 to 100), and 14.0 points (<sc>sd</sc> 12; 1.2 to 52.5), respectively. There   were no significant differences between RHA performed in acute or   delayed fashion. There were 30 re-operations (19 with, and 11 without   removal of the implant) during the first three post-operative years.   Painful loosening was the primary indication for removal in 14 patients.   Short-stemmed prostheses (16 mm to 22 mm in length) were also associated   with an increased risk of painful loosening (odds ratio 3.54 (1.02   to 12.2), p = 0.045). Radiocapitellar instability was the primary   indication for re-operation with retention of the implant (5). The   overall survival of the RHA, free from re-operation, was 60.8% (<sc>sd</sc> 5.7%)   at ten years.</p></sec><sec><title>Conclusion</title><p>Bipolar and press-fit RHA gives unsatisfactory mid-term outcomes   in the treatment of acute fractures of the radial head or their   sequelae. The outcome may vary according to the design of the implant.   The rate of re-operation during the first three years is predictive   of the long-term survival in tight-fitting RHAs.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B1197–1203.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/9/1197
10.1302/0301-620X.99B9.BJJ-2016-1043.R2
None

2
The Bone & Joint Journal
Primary hip and knee arthroplasty in a temporary operating theatre is associated with a significant increase in deep periprosthetic infection
<sec><title>Aims</title><p>Infection following total hip or knee arthroplasty is a serious   complication. We noted an increase in post-operative infection in   cases carried out in temporary operating theatres. We therefore   compared those cases performed in <strong><span style="color:yellowgreen">standard</span></strong> and temporary operating   theatres and examined the deep periprosthetic infection rates.</p></sec><sec><title>Patients and methods</title><p>A total of 1223 primary hip and knee arthroplasties were performed   between August 2012 and June 2013. A total of 539 (44%) were performed   in temporary theatres. The two groups were matched for age, gender,   body mass index and American Society of Anesthesiologists grade.</p></sec><sec><title>Results</title><p>The deep infection rate for <strong><span style="color:yellowgreen">standard</span></strong> operating theatres was 0   of 684 (0%); for temporary theatres it was eight of 539 (1.5%) (p   = 0.001).</p></sec><sec><title>Conclusion</title><p>Use of a temporary operating theatre for primary hip and knee   arthroplasty was associated with an unacceptable increase in deep   infection. We do not advocate the use of these theatres for primary   joint arthroplasty.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:917–20.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/7/917
10.1302/0301-620X.99B7.BJJ-2016-1293.R1
None

2
The Bone & Joint Journal
Dislocation of a primary total hip arthroplasty is more common in patients with a lumbar spinal fusion
<sec><title>Aims</title><p>Lumbar fusion is known to reduce the variation in pelvic tilt   between standing and sitting. A flexible lumbo-pelvic unit increases   the stability of total hip arthroplasty (THA) when seated by increasing   anterior clearance and acetabular anteversion, thereby preventing   impingement of the prosthesis. Lumbar fusion may eliminate this protective   pelvic movement. The effect of lumbar fusion on the stability of   total hip arthroplasty has not previously been investigated.</p></sec><sec><title>Patients and Methods</title><p>The Medicare database was searched for patients who had undergone   THA and spinal fusion between 2005 and 2012. PearlDiver software   was used to query the database by the International Classification   of Diseases, 9th Revision, Clinical Modification (ICD-9-CM) procedural   <strong><span style="color:yellowgreen">code</span></strong> for primary THA and lumbar spinal fusion. Patients who had   undergone both lumbar fusion and THA were then divided into three   groups: 1 to 2 levels, 3 to 7 levels and 8+ levels of fusion. The   rate of dislocation in each group was established using ICD-9-CM <strong><span style="color:yellowgreen">code</span></strong>s.   Patients who underwent THA without spinal fusion were used as a   control group. Statistical significant difference between groups   was tested using the chi-squared test, and significance set at p   < 0.05.</p></sec><sec><title>Results</title><p>At one-year follow-up, 14 747 patients were found to have had   a THA after lumbar spinal fusion (12 079 1 to 2 levels, 2594 3 to   7 levels, 74 8+ levels). The control group consisted of 839 004   patients. The dislocation rate in the control group was 1.55%. A   higher rate of dislocation was found in patients with a spinal fusion   of 1 to 2 levels (2.96%, p < 0.0001) and 3 to 7 levels (4.12%,   p < 0.0001). Patients with 3 to 7 levels of fusion had a higher   rate of dislocation than patients with 1 to 2 levels of fusion (odds   ratio (OR) = 1.60, p < 0.0001). When groups were matched for   age and gender to the unfused cohort, patients with 1 to 2 levels   of fusion had an OR of 1.93 (95% confidence interval (CI) 1.42 to   2.32, p < 0.001), and those with 3 to 7 levels of fusion an OR   of 2.77 (CI 2.04 to 4.80, p < 0.001) for dislocation.</p></sec><sec><title>Conclusion</title><p>Patients with a previous history of lumbar spinal fusion have   a significantly higher rate of dislocation of their THA than age-   and gender-matched patients without a lumbar spinal fusion.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:585–91.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/585
10.1302/0301-620X.99B5.BJJ-2016-0657.R1
None

2
The Bone & Joint Journal
The management of open tibial fractures in children
<sec><title>Aims</title><p>Following the introduction of national <strong><span style="color:yellowgreen">standard</span></strong>s in 2009, most   major paediatric trauma is now triaged to specialist units offering   combined orthopaedic and plastic surgical expertise. We investigated   the management of open tibia fractures at a paediatric trauma centre,   primarily reporting the risk of infection and rate of union.</p></sec><sec><title>Patients and Methods</title><p>A retrospective review was performed on 61 children who between   2007 and 2015 presented with an open tibia fracture. Their mean   age was nine years (2 to 16) and the median follow-up was ten months   (interquartile range 5 to 18). Management involved IV antibiotics,   early debridement and combined treatment of the skeletal and soft-tissue injuries   in line with <strong><span style="color:yellowgreen">standard</span></strong>s proposed by the British Orthopaedic Association.</p></sec><sec><title>Results</title><p>There were 36 diaphyseal fractures and 25 distal tibial fractures.   Of the distal fractures, eight involved the physis. Motor vehicle   collisions accounted for two thirds of the injuries and 38 patients   (62%) arrived outside of normal working hours. The initial method   of stabilisation comprised: casting in nine cases (15%); elastic   nailing in 19 (31%); Kirschner (K)-wiring in 13 (21%); intramedullary   nailing in one (2%); open reduction and plate fixation in four (7%); and   external fixation in 15 (25%). Wound management comprised: primary   wound closure in 24 (39%), delayed primary closure in 11 (18%),   split skin graft (SSG) in eight (13%), local flap with SSG in 17   (28%) and a free flap in one. A total of 43 fractures (70%) were   Gustilo-Anderson grade III. There were four superficial (6.6%) and   three (4.9%) deep infections. Two deep infections occurred following   open reduction and plate fixation and the third after    K-wire fixation of a distal fracture. No patient who underwent primary   wound closure developed an infection. All the fractures united,   although nine patients required revision of a mono-lateral to circular   frame for delayed union (two) or for altered alignment or length   (seven). The mean time to union was two weeks longer in diaphyseal fractures   than in distal fractures (13 weeks <i>versus</i> 10.8   weeks, p<i> = </i>0.016). Children aged > 12 years had   a significantly longer time to union than those aged < 12 years   (16.3 weeks <i>versus</i> 11.4 weeks, p<i> = </i>0.045).   The length of stay in hospital for patients with a Gustilo-Anderson   grade IIIB fracture was twice as long as for less severe injuries. </p></sec><sec><title>Conclusion</title><p>Fractures in children heal better than those in adults. Based   on our experience of deep infection we discourage the use of internal   fixation with a plate for open tibial fractures in children. We   advocate aggressive initial wound debridement in theatre with early   definitive combined orthopaedic and plastic surgery in order to   obtain skeletal stabilisation and soft-tissue cover.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:544–53.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/544
10.1302/0301-620X.99B4.37855
None

2
The Bone & Joint Journal
Reconstruction with 3D-printed pelvic endoprostheses after resection of a pelvic tumour
<sec><title>Aims</title><p>The aims of this retrospective study were to report the feasibility   of using 3D-printing technology for patients with a pelvic tumour   who underwent reconstruction.</p></sec><sec><title>Patients and Methods</title><p>A total of 35 patients underwent resection of a pelvic tumour   and reconstruction using 3D-printed endoprostheses between September   2013 and December 2015. According to Enneking’s classification of   bone defects, there were three Type I lesions, 12 Type II+III lesions,   five Type I+II lesions, two Type I+II+III lesions, ten type I+II+IV   lesions and three type I+II+III+IV lesions. A total of three patients   underwent reconstruction using an iliac prosthesis, 12 using a <strong><span style="color:yellowgreen">standard</span></strong>   hemipelvic prosthesis and 20 using a screw-rod connected hemipelvic   prosthesis.</p></sec><sec><title>Results</title><p>All patients had an <i>en bloc</i> resection. Margins   were wide in 15 patients, marginal in 14 and intralesional in six.   After a mean follow-up of 20.5 months (6 to 30), 25 patients survived   without evidence of disease, five were alive with disease and five   had died from metastatic disease. </p><p>Complications included seven patients with delayed wound healing   and two with a dislocation of the hip. None had a deep infection.   For the 30 surviving patients, the mean Musculoskeletal Society   93 score was 22.7 (20 to 25) for patients with an iliac prosthesis,   19.8 (15 to 26) for those with a <strong><span style="color:yellowgreen">standard</span></strong> prosthesis, and 17.7 (9   to 25) for those with a screw-rod connected prosthesis.</p></sec><sec><title>Conclusion</title><p>The application of 3D-printing technology can facilitate the   precise matching and osseointegration between implants and the host   bone. We found that the use of 3D-printed pelvic prostheses for   reconstruction of the bony defect after resection of a pelvic tumour   was safe, without additional complications, and gave good short-term functional   results.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:267–75.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/2/267
10.1302/0301-620X.99B2.BJJ-2016-0654.R1
None

2
The Bone & Joint Journal
Multiple boluses of intravenous tranexamic acid to reduce hidden blood loss and the inflammatory response following enhanced-recovery primary total hip arthroplasty
<sec><title>Aims</title><p>The aim of this study was to examine the efficacy and safety   of multiple boluses of intravenous (IV) tranexamic acid (TXA) on   the hidden blood loss (HBL) and inflammatory response following   primary total hip arthroplasty (THA).</p></sec><sec><title>Patients and Methods</title><p>A total of 150 patients were allocated randomly to receive a   single bolus of 20 mg/kg IV TXA before the incision (group A), a   single bolus followed by a second bolus of 1 g IV-TXA three hours   later (group B) or a single bolus followed by two boluses of 1 g   IV-TXA three and six hours later (group C). All patients were treated   using a <strong><span style="color:yellowgreen">standard</span></strong> peri-operative enhanced recovery protocol. Primary   outcomes were HBL and the level of haemoglobin (Hb) as well as the   levels of C-reactive protein (CRP) and interleukin-6 (IL-6) as markers   of inflammation. Secondary outcomes included the length of stay   in hospital and the incidence of venous thromboembolism (VTE).</p></sec><sec><title>Results</title><p>The mean HBL was significantly lower in group C (402.13 ml <strong><span style="color:yellowgreen">standard</span></strong>   deviation (<sc>sd)</sc> 225.97) than group A (679.28 ml<sc> sd</sc> 277.16,   p < 0.001) or B (560.62 ml <sc>sd</sc> 295.22, p = 0.010). The   decrease in the level of Hb between the pre-operative baseline and   the level on the third post-operative day was 30.82 g/L (<sc>sd</sc> 6.31   g/L) in group A, 27.16 g/L (<sc>sd</sc> 6.83) in group B and 21.98   g/L (<sc>sd</sc> 3.72) in group C. This decrease differed significantly   among the three groups (p < 0.01). The mean level of CRP was   significantly lower in group C than in the other two groups on the   second (p ≤ 0.034) and third post-operative days (p ≤ 0.014). The   levels of IL-6 were significantly lower in group C than group A   on the first three post-operative days (p = 0.023). The mean length   of stay was significantly lower in group C than group A (p = 0.023).   No VTE or other adverse events occurred.</p></sec><sec><title>Conclusion</title><p>Multiple boluses of IV-TXA can effectively reduce HBL following   primary THA. A regime of three boluses leads to a smaller decrease   in the level of Hb, less post-operative inflammation and a shorter   length of stay in hospital than a single bolus.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1442–9.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1442
10.1302/0301-620X.99B11.BJJ-2017-0488.R1
None

2
The Bone & Joint Journal
Metal-on-metal total hip arthroplasty is not associated with cardiac disease
<sec><title>Aims</title><p>Many case reports and small studies have suggested that cobalt   ions are a potential cause of cardiac complications, specifically   cardiomyopathy, after metal-on-metal (MoM) total hip arthroplasty   (THA). The impact of metal ions on the incidence of cardiac disease   after MoM THA has not been evaluated in large studies. The aim of   this study was to compare the rate of onset of new cardiac symptoms   in patients who have undergone MoM THA with those who have undergone   metal-on-polyethylene (MoP) THA.</p></sec><sec><title>Patients and Methods</title><p>Data were extracted from the Standard Analytics Files database   for patients who underwent MoM THA between 2005 and 2012. Bearing   surface was selected using International Classification of Diseases   ninth revision <strong><span style="color:yellowgreen">code</span></strong>s. Patients with a minimum five-year follow-up   were selected. An age and gender-matched cohort of patients who underwent   MoP THA served as a comparison group. New diagnoses of cardiac disease   were collected during the follow-up period. Comorbidities and demographics   were identified and routine descriptive statistics were used.</p></sec><sec><title>Results</title><p>We identified 29 483 patients who underwent MoM THA and 24 175   matched patients who underwent MoP THA. Both groups had a mean Charlson   comorbidity index score of 4. There were no statistically significant   differences in 30 of 31 pre-existing comorbidities. Patients undergoing   MoM THA had a slightly lower incidence of cardiac failure compared   with those undergoing MoP THA at three years (6.60% <i>versus</i> 7.06%,   odds ratio (OR) 0.93, 95% confidence interval (CI) 0.87 to 0.99)   and four years (8.73% <i>versus</i> 9.49%, OR 0.91, 95%   CI 0.86 to 0.97) postoperatively, with no difference in the incidence   of new cardiac failure in between the groups at five years. There   was no statistically significant difference in the incidence of   arrhythmia, myocardial infarction and cardiomyopathy at any time   between the two groups.</p></sec><sec><title>Conclusion</title><p>MoM THA is not associated with cardiac complications. Initial   reports may have represented individual instances of cardiac disease   in patients with a failing MoM articulation rather than an emerging   epidemiological trend.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:28–32.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1/28
10.1302/0301-620X.100B1.BJJ-2017-0366.R1
None

2
Circulation
How Do Resuscitation Teams at Top-Performing Hospitals for In-Hospital Cardiac Arrest Succeed?
<sec><title>Background:</title><p>In-hospital cardiac arrest (IHCA) is common, and outcomes vary substantially across US hospitals, but reasons for these differences are largely unknown. We set out to better understand how top-performing hospitals organize their resuscitation teams to achieve high survival rates for IHCA.</p></sec><sec><title>Methods:</title><p>We calculated risk-<strong><span style="color:yellowgreen">standard</span></strong>ized IHCA survival to discharge rates across American Heart Association Get With The Guidelines–Resuscitation registry hospitals between 2012 and 2014. We identified geographically and academically diverse hospitals in the top, middle, and bottom quartiles of survival for IHCA and performed a qualitative study that included site visits with in-depth interviews of clinical and administrative staff at 9 hospitals. With the use of thematic analysis, data were analyzed to identify salient themes of perceived performance by informants.</p></sec><sec><title>Results:</title><p>Across 9 hospitals, we interviewed 158 individuals from multiple disciplines including physicians (17.1%), nurses (45.6%), other clinical staff (17.1%), and administration (20.3%). We identified 4 broad themes related to resuscitation teams: (1) team design, (2) team composition and roles, (3) communication and leadership during IHCA, and (4) training and education. Resuscitation teams at top-performing hospitals demonstrated the following features: dedicated or designated resuscitation teams; participation of diverse disciplines as team members during IHCA; clear roles and responsibilities of team members; better communication and leadership during IHCA; and in-depth mock <strong><span style="color:yellowgreen">code</span></strong>s.</p></sec><sec><title>Conclusions:</title><p>Resuscitation teams at hospitals with high IHCA survival differ from non–top-performing hospitals. Our findings suggest core elements of successful resuscitation teams that are associated with better outcomes and form the basis for future work to improve IHCA.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/2/154
10.1161/CIRCULATIONAHA.118.033674
None

2
Circulation
Trends in Hospitalizations and Survival of Acute Decompensated Heart Failure in Four US Communities (2005–2014)
<sec><title>Background:</title><p>Community trends of acute decompensated heart failure (ADHF) in diverse populations may differ by race and sex.</p></sec><sec><title>Methods:</title><p>The ARIC study (Atherosclerosis Risk in Communities) sampled heart failure-related hospitalizations (≥55 years of age) in 4 US communities from 2005 to 2014 using International Classification of Diseases, Ninth Revision, Clinical Modification <strong><span style="color:yellowgreen">code</span></strong>s. ADHF hospitalizations were validated by <strong><span style="color:yellowgreen">standard</span></strong>ized physician review and computer algorithm, yielding 40 173 events after accounting for sampling design (unweighted n=8746).</p></sec><sec><title>Results:</title><p>Of the ADHF hospitalizations, 50% had reduced ejection fraction, and 39% had preserved EF (HFpEF). HF with reduced ejection fraction was more common in black men and white men, whereas HFpEF was most common in white women. Average age-adjusted rates of ADHF were highest in blacks (38.1 per 1000 black men, 30.5 per 1000 black women), with rates differing by HF type and sex. ADHF rates increased over the 10 years (average annual percentage change: black women +4.3%, black men +3.7%, white women +1.9%, white men +2.6%), mostly reflecting more acute HFpEF. Age-adjusted 28-day and 1-year case fatality proportions were ≈10% and 30%, respectively, similar across race-sex groups and HF types. Only blacks showed decreased 1-year mortality over time (average annual percentage change: black women –5.4%, black men –4.6%), with rates differing by HF type (average annual percentage change: black women HFpEF –7.1%, black men HF with reduced ejection fraction –4.7%).</p></sec><sec><title>Conclusions:</title><p>Between 2005 and 2014, trends in ADHF hospitalizations increased in 4 US communities, primarily driven by acute HFpEF. Survival at 1 year was poor regardless of EF but improved over time for black women and black men.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/1/12
10.1161/CIRCULATIONAHA.117.027551
None

2
Circulation
Diagnostic Accuracy of the Aortic Dissection Detection Risk Score Plus D-Dimer for Acute Aortic Syndromes
<sec><title>Background:</title><p>Acute aortic syndromes (AASs) are rare and severe cardiovascular emergencies with unspecific symptoms. For AASs, both misdiagnosis and overtesting are key concerns, and <strong><span style="color:yellowgreen">standard</span></strong>ized diagnostic strategies may help physicians to balance these risks. D-dimer (DD) is highly sensitive for AAS but is inadequate as a stand-alone test. Integration of pretest probability assessment with DD testing is feasible, but the safety and efficiency of such a diagnostic strategy are currently unknown.</p></sec><sec><title>Methods:</title><p>In a multicenter prospective observational study involving 6 hospitals in 4 countries from 2014 to 2016, consecutive outpatients were eligible if they had ≥1 of the following: chest/abdominal/back pain, syncope, perfusion deficit, and if AAS was in the differential diagnosis. The tool for pretest probability assessment was the aortic dissection detection risk score (ADD-RS, 0–3) per current guidelines. DD was considered negative (DD−) if <500 ng/mL. Final case adjudication was based on conclusive diagnostic imaging, autopsy, surgery, or 14-day follow-up. Outcomes were the failure rate and efficiency of a diagnostic strategy for ruling out AAS in patients with ADD-RS=0/DD− or ADD-RS ≤1/DD−.</p></sec><sec><title>Results:</title><p>A total of 1850 patients were analyzed. Of these, 438 patients (24%) had ADD-RS=0, 1071 patients (58%) had ADD-RS=1, and 341 patients (18%) had ADD-RS >1. Two hundred forty-one patients (13%) had AAS: 125 had type A aortic dissection, 53 had type B aortic dissection, 35 had intramural aortic hematoma, 18 had aortic rupture, and 10 had penetrating aortic ulcer. A positive DD test result had an overall sensitivity of 96.7% (95% confidence interval [CI], 93.6–98.6) and a specificity of 64% (95% CI, 61.6–66.4) for the diagnosis of AAS; 8 patients with AAS had DD−. In 294 patients with ADD-RS=0/DD−, 1 case of AAS was observed. This yielded a failure rate of 0.3% (95% CI, 0.1–1.9) and an efficiency of 15.9% (95% CI, 14.3–17.6) for the ADD-RS=0/DD− strategy. In 924 patients with ADD-RS ≤1/DD−, 3 cases of AAS were observed. This yielded a failure rate of 0.3% (95% CI, 0.1–1) and an efficiency of 49.9% (95% CI, 47.7–52.2) for the ADD-RS ≤1/DD− strategy.</p></sec><sec><title>Conclusions:</title><p>Integration of ADD-RS (either ADD-RS=0 or ADD-RS ≤1) with DD may be considered to <strong><span style="color:yellowgreen">standard</span></strong>ize diagnostic rule out of AAS.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02086136.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/3/250
10.1161/CIRCULATIONAHA.117.029457
None

2
Circulation
Comparison of Reduced-Dose Prasugrel and Standard-Dose Clopidogrel in Elderly Patients With Acute Coronary Syndromes Undergoing Early Percutaneous Revascularization
<sec><title>Background:</title><p>Elderly patients are at elevated risk of both ischemic and bleeding complications after an acute coronary syndrome and display higher on-clopidogrel platelet reactivity compared with younger patients. Prasugrel 5 mg provides more predictable platelet inhibition compared with clopidogrel in the elderly, suggesting the possibility of reducing ischemic events without increasing bleeding.</p></sec><sec><title>Methods:</title><p>In a multicenter, randomized, open-label, blinded end point trial, we compared a once-daily maintenance dose of prasugrel 5 mg with the <strong><span style="color:yellowgreen">standard</span></strong> clopidogrel 75 mg in patients >74 years of age with acute coronary syndrome undergoing percutaneous coronary intervention. The primary end point was the composite of mortality, myocardial infarction, disabling stroke, and rehospitalization for cardiovascular causes or bleeding within 1 year. The study was designed to demonstrate superiority of prasugrel 5 mg over clopidogrel 75 mg.</p></sec><sec><title>Results:</title><p>Enrollment was interrupted, according to prespecified criteria, after a planned interim analysis, when 1443 patients (40% women; mean age, 80 years) had been enrolled with a median follow-up of 12 months, because of futility for efficacy. The primary end point occurred in 121 patients (17%) with prasugrel and 121 (16.6%) with clopidogrel (hazard ratio, 1.007; 95% confidence interval, 0.78–1.30; <i>P</i>=0.955). Definite/probable stent thrombosis rates were 0.7% with prasugrel versus 1.9% with clopidogrel (odds ratio, 0.36; 95% confidence interval, 0.13–1.00; <i>P</i>=0.06). Bleeding Academic Research Consortium types 2 and greater rates were 4.1% with prasugrel versus 2.7% with clopidogrel (odds ratio, 1.52; 95% confidence interval, 0.85–3.16; <i>P</i>=0.18).</p></sec><sec><title>Conclusions:</title><p>The present study in elderly patients with acute coronary syndromes showed no difference in the primary end point between reduced-dose prasugrel and <strong><span style="color:yellowgreen">standard</span></strong>-dose clopidogrel. However, the study should be interpreted in light of the premature termination of the trial.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01777503.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/23/2435
10.1161/CIRCULATIONAHA.117.032180
None

2
Circulation
Carotid Stent Fractures Are Not Associated With Adverse Events
<sec><title>Background:</title><p>The impact of carotid artery stent fractures on the incidence of adverse clinical events remains unclear. The objective of this study is to report the stent fracture rate and its association with in-stent restenosis and adverse outcomes in the ACT-1 trial (Carotid Angioplasty and Stenting Versus Endarterectomy in Asymptomatic Subjects Who Are at <strong><span style="color:yellowgreen">standard</span></strong> Risk for Carotid Endarterectomy With Significant Extracranial Carotid Stenotic Disease).</p></sec><sec><title>Methods:</title><p>ACT-1 is a prospective multicenter trial of patients who have <strong><span style="color:yellowgreen">standard</span></strong> surgical risk with severe asymptomatic carotid artery stenosis randomly assigned to carotid artery stenting or carotid endarterectomy (Abbott Vascular). The primary end point was a composite of death, stroke, or myocardial infarction during the 30 days after the procedure or ipsilateral stroke during the 365 days after the procedure. After 771 patients were enrolled, successively randomly assigned patients were required to undergo annual radiographic (x-ray) analysis for stent fracture. Images were independently adjudicated by a core laboratory.</p></sec><sec><title>Results:</title><p>Of 1021 patients treated with carotid artery stenting during a mean follow-up of 3.1±1.6 years, 939 had at least 1 x-ray during the follow-up period. Stent fracture was reported in 51 (5.4%) patients. With a maximum follow-up period of 5 years, adverse clinical outcomes occurred in 39 patients with at least 1 x-ray during the follow-up. Of 826 (80.9%) subjects who underwent both duplex ultrasound and x-ray, 822 (99.5%) were interpretable. There was no association between stent fracture and the primary end point (<i>P</i>=0.86) or with restenosis (<i>P</i>=0.53).</p></sec><sec><title>Conclusions:</title><p>In this large, independently adjudicated, multicenter study, the stent fracture rate was low and not associated with major adverse clinical events or in-stent restenosis.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00106938.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/1/49
10.1161/CIRCULATIONAHA.117.030030
None

2
Circulation
Geographic Variation in Cardiac Rehabilitation Participation in Medicare and Veterans Affairs Populations
<sec><title>Background:</title><p>Cardiac rehabilitation is strongly recommended after myocardial infarction, percutaneous coronary intervention, or coronary artery bypass surgery, but it is historically underused. We sought to evaluate variation in cardiac rehabilitation participation across the United States.</p></sec><sec><title>Methods:</title><p>From administrative data from the Veterans Affairs (VA) healthcare system and a 5% Medicare sample, we used International Classification of Diseases, 9th Revision <strong><span style="color:yellowgreen">code</span></strong>s to identify patients hospitalized for myocardial infarction, percutaneous coronary intervention, or coronary artery bypass surgery from 2007 to 2011. After excluding patients who died in ≤30 days of hospitalization, we calculated the percentage of patients who participated in ≥1 outpatient visits for cardiac rehabilitation during the 12 months after hospitalization. We estimated adjusted and <strong><span style="color:yellowgreen">standard</span></strong>ized rates of participation in cardiac rehabilitation by state using hierarchical logistic regression models.</p></sec><sec><title>Results:</title><p>Overall, participation in cardiac rehabilitation was 16.3% (23 403/143 756) in Medicare and 10.3% (9123/88 826) in VA. However, participation rates varied widely across states, ranging from 3.2% to 41.8% in Medicare and 1.2% to 47.6% in VA. Similar regional variation was observed in both populations. Patients in the West North Central region (Iowa, Kansas, Minnesota, Missouri, Nebraska, North Dakota, and South Dakota) had the highest participation, whereas those in the Pacific region (Alaska, California, Hawaii, Oregon, and Washington) had the lowest participation in both Medicare (33.7% versus 10.6%) and VA (16.6% versus 5.1%) populations. Significant hospital-level variation was also present, with participation ranging from 3% to 75% in Medicare and 1% to 43% in VA.</p></sec><sec><title>Conclusions:</title><p>Cardiac rehabilitation participation remains low overall in both Medicare and VA populations. However, remarkably similar regional variation exists, with some regions and hospitals achieving high rates of participation in both populations. This provides an opportunity to identify best practices from higher performing hospitals and regions that could be used to improve cardiac rehabilitation participation in lower performing hospitals and regions.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/18/1899
10.1161/CIRCULATIONAHA.117.029471
None

2
Circulation
Study Comparing Vein Integrity and Clinical Outcomes in Open Vein Harvesting and 2 Types of Endoscopic Vein Harvesting for Coronary Artery Bypass Grafting
<sec><title>Background:</title><p>Current consensus statements maintain that endoscopic vein harvesting (EVH) should be <strong><span style="color:yellowgreen">standard</span></strong> care in coronary artery bypass graft surgery, but vein quality and clinical outcomes have been questioned. The VICO trial (Vein Integrity and Clinical Outcomes) was designed to assess the impact of different vein harvesting methods on vessel damage and whether this contributes to clinical outcomes after coronary artery bypass grafting.</p></sec><sec><title>Methods:</title><p>In this single-center, randomized clinical trial, patients undergoing coronary artery bypass grafting with an internal mammary artery and with 1 to 4 vein grafts were recruited. All veins were harvested by a single experienced practitioner. We randomly allocated 300 patients into closed tunnel CO<sub>2</sub> EVH (n=100), open tunnel CO<sub>2</sub> EVH (n=100), and traditional open vein harvesting (n=100) groups. The primary end point was endothelial integrity and muscular damage of the harvested vein. Secondary end points included clinical outcomes (major adverse cardiac events), use of healthcare resources, and impact on health status (quality-adjusted life-years).</p></sec><sec><title>Results:</title><p>The open vein harvesting group demonstrated marginally better endothelial integrity in random samples (85% versus 88% versus 93% for closed tunnel EVH, open tunnel EVH, and open vein harvesting; <i>P</i><0.001). Closed tunnel EVH displayed the lowest longitudinal hypertrophy (1% versus 13.5% versus 3%; <i>P</i>=0.001). However, no differences in endothelial stretching were observed between groups (37% versus 37% versus 31%; <i>P</i>=0.62). Secondary clinical outcomes demonstrated no significant differences in composite major adverse cardiac event scores at each time point up to 48 months. The quality-adjusted life-year gain per patient was 0.11 (<i>P</i><0.001) for closed tunnel EVH and 0.07 (<i>P</i>=0.003) for open tunnel EVH compared with open vein harvesting. The likelihood of being cost-effective, at a predefined threshold of £20 000 per quality-adjusted life-year gained, was 75% for closed tunnel EVH, 19% for open tunnel EVH, and 6% for open vein harvesting.</p></sec><sec><title>Conclusions:</title><p>Our study demonstrates that harvesting techniques affect the integrity of different vein layers, albeit only slightly. Secondary outcomes suggest that histological findings do not directly contribute to major adverse cardiac event outcomes. Gains in health status were observed, and cost-effectiveness was better with closed tunnel EVH. High-level experience with endoscopic harvesting performed by a dedicated specialist practitioner gives optimal results comparable to those of open vein harvesting.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.isrctn.com</ext-link>. International <strong><span style="color:yellowgreen">standard</span></strong> Randomised Controlled Trial Registry Number: 91485426.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1688
10.1161/CIRCULATIONAHA.117.028261
None

2
Circulation
Pericarditis as a Marker of Occult Cancer and a Prognostic Factor for Cancer Mortality
<sec><title>Background:</title><p>Pericarditis may be a serious complication of malignancy. Its significance as a first symptom of occult cancer and as a prognostic factor for cancer survival is unknown.</p></sec><sec><title>Methods:</title><p>Using Danish medical databases, we conducted a nationwide cohort study of all patients with a first-time diagnosis of pericarditis during 1994 to 2013. We excluded patients with previous cancer and followed up the remaining patients for subsequent cancer diagnosis until November 30, 2013. We calculated risks and <strong><span style="color:yellowgreen">standard</span></strong>ized incidence ratios of cancer for patients with pericarditis compared with the general population. We assessed whether pericarditis predicts cancer survival by the Kaplan-Meier method and Cox regression using a matched comparison cohort of cancer patients without pericarditis.</p></sec><sec><title>Results:</title><p>Among 13 759 patients with acute pericarditis, 1550 subsequently were diagnosed with cancer during follow-up. The overall cancer <strong><span style="color:yellowgreen">standard</span></strong>ized incidence ratio was 1.5 (95% confidence interval [CI], 1.4–1.5), driven predominantly by increased rates of lung, kidney, and bladder cancer, lymphoma, leukemia, and unspecified metastatic cancer. The <3-month cancer risk among patients with pericarditis was 2.7%, and the <strong><span style="color:yellowgreen">standard</span></strong>ized incidence ratio was 12.4 (95% CI, 11.2–13.7). The 3- to <12-month <strong><span style="color:yellowgreen">standard</span></strong>ized incidence ratio of cancer was 1.5 (95% CI, 1.2–1.7), subsequently decreasing to 1.1 (95% CI, 1.0–1.2). Three-month survival after the cancer diagnosis was 80% and 86% among those with and without pericarditis, respectively, and the hazard ratio was 1.5 (95% CI, 1.3–1.8). One-year survival was 65% and 70%, respectively, corresponding to a 3- to <12-month hazard ratio of 1.3 (95% CI, 1.1–1.5).</p></sec><sec><title>Conclusions:</title><p>Pericarditis may be a marker of occult cancer and augurs increased mortality after a cancer diagnosis.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/11/996
10.1161/CIRCULATIONAHA.116.024041
None

2
Circulation
Extended-Duration Betrixaban Reduces the Risk of Stroke Versus Standard-Dose Enoxaparin Among Hospitalized Medically Ill Patients
<sec><title>Background:</title><p>Stroke is a morbid and potentially mortal complication among patients hospitalized with acute medical illness. The potential of extended-duration thromboprophylaxis with the factor Xa inhibitor betrixaban to reduce the risk of stroke compared with <strong><span style="color:yellowgreen">standard</span></strong>-dose enoxaparin in this population was assessed in this retrospective APEX trial substudy (Acute Medically Ill Venous Thromboembolism Prevention With Extended Duration Betrixaban).</p></sec><sec><title>Methods:</title><p>Hospitalized acutely medically ill subjects (n=7513) were randomized in a double-dummy double-blind fashion to either extended-duration oral betrixaban (80 mg once daily for 35–42 days) or <strong><span style="color:yellowgreen">standard</span></strong>-dose subcutaneous enoxaparin (40 mg once daily for 10±4 days) for venous thromboprophylaxis. Stroke events were adjudicated by an independent, blinded event adjudication committee.</p></sec><sec><title>Results:</title><p>The mean age of study participants was 76 years; 45% were male; 13% had had a stroke; and 45% had congestive heart failure. There were fewer all-cause strokes (0.54% versus 0.97%; relative risk [RR]=0.56; 95% confidence interval, 0.32–0.96; <i>P</i>=0.032; adjusted RR=0.43%; number needed to treat=233) and ischemic strokes (0.48% versus 0.91%; RR=0.53; 95% confidence interval, 0.30–0.94; <i>P</i>=0.026; adjusted RR=0.43%; number needed to treat=233) among patients treated with betrixaban versus enoxaparin through 77 days of follow-up. Among high-risk subjects, those with congestive heart failure or ischemic stroke as their index event, betrixaban reduced the risk of all-cause stroke (0.72% versus 1.48%; RR=0.49; 95% confidence interval, 0.26–0.90; <i>P</i>=0.019; adjusted RR=0.76%; number needed to treat=132) and ischemic stroke (0.63% versus 1.38%; RR=0.45; 95% confidence interval, 0.24–0.87; <i>P</i>=0.014; adjusted RR=0.75%; number needed to treat=134) compared with enoxaparin.</p></sec><sec><title>Conclusions:</title><p>Among hospitalized medically ill patients, extended-duration betrixaban significantly reduced all-cause stroke and ischemic stroke through 77 days of follow-up</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01583218.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/7/648
10.1161/CIRCULATIONAHA.116.025427
None

