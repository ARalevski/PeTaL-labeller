15
Circulation
Association of Bystander Cardiopulmonary Resuscitation and Survival According to Ambulance Response Times After Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Bystander-initiated cardiopulmonary resuscitation (CPR) increases patient <strong><span style="color:yellowgreen">surviv</span></strong>al after out-of-hospital cardiac arrest, but it is unknown to what degree bystander CPR remains positively associated with <strong><span style="color:yellowgreen">surviv</span></strong>al with increasing time to potential defibrillation. The main objective was to examine the association of bystander CPR with <strong><span style="color:yellowgreen">surviv</span></strong>al as time to advanced treatment increases.</p></sec><sec><title>Methods:</title><p>We studied 7623 out-of-hospital cardiac arrest patients between 2005 and 2011, identified through the nationwide Danish Cardiac Arrest Registry. Multiple logistic regression analysis was used to examine the association between time from 911 call to emergency medical service arrival (response time) and <strong><span style="color:yellowgreen">surviv</span></strong>al according to whether bystander CPR was provided (yes or no). Reported are 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al chances with 95% bootstrap confidence intervals.</p></sec><sec><title>Results:</title><p>With increasing response times, adjusted 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al chances decreased for both patients with bystander CPR and those without. However, the contrast between the <strong><span style="color:yellowgreen">surviv</span></strong>al chances of patients with versus without bystander CPR increased over time: within 5 minutes, 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al was 14.5% (95% confidence interval [CI]: 12.8–16.4) versus 6.3% (95% CI: 5.1–7.6), corresponding to 2.3 times higher chances of <strong><span style="color:yellowgreen">surviv</span></strong>al associated with bystander CPR; within 10 minutes, 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al chances were 6.7% (95% CI: 5.4–8.1) versus 2.2% (95% CI: 1.5–3.1), corresponding to 3.0 times higher chances of 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al associated with bystander CPR. The contrast in 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al became statistically insignificant when response time was >13 minutes (bystander CPR vs no bystander CPR: 3.7% [95% CI: 2.2–5.4] vs 1.5% [95% CI: 0.6–2.7]), but 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al was still 2.5 times higher associated with bystander CPR. Based on the model and Danish out-of-hospital cardiac arrest statistics, an additional 233 patients could potentially be saved annually if response time was reduced from 10 to 5 minutes and 119 patients if response time was reduced from 7 (the median response time in this study) to 5 minutes.</p></sec><sec><title>Conclusions:</title><p>The absolute <strong><span style="color:yellowgreen">surviv</span></strong>al associated with bystander CPR declined rapidly with time. Yet bystander CPR while waiting for an ambulance was associated with a more than doubling of 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al even in case of long ambulance response time. Decreasing ambulance response time by even a few minutes could potentially lead to many additional lives saved every year.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2095
10.1161/CIRCULATIONAHA.116.024400
None

10
Molecular Biology and Evolution
Dynamic Convergent Evolution Drives the Passage Adaptation across 48 Years’ History of H3N2 Influenza Evolution
<p>Influenza viruses are often propagated in a diverse set of culturing media and additional substitutions known as passage <strong><span style="color:yellowgreen">adapt</span></strong>ation can cause extra evolution in the target strain, leading to ineffective vaccines. Using 25,482 H3N2 HA1 sequences curated from Global Initiative on Sharing All Influenza Data and National Center for Biotechnology Information databases, we found that passage <strong><span style="color:yellowgreen">adapt</span></strong>ation is a very dynamic process that changes over time and evolves in a seesaw like pattern. After crossing the species boundary from bird to human in 1968, the influenza H3N2 virus evolves to be better <strong><span style="color:yellowgreen">adapt</span></strong>ed to the human environment and passaging them in embryonated eggs (i.e., an avian environment) leads to increasingly stronger positive selection. On the contrary, passage <strong><span style="color:yellowgreen">adapt</span></strong>ation to the mammalian cell lines changes from positive selection to negative selection. Using two statistical tests, we identified 19 codon positions around the receptor binding domain strongly contributing to passage <strong><span style="color:yellowgreen">adapt</span></strong>ation in the embryonated egg. These sites show strong convergent evolution and overlap extensively with positively selected sites identified in humans, suggesting that passage <strong><span style="color:yellowgreen">adapt</span></strong>ation can confound many of the earlier studies on influenza evolution. Interestingly, passage <strong><span style="color:yellowgreen">adapt</span></strong>ation in recent years seems to target a few codon positions in antigenic surface epitopes, which makes it difficult to produce antigenically unaltered vaccines using embryonic eggs. Our study outlines another interesting scenario whereby both convergent and <strong><span style="color:yellowgreen">adapt</span></strong>ive evolution are working in synchrony driving viral <strong><span style="color:yellowgreen">adapt</span></strong>ation. Future studies from sequence analysis to vaccine production need to take careful consideration of passage <strong><span style="color:yellowgreen">adapt</span></strong>ation.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3133
10.1093/molbev/msw190
['human', 'bird']

10
The Bone & Joint Journal
Does a less intensive surveillance protocol affect the survival of patients after treatment of a sarcoma of the limb?
<sec><title>Aims</title><p>A single-centre prospective randomized trial was conducted to   investigate whether a less intensive follow-up protocol would not   be inferior to a conventional follow-up protocol, in terms of overall   <strong><span style="color:yellowgreen">surviv</span></strong>al, in patients who have undergone surgery for sarcoma of   the limb. Initial short-term results were published in 2014.</p></sec><sec><title>Patients and Methods</title><p>The primary objective was to show non-inferiority of a chest   radiograph (CXR) group compared with a CT scan group, and of a less   frequent (six-monthly) group than a more frequent (three-monthly)   group, in two-by-two comparison. The primary outcome was overall   <strong><span style="color:yellowgreen">surviv</span></strong>al and the secondary outcome was a recurrence-free <strong><span style="color:yellowgreen">surviv</span></strong>al.   Five-year <strong><span style="color:yellowgreen">surviv</span></strong>al was compared between the CXR and CT scan groups   and between the three-monthly and six-monthly groups. Of 500 patients   who were enrolled, 476 were available for follow-up. <strong><span style="color:yellowgreen">surviv</span></strong>al analyses   were performed on a per-protocol basis (n = 412).</p></sec><sec><title>Results</title><p>The updated results recorded 12 (2.4%) local recurrences, 182   (36.8%) metastases, and 56 (11.3%) combined (local + metastases)   recurrence at a median follow-up of 81 months (60 to 118). Of 68   local recurrences, 60 (88%) were identified by the patients themselves.   The six-monthly regime (overall <strong><span style="color:yellowgreen">surviv</span></strong>al (OS) 54%, recurrence-free   <strong><span style="color:yellowgreen">surviv</span></strong>al (RFS) 46%) did not lead to a worse <strong><span style="color:yellowgreen">surviv</span></strong>al and was not   inferior to the three-monthly regime (OS 55%, RFS 47%) in terms   of detecting recurrence. Although CT scans (OS 53%, RFS 54%) detected   pulmonary metastasis earlier, it did not lead to a better <strong><span style="color:yellowgreen">surviv</span></strong>al   compared with CXR (OS 56%, RFS 59%).</p></sec><sec><title>Conclusion</title><p>The overall <strong><span style="color:yellowgreen">surviv</span></strong>al of patients who are treated for a sarcoma   of the limb is not inferior to those followed up with a less intensive   regimen than a more intensive protocol, in terms of frequency of   visits and mode of imaging. CXR at six-monthly intervals and patient   education about examination of the site of the surgery will detect   most recurrences without deleterious effects on the eventual outcome.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:262–8.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/262
10.1302/0301-620X.100B2.BJJ-2017-0789.R1
None

9
Circulation
Association Between Prompt Defibrillation and Epinephrine Treatment With Long-Term Survival After In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Prior studies have reported higher in-hospital <strong><span style="color:yellowgreen">surviv</span></strong>al with prompt defibrillation and epinephrine treatment in patients with in-hospital cardiac arrest (IHCA). Whether this <strong><span style="color:yellowgreen">surviv</span></strong>al benefit persists after discharge is unknown.</p></sec><sec><title>Methods:</title><p>We linked data from a national IHCA registry with Medicare files and identified 36 961 patients ≥65 years of age with an IHCA at 517 hospitals between 2000 and 2011. Patients with IHCA caused by pulseless ventricular tachycardia or ventricular fibrillation were stratified by prompt (≤2 minutes) versus delayed (>2 minutes) defibrillation, whereas patients with IHCA caused by asystole or pulseless electric activity were stratified by prompt (≤5 minutes) versus delayed (>5 minutes) epinephrine treatment. The association between prompt treatment and long-term <strong><span style="color:yellowgreen">surviv</span></strong>al for each rhythm type was assessed with multivariable hierarchical modified Poisson regression models.</p></sec><sec><title>Results:</title><p>Of 8119 patients with an IHCA caused by ventricular tachycardia or ventricular fibrillation, the rate of 1-year <strong><span style="color:yellowgreen">surviv</span></strong>al was higher in those treated with prompt defibrillation than with delayed defibrillation (25.7% [1466 of 5714] versus 15.5% [373 of 2405]; adjusted relative risk [RR], 1.49; 95% confidence interval [CI] 1.32–1.69; <i>P</i><0.0001). This <strong><span style="color:yellowgreen">surviv</span></strong>al advantage persisted at 3 years (19.1% versus 11.0%; adjusted RR, 1.45; 95% CI, 1.23–1.69; <i>P</i><0.0001) and at 5 years (14.7% versus 7.9%; adjusted RR, 1.50; 95% CI, 1.22–1.83; <i>P</i><0.0001). Of 28 842 patients with an IHCA caused by asystole/pulseless electric activity, the rate of 1-year <strong><span style="color:yellowgreen">surviv</span></strong>al with prompt epinephrine treatment was higher than with delayed treatment (5.4% [1341 of 24 885] versus 4.3% [168 of 3957]; adjusted RR, 1.20; 95% CI, 1.02–1.41; <i>P</i>=0.02), but this <strong><span style="color:yellowgreen">surviv</span></strong>al benefit was no longer present at 3 years (3.5% versus 2.9%; adjusted RR, 1.17; 95% CI, 0.95–1.45; <i>P</i>=0.15) and at 5 years (2.3% versus 1.9%; adjusted RR, 1.18; 95% CI, 0.88–1.58; <i>P</i>=0.27).</p></sec><sec><title>Conclusions:</title><p>Prompt defibrillation for IHCA caused by ventricular tachycardia or ventricular fibrillation was associated with higher rates of long-term <strong><span style="color:yellowgreen">surviv</span></strong>al throughout 5 years of follow-up, whereas prompt epinephrine treatment for asystole/pulseless electric activity was associated with greater <strong><span style="color:yellowgreen">surviv</span></strong>al at 1 year but not at 3 or 5 years. By quantifying the greater <strong><span style="color:yellowgreen">surviv</span></strong>al associated with timely defibrillation and epinephrine administration, these findings provide important insights into the durability of <strong><span style="color:yellowgreen">surviv</span></strong>al benefits for 2 process-of-care measures in current resuscitation guidelines.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/19/2041
10.1161/CIRCULATIONAHA.117.030488
None

9
Circulation
Hospital Variation in Time to Epinephrine for Nonshockable In-Hospital Cardiac Arrest
<sec><title>Background:</title><p>For patients with in-hospital cardiac arrests attributable to nonshockable rhythms, delays in epinephrine administration beyond 5 minutes is associated with worse <strong><span style="color:yellowgreen">surviv</span></strong>al. However, the extent of hospital variation in delayed epinephrine administration and its effect on hospital-level outcomes is unknown.</p></sec><sec><title>Methods:</title><p>Within Get With The Guidelines-Resuscitation, we identified 103 932 adult patients (≥18 years) at 548 hospitals with an in-hospital cardiac arrest attributable to a nonshockable rhythm who received at least 1 dose of epinephrine between 2000 and 2014. We constructed 2-level hierarchical regression models to quantify hospital variation in rates of delayed epinephrine administration (>5 minutes) and its association with hospital rates of <strong><span style="color:yellowgreen">surviv</span></strong>al to discharge and <strong><span style="color:yellowgreen">surviv</span></strong>al with functional recovery.</p></sec><sec><title>Results:</title><p>Overall, 13 213 (12.7%) patients had delays to epinephrine, and this rate varied markedly across hospitals (range, 0%–53.8%). The odds of delay in epinephrine administration were 58% higher at 1 randomly selected hospital in comparison with a similar patient at another randomly selected hospital (median odds ratio, 1.58; 95% confidence interval, 1.51–1.64). The median risk-standardized <strong><span style="color:yellowgreen">surviv</span></strong>al rate was 12.0% (range, 5.4%–31.9%), and the risk-standardized <strong><span style="color:yellowgreen">surviv</span></strong>al with functional recovery was 7.4% (range, 0.9%–30.8%). There was an inverse correlation between a hospital’s rate of delayed epinephrine administration and its risk-standardized rate of <strong><span style="color:yellowgreen">surviv</span></strong>al to discharge (ρ=–0.22, <i>P</i><0.0001) and <strong><span style="color:yellowgreen">surviv</span></strong>al with functional recovery (ρ=–0.14, <i>P</i>=0.001). In comparison with a median <strong><span style="color:yellowgreen">surviv</span></strong>al rate of 12.9% (interquartile range, 11.1%–15.4%) at hospitals in the lowest quartile of epinephrine delay, risk-standardized <strong><span style="color:yellowgreen">surviv</span></strong>al was 16% lower at hospitals in the quartile with the highest rate of epinephrine delays (10.8%; interquartile range, 9.7%–12.7%).</p></sec><sec><title>Conclusions:</title><p>Delays in epinephrine administration following in-hospital cardiac arrest are common and variy across hospitals. Hospitals with high rates of delayed epinephrine administration had lower rates of overall <strong><span style="color:yellowgreen">surviv</span></strong>al for in-hospital cardiac arrest attributable to nonshockable rhythm. Further studies are needed to determine whether improving hospital performance on time to epinephrine administration, especially at hospitals with poor performance on this metric, will lead to improved outcomes.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2105
10.1161/CIRCULATIONAHA.116.025459
None

8
Circulation
The Optimal Timing of Stage 2 Palliation for Hypoplastic Left Heart Syndrome
<sec><title>Background:</title><p>In infants requiring 3-stage single-ventricle palliation for hypoplastic left heart syndrome, attrition after the Norwood procedure remains significant. The effect of the timing of stage 2 palliation (S2P), a physician-modifiable factor, on long-term <strong><span style="color:yellowgreen">surviv</span></strong>al is not well understood. We hypothesized that an optimal interval between the Norwood and S2P that both minimizes pre-S2P attrition and maximizes post-S2P <strong><span style="color:yellowgreen">surviv</span></strong>al exists and is associated with individual patient characteristics.</p></sec><sec><title>Methods:</title><p>The National Institutes of Health/National Heart, Lung, and Blood Institute Pediatric Heart Network Single Ventricle Reconstruction Trial public data set was used. Transplant-free <strong><span style="color:yellowgreen">surviv</span></strong>al (TFS) was modeled from (1) Norwood to S2P and (2) S2P to 3 years by using parametric hazard analysis. Factors associated with death or heart transplantation were determined for each interval. To account for staged procedures, risk-adjusted, 3-year, post-Norwood TFS (the probability of TFS at 3 years given <strong><span style="color:yellowgreen">surviv</span></strong>al to S2P) was calculated using parametric conditional <strong><span style="color:yellowgreen">surviv</span></strong>al analysis. TFS from the Norwood to S2P was first predicted. TFS after S2P to 3 years was then predicted and adjusted for attrition before S2P by multiplying by the estimate of TFS to S2P. The optimal timing of S2P was determined by generating nomograms of risk-adjusted, 3-year, post-Norwood, TFS versus the interval from the Norwood to S2P.</p></sec><sec><title>Results:</title><p>Of 547 included patients, 399 <strong><span style="color:yellowgreen">surviv</span></strong>ed to S2P (73%). Of the <strong><span style="color:yellowgreen">surviv</span></strong>ors to S2P, 349 (87%) <strong><span style="color:yellowgreen">surviv</span></strong>ed to 3-year follow-up. The median interval from the Norwood to S2P was 5.1 (interquartile range, 4.1–6.0) months. The risk-adjusted, 3-year, TFS was 68±7%. A Norwood-S2P interval of 3 to 6 months was associated with greatest 3-year TFS overall and in patients with few risk factors. In patients with multiple risk factors, TFS was severely compromised, regardless of the timing of S2P and most severely when S2P was performed early. No difference in the optimal timing of S2P existed when stratified by shunt type.</p></sec><sec><title>Conclusions:</title><p>In infants with few risk factors, progressing to S2P at 3 to 6 months after the Norwood procedure was associated with maximal TFS. Early S2P did not rescue patients with greater risk factor burdens. Instead, referral for heart transplantation may offer their best chance at long-term <strong><span style="color:yellowgreen">surviv</span></strong>al.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00115934.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1737
10.1161/CIRCULATIONAHA.117.028481
None

8
Circulation
Long-Term Outcomes and Prognostic Factors of Complications in Takayasu Arteritis
<sec><title>Background:</title><p>Because of the wide variation in the course of Takayasu arteritis (TA), predicting outcome is challenging. We assess long-term outcome and prognosis factors for vascular complications in patients with TA.</p></sec><sec><title>Methods:</title><p>A retrospective multicenter study of characteristics and outcomes of 318 patients with TA fulfilling American College of Rheumatology and Ishikawa criteria was analyzed. Factors associated with event-free <strong><span style="color:yellowgreen">surviv</span></strong>al, relapse-free <strong><span style="color:yellowgreen">surviv</span></strong>al, and incidences of vascular complications were assessed. Risk factors for vascular complications were identified in a multivariable model.</p></sec><sec><title>Results:</title><p>The median age at TA diagnosis was 36 [25–47] years, and 276 patients (86.8%) were women. After a median follow-up of 6.1 years, relapses were observed in 43%, vascular complications in 38%, and death in 5%. Progressive clinical course was observed in 45%, carotidodynia in 10%, and retinopathy in 4%. The 5- and 10-year event-free <strong><span style="color:yellowgreen">surviv</span></strong>al, relapse-free <strong><span style="color:yellowgreen">surviv</span></strong>al, and complication-free <strong><span style="color:yellowgreen">surviv</span></strong>al were 48.2% (42.2; 54.9) and 36.4% (30.3; 43.9), 58.6% (52.7; 65.1) and 47.7% (41.2; 55.1), and 69.9% (64.3; 76.0) and 53.7% (46.8; 61.7), respectively. Progressive disease course (<i>P</i>=0.018) and carotidynia (<i>P</i>=0.036) were independently associated with event-free <strong><span style="color:yellowgreen">surviv</span></strong>al. Male sex (<i>P</i>=0.048), elevated C-reactive protein (<i>P</i>=0.013), and carotidynia (<i>P</i>=0.003) were associated with relapse-free <strong><span style="color:yellowgreen">surviv</span></strong>al. Progressive disease course (<i>P</i>=0.017), thoracic aorta involvement (<i>P</i>=0.009), and retinopathy (<i>P</i>=0.002) were associated with complication-free <strong><span style="color:yellowgreen">surviv</span></strong>al.</p></sec><sec><title>Conclusions:</title><p>This nationwide study shows that 50% of patients with TA will relapse and experience a vascular complication ≤10 years from diagnosis. We identified specific characteristics that identified those at highest risk for subsequent vascular complications.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/12/1114
10.1161/CIRCULATIONAHA.116.027094
None

7
The Bone & Joint Journal
Long-term survival and risk factors for failure of the native hip joint after operatively treated displaced acetabular fractures
<sec><title>Aims</title><p>Our aim in this study was to describe the long-term <strong><span style="color:yellowgreen">surviv</span></strong>al   of the native hip joint after open reduction and internal fixation   of a displaced fracture of the acetabulum. We also present long-term   clinical outcomes and risk factors associated with a poor outcome.</p></sec><sec><title>Patients and Methods</title><p>A total of 285 patients underwent surgery for a displaced acetabular   fracture between 1993 and 2005. For the <strong><span style="color:yellowgreen">surviv</span></strong>al analysis 253 were   included, there were 197 men and 56 women with a mean age of 42   years (12 to 78). The mean follow-up of 11 years (1 to 20) was identified   from our pelvic fracture registry. There were 99 elementary and 154   associated fracture types. For the long-term clinical follow-up,   192 patients with complete data were included. Their mean age was   40 years (13 to 78) with a mean follow-up of 12 years (5 to 20).   Injury to the femoral head and acetabular impaction were assessed   with CT scans and patients with an ipsilateral fracture of the femoral   head were excluded.</p></sec><sec><title>Results</title><p>A total of 36 patients underwent total hip arthroplasty (THA).   The overall ten-year <strong><span style="color:yellowgreen">surviv</span></strong>al of the hip joint was 86% (95% confidence   interval (CI) 81% to 90%) and the 20-year <strong><span style="color:yellowgreen">surviv</span></strong>al was 82% (95%   CI 76% to 87%). Injury to the femoral head and acetabular impaction   were the strongest predictors of failure, with the long-term <strong><span style="color:yellowgreen">surviv</span></strong>al   rate falling towards 50% in these patients. The <strong><span style="color:yellowgreen">surviv</span></strong>al fell to   0% at three years when both these risk factors were present in patients   aged > 60 years.</p></sec><sec><title>Conclusion</title><p>The long-term <strong><span style="color:yellowgreen">surviv</span></strong>al of the native hip joint after acetabular   fractures was good, but the presence of injury to the femoral head   and acetabular impaction proved to be strong predictors of failure,   especially in patients aged > 60 years. These patients may be better   treated with a combination of open reduction and internal fixation   and primary arthroplasty.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:834–40.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/6/834
10.1302/0301-620X.99B6.BJJ-2016-1013.R1
None

7
Circulation
Nationwide Study of the Treatment of Mycotic Abdominal Aortic Aneurysms Comparing Open and Endovascular Repair
<sec><title>Background:</title><p>No reliable comparative data exist between open repair (OR) and endovascular aneurysm repair (EVAR) for mycotic abdominal aortic aneurysms (MAAAs). This nationwide study assessed outcomes after OR and EVAR for MAAA in a population-based cohort.</p></sec><sec><title>Methods:</title><p>All patients treated for MAAAs in Sweden between 1994 and 2014 were identified in the Swedish vascular registry. The primary aim was to assess <strong><span style="color:yellowgreen">surviv</span></strong>al after MAAA with OR and EVAR. Secondary aims were analyses of the rate of recurrent infections and reoperations, and time trends in surgical treatment. <strong><span style="color:yellowgreen">surviv</span></strong>al was analyzed using Kaplan-Meier and log-rank tests. A propensity score–weighted correction for risk factor differences in the 2 groups was performed, including the operation year to account for differences in treatment and outcomes over time.</p></sec><sec><title>Results:</title><p>We identified 132 patients (0.6% of all operated abdominal aortic aneurysms in Sweden). Mean age was 70 years (standard deviation, 9.2), and 50 presented with rupture. <strong><span style="color:yellowgreen">surviv</span></strong>al at 3 months was 86% (95% confidence interval, 80%–92%), at 1 year 79% (72%–86%), and at 5 years 59% (50%–68%). The preferred operative technique shifted from OR to EVAR after 2001 (proportion EVAR 1994–2000 0%, 2001–2007 58%, 2008–2014 60%). Open repair was performed in 62 patients (47%): aortic resection and extra-anatomic bypass (n=7), in situ reconstruction (n=50), and patch plasty (n=3); 2 patients died intraoperatively. EVAR was performed in 70 patients (53%): standard EVAR (n=55), fenestrated/branched EVAR (n=8), and visceral deviation with stent grafting (n=7); no deaths occurred intraoperatively. <strong><span style="color:yellowgreen">surviv</span></strong>al at 3 months was lower for OR than for EVAR (74% versus 96%, <i>P</i><0.001), with a similar trend present at 1 year (73% versus 84%, <i>P</i>=0.054). A propensity score–weighted risk-adjusted analysis confirmed the early better <strong><span style="color:yellowgreen">surviv</span></strong>al associated with EVAR. During median follow-up of 36 and 41 months for OR and EVAR, respectively, there was no difference in long-term <strong><span style="color:yellowgreen">surviv</span></strong>al (5 years 60% versus 58%, <i>P</i>=0.771), infection-related complications (18% versus 24%, <i>P</i>=0.439), or reoperation (21% versus 24%, <i>P</i>=0.650).</p></sec><sec><title>Conclusion:</title><p>This study demonstrates a paradigm shift in treatment of MAAA in Sweden, with EVAR being the preferred treatment modality. EVAR was associated with improved short-term <strong><span style="color:yellowgreen">surviv</span></strong>al in comparison with OR, without higher associated incidence of serious infection-related complications or reoperations.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/23/1822
10.1161/CIRCULATIONAHA.116.024021
None

6
The Bone & Joint Journal
Long-term outcomes of cemented <i>versus</i> cementless humeral components in arthroplasty of the shoulder
<sec><title>Aims</title><p>In the initial development of total shoulder arthroplasty (TSA),   the humeral component was usually fixed with cement. Cementless   components were subsequently introduced. The aim of this study was   to compare the long-term outcome of cemented and cementless humeral   components in arthroplasty of the shoulder.</p></sec><sec><title>Patients and Methods</title><p>All patients who underwent primary arthroplasty of the shoulder   at our institution between 1970 and 2012 were included in the study.   There were 4636 patients with 1167 cemented humeral components and   3469 cementless components. Patients with the two types of fixation   were matched for nine different covariates using a propensity score   analysis. A total of 551 well-balanced pairs of patients with cemented   and cementless components were available after matching for comparison   of the outcomes. The clinical outcomes which were analysed included loosening   of the humeral component determined at revision surgery, periprosthetic   fractures, post-operative infection and operating time.</p></sec><sec><title>Results</title><p>The overall five-, ten-, 15- and 20-year rates of <strong><span style="color:yellowgreen">surviv</span></strong>al were   98.9%, 97.2%, 95.5%, and 94.4%, respectively. <strong><span style="color:yellowgreen">surviv</span></strong>al without loosening   at 20 years was 98% for cemented components and 92.4% for cementless   components. After propensity score matching including fixation as   determined by the design of the component, humeral loosening was   also found to be significantly higher in the cementless group. <strong><span style="color:yellowgreen">surviv</span></strong>al   without humeral loosening at 20 years was 98.7% for cemented components   and 91.0% for cementless components. There was no significant difference   in the risk of intra- or post-operative fracture. The rate of <strong><span style="color:yellowgreen">surviv</span></strong>al   without deep infection and the mean operating time were significantly   higher in the cemented group.</p></sec><sec><title>Conclusion</title><p>Both types of fixation give rates of long-term <strong><span style="color:yellowgreen">surviv</span></strong>al of >   90%. Cemented components have better rates of <strong><span style="color:yellowgreen">surviv</span></strong>al without loosening   but this should be weighed against increased operating time and   the risk of bony destruction of the proximal humerus at the time   of revision of a cemented humeral component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:666–73.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/666
10.1302/0301-620X.99B5.BJJ-2016-0910.R1
None

6
The Bone & Joint Journal
Anterior knee pain and evidence of osteoarthritis of the patellofemoral joint should not be considered contraindications to mobile-bearing unicompartmental knee arthroplasty
<sec><title>Aims</title><p>It is not clear whether anterior knee pain and osteoarthritis   (OA) of the patellofemoral joint (PFJ) are contraindications to   medial unicompartmental knee arthroplasty (UKA). Our aim was to   investigate the long-term outcome of a consecutive series of patients,   some of whom had anterior knee pain and PFJ OA managed with UKA.</p></sec><sec><title>Patients and Methods</title><p>We assessed the ten-year functional outcomes and 15-year implant   <strong><span style="color:yellowgreen">surviv</span></strong>al of 805 knees (677 patients) following medial mobile-bearing   UKA. The intra-operative status of the PFJ was documented and, with   the exception of bone loss with grooving to the lateral side, neither   the clinical or radiological state of the PFJ nor the presence of   anterior knee pain were considered a contraindication. The impact   of radiographic findings and anterior knee pain was studied in a   subgroup of 100 knees (91 patients).</p></sec><sec><title>Results</title><p>There was no relationship between functional outcomes, at a mean   of ten years, or 15-year implant <strong><span style="color:yellowgreen">surviv</span></strong>al, and pre-operative anterior   knee pain, or the presence or degree of cartilage loss documented   intra-operatively at the medial patella or trochlea, or radiographic   evidence of OA in the medial side of the PFJ. In 6% of cases there   was full thickness cartilage loss on the lateral side of the patella.   In these cases, the overall ten-year function and 15-year <strong><span style="color:yellowgreen">surviv</span></strong>al   was similar to those without cartilage loss; however they had slightly   more difficulty with descending stairs. Radiographic signs of OA   seen in the lateral part of the PFJ were not associated with a definite   compromise in functional outcome or implant <strong><span style="color:yellowgreen">surviv</span></strong>al.</p></sec><sec><title>Conclusion</title><p>Severe damage to the lateral side of the PFJ with bone loss and   grooving remains a contraindication to mobile-bearing UKA. Less   severe damage to the lateral side of the PFJ and damage to the medial   side, however severe, does not compromise the overall function or   <strong><span style="color:yellowgreen">surviv</span></strong>al, so should not be considered to be a contraindication. However,   if a patient does have full thickness cartilage loss on the lateral   side of the PFJ they may have a slight compromise in their ability   to descend stairs. Pre-operative anterior knee pain also does not   compromise the functional outcome or <strong><span style="color:yellowgreen">surviv</span></strong>al and should not be   considered to be a contraindication.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:632–9</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/632
10.1302/0301-620X.99B5.BJJ-2016-0695.R2
None

6
Circulation
Impact of Bystander Automated External Defibrillator Use on Survival and Functional Outcomes in Shockable Observed Public Cardiac Arrests
<sec><title>Background:</title><p><strong><span style="color:yellowgreen">surviv</span></strong>al following out-of-hospital cardiac arrest (OHCA) with shockable rhythms can be improved with early defibrillation. Although shockable OHCA accounts for only ≈25% of overall arrests, ≈60% of public OHCAs are shockable, offering the possibility of restoring thousands of individuals to full recovery with early defibrillation by bystanders. We sought to determine the association of bystander automated external defibrillator use with <strong><span style="color:yellowgreen">surviv</span></strong>al and functional outcomes in shockable observed public OHCA.</p></sec><sec><title>Methods:</title><p>From 2011 to 2015, the Resuscitation Outcomes Consortium prospectively collected detailed information on all cardiac arrests at 9 regional centers. The exposures were shock administration by a bystander-applied automated external defibrillator in comparison with initial defibrillation by emergency medical services. The primary outcome measure was discharge with normal or near-normal (favorable) functional status defined as a modified Rankin Score ≤2. <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge was the secondary outcome measure.</p></sec><sec><title>Results:</title><p>Among 49 555 OHCAs, 4115 (8.3%) observed public OHCAs were analyzed, of which 2500 (60.8%) were shockable. A bystander shock was applied in 18.8% of the shockable arrests. Patients shocked by a bystander were significantly more likely to <strong><span style="color:yellowgreen">surviv</span></strong>e to discharge (66.5% versus 43.0%) and be discharged with favorable functional outcome (57.1% versus 32.7%) than patients initially shocked by emergency medical services. After adjusting for known predictors of outcome, the odds ratio associated with a bystander shock was 2.62 (95% confidence interval, 2.07–3.31) for <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge and 2.73 (95% confidence interval, 2.17–3.44) for discharge with favorable functional outcome. The benefit of bystander shock increased progressively as emergency medical services response time became longer.</p></sec><sec><title>Conclusions:</title><p>Bystander automated external defibrillator use before emergency medical services arrival in shockable observed public OHCA was associated with better <strong><span style="color:yellowgreen">surviv</span></strong>al and functional outcomes. Continued emphasis on public automated external defibrillator utilization programs may further improve outcomes of OHCA.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/20/2104
10.1161/CIRCULATIONAHA.117.030700
None

6
Circulation
Time to Epinephrine Administration and Survival From Nonshockable Out-of-Hospital Cardiac Arrest Among Children and Adults
<sec><title>Background:</title><p>Previous studies have demonstrated that earlier epinephrine administration is associated with improved <strong><span style="color:yellowgreen">surviv</span></strong>al from out-of-hospital cardiac arrest (OHCA) with shockable initial rhythms. However, the effect of epinephrine timing on patients with nonshockable initial rhythms is unclear. The objective of this study was to measure the association between time to epinephrine administration and <strong><span style="color:yellowgreen">surviv</span></strong>al in adults and children with emergency medical services (EMS)–treated OHCA with nonshockable initial rhythms.</p></sec><sec><title>Methods:</title><p>We performed a secondary analysis of OHCAs prospectively identified by the Resuscitation Outcomes Consortium network from June 4, 2011, to June 30, 2015. We included patients of all ages with an EMS-treated OHCA and an initial nonshockable rhythm. We excluded those with return of spontaneous circulation in <10 minutes. We conducted a subgroup analysis involving patients <18 years of age. The primary exposure was time (minutes) from arrival of the first EMS agency to the first dose of epinephrine. Secondary exposure was time to epinephrine dichotomized as early (<10 minutes) or late (≥10 minutes). The primary outcome was <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge. We adjusted for Utstein covariates and Resuscitation Outcomes Consortium study site.</p></sec><sec><title>Results:</title><p>From 55 568 EMS-treated OHCAs, 32 101 patients with initial nonshockable rhythms were included. There were 12 238 in the early group, 14 517 in the late group, and 5346 not treated with epinephrine. After adjusting for potential confounders, each minute from EMS arrival to epinephrine administration was associated with a 4% decrease in odds of <strong><span style="color:yellowgreen">surviv</span></strong>al for adults, odds ratio=0.96 (95% confidence interval, 0.95–0.98). A subgroup analysis (n=13 290) examining neurological outcomes showed a similar association (adjusted odds ratio, 0.94 per minute; 95% confidence interval, 0.89–0.98). When epinephrine was given late in comparison with early, odds of <strong><span style="color:yellowgreen">surviv</span></strong>al were 18% lower (odds ratio, 0.82; 95% confidence interval, 0.68–0.98). In a pediatric analysis (n=595), odds of <strong><span style="color:yellowgreen">surviv</span></strong>al were 9% lower (odds ratio, 0.91; 95% confidence interval, 0.81–1.01) for each minute delay in epinephrine.</p></sec><sec><title>Conclusions:</title><p>Among OHCAs with nonshockable initial rhythms, the majority of patients were administered epinephrine >10 minutes after EMS arrival. Each minute delay in epinephrine administration was associated with decreased <strong><span style="color:yellowgreen">surviv</span></strong>al and unfavorable neurological outcomes. EMS agencies should consider strategies to reduce epinephrine administration times in patients with initial nonshockable rhythms.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/19/2032
10.1161/CIRCULATIONAHA.117.033067
None

6
Circulation
Association Between Duration of Resuscitation and Favorable Outcome After Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Little evidence guides the appropriate duration of resuscitation in out-of-hospital cardiac arrest, and case features justifying longer or shorter durations are ill defined. We estimated the impact of resuscitation duration on the probability of favorable functional outcome in out-of-hospital cardiac arrest using a large, multicenter cohort.</p></sec><sec><title>Methods:</title><p>This was a secondary analysis of a North American, single-blind, multicenter, cluster-randomized, clinical trial (ROC-PRIMED [Resuscitation Outcomes Consortium Prehospital Resuscitation Using an Impedance Valve and Early Versus Delayed]) of consecutive adults with nontraumatic, emergency medical services–treated out-of-hospital cardiac arrest. Primary exposure was duration of resuscitation in minutes (onset of professional resuscitation to return of spontaneous circulation [ROSC] or termination of resuscitation). Primary outcome was <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge with favorable outcome (modified Rankin scale [mRS] score of 0–3). Subjects were additionally classified as <strong><span style="color:yellowgreen">surviv</span></strong>al with unfavorable outcome (mRS score of 4–5), ROSC without <strong><span style="color:yellowgreen">surviv</span></strong>al (mRS score of 6), or without ROSC. Subject accrual was plotted as a function of resuscitation duration, and the dynamic probability of favorable outcome at discharge was estimated for the whole cohort and subgroups. Adjusted logistic regression models tested the association between resuscitation duration and <strong><span style="color:yellowgreen">surviv</span></strong>al with favorable outcome.</p></sec><sec><title>Results:</title><p>The primary cohort included 11 368 subjects (median age, 69 years [interquartile range, 56–81 years]; 7121 men [62.6%]). Of these, 4023 (35.4%) achieved ROSC, 1232 (10.8%) <strong><span style="color:yellowgreen">surviv</span></strong>ed to hospital discharge, and 905 (8.0%) had an mRS score of 0 to 3 at discharge. Distribution of cardiopulmonary resuscitation duration differed by outcome (<i>P</i><0.00001). For cardiopulmonary resuscitation duration up to 37.0 minutes (95% confidence interval, 34.9–40.9 minutes), 99% with an eventual mRS score of 0 to 3 at discharge achieved ROSC. The dynamic probability of an mRS score of 0 to 3 at discharge declined over elapsed resuscitation duration, but subjects with initial shockable cardiac rhythm, witnessed cardiac arrest, and bystander cardiopulmonary resuscitation were more likely to <strong><span style="color:yellowgreen">surviv</span></strong>e with favorable outcome after prolonged efforts (30–40 minutes). After adjustment for prehospital (odds ratio, 0.93; 95% confidence interval, 0.92–0.95) and inpatient (odds ratio, 0.97; 95% confidence interval, 0.95–0.99) covariates, resuscitation duration was associated with <strong><span style="color:yellowgreen">surviv</span></strong>al to discharge with an mRS score of 0 to 3.</p></sec><sec><title>Conclusions:</title><p>Shorter resuscitation duration was associated with likelihood of favorable outcome at hospital discharge. Subjects with favorable case features were more likely to <strong><span style="color:yellowgreen">surviv</span></strong>e prolonged resuscitation up to 47 minutes.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT00394706.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2084
10.1161/CIRCULATIONAHA.116.023309
None

5
Tree Physiology
Carbon dynamics of <i>Acer pseudoplatanus</i> seedlings under drought and complete darkness
<p>Carbon (C) storage is considered a key component to plant <strong><span style="color:yellowgreen">surviv</span></strong>al under drought and shade, although the combined effects of these factors on <strong><span style="color:yellowgreen">surviv</span></strong>al remain poorly understood. We investigated how drought and shade alter the C dynamics and <strong><span style="color:yellowgreen">surviv</span></strong>al of tree seedlings, and whether drought limits the access to or usage of stored C. We experimentally applied two levels of soil humidity (well-watered versus drought, the latter induced by dry-down) and light availability (light versus complete darkness) on 1-year-old seedlings of <i>Acer pseudoplatanus</i> L. for 3 months. We quantified the <strong><span style="color:yellowgreen">surviv</span></strong>al, biomass, growth rate and non-structural carbohydrates (NSC) of seedlings at their time of death or at the end of the experiment for those that <strong><span style="color:yellowgreen">surviv</span></strong>ed. We found that the soil dried out faster when drought was combined with light than when it was combined with complete darkness. Seedlings subjected to both drought and light showed reduced growth and reached 100% mortality earlier than any other treatment, with the highest NSC concentrations at the time of death. Seedlings exposed to both drought and complete darkness died significantly earlier than seedlings exposed to complete darkness only, but had similar NSC concentrations at time of their death, suggesting that drought accelerated the use of stored C under complete darkness. Complete darkness significantly reduced seedling growth and whole-plant NSC concentrations regardless of soil humidity, while root NSC concentrations were significantly more reduced when complete darkness was combined with drought conditions. Thus, the C dynamics in <i>A. pseudoplatanus</i> seedlings under complete darkness was not hindered by drought, i.e., the access and use of stored C was not limited by drought. The contrasting growth and C storage responses driven by drought under light versus complete darkness are consistent with a key role of the drought progression in the C dynamics of trees.</p>
http://treephys.oxfordjournals.org/cgi/content/abstract/36/11/1400
10.1093/treephys/tpw063
['Acer', 'Acer pseudoplatanus']

5
Science
The genomic landscape of rapid repeated evolutionary adaptation to toxic pollution in wild fish
<p>Atlantic killifish populations have rapidly <strong><span style="color:yellowgreen">adapt</span></strong>ed to normally lethal levels of pollution in four urban estuaries. Through analysis of 384 whole killifish genome sequences and comparative transcriptomics in four pairs of sensitive and tolerant populations, we identify the aryl hydrocarbon receptor–based signaling pathway as a shared target of selection. This suggests evolutionary constraint on <strong><span style="color:yellowgreen">adapt</span></strong>ive solutions to complex toxicant mixtures at each site. However, distinct molecular variants apparently contribute to <strong><span style="color:yellowgreen">adapt</span></strong>ive pathway modification among tolerant populations. Selection also targets other toxicity-mediating genes and genes of connected signaling pathways; this indicates complex tolerance phenotypes and potentially compensatory <strong><span style="color:yellowgreen">adapt</span></strong>ations. Molecular changes are consistent with selection on standing genetic variation. In killifish, high nucleotide diversity has likely been a crucial substrate for selective sweeps to propel rapid <strong><span style="color:yellowgreen">adapt</span></strong>ation.</p>
http://sciencemag.org/cgi/content/abstract/354/6317/1305
10.1126/science.aah4993
['fish']

5
Molecular Biology and Evolution
A Photoreceptor Contributes to the Natural Variation of Diapause Induction in <i>Daphnia magna</i>
<p>Diapause is an <strong><span style="color:yellowgreen">adapt</span></strong>ation that allows organisms to <strong><span style="color:yellowgreen">surviv</span></strong>e harsh environmental conditions. In species occurring over broad habitat ranges, both the timing and the intensity of diapause induction can vary across populations, revealing patterns of local <strong><span style="color:yellowgreen">adapt</span></strong>ation. Understanding the genetic architecture of this fitness-related trait would help clarify how populations <strong><span style="color:yellowgreen">adapt</span></strong> to their local environments. In the cyclical parthenogenetic crustacean <i>Daphnia magna</i>, diapause induction is a phenotypic plastic life history trait linked to sexual reproduction, as asexual females have the ability to switch to sexual reproduction and produce resting stages, their sole strategy for <strong><span style="color:yellowgreen">surviv</span></strong>ing habitat deterioration. We have previously shown that the induction of resting stage production correlates with changes in photoperiod that indicate the imminence of habitat deterioration and have identified a Quantitative Trait Locus (QTL) responsible for some of the variation in the induction of resting stages. Here, new data allows us to anchor the QTL to a large scaffold and then, using a combination of a new mapping panel, targeted association mapping and selection analysis in natural populations, to identify candidate genes within the QTL. Our results show that variation in a rhodopsin photoreceptor gene plays a significant role in the variation observed in resting stage induction. This finding provides a mechanistic explanation for the link between diapause and day-length perception that has been suggested in diverse arthropod taxa.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3194
10.1093/molbev/msw200
['Daphnia']

5
Molecular Biology and Evolution
Differential Codon Adaptation between dsDNA and ssDNA Phages in <i>Escherichia coli</i>
<p>Because phages use their host translation machinery, their codon usage should evolve toward that of highly expressed host genes. We used two indices to measure codon <strong><span style="color:yellowgreen">adapt</span></strong>ation of phages to their host, <i>r</i><sub>RSCU</sub> (the correlation in relative synonymous codon usage [RSCU] between phages and their host) and Codon <strong><span style="color:yellowgreen">adapt</span></strong>ation Index (CAI) computed with highly expressed host genes as the reference set (because phage translation depends on host translation machinery). These indices used for this purpose are appropriate only when hosts exhibit little mutation bias, so only phages parasitizing <i>Escherichia coli</i> were included in the analysis. For double-stranded DNA (dsDNA) phages, both <i>r</i><sub>RSCU</sub> and CAI decrease with increasing number of transfer RNA genes encoded by the phage genome. <i>r</i><sub>RSCU</sub> is greater for dsDNA phages than for single-stranded DNA (ssDNA) phages, and the low <i>r</i><sub>RSCU</sub> values are mainly due to poor concordance in RSCU values for Y-ending codons between ssDNA phages and the <i>E. coli</i> host, consistent with the predicted effect of C→T mutation bias in the ssDNA phages. Strong C→T mutation bias would improve codon <strong><span style="color:yellowgreen">adapt</span></strong>ation in codon families (e.g., Gly) where U-ending codons are favored over C-ending codons (“U-friendly” codon families) by highly expressed host genes but decrease codon <strong><span style="color:yellowgreen">adapt</span></strong>ation in other codon families where highly expressed host genes favor C-ending codons against U-ending codons (“U-hostile” codon families). It is remarkable that ssDNA phages with increasing C→T mutation bias also increased the usage of codons in the “U-friendly” codon families, thereby achieving CAI values almost as large as those of dsDNA phages. This represents a new type of codon <strong><span style="color:yellowgreen">adapt</span></strong>ation.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/31/6/1606
10.1093/molbev/msu087
['Escherichia', 'Escherichia coli']

5
The Bone & Joint Journal
The unsuspected prosthetic joint infection
<sec><title>Aims</title><p>Positive cultures are not uncommon in cases of revision total   knee and hip arthroplasty (TKA and THA) for presumed aseptic causes.   The purpose of this study was to assess the incidence of positive   intra-operative cultures in presumed aseptic revision of TKA and   THA, and to determine whether the presence of intra-operative positive cultures   results in inferior <strong><span style="color:yellowgreen">surviv</span></strong>al in such cases.</p></sec><sec><title>Patients and Methods</title><p>A retrospective cohort study was assembled with 679 patients   undergoing revision knee (340 cases) or hip arthroplasty (339 cases)   for presumed aseptic causes. For all patients three or more separate   intra-operative cultures were obtained. Patients were diagnosed   with a previously unsuspected prosthetic joint infection (PJI) if two   or more cultures were positive with the same organism. Records were   reviewed for demographic details, pre-operative laboratory results   and culture results. The primary outcome measure was infection-free   implant <strong><span style="color:yellowgreen">surviv</span></strong>al at two years.</p></sec><sec><title>Results</title><p>The incidence of unsuspected PJI was 27 out of 340 (7.9%) in   TKA and 41 out of 339 (12.1%) in THA. Following revision TKA, the   rate of infection-free implant <strong><span style="color:yellowgreen">surviv</span></strong>al in patients with an unsuspected   PJI was 88% (95% confidence intervals (CI) 60 to 97) at two years   compared with 98% (95% CI 94 to 99) in patients without PJI (p = 0.001).   After THA, the rate of <strong><span style="color:yellowgreen">surviv</span></strong>al was similar in those with unsuspected   PJI (92% (95% CI 73 to 98) at two years) and those without (94%   (95% CI 89 to 97), p = 0.31).</p></sec><sec><title>Conclusion</title><p>Following revision of TKA and THA for aseptic diagnoses, around   10% of cases were found to have positive cultures. In the knee,   such cases had inferior infection-free <strong><span style="color:yellowgreen">surviv</span></strong>al at two years compared   with those with negative cultures; there was no difference between   the groups following THA.</p><p>Cite this article: Bone Joint J 2017;99-B:1482–9.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1482
10.1302/0301-620X.99B11.BJJ-2016-0655.R2
None

5
The Bone & Joint Journal
Is limb salvage surgery safe for bone sarcomas identified after a previous surgical procedure?
<p>Bone sarcomas are rare cancers and orthopaedic   surgeons come across them infrequently, sometimes unexpectedly during   surgical procedures. We investigated the outcomes of patients who   underwent a surgical procedure where sarcomas were found unexpectedly   and were subsequently referred to our unit for treatment. We identified   95 patients (44 intra-lesional excisions, 35 fracture fixations,   16 joint replacements) with mean age of 48 years (11 to 83); 60%   were males (n = 57). Local recurrence arose in 40% who underwent   limb salvage surgery <i>versus</i> 12% who had an amputation.   Despite achieving local control, overall <strong><span style="color:yellowgreen">surviv</span></strong>al was worse for   patients treated with amputation rather than limb salvage (54% <i>vs</i> 75%   five-year <strong><span style="color:yellowgreen">surviv</span></strong>al). Factors that negatively influenced <strong><span style="color:yellowgreen">surviv</span></strong>al   were invasive primary surgery (fracture fixation, joint replacement),   a delay of greater than two months until referral to our oncology   service, and high-grade tumours. <strong><span style="color:yellowgreen">surviv</span></strong>al in these circumstances   depends mostly on factors that are determined prior to definitive   treatment by a tertiary orthopaedic oncology unit. Limb salvage   in this group of patients is associated with a higher rate of inadequate   marginal surgery and, consequently, higher local recurrence rates   than amputation, but should still be attempted whenever possible,   as local control is not the primary determinant of <strong><span style="color:yellowgreen">surviv</span></strong>al. </p><p>Cite this article: <i>Bone Joint J</i> 2014;96-B:665–72.</p>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/96-B/5/665
10.1302/0301-620X.96B5.33140
None

5
Circulation
Duct Stenting Versus Modified Blalock-Taussig Shunt in Neonates With Duct-Dependent Pulmonary Blood Flow
<sec><title>Background:</title><p>Infants born with cardiac abnormalities causing dependence on the arterial duct for pulmonary blood flow are often palliated with a shunt usually between the subclavian artery and either pulmonary artery. A so-called modified Blalock-Taussig shunt allows progress through early life to an age and weight at which repair or further more stable palliation can be safely achieved. Modified Blalock-Taussig shunts continue to present concern for postprocedural instability and early mortality such that other alternatives continue to be explored. Duct stenting (DS) is emerging as one such alternative with potential for greater early stability and improved <strong><span style="color:yellowgreen">surviv</span></strong>al.</p></sec><sec><title>Methods:</title><p>The purpose of this study was to compare postprocedural outcomes and <strong><span style="color:yellowgreen">surviv</span></strong>al to next-stage palliative or reparative surgery between patients undergoing a modified Blalock-Taussig shunt or a DS in infants with duct-dependent pulmonary blood flow. All patients undergoing cardiac surgery and congenital interventions in the United Kingdom are prospectively recruited to an externally validated national outcome audit. From this audit, participating UK centers identified infants <30 days of age undergoing either a Blalock-Taussig shunt or a DS for cardiac conditions with duct-dependent pulmonary blood flow between January 2012 and December 31, 2015. One hundred seventy-one patients underwent a modified Blalock-Taussig shunt, and in 83 patients, DS was attempted. Primary and secondary outcomes of <strong><span style="color:yellowgreen">surviv</span></strong>al and need for extracorporeal support were analyzed with multivariable logistic regression. Longer-term mortality before repair and reintervention were analyzed with Cox proportional hazards regression. All multivariable analyses accommodated a propensity score to balance patient characteristics between the groups.</p></sec><sec><title>Results:</title><p>There was an early (to discharge) <strong><span style="color:yellowgreen">surviv</span></strong>al advantage for infants before next-stage surgery in the DS group (odds ratio, 4.24; 95% confidence interval, 1.37–13.14; <i>P</i>=0.012). There was also a difference in the need for postprocedural extracorporeal support in favor of the DS group (odds ratio, 0.22; 95% confidence interval, 0.05–1.05; <i>P</i>=0.058). Longer-term <strong><span style="color:yellowgreen">surviv</span></strong>al outcomes showed a reduced risk of death before repair in the DS group (hazard ratio, 0.25; 95% confidence interval, 0.07–0.85; <i>P</i>=0.026) but a slightly increased risk of reintervention (hazard ratio, 1.50; 95% confidence interval, 0.85–2.64; <i>P</i>=0.165).</p></sec><sec><title>Conclusions:</title><p>DS is emerging as a preferred alternative to a surgical shunt for neonatal palliation with evidence for greater postprocedural stability and improved patient <strong><span style="color:yellowgreen">surviv</span></strong>al to destination surgical treatment.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/6/581
10.1161/CIRCULATIONAHA.117.028972
None

5
Circulation
Antiarrhythmic Drugs for Nonshockable-Turned-Shockable Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Out-of-hospital cardiac arrest (OHCA) commonly presents with nonshockable rhythms (asystole and pulseless electric activity). It is unknown whether antiarrhythmic drugs are safe and effective when nonshockable rhythms evolve to shockable rhythms (ventricular fibrillation/pulseless ventricular tachycardia [VF/VT]) during resuscitation.</p></sec><sec><title>Methods:</title><p>Adults with nontraumatic OHCA, vascular access, and VF/VT anytime after ≥1 shock(s) were prospectively randomized, double-blind, to receive amiodarone, lidocaine, or placebo by paramedics. Patients presenting with initial shock-refractory VF/VT were previously reported. The current study was a prespecified analysis in a separate cohort that initially presented with nonshockable OHCA and was randomized on subsequently developing shock-refractory VF/VT. The primary outcome was <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge. Secondary outcomes included discharge functional status and adverse drug-related effects.</p></sec><sec><title>Results:</title><p>Of 37 889 patients with OHCA, 3026 with initial VF/VT and 1063 with initial nonshockable-turned-shockable rhythms were treatment-eligible, were randomized, and received their assigned drug. Baseline characteristics among patients with nonshockable-turned-shockable rhythms were balanced across treatment arms, except that recipients of a placebo included fewer men and were less likely to receive bystander cardiopulmonary resuscitation. Active-drug recipients in this cohort required fewer shocks, supplemental doses of their assigned drug, and ancillary antiarrhythmic drugs than recipients of a placebo (<i>P</i><0.05). In all, 16 (4.1%) amiodarone, 11 (3.1%) lidocaine, and 6 (1.9%) placebo-treated patients <strong><span style="color:yellowgreen">surviv</span></strong>ed to hospital discharge (<i>P</i>=0.24). No significant interaction between treatment assignment and discharge <strong><span style="color:yellowgreen">surviv</span></strong>al occurred with the initiating OHCA rhythm (asystole, pulseless electric activity, or VF/VT). <strong><span style="color:yellowgreen">surviv</span></strong>al in each of these categories was consistently higher with active drugs, although the trends were not statistically significant. Adjusted absolute differences (95% confidence interval) in <strong><span style="color:yellowgreen">surviv</span></strong>al from nonshockable-turned-shockable arrhythmias with amiodarone versus placebo were 2.3% (−0.3, 4.8), <i>P</i>=0.08, and for lidocaine versus placebo 1.2% (−1.1, 3.6), <i>P</i>=0.30. More than 50% of these <strong><span style="color:yellowgreen">surviv</span></strong>ors were functionally independent or required minimal assistance. Drug-related adverse effects were infrequent.</p></sec><sec><title>Conclusions:</title><p>Outcome from nonshockable-turned-shockable OHCA is poor but not invariably fatal. Although not statistically significant, point estimates for <strong><span style="color:yellowgreen">surviv</span></strong>al were greater after amiodarone or lidocaine than placebo, without increased risk of adverse effects or disability and consistent with previously observed favorable trends from treatment of initial shock-refractory VF/VT with these drugs. Together the findings may signal a clinical benefit that invites further investigation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01401647.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2119
10.1161/CIRCULATIONAHA.117.028624
None

5
Circulation
Enhanced Therapeutic and Long-Term Dynamic Vascularization Effects of Human Pluripotent Stem Cell–Derived Endothelial Cells Encapsulated in a Nanomatrix Gel
<sec><title>Background:</title><p>Human pluripotent stem cell (hPSC)–derived endothelial cells (ECs) have limited clinical utility because of undefined components in the differentiation system and poor cell <strong><span style="color:yellowgreen">surviv</span></strong>al in vivo. Here, we aimed to develop a fully defined and clinically compatible system to differentiate hPSCs into ECs. Furthermore, we aimed to enhance cell <strong><span style="color:yellowgreen">surviv</span></strong>al, vessel formation, and therapeutic potential by encapsulating hPSC-ECs with a peptide amphiphile (PA) nanomatrix gel.</p></sec><sec><title>Methods:</title><p>We induced differentiation of hPSCs into the mesodermal lineage by culturing on collagen-coated plates with a glycogen synthase kinase 3β inhibitor. Next, vascular endothelial growth factor, endothelial growth factor, and basic fibroblast growth factor were added for endothelial lineage differentiation, followed by sorting for CDH5 (VE-cadherin). We constructed an extracellular matrix–mimicking PA nanomatrix gel (PA-RGDS) by incorporating the cell adhesive ligand Arg-Gly-Asp-Ser (RGDS) and a matrix metalloproteinase-2–degradable sequence. We then evaluated whether the encapsulation of hPSC-CDH5<sup>+</sup> cells in PA-RGDS could enhance long-term cell <strong><span style="color:yellowgreen">surviv</span></strong>al and vascular regenerative effects in a hind-limb ischemia model with laser Doppler perfusion imaging, bioluminescence imaging, real-time reverse transcription–polymerase chain reaction, and histological analysis.</p></sec><sec><title>Results:</title><p>The resultant hPSC-derived CDH5<sup>+</sup> cells (hPSC-ECs) showed highly enriched and genuine EC characteristics and proangiogenic activities. When injected into ischemic hind limbs, hPSC-ECs showed better perfusion recovery and higher vessel-forming capacity compared with media-, PA-RGDS–, or human umbilical vein EC–injected groups. However, the group receiving the PA-RGDS–encapsulated hPSC-ECs showed better perfusion recovery, more robust and longer cell <strong><span style="color:yellowgreen">surviv</span></strong>al (> 10 months), and higher and prolonged angiogenic and vascular incorporation capabilities than the bare hPSC-EC–injected group. Surprisingly, the engrafted hPSC-ECs demonstrated previously unknown sustained and dynamic vessel-forming behavior: initial perivascular concentration, a guiding role for new vessel formation, and progressive incorporation into the vessels over 10 months.</p></sec><sec><title>Conclusions:</title><p>We generated highly enriched hPSC-ECs via a clinically compatible system. Furthermore, this study demonstrated that a biocompatible PA-RGDS nanomatrix gel substantially improved long-term <strong><span style="color:yellowgreen">surviv</span></strong>al of hPSC-ECs in an ischemic environment and improved neovascularization effects of hPSC-ECs via prolonged and unique angiogenic and vessel-forming properties. This PA-RGDS–mediated transplantation of hPSC-ECs can serve as a novel platform for cell-based therapy and investigation of long-term behavior of hPSC-ECs.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/20/1939
10.1161/CIRCULATIONAHA.116.026329
['human']

5
Circulation
Right Ventricular Systolic Function in Organic Mitral Regurgitation
<sec><title>Background—</title><p>To assess the prevalence, determinants, and prognosis value of right ventricular (RV) ejection fraction (EF) impairment in organic mitral regurgitation.</p></sec><sec><title>Methods and Results—</title><p>Two hundred eight patients (62±12 years, 138 males) with chronic organic mitral regurgitation referred to surgery underwent an echocardiography and biventricular radionuclide angiography with regional function assessment. Mean RV EF was 40.4±10.2%, ranging from 10% to 65%. RV EF was severely impaired (≤35%) in 63 patients (30%), and biventricular impairment (left ventricular EF<60% and RV EF≤35%) was found in 34 patients (16%). Pathophysiologic correlates of RV EF were left ventricular septal function (β=0.42, <i>P</i><0.0001), left ventricular end-diastolic diameter index (β=−0.22, <i>P</i>=0.002), and pulmonary artery systolic pressure (β=−0.14, <i>P</i>=0.047). Mitral effective regurgitant orifice size (n=84) influenced RV EF (β=−0.28, <i>P</i>=0.012). In 68 patients examined after surgery, RV EF increased strongly (27.5±4.3–37.9±7.3, <i>P</i><0.0001) in patients with depressed RV EF, whereas it did not change in others (<i>P</i>=0.91). RV EF ≤35% impaired 10-year cardiovascular <strong><span style="color:yellowgreen">surviv</span></strong>al (71.6±8.4% versus 89.8±3.7%, <i>P</i>=0.037). Biventricular impairment dramatically reduced 10-year cardiovascular <strong><span style="color:yellowgreen">surviv</span></strong>al (51.9±15.3% versus 90.3±3.2%, <i>P</i><0.0001; hazard ratio, 5.2; <i>P</i><0.0001) even after adjustment for known predictors (hazard ratio, 4.6; <i>P</i>=0.004). Biventricular impairment reduced also 10-year overall <strong><span style="color:yellowgreen">surviv</span></strong>al (34.8±13.0% versus 72.6±4.5%, <i>P</i>=0.003; hazard ratio, 2.5; <i>P</i>=0.005) even after adjustment for known predictors (<i>P</i>=0.048).</p></sec><sec><title>Conclusions—</title><p>In patients with organic mitral regurgitation referred to surgery, RV function impairment is frequent (30%) and depends weakly on pulmonary artery systolic pressure but mainly on left ventricular remodeling and septal function. RV function is a predictor of postoperative cardiovascular <strong><span style="color:yellowgreen">surviv</span></strong>al, whereas biventricular impairment is a powerful predictor of both cardiovascular and overall <strong><span style="color:yellowgreen">surviv</span></strong>al.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/15/1597
10.1161/CIRCULATIONAHA.112.000999
None

5
Circulation
Effect of Time of Day on Prehospital Care and Outcomes After Out-of-Hospital Cardiac Arrest
<sec><title>Background—</title><p>More than 300 000 out-of-hospital cardiac arrests (OHCA) occur each year in the United States. The relationship between time of day and OHCA outcomes in the prehospital setting is unknown. Any such association may have important implications for emergency medical services resource allocation.</p></sec><sec><title>Methods and Results—</title><p>We performed a retrospective review of cardiac arrest data from a large, urban emergency medical services system. Included were OHCA occurring in adults from January 2008 to February 2012. Excluded were traumatic arrests and cases in which resuscitation measures were not performed. Day was defined as 8 <sc>am</sc> to 7:59 <sc>pm</sc>; night, as 8 <sc>pm</sc> to 7:59 <sc>am</sc>. A relative risk regression model was used to evaluate the association between time of day and prehospital return of spontaneous circulation and 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al, with adjustment for clinically relevant predictors of <strong><span style="color:yellowgreen">surviv</span></strong>al. Among the 4789 included cases, 1962 (41.0%) occurred at night. Mean age was 63.8 years (SD, 17.4 years); 54.5% were male. Patients with an OHCA occurring at night did not have significantly lower rates of prehospital return of spontaneous circulation compared with patients having daytime arrests (11.6% versus 12.8%; <i>P</i>=0.20). However, rates of 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al were significantly lower at night (8.56% versus 10.9%; <i>P</i>=0.02). After adjustment for demographics, presenting rhythm, field termination, duration of call, dispatch-to-scene interval, automated external defibrillator application, bystander cardiopulmonary resuscitation, and location, 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al remained significantly higher after daytime OHCA, with a relative risk of 1.10 (95% confidence interval, 1.02–1.18).</p></sec><sec><title>Conclusion—</title><p>Rates of 30-day <strong><span style="color:yellowgreen">surviv</span></strong>al were significantly higher for OHCA occurring during the day compared with at night, even after adjustment for patient, event, and prehospital care differences.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/15/1591
10.1161/CIRCULATIONAHA.113.002058
None

4
Science Signaling
Ca<sup>2+</sup> concentration–dependent premature death of <i>igfbp5a</i><sup><i>−/−</i></sup> fish reveals a critical role of IGF signaling in adaptive epithelial growth
<p>The phenotype gap is a challenge for genetically dissecting redundant endocrine signaling pathways, such as the six isoforms in the insulin-like growth factor binding protein (IGFBP) family. Although overexpressed IGFBPs can inhibit or potentiate IGF actions or have IGF-independent actions, mutant mice lacking IGFBP-encoding genes do not exhibit major phenotypes. We found that although zebrafish deficient in <i>igfbp5a</i> did not show overt phenotypes when raised in Ca<sup>2+</sup>-rich solutions, they died prematurely in low Ca<sup>2+</sup> conditions. A group of epithelial cells expressing <i>igfbp5a</i> take up Ca<sup>2+</sup> and proliferate under low Ca<sup>2+</sup> conditions because of activation of IGF signaling. Deletion of <i>igfbp5a</i> blunted low Ca<sup>2+</sup> stress–induced IGF signaling and impaired <strong><span style="color:yellowgreen">adapt</span></strong>ive proliferation. Reintroducing zebrafish Igfbp5a, but not its ligand binding–deficient mutant, restored <strong><span style="color:yellowgreen">adapt</span></strong>ive proliferation. Similarly, <strong><span style="color:yellowgreen">adapt</span></strong>ive proliferation was restored in zebrafish lacking <i>igfbp5a</i> by expression of human IGFBP5, but not two cancer-associated IGFBP5 mutants. Knockdown of IGFBP5 in human colon carcinoma cells resulted in reduced IGF-stimulated cell proliferation. These results reveal a conserved mechanism by which a locally expressed Igfbp regulates organismal Ca<sup>2+</sup> homeostasis and <strong><span style="color:yellowgreen">surviv</span></strong>al by activating IGF signaling in epithelial cells and promoting their proliferation in Ca<sup>2+</sup>-deficient states. These findings underscore the importance of physiological context when analyzing loss-of-function phenotypes of endocrine factors.</p>
http://classic.stke.sciencemag.org/cgi/content/summary/11/548/eaat2231
10.1126/scisignal.aat2231
['zebrafish', 'fish', 'human']

4
Science Signaling
Inhibition of somatosensory mechanotransduction by annexin A6
<p>Mechanically activated, slowly <strong><span style="color:yellowgreen">adapt</span></strong>ing currents in sensory neurons have been linked to noxious mechanosensation. The conotoxin NMB-1 (noxious mechanosensation blocker-1) blocks such currents and inhibits mechanical pain. Using a biotinylated form of NMB-1 in mass spectrometry analysis, we identified 67 binding proteins in sensory neurons and a sensory neuron–derived cell line, of which the top candidate was annexin A6, a membrane-associated calcium-binding protein. Annexin A6–deficient mice showed increased sensitivity to mechanical stimuli. Sensory neurons from these mice showed increased activity of the cation channel Piezo2, which mediates a rapidly <strong><span style="color:yellowgreen">adapt</span></strong>ing mechano-gated current linked to proprioception and touch, and a decrease in mechanically activated, slowly <strong><span style="color:yellowgreen">adapt</span></strong>ing currents. Conversely, overexpression of annexin A6 in sensory neurons inhibited rapidly <strong><span style="color:yellowgreen">adapt</span></strong>ing currents that were partially mediated by Piezo2. Furthermore, overexpression of annexin A6 in sensory neurons attenuated mechanical pain in a mouse model of osteoarthritis, a disease in which mechanically evoked pain is particularly problematic. These data suggest that annexin A6 can be exploited to inhibit chronic mechanical pain.</p>
http://classic.stke.sciencemag.org/cgi/content/summary/11/535/eaao2060
10.1126/scisignal.aao2060
None

4
Science Signaling
Niche-derived laminin-511 promotes midbrain dopaminergic neuron survival and differentiation through YAP
<p>Parkinson’s disease (PD) is a neurodegenerative disorder in which the loss of dopaminergic neurons in the midbrain (mDA neurons) causes progressive loss of motor control and function. Using embryonic and mDA neurons, midbrain tissue from mice, and differentiated human neural stem cells, we investigated the mechanisms controlling the <strong><span style="color:yellowgreen">surviv</span></strong>al of mDA neurons. We found that the extracellular matrix protein laminin-511 (LM511) promoted the <strong><span style="color:yellowgreen">surviv</span></strong>al and differentiation of mDA neurons. LM511 bound to integrin α<sub>3</sub>β<sub>1</sub> and activated the transcriptional cofactor YAP. LM511-YAP signaling enhanced cell <strong><span style="color:yellowgreen">surviv</span></strong>al by inducing the expression of the microRNA miR-130a, which suppressed the synthesis of the cell death–associated protein PTEN. In addition, LM511-YAP signaling increased the expression of transcription factors critical for mDA identity, such as LMX1A and PITX3, and prevented the loss of mDA neurons in response to oxidative stress, a finding that warrants further investigation to assess therapeutic potential for PD patients. We propose that by enhancing LM511-YAP signaling, it may be possible to prevent mDA neuron degeneration in PD or enhance the <strong><span style="color:yellowgreen">surviv</span></strong>al of mDA neurons in cell replacement therapies.</p>
http://classic.stke.sciencemag.org/cgi/content/summary/10/493/eaal4165
10.1126/scisignal.aal4165
['human']

4
Science
Adaptive introgression enables evolutionary rescue from extreme environmental pollution
<p>Radical environmental change that provokes population decline can impose constraints on the sources of genetic variation that may enable evolutionary rescue. <strong><span style="color:yellowgreen">adapt</span></strong>ive toxicant resistance has rapidly evolved in Gulf killifish (<i>Fundulus grandis</i>) that occupy polluted habitats. We show that resistance scales with pollution level and negatively correlates with inducibility of aryl hydrocarbon receptor (AHR) signaling. Loci with the strongest signatures of recent selection harbor genes regulating AHR signaling. Two of these loci introgressed recently (18 to 34 generations ago) from Atlantic killifish (<i>F. heteroclitus</i>). One introgressed locus contains a deletion in <i>AHR</i> that confers a large <strong><span style="color:yellowgreen">adapt</span></strong>ive advantage [selection coefficient (<i>s</i>) = 0.8]. Given the limited migration of killifish, recent <strong><span style="color:yellowgreen">adapt</span></strong>ive introgression was likely mediated by human-assisted transport. We suggest that interspecies connectivity may be an important source of <strong><span style="color:yellowgreen">adapt</span></strong>ive variation during extreme environmental change.</p>
http://sciencemag.org/cgi/content/abstract/364/6439/455
10.1126/science.aav4155
['Fundulus', 'human']

4
Science
Intense threat switches dorsal raphe serotonin neurons to a paradoxical operational mode
<p>Survival depends on the selection of behaviors <strong><span style="color:yellowgreen">adapt</span></strong>ive for the current environment. For example, a mouse should run from a rapidly looming hawk but should freeze if the hawk is coasting across the sky. Although serotonin has been implicated in <strong><span style="color:yellowgreen">adapt</span></strong>ive behavior, environmental regulation of its functional role remains poorly understood. In mice, we found that stimulation of dorsal raphe serotonin neurons suppressed movement in low- and moderate-threat environments but induced escape behavior in high-threat environments, and that movement-related dorsal raphe serotonin neural dynamics inverted in high-threat environments. Stimulation of dorsal raphe γ-aminobutyric acid (GABA) neurons promoted movement in negative but not positive environments, and movement-related GABA neural dynamics inverted between positive and negative environments. Thus, dorsal raphe circuits switch between distinct operational modes to promote environment-specific <strong><span style="color:yellowgreen">adapt</span></strong>ive behaviors.</p>
http://sciencemag.org/cgi/content/abstract/363/6426/538
10.1126/science.aau8722
None

4
Science
Genomic estimation of complex traits reveals ancient maize adaptation to temperate North America
<p>By 4000 years ago, people had introduced maize to the southwestern United States; full agriculture was established quickly in the lowland deserts but delayed in the temperate highlands for 2000 years. We test if the earliest upland maize was <strong><span style="color:yellowgreen">adapt</span></strong>ed for early flowering, a characteristic of modern temperate maize. We sequenced fifteen 1900-year-old maize cobs from Turkey Pen Shelter in the temperate Southwest. Indirectly validated genomic models predicted that Turkey Pen maize was marginally <strong><span style="color:yellowgreen">adapt</span></strong>ed with respect to flowering, as well as short, tillering, and segregating for yellow kernel color. Temperate <strong><span style="color:yellowgreen">adapt</span></strong>ation drove modern population differentiation and was selected in situ from ancient standing variation. Validated prediction of polygenic traits improves our understanding of ancient phenotypes and the dynamics of environmental <strong><span style="color:yellowgreen">adapt</span></strong>ation.</p>
http://sciencemag.org/cgi/content/abstract/357/6350/512
10.1126/science.aam9425
['maize']

4
Science
Convergent local adaptation to climate in distantly related conifers
<p>When confronted with an <strong><span style="color:yellowgreen">adapt</span></strong>ive challenge, such as extreme temperature, closely related species frequently evolve similar phenotypes using the same genes. Although such repeated evolution is thought to be less likely in highly polygenic traits and distantly related species, this has not been tested at the genome scale. We performed a population genomic study of convergent local <strong><span style="color:yellowgreen">adapt</span></strong>ation among two distantly related species, lodgepole pine and interior spruce. We identified a suite of 47 genes, enriched for duplicated genes, with variants associated with spatial variation in temperature or cold hardiness in both species, providing evidence of convergent local <strong><span style="color:yellowgreen">adapt</span></strong>ation despite 140 million years of separate evolution. These results show that <strong><span style="color:yellowgreen">adapt</span></strong>ation to climate can be genetically constrained, with certain key genes playing nonredundant roles.</p>
http://sciencemag.org/cgi/content/abstract/353/6306/1431
10.1126/science.aaf7812
['conifers', 'pine', 'spruce']

4
PLANT PHYSIOLOGY
TATA Box Insertion Provides a Selection Mechanism Underpinning Adaptations to Fe Deficiency
<p>Intraspecific genetic variation is essential for the responses and <strong><span style="color:yellowgreen">adapt</span></strong>ion of plants to evolutionary challenges, such as changing environmental conditions. The development of the Earth’s aerobic atmosphere has increased the demand for iron (Fe) in organisms, and Fe deficiency has become a limiting environmental factor for plant growth. Here, we demonstrate that genus <i>Malus</i> <strong><span style="color:yellowgreen">adapt</span></strong> to Fe deficiency through modification of the <i>Iron-Regulated Transporter1</i> (<i>IRT1</i>) promoter. Specifically, an <i>IRT1</i> mutant allele with a TATA-box insertion in the promoter region upstream of the coding region exhibited increased <i>IRT1</i> expression. The altered <i>IRT1</i> promoter is responsible for enhancing Fe uptake. Increasing the number of synthetic repeat TATA-boxes correlates with increased promoter activity. Furthermore, we demonstrate that the insertion of the TATA-box correlates with an increase in transcriptional activation via specific binding of the transcription factor IID (MDP0000939369). Taken together, these results indicate that an allelic insertion of a TATA-box in a gene promoter has allowed apple to <strong><span style="color:yellowgreen">adapt</span></strong> to the selective pressure posed by Fe deficiency. More broadly, this study reveals a new mechanism for enhancing gene expression to help plants <strong><span style="color:yellowgreen">adapt</span></strong> to different environments, providing new insights into molecular genetic divergence in plants.</p>
http://plantphysiol.org/cgi/content/abstract/173/1/715
10.1104/pp.16.01504
['Malus', 'apple', 'plants']

4
Journal of Experimental Biology
Invasion and adaptation of a warm-adapted species to montane localities: effect of acclimation potential
<p><i>Drosophila ananassae</i> has successfully invaded the cold and dry montane localities of the Western Himalayas in recent years. The ability of this desiccation- and cold-sensitive tropical species to evolve in response to seasonal changes in montane localities is largely unknown. Here, we investigated how this sensitive species <strong><span style="color:yellowgreen">adapt</span></strong> to seasonally varying environmental conditions that are lethal to its <strong><span style="color:yellowgreen">surviv</span></strong>al. We observed change in the frequency of dark and light morphs of <i>D. ananassae</i> in five mid-altitude localities during the last decade (2000–2010). We document invasion of <i>D. ananassae</i> to montane localities and increase in frequency of the dark morph. The stress tolerance of morphs (dark and light) remained unaffected of developmental acclimation. However, adult acclimation has shown significant effects on tolerance to various environmental stresses in morphs and effect of this acclimation persist for long durations. Desiccation and cold stress tolerance was increased after adult acclimation for respective stress in the dark morph; while tolerance of the light morph was not affected. Further, heat tolerance of the light morph was increased after adult heat acclimation with no influence on heat tolerance of the dark morph. Our results suggest a possible role of adult acclimation in successful invasion and <strong><span style="color:yellowgreen">adapt</span></strong>ation of <i>D. ananassae</i> to montane localities. Future experiments should be carried out to determine whether the <strong><span style="color:yellowgreen">surviv</span></strong>al in adverse conditions of low <i>versus</i> high temperature and humidity during seasonal changes is assisted by different acclimation abilities of the two morphs of <i>D. ananassae</i>.</p>
http://jeb.biologists.org/cgi/content/abstract/216/9/1578
10.1242/jeb.080200
['Drosophila', 'Drosophila ananassae']

4
The Bone & Joint Journal
The outcome of the surgical treatment of pelvic chondrosarcomas
<sec><title>Aims</title><p>Few studies dealing with chondrosarcoma of the pelvis are currently   available. Different data about the overall <strong><span style="color:yellowgreen">surviv</span></strong>al and prognostic   factors have been published but without a detailed analysis of surgery-related complications.   We aimed to analyse the outcome of a series of pelvic chondrosarcomas   treated at a single institution, with particular attention to the   prognostic factors. Based on a competing risk model, our objective   was to identify risk factors for the development of complications.</p></sec><sec><title>Patients and Methods</title><p>In a retrospective single-centre study, 58 chondrosarcomas (26   patients alive, 32 patients dead) of the pelvis were reviewed. The   mean follow-up was 13 years (one week to 23.1 years).</p></sec><sec><title>Results</title><p>A total of 26 patients (45%) were alive and 32 patients (55%)   had died. Overall <strong><span style="color:yellowgreen">surviv</span></strong>al was 76%, 55% and 45% at one, five and   ten years post-operatively, respectively. In a competing risk model   the cumulative risk of the development of a surgery-related complication   was 64% at six months and 69% at one year, post-operatively, respectively.   Endoprosthetic reconstruction was a significant risk factor for   the development of complications (p = 0.006). Complications were   not significantly related to age or the location or grade of the   tumour (p = 0.823, p = 0.976, p = 0.858). The development of complications   did not have a negative effect on <strong><span style="color:yellowgreen">surviv</span></strong>al (p = 0.147).</p></sec><sec><title>Conclusion</title><p>This is the first study with competing risk analysis of surgery-related   complications in patients with a pelvic chondrosarcoma. The surgery   in these patients remains prone to complications. Endoprosthetic   reconstruction significantly increases the risk of the development   of complications (p = 0.006). A competing risk model showed that   the development of complications does not have a negative influence   on overall <strong><span style="color:yellowgreen">surviv</span></strong>al (p = 0.147). An aggressive, surgical resection   with the goal of achieving wide margins whenever possible remains   the mainstay of treatment. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:686–96.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/686
10.1302/0301-620X.99B5.BJJ-2016-0761.R1
None

4
Circulation
How Do Resuscitation Teams at Top-Performing Hospitals for In-Hospital Cardiac Arrest Succeed?
<sec><title>Background:</title><p>In-hospital cardiac arrest (IHCA) is common, and outcomes vary substantially across US hospitals, but reasons for these differences are largely unknown. We set out to better understand how top-performing hospitals organize their resuscitation teams to achieve high <strong><span style="color:yellowgreen">surviv</span></strong>al rates for IHCA.</p></sec><sec><title>Methods:</title><p>We calculated risk-standardized IHCA <strong><span style="color:yellowgreen">surviv</span></strong>al to discharge rates across American Heart Association Get With The Guidelines–Resuscitation registry hospitals between 2012 and 2014. We identified geographically and academically diverse hospitals in the top, middle, and bottom quartiles of <strong><span style="color:yellowgreen">surviv</span></strong>al for IHCA and performed a qualitative study that included site visits with in-depth interviews of clinical and administrative staff at 9 hospitals. With the use of thematic analysis, data were analyzed to identify salient themes of perceived performance by informants.</p></sec><sec><title>Results:</title><p>Across 9 hospitals, we interviewed 158 individuals from multiple disciplines including physicians (17.1%), nurses (45.6%), other clinical staff (17.1%), and administration (20.3%). We identified 4 broad themes related to resuscitation teams: (1) team design, (2) team composition and roles, (3) communication and leadership during IHCA, and (4) training and education. Resuscitation teams at top-performing hospitals demonstrated the following features: dedicated or designated resuscitation teams; participation of diverse disciplines as team members during IHCA; clear roles and responsibilities of team members; better communication and leadership during IHCA; and in-depth mock codes.</p></sec><sec><title>Conclusions:</title><p>Resuscitation teams at hospitals with high IHCA <strong><span style="color:yellowgreen">surviv</span></strong>al differ from non–top-performing hospitals. Our findings suggest core elements of successful resuscitation teams that are associated with better outcomes and form the basis for future work to improve IHCA.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/2/154
10.1161/CIRCULATIONAHA.118.033674
None

4
Circulation
Transplant-Free Survival and Interventions at 6 Years in the SVR Trial
<sec><title>Background:</title><p>In the SVR trial (Single Ventricle Reconstruction), 1-year transplant-free <strong><span style="color:yellowgreen">surviv</span></strong>al was better for the Norwood procedure with right ventricle-to-pulmonary artery shunt (RVPAS) compared with a modified Blalock–Taussig shunt in patients with hypoplastic left heart and related syndromes. At 6 years, we compared transplant-free <strong><span style="color:yellowgreen">surviv</span></strong>al and other outcomes between the groups.</p></sec><sec><title>Methods:</title><p>Medical history was collected annually using medical record review, telephone interviews, and the death index. The cohort included 549 patients randomized and treated in the SVR trial.</p></sec><sec><title>Results:</title><p>Transplant-free <strong><span style="color:yellowgreen">surviv</span></strong>al for the RVPAS versus modified Blalock–Taussig shunt groups did not differ at 6 years (64% versus 59%, <i>P</i>=0.25) or with all available follow-up of 7.1±1.6 years (log-rank <i>P</i>=0.13). The RVPAS versus modified Blalock–Taussig shunt treatment effect had nonproportional hazards (<i>P</i>=0.009); the hazard ratio (HR) for death or transplant favored the RVPAS before stage II surgery (HR, 0.66; 95% confidence interval, 0.48–0.92). The effect of shunt type on death or transplant was not statistically significant between stage II to Fontan surgery (HR, 1.36; 95% confidence interval, 0.86–2.17; <i>P</i>=0.17) or after the Fontan procedure (HR, 0.76; 95% confidence interval, 0.33–1.74; <i>P</i>=0.52). By 6 years, patients with RVPAS had a higher incidence of catheter interventions (0.38 versus 0.23/patient-year, <i>P</i><0.001), primarily because of more interventions between the stage II and Fontan procedures (HR, 1.72; 95% confidence interval, 1.00–3.03). Complications did not differ by shunt type; by 6 years, 1 in 5 patients had had a thrombotic event, and 1 in 6 had had seizures.</p></sec><sec><title>Conclusions:</title><p>By 6 years, the hazards of death or transplant and catheter interventions were not different between the RVPAS versus modified Blalock–Taussig shunt groups. Children assigned to the RVPAS group had 5% higher transplant-free <strong><span style="color:yellowgreen">surviv</span></strong>al, but the difference did not reach statistical significance, and they required more catheter interventions. Both treatment groups have accrued important complications.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00115934.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/21/2246
10.1161/CIRCULATIONAHA.117.029375
None

4
Circulation
Association Between Diastolic Blood Pressure During Pediatric In-Hospital Cardiopulmonary Resuscitation and Survival
<sec><title>Background:</title><p>On the basis of laboratory cardiopulmonary resuscitation (CPR) investigations and limited adult data demonstrating that <strong><span style="color:yellowgreen">surviv</span></strong>al depends on attaining adequate arterial diastolic blood pressure (DBP) during CPR, the American Heart Association recommends using blood pressure to guide pediatric CPR. However, evidence-based blood pressure targets during pediatric CPR remain an important knowledge gap for CPR guidelines.</p></sec><sec><title>Methods:</title><p>All children ≥37 weeks’ gestation and <19 years old in Collaborative Pediatric Critical Care Research Network intensive care units with chest compressions for ≥1 minute and invasive arterial blood pressure monitoring before and during CPR between July 1, 2013, and June 31, 2016, were included. Mean DBP during CPR and Utstein-style standardized cardiac arrest data were collected. The hypothesis was that DBP ≥25 mm Hg during CPR in infants and ≥30 mm Hg in children ≥1 year old would be associated with <strong><span style="color:yellowgreen">surviv</span></strong>al. Primary outcome was <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge. Secondary outcome was <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge with favorable neurological outcome, defined as Pediatric Cerebral Performance Categories 1 to 3 or no worse than prearrest baseline. Multivariable Poisson regression models with robust error estimates were used to estimate the relative risk of outcomes.</p></sec><sec><title>Results:</title><p>Blinded investigators analyzed blood pressure waveforms during CPR from 164 children, including 60% <1 year old, 60% with congenital heart disease, and 54% after cardiac surgery. The immediate cause of arrest was hypotension in 67%, respiratory decompensation in 44%, and arrhythmia in 19%. Median duration of CPR was 8 minutes (quartiles, 3 and 27 minutes). Ninety percent <strong><span style="color:yellowgreen">surviv</span></strong>ed the event, 68% with return of spontaneous circulation and 22% by extracorporeal life support. Forty-seven percent <strong><span style="color:yellowgreen">surviv</span></strong>ed to hospital discharge, and 43% <strong><span style="color:yellowgreen">surviv</span></strong>ed to discharge with favorable neurological outcome. Maintaining mean DBP ≥25 mm Hg in infants and ≥30 mm Hg in children ≥1 year old occurred in 101 of 164 children (62%) and was associated with <strong><span style="color:yellowgreen">surviv</span></strong>al (adjusted relative risk, 1.7; 95% confidence interval, 1.2–2.6; <i>P</i>=0.007) and <strong><span style="color:yellowgreen">surviv</span></strong>al with favorable neurological outcome (adjusted relative risk, 1.6; 95% confidence interval, 1.1–2.5; <i>P</i>=0.02).</p></sec><sec><title>Conclusions:</title><p>These data demonstrate that mean DBP ≥25 mm Hg during CPR in infants and ≥30 mm Hg in children ≥1 year old was associated with greater likelihood of <strong><span style="color:yellowgreen">surviv</span></strong>al to hospital discharge and <strong><span style="color:yellowgreen">surviv</span></strong>al with favorable neurological outcome.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/17/1784
10.1161/CIRCULATIONAHA.117.032270
None

4
Circulation
C1q/Tumor Necrosis Factor–Related Protein-9 Regulates the Fate of Implanted Mesenchymal Stem Cells and Mobilizes Their Protective Effects Against Ischemic Heart Injury via Multiple Novel Signaling Pathways
<sec><title>Background:</title><p>Cell therapy remains the most promising approach against ischemic heart injury. However, the poor <strong><span style="color:yellowgreen">surviv</span></strong>al of engrafted stem cells in the ischemic environment limits their therapeutic efficacy for cardiac repair after myocardial infarction. CTRP9 (C1q/tumor necrosis factor–related protein-9) is a novel pro<strong><span style="color:yellowgreen">surviv</span></strong>al cardiokine with significantly downregulated expression after myocardial infarction. Here we tested a hypothesis that CTRP9 might be a cardiokine required for a healthy microenvironment promoting implanted stem cell <strong><span style="color:yellowgreen">surviv</span></strong>al and cardioprotection.</p></sec><sec><title>Methods:</title><p>Mice were subjected to myocardial infarction and treated with adipose-derived mesenchymal stem cells (ADSCs, intramyocardial transplantation), CTRP9, or their combination. <strong><span style="color:yellowgreen">surviv</span></strong>al, cardiac remodeling and function, cardiomyocytes apoptosis, and ADSCs engraftment were evaluated. Whether CTRP9 directly regulates ADSCs function was determined in vitro. Discovery-drive approaches followed by cause-effect analysis were used to uncover the molecular mechanisms of CTRP9.</p></sec><sec><title>Results:</title><p>Administration of ADSCs alone failed to exert significant cardioprotection. However, administration of ADSCs in addition to CTRP9 further enhanced the cardioprotective effect of CTRP9 (<i>P</i><0.05 or <i>P</i><0.01 versus CTRP9 alone), suggesting a synergistic effect. Administration of CTRP9 at a dose recovering physiological CTRP9 levels significantly prolonged ADSCs retention/<strong><span style="color:yellowgreen">surviv</span></strong>al after implantation. Conversely, the number of engrafted ADSCs was significantly reduced in the CTRP9 knockout heart. In vitro study demonstrated that CTRP9 promoted ADSCs proliferation and migration, and it protected ADSCs against hydrogen peroxide–induced cellular death. CTRP9 enhances ADSCs proliferation/migration by extracellular regulated protein kinases (ERK)1/2–matrix metallopeptidase 9 signaling and promotes antiapoptotic/cell <strong><span style="color:yellowgreen">surviv</span></strong>al via ERK–nuclear factor erythroid-derived 2—like 2/antioxidative protein expression. N-cadherin was identified as a novel CTRP9 receptor mediating ADSCs signaling. Blockade of either N-cadherin or ERK1/2 completely abolished the previously noted CTRP9 effects. Although CTRP9 failed to promote ADSCs cardiogenic differentiation, CTRP9 promotes superoxide dismutase 3 expression and secretion from ADSCs, protecting cardiomyocytes against oxidative stress-induced cell death.</p></sec><sec><title>Conclusions:</title><p>We provide the first evidence that CTRP9 promotes ADSCs proliferation/<strong><span style="color:yellowgreen">surviv</span></strong>al, stimulates ADSCs migration, and attenuates cardiomyocyte cell death by previously unrecognized signaling mechanisms. These include binding with N-cadherin, activation of ERK-matrix metallopeptidase 9 and ERK-nuclear factor erythroid-derived 2—like 2 signaling, and upregulation/secretion of antioxidative proteins. These results suggest that CTRP9 is a cardiokine critical in maintaining a healthy microenvironment facilitating stem cell engraftment in infarcted myocardial tissue, thereby enhancing stem cell therapeutic efficacy.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/22/2162
10.1161/CIRCULATIONAHA.117.029557
None

4
Circulation
Transplantation-Free Survival and Interventions at 3 Years in the Single Ventricle Reconstruction Trial
<sec><title>Background—</title><p>In the Single Ventricle Reconstruction (SVR) trial, 1-year transplantation-free <strong><span style="color:yellowgreen">surviv</span></strong>al was better for the Norwood procedure with right ventricle–to–pulmonary artery shunt (RVPAS) compared with a modified Blalock-Taussig shunt (MBTS). At 3 years, we compared transplantation-free <strong><span style="color:yellowgreen">surviv</span></strong>al, echocardiographic right ventricular ejection fraction, and unplanned interventions in the treatment groups.</p></sec><sec><title>Methods and Results—</title><p>Vital status and medical history were ascertained from annual medical records, death indexes, and phone interviews. The cohort included 549 patients randomized and treated in the SVR trial. Transplantation-free <strong><span style="color:yellowgreen">surviv</span></strong>al for the RVPAS versus MBTS groups did not differ at 3 years (67% versus 61%; <i>P</i>=0.15) or with all available follow-up of 4.8±1.1 years (log-rank <i>P</i>=0.14). Pre-Fontan right ventricular ejection fraction was lower in the RVPAS group than in the MBTS group (41.7<i>±</i>5.1% versus 44.7<i>±</i>6.0%; <i>P</i>=0.007), and right ventricular ejection fraction deteriorated in RVPAS (<i>P</i>=0.004) but not MBTS (<i>P</i>=0.40) subjects (pre-Fontan minus 14-month mean, −3.25±8.24% versus 0.99±8.80%; <i>P</i>=0.009). The RVPAS versus MBTS treatment effect had nonproportional hazards (<i>P</i>=0.004); the hazard ratio favored the RVPAS before 5 months (hazard ratio=0.63; 95% confidence interval, 0.45–0.88) but the MBTS beyond 1 year (hazard ratio=2.22; 95% confidence interval, 1.07–4.62). By 3 years, RVPAS subjects had a higher incidence of catheter interventions (<i>P</i><0.001) with an increasing HR over time (<i>P</i>=0.005): <5 months, 1.14 (95% confidence interval, 0.81–1.60); from 5 months to 1 year, 1.94 (95% confidence interval, 1.02–3.69); and >1 year, 2.48 (95% confidence interval, 1.28–4.80).</p></sec><sec><title>Conclusions—</title><p>By 3 years, the Norwood procedure with RVPAS compared with MBTS was no longer associated with superior transplantation-free <strong><span style="color:yellowgreen">surviv</span></strong>al. Moreover, RVPAS subjects had slightly worse right ventricular ejection fraction and underwent more catheter interventions with increasing hazard ratio over time.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00115934.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/20/2013
10.1161/CIRCULATIONAHA.113.006191
None

4
Circulation
STARTS-2
<sec><title>Background—</title><p>The double-blind, placebo-controlled Sildenafil in Treatment-Naive Children, Aged 1 to 17 Years, With Pulmonary Arterial Hypertension (STARTS-1) study assessed sildenafil in pediatric patients with pulmonary arterial hypertension; improved hemodynamics and exercise capacity occurred in medium- and high-dose groups. STARTS-2 was the extension study.</p></sec><sec><title>Methods and Results—</title><p>In STARTS-1, 234 children ≥8 kg were randomly assigned to low-, medium-, or high-dose sildenafil or placebo orally thrice daily; within-group dose depended on weight. In STARTS-2, sildenafil-treated patients continued STARTS-1 dosing; placebo-treated patients were randomized to 1 of the 3 sildenafil dose groups. Patients requiring additional pulmonary arterial hypertension–specific therapy discontinued study treatment; <strong><span style="color:yellowgreen">surviv</span></strong>al follow-up was attempted. As of August 2011, all children received ≥3 years of treatment (unless discontinued) from STARTS-1 baseline; 37 deaths were reported (26 on study treatment), 1 of which occurred within the first year of treatment. Most patients who died (28/37) had idiopathic/heritable pulmonary arterial hypertension (76% versus 33% overall) and baseline functional class III/IV disease (38% versus 15% overall); patients who died had worse baseline hemodynamics. Kaplan-Meier estimated 3-year <strong><span style="color:yellowgreen">surviv</span></strong>al rates from start of sildenafil were 94%, 93%, and 88% for patients randomized to low-, medium-, and high-dose sildenafil, respectively; 87%, 89%, and 80% were known to be alive at 3 years. Hazard ratios for mortality were 3.95 (95% confidence interval, 1.46–10.65) for high versus low and 1.92 (95% confidence interval, 0.65–5.65) for medium versus low dose; however, multiple analyses raised uncertainty about the <strong><span style="color:yellowgreen">surviv</span></strong>al/dose relationship.</p></sec><sec><title>Conclusions—</title><p>Although children randomized to higher compared with lower sildenafil doses had an unexplained increased mortality, all sildenafil dose groups displayed favorable <strong><span style="color:yellowgreen">surviv</span></strong>al for children with pulmonary arterial hypertension.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://clinicaltrials.gov/ct2/show/NCT00159874</ext-link> (extension study of NCT00149913). Unique identifier: NCT00159874.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/129/19/1914
10.1161/CIRCULATIONAHA.113.005698
None

3
Molecular Biology and Evolution
Genomic Basis of Adaptive Evolution: The Survival of Amur Ide (<i>Leuciscu</i>s <i>waleckii</i>) in an Extremely Alkaline Environment
<p>The Amur ide (<i>Leuciscus waleckii</i>) is a cyprinid fish that is widely distributed in Northeast Asia. The Lake Dali Nur population inhabits one of the most extreme aquatic environments on Earth, with an alkalinity up to 50 mmol/L (pH 9.6), thus providing an exceptional model with which to characterize the mechanisms of genomic evolution underlying <strong><span style="color:yellowgreen">adapt</span></strong>ation to extreme environments. Here, we developed the reference genome assembly for <i>L. waleckii</i> from Lake Dali Nur. Intriguingly, we identified unusual expanded long terminal repeats (LTRs) with higher nucleotide substitution rates than in many other teleosts, suggesting their more recent insertion into the <i>L. waleckii</i> genome. We also identified expansions in genes encoding egg coat proteins and natriuretic peptide receptors, possibly underlying the <strong><span style="color:yellowgreen">adapt</span></strong>ation to extreme environmental stress. We further sequenced the genomes of 10 additional individuals from freshwater and 18 from Lake Dali Nur populations, and we detected a total of 7.6 million SNPs from both populations. In a genome scan and comparison of these two populations, we identified a set of genomic regions under selective sweeps that harbor genes involved in ion homoeostasis, acid-base regulation, unfolded protein response, reactive oxygen species elimination, and urea excretion. Our findings provide comprehensive insight into the genomic mechanisms of teleost fish that underlie their <strong><span style="color:yellowgreen">adapt</span></strong>ation to extreme alkaline environments.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/145
10.1093/molbev/msw230
['fish', 'Leuciscus', 'Leuciscus waleckii']

3
Molecular Biology and Evolution
Population Parameters Underlying an Ongoing Soft Sweep in Southeast Asian Malaria Parasites
<p>Multiple <i>kelch13</i> alleles conferring artemisinin resistance (ART-R) are currently spreading through Southeast Asian malaria parasite populations, providing a unique opportunity to observe an ongoing soft selective sweep, investigate why resistance alleles have evolved multiple times and determine fundamental population genetic parameters for <i>Plasmodium</i>. We sequenced <i>kelch13</i> (<i>n</i> = 1,876), genotyped 75 flanking SNPs, and measured clearance rate (<i>n</i> = 3,552) in parasite infections from Western Thailand (2001–2014). We describe 32 independent coding mutations including common mutations outside the <i>kelch13</i> propeller associated with significant reductions in clearance rate. Mutations were first observed in 2003 and rose to 90% by 2014, consistent with a selection coefficient of ∼0.079. ART-R allele diversity rose until 2012 and then dropped as one allele (C580Y) spread to high frequency. The frequency with which <strong><span style="color:yellowgreen">adapt</span></strong>ive alleles arise is determined by the rate of mutation and the population size. Two factors drive this soft sweep: (1) multiple <i>kelch13</i> amino-acid mutations confer resistance providing a large mutational target—we estimate the target is 87–163 bp. (2) The population mutation parameter (<i>Θ</i> = 2<i>N</i><sub>e</sub><i>μ</i>) can be estimated from the frequency distribution of ART-R alleles and is ∼5.69, suggesting that short term effective population size is 88 thousand to 1.2 million. This is 52–705 times greater than <i>N</i><sub>e</sub> estimated from fluctuation in allele frequencies, suggesting that we have previously underestimated the capacity for <strong><span style="color:yellowgreen">adapt</span></strong>ive evolution in <i>Plasmodium</i>. Our central conclusions are that retrospective studies may underestimate the complexity of selective events and the <i>N</i><sub>e</sub> relevant for <strong><span style="color:yellowgreen">adapt</span></strong>ation for malaria is considerably higher than previously estimated.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/131
10.1093/molbev/msw228
['rose']

3
Molecular Biology and Evolution
Detecting Adaptation in Protein-Coding Genes Using a Bayesian Site-Heterogeneous Mutation-Selection Codon Substitution Model
<p>Codon substitution models have traditionally attempted to uncover signatures of <strong><span style="color:yellowgreen">adapt</span></strong>ation within protein-coding genes by contrasting the rates of synonymous and non-synonymous substitutions. Another modeling approach, known as the mutation–selection framework, attempts to explicitly account for selective patterns at the amino acid level, with some approaches allowing for heterogeneity in these patterns across codon sites. Under such a model, substitutions at a given position occur at the neutral or nearly neutral rate when they are synonymous, or when they correspond to replacements between amino acids of similar fitness; substitutions from high to low (low to high) fitness amino acids have comparatively low (high) rates. Here, we study the use of such a mutation–selection framework as a null model for the detection of <strong><span style="color:yellowgreen">adapt</span></strong>ation. Following previous works in this direction, we include a deviation parameter that has the effect of capturing the surplus, or deficit, in non-synonymous rates, relative to what would be expected under a mutation–selection modeling framework that includes a Dirichlet process approach to account for across-codon-site variation in amino acid fitness profiles. We use simulations, along with a few real data sets, to study the behavior of the approach, and find it to have good power with a low false-positive rate. Altogether, we emphasize the potential of recent mutation–selection models in the detection of <strong><span style="color:yellowgreen">adapt</span></strong>ation, calling for further model refinements as well as large-scale applications.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/204
10.1093/molbev/msw220
None

3
Molecular Biology and Evolution
Reconstruction of Haplotype-Blocks Selected during Experimental Evolution
<p>The genetic analysis of experimentally evolving populations typically relies on short reads from pooled individuals (Pool-Seq). While this method provides reliable allele frequency estimates, the underlying haplotype structure remains poorly characterized. With small population sizes and <strong><span style="color:yellowgreen">adapt</span></strong>ive variants that start from low frequencies, the interpretation of selection signatures in most Evolve and Resequencing studies remains challenging. To facilitate the characterization of selection targets, we propose a new approach that reconstructs selected haplotypes from replicated time series, using Pool-Seq data. We identify selected haplotypes through the correlated frequencies of alleles carried by them. Computer simulations indicate that selected haplotype-blocks of several Mb can be reconstructed with high confidence and low error rates, even when allele frequencies change only by 20% across three replicates. Applying this method to real data from <i>D. melanogaster</i> populations <strong><span style="color:yellowgreen">adapt</span></strong>ing to a hot environment, we identify a selected haplotype-block of 6.93 Mb. We confirm the presence of this haplotype-block in evolved populations by experimental haplotyping, demonstrating the power and accuracy of our haplotype reconstruction from Pool-Seq data. We propose that the combination of allele frequency estimates with haplotype information will provide the key to understanding the dynamics of <strong><span style="color:yellowgreen">adapt</span></strong>ive alleles.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/34/1/174
10.1093/molbev/msw210
None

3
Molecular Biology and Evolution
Unusual Diversity of Myoglobin Genes in the Lungfish
<p>Myoglobin is a respiratory protein that serves as a model system in a variety of biological fields. Its main function is to deliver and store O<sub>2</sub> in the heart and skeletal muscles, but myoglobin is also instrumental in homeostasis of nitric oxide (NO) and detoxification of reactive oxygen species (ROS). Almost every vertebrate harbors a single myoglobin gene; only some cyprinid fishes have two recently duplicated myoglobin genes. Here we show that the West African lungfish <i>Protopterus annectens</i> has at least seven distinct myoglobin genes (<i>PanMb1–7</i>), which diverged early in the evolution of lungfish and showed an enhanced evolutionary rate. These myoglobins are lungfish specific, and no other globin gene was found amplified. The myoglobins are differentially expressed in various lungfish tissues, and the brain is the main site of myoglobin expression. The typical myoglobin-containing tissues, the skeletal muscle and the heart, have much lower myoglobin mRNA levels. Muscle and heart express distinct myoglobins (<i>PanMb1</i> and <i>PanMb3</i>, respectively). In cell culture, lungfish myoglobins improved cellular <strong><span style="color:yellowgreen">surviv</span></strong>al under hypoxia albeit with different efficiencies and reduced the production of reactive oxygen species. Only <i>Mb2</i> and <i>Mb6</i> enhanced the energy status of the cells. The unexpected diversity of myoglobin hints to a functional diversification of this gene: some myoglobins may have <strong><span style="color:yellowgreen">adapt</span></strong>ed to the O<sub>2</sub> requirements of the specific tissue and help the lungfish to <strong><span style="color:yellowgreen">surviv</span></strong>e hypoxic periods; other myoglobins may have taken over the roles of neuroglobin and cytoglobin, which appear to be missing in the West African lungfish.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3033
10.1093/molbev/msw159
['Protopterus', 'Protopterus annectens']

3
Molecular Biology and Evolution
Molecular Adaptation during a Rapid Adaptive Radiation
<p>“Explosive” <strong><span style="color:yellowgreen">adapt</span></strong>ive radiations on islands remain one of the most puzzling evolutionary phenomena and the evolutionary genetic processes behind such radiations remain unclear. Rapid morphological and ecological evolution during island radiations suggests that many genes may be under fairly strong selection, although this remains untested. Here, we report that during a rapid recent diversification in the Hawaiian endemic plant genus <i>Schiedea</i> (<i>Caryophyllaceae</i>), 5 in 36 studied genes evolved under positive selection. Positively selected genes are involved in defence mechanisms, photosynthesis, and reproduction. Comparison with eight mainland plant groups demonstrates both the relaxation of purifying selection and more widespread positive selection in Hawaiian <i>Schiedea</i>. This provides compelling evidence that <strong><span style="color:yellowgreen">adapt</span></strong>ive evolution of protein-coding genes may play a significant role during island <strong><span style="color:yellowgreen">adapt</span></strong>ive radiations.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/30/5/1051
10.1093/molbev/mst013
['Caryophyllaceae', 'Schiedea']

3
Journal of Experimental Biology
Physiological basis of starvation resistance in <i>Drosophila leontia</i>: analysis of sexual dimorphism
<p>Geographically varying starvation stress has often been considered as a natural selector that constrains between-population differences for starvation resistance (SR) in <i>Drosophila</i> species. On the Indian subcontinent, a dozen <i>Drosophila</i> species have shown clinal variations in SR across latitude, but the evolved physiological basis of such contrasting <strong><span style="color:yellowgreen">adapt</span></strong>ations is largely unknown. In the present study, I untangled the physiological basis of sex-specific as well as between-population divergence for SR in <i>D. leontia</i>, collected across a latitudinal transect of the Indian subcontinent (11°45′–31°19′N). Secondly, I tested the assumptions that hardening to starvation stress facilitates an increased <strong><span style="color:yellowgreen">surviv</span></strong>al under subsequent lethal levels of starvation, and such plastic effects differ between the sexes. I observed several interesting results. In contrast to a steeper cline of starvation-related traits with latitude in females, a shallower gradient was observed for males. Females stored higher (~1.3-fold) dry-mass-specific levels of body lipids and glycogen contents, and utilized these both of these energy resources under starvation stress, whereas the starved males metabolized only body lipids as a source of energy. Conversely, the rate of body lipid utilization and threshold need were considerably higher in females as compared with males. Between-population differences were significant for storage levels of energy reserves only, but not for other avenues (rate of metabolite utilization and threshold need) of SR for both sexes. These findings indicate that multiple pathways shape the physiological basis of sexual dimorphism for SR in <i>D. leontia</i>. Further, single or multiple bouts of starvation hardening conferred an increased longevity (~4–9 h; <i>P</i><0.001) under subsequent lethal levels of starvation stress for females only, and such plastic responses were consistent with a decrease in rate of metabolite utilization. Nevertheless, between-population effects were non-significant for absolute hardening capacity (AHC=<i>K</i><sub>SR</sub>–C). Altogether, these findings suggest that similar evolutionary constraints have resulted in divergent genetic as well as plastic responses to evolve <strong><span style="color:yellowgreen">adapt</span></strong>ations under starvation stress, and account for the observed sexual dimorphism for basal SR in <i>D. leontia</i>.</p>
http://jeb.biologists.org/cgi/content/abstract/217/11/1849
10.1242/jeb.096792
['Drosophila']

3
The Bone & Joint Journal
Which factors influence the rate of failure following metal-on-metal hip arthroplasty revision surgery performed for adverse reactions to metal debris?
<sec><title>Aims</title><p>To determine the outcomes following revision surgery of metal-on-metal   hip arthroplasties (MoMHA) performed for adverse reactions to metal   debris (ARMD), and to identify factors predictive of re-revision.</p></sec><sec><title>Patients and Methods</title><p>We performed a retrospective observational study using National   Joint Registry (NJR) data on 2535 MoMHAs undergoing revision surgery   for ARMD between 2008 and 2014. The outcomes studied following revision were   intra-operative complications, mortality and re-revision surgery.   Predictors of re-revision were identified using competing-risk regression   modelling.</p></sec><sec><title>Results</title><p>Intra-operative complications occurred in 40 revisions (1.6%).   The cumulative five-year patient <strong><span style="color:yellowgreen">surviv</span></strong>al rate was 95.9% (95% confidence   intervals (CI) 92.3 to 97.8). Re-revision surgery was performed   in 192 hips (7.6%). The cumulative five-year implant <strong><span style="color:yellowgreen">surviv</span></strong>al rate   was 89.5% (95% CI 87.3 to 91.3). Predictors of re-revision were   high body mass index at revision (subhazard ratio (SHR) 1.06 per   kg/m<sup>2 </sup>increase, 95% CI 1.02 to 1.09), modular component   only revisions (head and liner with or without taper <strong><span style="color:yellowgreen">adapt</span></strong>er; SHR   2.01, 95% CI 1.19 to 3.38), ceramic-on-ceramic revision bearings   (SHR 1.86, 95% CI 1.23 to 2.80), and acetabular bone grafting (SHR   2.10, 95% CI 1.43 to 3.07). These four factors remained predictive   of re-revision when the missing data were imputed.</p></sec><sec><title>Conclusion</title><p>The short-term risk of re-revision following MoMHA revision surgery   performed for ARMD was comparable with that reported in the NJR   following all-cause non-MoMHA revision surgery. However, the factors   predictive of re-revision included those which could be modified   by the surgeon, suggesting that rates of failure following ARMD revision   may be reduced further.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1020–7.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/8/1020
10.1302/0301-620X.99B8.BJJ-2016-0889.R1
None

3
The Bone & Joint Journal
Intercalary allograft augmented with intramedullary cement and plate fixation is a reliable solution after resection of a diaphyseal tumour
<sec><title>Aims</title><p>Intercalary allografts following resection of a primary diaphyseal   tumour have high rates of complications and failures. At our institution   intercalary allografts are augmented with intramedullary cement   and fixed using compression plating. Our aim was to evaluate their   long-term outcomes.</p></sec><sec><title>Patients and Methods</title><p>A total of 46 patients underwent reconstruction with an intercalary   allograft between 1989 and 2014. The patients had a mean age of   32.8 years (14 to 77). The most common diagnoses were osteosarcoma   (n = 16) and chondrosarcoma (n = 9). The location of the tumours   was in the femur in 21, the tibia in 16 and the humerus in nine. Function   was assessed using the Musculoskeletal Tumor Society (MSTS) scoring   system and the Toronto Extremity Salvage Score (TESS). The <strong><span style="color:yellowgreen">surviv</span></strong>al   of the graft and the overall <strong><span style="color:yellowgreen">surviv</span></strong>al were assessed using the Kaplan-Meier method.</p></sec><sec><title>Results</title><p>The median follow-up was 92 months (4 to 288). The mean MSTS   87 score was 29.1 (19 to 35), the mean MSTS 93 score was 82.2 (50   to 100) and the mean TESS score was 81.2 (43 to 100). Overall <strong><span style="color:yellowgreen">surviv</span></strong>al   of the allograft was 84.8%. A total of 15 patients (33%) had a complication.   Five allografts were revised for complications and one for local recurrence.</p></sec><sec><title>Conclusion</title><p>Intercalary allografts augmented with intramedullary cement and   compression plate fixation provide a reliable and durable method   of reconstruction after the excision of a primary diaphyseal bone   tumour, with high levels of function and satisfaction. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:973–8.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/7/973
10.1302/0301-620X.99B7.BJJ-2016-0996
None

