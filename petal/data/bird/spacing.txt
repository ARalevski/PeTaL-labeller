17
The Bone & Joint Journal
Unsatisfactory outcomes following unicompartmental knee arthroplasty in patients with partial thickness cartilage loss
<sec><title>Aims</title><p>While medial unicompartmental knee arthroplasty (UKA) is indicated   for patients with full-<strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss, it is occasionally   used to treat those with partial-<strong><span style="color:yellowgreen">thick</span></strong>ness loss. The aim of this   study was to investigate the five-year outcomes in a consecutive   series of UKAs used in patients with partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage   loss in the medial compartment of the knee.</p></sec><sec><title>Patients and Methods</title><p>Between 2002 and 2014, 94 consecutive UKAs were undertaken in   90 patients with partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss and followed up   independently for a mean of six years (1 to 13). These patients   had partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss either on both femur and tibia   (13 knees), or on either the femur or the tibia, with full <strong><span style="color:yellowgreen">thick</span></strong>ness   loss on the other surface of the joint (18 and 63 knees respectively).   Using propensity score analysis, these patients were matched 1:2 based   on age, gender and pre-operative Oxford Knee Score (OKS) with knees   with full <strong><span style="color:yellowgreen">thick</span></strong>ness loss on both the femur and tibia. The functional   outcomes, implant survival and incidence of re-operations were assessed   at one, two and five years post-operatively. A subgroup of 36 knees   in 36 patients with partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss, who had pre-operative   MRI scans, was assessed to identify whether there were any factors   identified on MRI that predicted the outcome.</p></sec><sec><title>Results</title><p>Knees with partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss had significantly   worse functional outcomes at one, two and five years post-operatively   compared with those with full <strong><span style="color:yellowgreen">thick</span></strong>ness loss. A quarter of knees   with partial <strong><span style="color:yellowgreen">thick</span></strong>ness loss had a fair or poor result and a fifth   failed to achieve a clinically significant improvement in OKS from   a baseline of four points or more; double that seen in knees with   full <strong><span style="color:yellowgreen">thick</span></strong>ness loss. Whilst there was no difference in implant survival between   the groups, the rate of re-operation in knees with partial <strong><span style="color:yellowgreen">thick</span></strong>ness   loss was three times higher. Most of the re-operations (three-quarters),   were arthroscopies for persistent pain.</p><p>Compared with those achieving good or excellent outcomes, patients   with partial <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss who achieved fair or poor   outcomes were younger and had worse pre-operative functional scores.   However, there were no other differences in the baseline demographics.   MRI findings of full <strong><span style="color:yellowgreen">thick</span></strong>ness cartilage loss, subchondral oedema,   synovitis or effusion did not provide additional prognostic information.</p></sec><sec><title>Conclusion</title><p>Medial UKA should be reserved for patients with full <strong><span style="color:yellowgreen">thick</span></strong>ness   cartilage loss on both the femur and tibia. Whilst some patients   with partial <strong><span style="color:yellowgreen">thick</span></strong>ness loss achieve a good result we cannot currently   identify which these will be and in this situation MRI is unhelpful   and misleading.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:475–82.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/475
10.1302/0301-620X.99B4.BJJ-2016-1061.R1
None

10
PLANT PHYSIOLOGY
ANGUSTIFOLIA Regulates Actin Filament Alignment for Nuclear Positioning in Leaves
<p>During dark adaptation, plant nuclei move centripetally toward the midplane of the leaf blade; thus, the nuclei on both the adaxial and abaxial sides become <strong><span style="color:yellowgreen">posit</span></strong>ioned at the inner periclinal walls of cells. This centripetal nuclear <strong><span style="color:yellowgreen">posit</span></strong>ioning implies that a characteristic cell polarity exists within a leaf, but little is known about the mechanism underlying this process. Here, we show that ANGUSTIFOLIA (AN) and ACTIN7 regulate centripetal nuclear <strong><span style="color:yellowgreen">posit</span></strong>ioning in Arabidopsis (<i>Arabidopsis thaliana</i>) leaves. Two mutants defective in the <strong><span style="color:yellowgreen">posit</span></strong>ioning of nuclei in the dark were <strong><span style="color:yellowgreen">isol</span></strong>ated and designated as <i>unusual nuclear <strong><span style="color:yellowgreen">posit</span></strong>ioning1</i> (<i>unp1</i>) and <i>unp2</i>. In the dark, nuclei of <i>unp1</i> were <strong><span style="color:yellowgreen">posit</span></strong>ioned at the anticlinal walls of adaxial and abaxial mesophyll cells and abaxial pavement cells, whereas the nuclei of <i>unp2</i> were <strong><span style="color:yellowgreen">posit</span></strong>ioned at the anticlinal walls of mesophyll and pavement cells on both the adaxial and abaxial sides. <i>unp1</i> was caused by a dominant-negative mutation in <i>ACTIN7</i>, and <i>unp2</i> resulted from a recessive mutation in <i>AN</i>. Actin filaments in <i>unp1</i> were fragmented and reduced in number, which led to pleiotropic defects in nuclear morphology, cytoplasmic streaming, and plant growth. The mutation in <i>AN</i> caused aberrant <strong><span style="color:yellowgreen">posit</span></strong>ioning of nuclei-associated actin filaments at the anticlinal walls. AN was detected in the cytosol, where it interacted physically with plant-specific dual-specificity tyrosine phosphorylation-regulated kinases (DYRKPs) and itself. The DYRK inhibitor (1<i>Z</i>)-1-(3-ethyl-5-hydroxy-2(3<i>H</i>)-benzothiazolylidene)-2-propanone significantly inhibited dark-induced nuclear <strong><span style="color:yellowgreen">posit</span></strong>ioning. Collectively, these results suggest that the AN-DYRKP complex regulates the alignment of actin filaments during centripetal nuclear <strong><span style="color:yellowgreen">posit</span></strong>ioning in leaf cells.</p>
http://plantphysiol.org/cgi/content/abstract/179/1/233
10.1104/pp.18.01150
['Arabidopsis', 'Arabidopsis thaliana']

9
PLANT PHYSIOLOGY
Genetic Architecture and Molecular Networks Underlying Leaf Thickness in Desert-Adapted Tomato <i>Solanum pennellii</i>
<p><strong><span style="color:yellowgreen">thick</span></strong>er leaves allow plants to grow in water-limited conditions. However, our understanding of the genetic underpinnings of this highly functional leaf shape trait is poor. We used a custom-built confocal profilometer to directly measure leaf <strong><span style="color:yellowgreen">thick</span></strong>ness in a set of introgression lines (ILs) derived from the desert tomato <i>Solanum pennellii</i> and identified quantitative trait loci. We report evidence of a complex genetic architecture of this trait and roles for both genetic and environmental factors. Several ILs with <strong><span style="color:yellowgreen">thick</span></strong> leaves have dramatically elongated palisade mesophyll cells and, in some cases, increased leaf ploidy. We characterized the <strong><span style="color:yellowgreen">thick</span></strong> IL2-5 and IL4-3 in detail and found increased mesophyll cell size and leaf ploidy levels, suggesting that endoreduplication underpins leaf <strong><span style="color:yellowgreen">thick</span></strong>ness in tomato. Next, we queried the transcriptomes and inferred dynamic Bayesian networks of gene expression across early leaf ontogeny in these lines to compare the molecular networks that pattern leaf <strong><span style="color:yellowgreen">thick</span></strong>ness. We show that <strong><span style="color:yellowgreen">thick</span></strong> ILs share <i>S. pennellii</i>-like expression profiles for putative regulators of cell shape and meristem determinacy as well as a general signature of cell cycle-related gene expression. However, our network data suggest that leaf <strong><span style="color:yellowgreen">thick</span></strong>ness in these two lines is patterned at least partially by distinct mechanisms. Consistent with this hypothesis, double homozygote lines combining introgression segments from these two ILs show additive phenotypes, including <strong><span style="color:yellowgreen">thick</span></strong> leaves, higher ploidy levels, and larger palisade mesophyll cells. Collectively, these data establish a framework of genetic, anatomical, and molecular mechanisms that pattern leaf <strong><span style="color:yellowgreen">thick</span></strong>ness in desert-adapted tomato.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/376
10.1104/pp.17.00790
['Solanum', 'Solanum pennellii', 'plants']

8
PLANT PHYSIOLOGY
Genetics of Variable Disease Expression Conferred by Inverse Gene-For-Gene Interactions in the Wheat-<i>Parastagonospora nodorum</i> Pathosystem
<p>The wheat-<i>Parastagonospora nodorum</i> pathosystem involves the recognition of pathogen-secreted necrotrophic effectors (NEs) by corresponding wheat NE sensitivity genes. This inverse gene-for-gene recognition leads to necrotrophic effector-triggered susceptibility and ultimately septoria nodorum blotch disease. Here, we used multiple pathogen <strong><span style="color:yellowgreen">isol</span></strong>ates to individually evaluate the effects of the host gene-NE interactions <i>Tan spot necrosis1</i>-Stagonospora nodorum ToxinA (<i>Tsn1</i>-SnToxA), <i>Stagonospora nodorum necrosis1</i>-Stagonospora nodorum Toxin1 (<i>Snn1</i>-SnTox1), and <i>Stagonospora nodorum necrosis3-B genome homeolog1</i>-Stagonospora nodorum Toxin3 (<i>Snn3-B1</i>-SnTox3), alone and in various combinations, to determine the relative importance of these interactions in causing disease. Genetic analysis of a recombinant inbred wheat population inoculated <strong><span style="color:yellowgreen">separ</span></strong>ately with three <i>P. nodorum</i> <strong><span style="color:yellowgreen">isol</span></strong>ates, all of which produce all three NEs, indicated that the <i>Tsn1</i>-SnToxA and <i>Snn3-B1</i>-SnTox3 interactions contributed to disease caused by all four <strong><span style="color:yellowgreen">isol</span></strong>ates, but their effects varied and ranged from epistatic to additive. The <i>Snn1</i>-SnTox1 interaction was associated with increased disease for one <strong><span style="color:yellowgreen">isol</span></strong>ate, but for other <strong><span style="color:yellowgreen">isol</span></strong>ates, there was evidence that this interaction inhibited the expression of other host gene-NE interactions. RNA sequencing analysis in planta showed that <i>SnTox1</i> was differentially expressed between these three <strong><span style="color:yellowgreen">isol</span></strong>ates after infection. Further analysis of NE gene-knockout <strong><span style="color:yellowgreen">isol</span></strong>ates showed that the effect of some interactions could be masked or inhibited by other compatible interactions, and the regulation of this occurs at the level of NE gene transcription. Collectively, these results show that the inverse gene-for-gene interactions leading to necrotrophic effector-triggered susceptibility in the wheat-<i>P. nodorum</i> pathosystem vary in their effects depending on the genetic backgrounds of the pathogen and host, and interplay among the interactions is complex and intricately regulated.</p>
http://plantphysiol.org/cgi/content/abstract/180/1/420
10.1104/pp.19.00149
['Stagonospora', 'wheat']

8
The Bone & Joint Journal
A positive bacterial culture during re-implantation is associated with a poor outcome in two-stage exchange arthroplasty for deep infection
<sec><title>Aims</title><p>The aim of this study was to identify the incidence of <strong><span style="color:yellowgreen">posit</span></strong>ive   cultures during the second stage of a two-stage revision arthroplasty   and to analyse the association between <strong><span style="color:yellowgreen">posit</span></strong>ive cultures and an   infection-free outcome.</p></sec><sec><title>Patients and Methods</title><p>This single-centre retrospective review of prospectively collected   data included patients with a periprosthetic joint infection (PJI)   of either the hip or the knee between 2013 and 2015, who were treated   using a standardised diagnostic and therapeutic algorithm with two-stage   exchange. Failure of treatment was assessed according to a definition   determined by a Delphi-based consensus. Logistic regression analysis   was performed to assess the predictors of <strong><span style="color:yellowgreen">posit</span></strong>ive culture and risk   factors for failure. The mean follow-up was 33 months (24 to 48).</p></sec><sec><title>Results</title><p>A total of 163 two-stage revision arthroplasties involving 84   total hip arthroplasties (THAs) and 79 total knee arthroplasties   (TKAs) were reviewed. In 27 patients (16.6%), ≥ 1 <strong><span style="color:yellowgreen">posit</span></strong>ive culture   was identified at re-implantation and eight (29.6%) of these subsequently   failed compared with 20 (14.7%) patients who were culture-negative.   The same initially infecting organism was <strong><span style="color:yellowgreen">isol</span></strong>ated at re-implantation   in nine of 27 patients (33.3%). The organism causing re-infection   in none of the patients was the same as that <strong><span style="color:yellowgreen">isol</span></strong>ated at re-implantation.   The risk of the failure of treatment was significantly higher in   patients with a <strong><span style="color:yellowgreen">posit</span></strong>ive culture (odds ratio (OR) 1.7; 95% confidence   <strong><span style="color:yellowgreen">interv</span></strong>al (CI) 1.0 to 3.0; p = 0.049) and in patients with a higher   Charlson Comorbidity Index (OR 1.5; 95% CI 1.6 to 1.8; p = 0.001).</p></sec><sec><title>Conclusion</title><p><strong><span style="color:yellowgreen">posit</span></strong>ive culture at re-implantation was independently associated   with subsequent failure. Surgeons need to be aware of this association   and should consider the medical optimisation of patients with severe   comorbidities both before and during treatment.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1490–5.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1490
10.1302/0301-620X.99B11.BJJ-2017-0243-R1
None

8
Circulation
Angiography Versus Hemodynamics to Predict the Natural History of Coronary Stenoses
<sec><title>Background:</title><p>Among patients with documented stable coronary artery disease and in whom no revascularization was performed, we compared the respective values of angiographic diameter stenosis (DS) and fractional flow reserve (FFR) in predicting natural history.</p></sec><sec><title>Methods:</title><p>The present analysis included the 607 patients from the FAME 2 trial (Fractional Flow Reserve Versus Angiography in Multivessel Evaluation 2) in whom no revascularization was performed. FFR varied from 0.20 to 1.00 (average 0.74±0.16), and DS (by quantitative coronary analysis) varied from 8% to 98% (average 53±15). The primary end point, defined as vessel-oriented clinical end point (VOCE) at 2 years, was a com<strong><span style="color:yellowgreen">posit</span></strong>e of prospectively adjudicated cardiac death, vessel-related myocardial infarction, vessel-related urgent, and not urgent revascularization. The stenoses were divided into 4 groups according to FFR and %DS values: <strong><span style="color:yellowgreen">posit</span></strong>ive concordance (FFR≤0.80; DS≥50%), negative concordance (FFR>0.80; DS<50%), <strong><span style="color:yellowgreen">posit</span></strong>ive mismatch (FFR≤0.80; DS<50%), and negative mismatch (FFR>0.80; DS≥50%).</p></sec><sec><title>Results:</title><p>The rate of VOCE was highest in the <strong><span style="color:yellowgreen">posit</span></strong>ive concordance group (log rank: X<sup>2</sup>=80.96; <i>P</i>=0.001) and lowest in the negative concordance group. The rate of VOCE was higher in the <strong><span style="color:yellowgreen">posit</span></strong>ive mismatch group than in the negative mismatch group (hazard ratio, 0.38; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.21–0.67; <i>P</i>=0.001). There was no significant difference in VOCE between the <strong><span style="color:yellowgreen">posit</span></strong>ive concordance and <strong><span style="color:yellowgreen">posit</span></strong>ive mismatch groups (FFR≤0.80; hazard ratio, 0.77; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.57–1.09; <i>P</i>=0.149) and no significant difference in rate of VOCE between the negative mismatch and negative concordance groups (FFR>0.80; hazard ratio, 1.89; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.96–3.74; <i>P</i>=0.067).</p></sec><sec><title>Conclusions:</title><p>In patients with stable coronary disease, physiology (FFR) is a more important determinant of the natural history of coronary stenoses than anatomy (DS).</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://clinicaltrials.gov</ext-link>. Unique identifier: NCT01132495.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/14/1475
10.1161/CIRCULATIONAHA.117.028782
None

7
The Bone & Joint Journal
Variation in functional pelvic tilt in patients undergoing total hip arthroplasty
<sec><title>Aims</title><p>The pelvis rotates in the sagittal plane during daily activities.   These rotations have a direct effect on the functional orientation   of the acetabulum. The aim of this study was to quantify changes   in pelvic tilt between different functional <strong><span style="color:yellowgreen">posit</span></strong>ions.</p></sec><sec><title>Patients and Methods</title><p>Pre-operatively, pelvic tilt was measured in 1517 patients undergoing   total hip arthroplasty (THA) in three functional <strong><span style="color:yellowgreen">posit</span></strong>ions – supine,   standing and flexed seated (the moment when patients initiate rising   from a seated <strong><span style="color:yellowgreen">posit</span></strong>ion). Supine pelvic tilt was measured from CT   scans, standing and flexed seated pelvic tilts were measured from standardised   lateral radiographs. Anterior pelvic tilt was assigned a <strong><span style="color:yellowgreen">posit</span></strong>ive   value.</p></sec><sec><title>Results</title><p>The mean pelvic tilt was 4.2° (-20.5° to 24.5°), -1.3° (-30.2°   to 27.9°) and 0.6° (-42.0° to 41.3°) in the three <strong><span style="color:yellowgreen">posit</span></strong>ions, respectively.   The mean sagittal pelvic rotation from supine to standing was -5.5°   (-21.8° to 8.4°), from supine to flexed seated was -3.7° (-48.3°   to 38.6°) and from standing to flexed seated was 1.8° (-51.8° to   39.5°). In 259 patients (17%), the extent of sagittal pelvic rotation   could lead to functional malorientation of the acetabular component. Factoring   in an intra-operative delivery error of ± 5° extends this risk to   51% of patients.</p></sec><sec><title>Conclusion</title><p>Planning and measurement of the intended <strong><span style="color:yellowgreen">posit</span></strong>ion of the acetabular   component in the supine <strong><span style="color:yellowgreen">posit</span></strong>ion may fail to predict clinically   significant changes in its orientation during functional activities,   as a consequence of individual pelvic kinematics. Optimal orientation   is patient-specific and requires an evaluation of functional pelvic   tilt pre-operatively.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:184–91.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/2/184
10.1302/0301-620X.99B2.BJJ-2016-0098.R1
None

6
Tree Physiology
Root diameter variations explained by anatomy and phylogeny of 50 tropical and temperate tree species
<p>Root diameter, a critical indicator of root physiological function, varies greatly among tree species, but the underlying mechanism of this high variability is unclear. Here, we sampled 50 tree species across tropical and temperate zones in China, and measured root morphological and anatomical traits along the first five branch orders in each species. Our objectives were (i) to reveal the relationships between root diameter, cortical <strong><span style="color:yellowgreen">thick</span></strong>ness and stele diameter among tree species in tropical and temperate forests, and (ii) to investigate the relationship of both root morphological and anatomical traits with divergence time during species radiation. The results showed that root diameter was strongly affected by cortical <strong><span style="color:yellowgreen">thick</span></strong>ness but less by stele diameter in both tropical and temperate species. Changes in cortical <strong><span style="color:yellowgreen">thick</span></strong>ness explained over 90% of variation in root diameter for the first order, and ∼74–87% for the second and third orders. <strong><span style="color:yellowgreen">thick</span></strong>er roots displayed greater cortical <strong><span style="color:yellowgreen">thick</span></strong>ness and more cortical cell layers than thinner roots. Phylogenetic analysis demonstrated that root diameter, cortical <strong><span style="color:yellowgreen">thick</span></strong>ness and number of cortical cell layers significantly correlated with divergence time at the family level, showing similar variation trends in geological time. The results also suggested that trees tend to decrease their root cortical <strong><span style="color:yellowgreen">thick</span></strong>ness rather than stele diameter during species radiation. The close linkage of variations in root morphology and anatomy to phylogeny as demonstrated by the data from the 50 tree species should provide some insights into the mechanism of root diameter variability among tree species.</p>
http://treephys.oxfordjournals.org/cgi/content/abstract/34/4/415
10.1093/treephys/tpu019
None

6
The Bone & Joint Journal
The unsuspected prosthetic joint infection
<sec><title>Aims</title><p><strong><span style="color:yellowgreen">posit</span></strong>ive cultures are not uncommon in cases of revision total   knee and hip arthroplasty (TKA and THA) for presumed aseptic causes.   The purpose of this study was to assess the incidence of <strong><span style="color:yellowgreen">posit</span></strong>ive   intra-operative cultures in presumed aseptic revision of TKA and   THA, and to determine whether the presence of intra-operative <strong><span style="color:yellowgreen">posit</span></strong>ive cultures   results in inferior survival in such cases.</p></sec><sec><title>Patients and Methods</title><p>A retrospective cohort study was assembled with 679 patients   undergoing revision knee (340 cases) or hip arthroplasty (339 cases)   for presumed aseptic causes. For all patients three or more <strong><span style="color:yellowgreen">separ</span></strong>ate   intra-operative cultures were obtained. Patients were diagnosed   with a previously unsuspected prosthetic joint infection (PJI) if two   or more cultures were <strong><span style="color:yellowgreen">posit</span></strong>ive with the same organism. Records were   reviewed for demographic details, pre-operative laboratory results   and culture results. The primary outcome measure was infection-free   implant survival at two years.</p></sec><sec><title>Results</title><p>The incidence of unsuspected PJI was 27 out of 340 (7.9%) in   TKA and 41 out of 339 (12.1%) in THA. Following revision TKA, the   rate of infection-free implant survival in patients with an unsuspected   PJI was 88% (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>als (CI) 60 to 97) at two years   compared with 98% (95% CI 94 to 99) in patients without PJI (p = 0.001).   After THA, the rate of survival was similar in those with unsuspected   PJI (92% (95% CI 73 to 98) at two years) and those without (94%   (95% CI 89 to 97), p = 0.31).</p></sec><sec><title>Conclusion</title><p>Following revision of TKA and THA for aseptic diagnoses, around   10% of cases were found to have <strong><span style="color:yellowgreen">posit</span></strong>ive cultures. In the knee,   such cases had inferior infection-free survival at two years compared   with those with negative cultures; there was no difference between   the groups following THA.</p><p>Cite this article: Bone Joint J 2017;99-B:1482–9.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1482
10.1302/0301-620X.99B11.BJJ-2016-0655.R2
None

6
Circulation
Oral Anticoagulation in Very Elderly Patients With Atrial Fibrillation
<sec><title>Background:</title><p>Stroke prevention with oral anticoagulants (OACs) is the cornerstone for the management of atrial fibrillation (AF). However, data about the use of OACs among patients ≥90 years of age are limited. We aimed to investigate the risk of ischemic stroke and intracranial hemorrhage (ICH) and the net clinical benefit of OAC treatment for very elderly patients with AF (≥90 years of age).</p></sec><sec><title>Methods:</title><p>This study used the National Health Insurance Research Database in Taiwan. Risks of ischemic stroke and ICH were compared between 11 064 and 14 658 patients with and without AF ≥90 years of age without antithrombotic therapy from 1996 to 2011. Patients with AF (n=15 756) were divided into 3 groups (no treatment, antiplatelet agents, and warfarin), and the risks of stroke and ICH were analyzed. The risks of ischemic stroke and ICH were further compared between patients treated with warfarin and nonvitamin K antagonist OACs (NOACs) from 2012 to 2015 when NOACs were available in Taiwan.</p></sec><sec><title>Results:</title><p>Compared with patients without AF, patients with AF had an increased risk of ischemic stroke (event number/patient number, incidence = 742/11 064, 5.75%/y versus 1399/14 658, 3.00%/y; hazard ratio, 1.93; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.74–2.14) and similar risk of ICH (131/11 064, 0.97%/y versus 206/14 658, 0.54%/y; hazard ratio, 0.85; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.66–1.09) in competing risk analysis for mortality. Among patients with AF, warfarin use was associated with a lower stroke risk (39/617, 3.83%/y versus 742/11 064, 5.75%/y; hazard ratio, 0.69; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.49–0.96 in a competing risk model), with no difference in ICH risk compared with nontreatment. When compared with no antithrombotic therapy or antiplatelet drugs, warfarin was associated with a <strong><span style="color:yellowgreen">posit</span></strong>ive net clinical benefit. These findings persisted in propensity-matched analyses. Compared with warfarin, NOACs were associated with a lower risk of ICH (4/978, 0.42%/y versus 19/768, 1.63%/y; hazard ratio, 0.32; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.10–0.97 in a competing risk model), with no difference in risk of ischemic stroke.</p></sec><sec><title>Conclusions:</title><p>Among patients with AF ≥90 years of age, warfarin was associated with a lower risk of ischemic stroke and <strong><span style="color:yellowgreen">posit</span></strong>ive net clinical benefit. Compared with warfarin, NOACs were associated with a lower risk of ICH. Thus, OACs may still be considered as thromboprophylaxis for elderly patients, with NOACs being the more favorable choice.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/1/37
10.1161/CIRCULATIONAHA.117.031658
None

6
Circulation
Common Genetic Variant Risk Score Is Associated With Drug-Induced QT Prolongation and Torsade de Pointes Risk
<sec><title>Background:</title><p>Drug-induced QT <strong><span style="color:yellowgreen">interv</span></strong>al prolongation, a risk factor for life-threatening ventricular arrhythmias, is a potential side effect of many marketed and withdrawn medications. The contribution of common genetic variants previously associated with baseline QT <strong><span style="color:yellowgreen">interv</span></strong>al to drug-induced QT prolongation and arrhythmias is not known.</p></sec><sec><title>Methods:</title><p>We tested the hypothesis that a weighted combination of common genetic variants contributing to QT <strong><span style="color:yellowgreen">interv</span></strong>al at baseline, identified through genome-wide association studies, can predict individual response to multiple QT-prolonging drugs. Genetic analysis of 22 subjects was performed in a secondary analysis of a randomized, double-blind, placebo-controlled, crossover trial of 3 QT-prolonging drugs with 15 time-matched QT and plasma drug concentration measurements. Subjects received single doses of dofetilide, quinidine, ranolazine, and placebo. The outcome was the correlation between a genetic QT score comprising 61 common genetic variants and the slope of an individual subject’s drug-induced increase in heart rate–corrected QT (QTc) versus drug concentration.</p></sec><sec><title>Results:</title><p>The genetic QT score was correlated with drug-induced QTc prolongation. Among white subjects, genetic QT score explained 30% of the variability in response to dofetilide (<i>r</i>=0.55; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.09–0.81; <i>P</i>=0.02), 23% in response to quinidine (<i>r</i>=0.48; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, −0.03 to 0.79; <i>P</i>=0.06), and 27% in response to ranolazine (<i>r</i>=0.52; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.05–0.80; <i>P</i>=0.03). Furthermore, the genetic QT score was a significant predictor of drug-induced torsade de pointes in an independent sample of 216 cases compared with 771 controls (<i>r</i><sup>2</sup>=12%, <i>P</i>=1×10<sup>−7</sup>).</p></sec><sec><title>Conclusions:</title><p>We demonstrate that a genetic QT score comprising 61 common genetic variants explains a significant proportion of the variability in drug-induced QT prolongation and is a significant predictor of drug-induced torsade de pointes. These findings highlight an opportunity for recent genetic discoveries to improve individualized risk-benefit assessment for pharmacological therapies. Replication of these findings in larger samples is needed to more precisely estimate variance explained and to establish the individual variants that drive these effects.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01873950.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/14/1300
10.1161/CIRCULATIONAHA.116.023980
None

6
Circulation
Assessment of the European Society of Cardiology 0-Hour/1-Hour Algorithm to Rule-Out and Rule-In Acute Myocardial Infarction
<sec><title>Background:</title><p>The new European Society of Cardiology guidelines to rule-in and rule-out acute myocardial infarction (AMI) in the emergency department include a rapid assessment algorithm based on high-sensitivity cardiac troponin and sampling at 0 and 1 hour. Emergency department physicians require high sensitivity to confidently rule-out AMI, whereas cardiologists aim to minimize false-<strong><span style="color:yellowgreen">posit</span></strong>ive results.</p></sec><sec><title>Methods:</title><p>High-sensitivity troponin I and T assays were used to measure troponin concentrations in patients presenting with chest-pain symptoms and being investigated for possible acute coronary syndrome at hospitals in New Zealand, Australia, and Canada. AMI outcomes were independently adjudicated by at least 2 physicians. The European Society of Cardiology algorithm performance with each assay was assessed by the sensitivity and proportion with AMI ruled out and the <strong><span style="color:yellowgreen">posit</span></strong>ive predictive value and proportion ruled-in.</p></sec><sec><title>Results:</title><p>There were 2222 patients with serial high-sensitivity troponin T and high-sensitivity troponin I measurements. The high-sensitivity troponin T algorithm ruled out 1425 (64.1%) with a sensitivity of 97.1% (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al [CI], 94.0%–98.8%) and ruled-in 292 (13.1%) with a <strong><span style="color:yellowgreen">posit</span></strong>ive predictive value of 63.4% (95% CI, 57.5%–68.9%).</p><p>The high-sensitivity troponin I algorithm ruled out 1205 (54.2%) with a sensitivity of 98.8% (95% CI, 96.4%–99.7%)) and ruled-in 310 (14.0%) with a <strong><span style="color:yellowgreen">posit</span></strong>ive predictive value of 68.1% (95% CI, 62.6%–73.2%).</p></sec><sec><title>Conclusions:</title><p>The sensitivity of the European Society of Cardiology rapid assessment 0-/1-hour algorithm to rule-out AMI with high-sensitivity troponin may be insufficient for some emergency department physicians to confidently send patients home. These algorithms may prove useful to identify patients requiring expedited management. However, the <strong><span style="color:yellowgreen">posit</span></strong>ive predictive value was modest for both algorithms.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/20/1532
10.1161/CIRCULATIONAHA.116.022677
None

5
Science
Social place-cells in the bat hippocampus
<p>Social animals have to know the spatial <strong><span style="color:yellowgreen">posit</span></strong>ions of conspecifics. However, it is unknown how the <strong><span style="color:yellowgreen">posit</span></strong>ion of others is represented in the brain. We designed a spatial observational-learning task, in which an observer bat mimicked a demonstrator bat while we recorded hippocampal dorsal-CA1 neurons from the observer bat. A neuronal subpopulation represented the <strong><span style="color:yellowgreen">posit</span></strong>ion of the other bat, in allocentric coordinates. About half of these “social place-cells” represented also the observer’s own <strong><span style="color:yellowgreen">posit</span></strong>ion—that is, were place cells. The representation of the demonstrator bat did not reflect self-movement or trajectory planning by the observer. Some neurons represented also the <strong><span style="color:yellowgreen">posit</span></strong>ion of inanimate moving objects; however, their representation differed from the representation of the demonstrator bat. This suggests a role for hippocampal CA1 neurons in social-spatial cognition.</p>
http://sciencemag.org/cgi/content/abstract/359/6372/218
10.1126/science.aao3474
['animals']

5
PLANT PHYSIOLOGY
SHORTROOT-Mediated Increase in Stomatal Density Has No Impact on Photosynthetic Efficiency
<p>The coordinated <strong><span style="color:yellowgreen">posit</span></strong>ioning of veins, mesophyll cells, and stomata across a leaf is crucial for efficient gas exchange and transpiration and, therefore, for overall function. In monocot leaves, stomatal cell files are <strong><span style="color:yellowgreen">posit</span></strong>ioned at the flanks of underlying longitudinal leaf veins, rather than directly above or below. This pattern suggests either that stomatal formation is inhibited in epidermal cells directly in contact with the vein or that specification is induced in cell files beyond the vein. The SHORTROOT pathway specifies distinct cell types around the vasculature in subepidermal layers of both root and shoots, with cell type identity determined by distance from the vein. To test whether the pathway has the potential to similarly pattern epidermal cell types, we expanded the expression domain of the rice (<i>Oryza sativa</i> ssp <i>japonica</i>) <i>OsSHR2</i> gene, which we show is restricted to developing leaf veins, to include bundle sheath cells encircling the vein. In transgenic lines, which were generated using the orthologous <i>ZmSHR1</i> gene to avoid potential silencing of <i>OsSHR2</i>, stomatal cell files were observed both in the normal <strong><span style="color:yellowgreen">posit</span></strong>ion and in more distant <strong><span style="color:yellowgreen">posit</span></strong>ions from the vein. Contrary to theoretical predictions, and to phenotypes observed in eudicot leaves, the increase in stomatal density did not enhance photosynthetic capacity or increase mesophyll cell density. Collectively, these results suggest that the SHORTROOT pathway may coordinate the <strong><span style="color:yellowgreen">posit</span></strong>ioning of veins and stomata in monocot leaves and that distinct mechanisms may operate in monocot and eudicot leaves to coordinate stomatal patterning with the development of underlying mesophyll cells.</p>
http://plantphysiol.org/cgi/content/abstract/176/1/757
10.1104/pp.17.01005
['Oryza', 'Oryza sativa', 'rice']

5
PLANT PHYSIOLOGY
Characterization of Trichome-Expressed BAHD Acyltransferases in <i>Petunia axillaris</i> Reveals Distinct Acylsugar Assembly Mechanisms within the Solanaceae
<p>Acylsugars are synthesized in the glandular trichomes of the Solanaceae family and are implicated in protection against abiotic and biotic stress. Acylsugars are composed of either sucrose or glucose esterified with varying numbers of acyl chains of differing length. In tomato (<i>Solanum lycopersicum</i>), acylsugar assembly requires four acylsugar acyltransferases (ASATs) of the BAHD superfamily. Tomato ASATs catalyze the sequential esterification of acyl-coenzyme A thioesters to the R4, R3, R3′, and R2 <strong><span style="color:yellowgreen">posit</span></strong>ions of sucrose, yielding a tetra-acylsucrose. <i>Petunia</i> spp. synthesize acylsugars that are structurally distinct from those of tomato. To explore the mechanisms underlying this chemical diversity, a <i>Petunia</i> <i>axillaris</i> transcriptome was mined for trichome preferentially expressed BAHDs. A combination of phylogenetic analyses, gene silencing, and biochemical analyses coupled with structural elucidation of metabolites revealed that acylsugar assembly is not conserved between tomato and petunia. In <i>P. axillaris</i>, tetra-acylsucrose assembly occurs through the action of four ASATs, which catalyze sequential addition of acyl groups to the R2, R4, R3, and R6 <strong><span style="color:yellowgreen">posit</span></strong>ions. Notably, in <i>P. axillaris</i>, PaxASAT1 and PaxASAT4 catalyze the acylation of the R2 and R6 <strong><span style="color:yellowgreen">posit</span></strong>ions of sucrose, respectively, and no clear orthologs exist in tomato. Similarly, petunia acylsugars lack an acyl group at the R3′ <strong><span style="color:yellowgreen">posit</span></strong>ion, and congruently, an ortholog of SlASAT3, which catalyzes acylation at the R3′ <strong><span style="color:yellowgreen">posit</span></strong>ion in tomato, is absent in <i>P. axillaris</i>. Furthermore, where putative orthologous relationships of ASATs are predicted between tomato and petunia, these are not supported by biochemical assays. Overall, these data demonstrate the considerable evolutionary plasticity of acylsugar biosynthesis.</p>
http://plantphysiol.org/cgi/content/abstract/175/1/36
10.1104/pp.17.00538
['Petunia', 'Petunia axillaris', 'Solanaceae', 'Solanum', 'Solanum lycopersicum', 'petunia']

5
Molecular Biology and Evolution
Dynamic Convergent Evolution Drives the Passage Adaptation across 48 Years’ History of H3N2 Influenza Evolution
<p>Influenza viruses are often propagated in a diverse set of culturing media and additional substitutions known as passage adaptation can cause extra evolution in the target strain, leading to ineffective vaccines. Using 25,482 H3N2 HA1 sequences curated from Global Initiative on Sharing All Influenza Data and National Center for Biotechnology Information databases, we found that passage adaptation is a very dynamic process that changes over time and evolves in a seesaw like pattern. After crossing the species boundary from bird to human in 1968, the influenza H3N2 virus evolves to be better adapted to the human environment and passaging them in embryonated eggs (i.e., an avian environment) leads to increasingly stronger <strong><span style="color:yellowgreen">posit</span></strong>ive selection. On the contrary, passage adaptation to the mammalian cell lines changes from <strong><span style="color:yellowgreen">posit</span></strong>ive selection to negative selection. Using two statistical tests, we identified 19 codon <strong><span style="color:yellowgreen">posit</span></strong>ions around the receptor binding domain strongly contributing to passage adaptation in the embryonated egg. These sites show strong convergent evolution and overlap extensively with <strong><span style="color:yellowgreen">posit</span></strong>ively selected sites identified in humans, suggesting that passage adaptation can confound many of the earlier studies on influenza evolution. Interestingly, passage adaptation in recent years seems to target a few codon <strong><span style="color:yellowgreen">posit</span></strong>ions in antigenic surface epitopes, which makes it difficult to produce antigenically unaltered vaccines using embryonic eggs. Our study outlines another interesting scenario whereby both convergent and adaptive evolution are working in synchrony driving viral adaptation. Future studies from sequence analysis to vaccine production need to take careful consideration of passage adaptation.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3133
10.1093/molbev/msw190
['human', 'bird']

5
The Bone & Joint Journal
Lunate morphology as a risk factor of idiopathic ulnar impaction syndrome
<sec><title>Aims</title><p><strong><span style="color:yellowgreen">posit</span></strong>ive ulnar variance is an established risk factor for idiopathic   ulnar impaction syndrome (UIS). However, not all patients with <strong><span style="color:yellowgreen">posit</span></strong>ive   ulnar variance develop symptomatic UIS and other factors, including   the morphology of the lunate, may be involved. The aim of this study   was to clarify the relationship between lunate morphology and idiopathic   UIS.</p></sec><sec><title>Patients and Methods</title><p>A cohort of 95 patients with idiopathic UIS (UIS group) was compared   with 95 asymptomatic controls with <strong><span style="color:yellowgreen">posit</span></strong>ive ulnar variance. The   shape of the lunate was measured using the capitate-triquetrum distance   (CTD), ulnar coverage ratio (UCR), radiolunate distance and radiolunate   angle. The association of radiographic parameters and lunate types   with the development of UIS was investigated in univariable and   multivariable analyses. Receiver operating characteristic curves   were used to estimate a cutoff for any statistically significant   variables.</p></sec><sec><title>Results</title><p>The proportion of type II lunates, which have a medial hamate   facet, were significantly higher in the UIS group than in the control   group in the univariable analysis (p = 0.001). CTD (odds ratio (OR)   1.52; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al (CI) 1.11 to 2.06; p = 0.008) and   UCR (OR 44.78; 95% CI 5.35 to 374.90; p = 0.002) showed a <strong><span style="color:yellowgreen">posit</span></strong>ive   association with UIS in the multivariable analysis. Estimated cutoff   values were 2.5 mm for the CTD (area under the curve (AUC) = 0.65) and   0.4 for the UCR (AUC = 0.64).</p></sec><sec><title>Conclusion</title><p>The proportion of type II lunates was greater in the UIS group   than in the control group. A large UCR, which represents the broad   base of the lunate, was <strong><span style="color:yellowgreen">posit</span></strong>ively associated with the development   of idiopathic UIS.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1508–14.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1508
10.1302/0301-620X.99B11.BJJ-2016-1238.R2
None

5
The Bone & Joint Journal
Appropriate hinge position for prevention of unstable lateral hinge fracture in open wedge high tibial osteotomy
<sec><title>Aims</title><p>Open wedge high tibial osteotomy (OWHTO) for medial-compartment   osteoarthritis of the knee can be complicated by intra-operative   lateral hinge fracture (LHF). We aimed to establish the relationship   between hinge <strong><span style="color:yellowgreen">posit</span></strong>ion and fracture types, and suggest an appropriate   hinge <strong><span style="color:yellowgreen">posit</span></strong>ion to reduce the risk of this complication.</p></sec><sec><title>Patients and Methods</title><p>Consecutive patients undergoing OWHTO were evaluated on coronal   multiplanar reconstruction CT images. Hinge <strong><span style="color:yellowgreen">posit</span></strong>ions were divided   into five zones in our new classification, by their relationship   to the proximal tibiofibular joint (PTFJ). Fractures were classified   into types I, II, and III according to the Takeuchi classification.</p></sec><sec><title>Results</title><p>Among 111 patients undergoing OWHTOs, 22 sustained lateral hinge   fractures. Of the 89 patients without fractures, 70 had hinges in   the zone within the PTFJ and lateral to the medial margin of the   PTFJ (zone WL), just above the PTFJ. Among the five zones, the relative   risk of unstable fracture was significantly lower in zone WL (relative   risk 0.24, confidence <strong><span style="color:yellowgreen">interv</span></strong>al 0.17 to 0.34).</p></sec><sec><title>Conclusion</title><p>Zone WL appears to offer the safest <strong><span style="color:yellowgreen">posit</span></strong>ion for the placement   of the osteotomy hinge when trying to avoid a fracture at the osteotomy   site.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99B10:1313–18</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/10/1313
10.1302/0301-620X.99B10.BJJ-2017-0103.R1
None

5
Circulation
The Optimal Timing of Stage 2 Palliation for Hypoplastic Left Heart Syndrome
<sec><title>Background:</title><p>In infants requiring 3-stage single-ventricle palliation for hypoplastic left heart syndrome, attrition after the Norwood procedure remains significant. The effect of the timing of stage 2 palliation (S2P), a physician-modifiable factor, on long-term survival is not well understood. We hypothesized that an optimal <strong><span style="color:yellowgreen">interv</span></strong>al between the Norwood and S2P that both minimizes pre-S2P attrition and maximizes post-S2P survival exists and is associated with individual patient characteristics.</p></sec><sec><title>Methods:</title><p>The National Institutes of Health/National Heart, Lung, and Blood Institute Pediatric Heart Network Single Ventricle Reconstruction Trial public data set was used. Transplant-free survival (TFS) was modeled from (1) Norwood to S2P and (2) S2P to 3 years by using parametric hazard analysis. Factors associated with death or heart transplantation were determined for each <strong><span style="color:yellowgreen">interv</span></strong>al. To account for staged procedures, risk-adjusted, 3-year, post-Norwood TFS (the probability of TFS at 3 years given survival to S2P) was calculated using parametric conditional survival analysis. TFS from the Norwood to S2P was first predicted. TFS after S2P to 3 years was then predicted and adjusted for attrition before S2P by multiplying by the estimate of TFS to S2P. The optimal timing of S2P was determined by generating nomograms of risk-adjusted, 3-year, post-Norwood, TFS versus the <strong><span style="color:yellowgreen">interv</span></strong>al from the Norwood to S2P.</p></sec><sec><title>Results:</title><p>Of 547 included patients, 399 survived to S2P (73%). Of the survivors to S2P, 349 (87%) survived to 3-year follow-up. The median <strong><span style="color:yellowgreen">interv</span></strong>al from the Norwood to S2P was 5.1 (interquartile range, 4.1–6.0) months. The risk-adjusted, 3-year, TFS was 68±7%. A Norwood-S2P <strong><span style="color:yellowgreen">interv</span></strong>al of 3 to 6 months was associated with greatest 3-year TFS overall and in patients with few risk factors. In patients with multiple risk factors, TFS was severely compromised, regardless of the timing of S2P and most severely when S2P was performed early. No difference in the optimal timing of S2P existed when stratified by shunt type.</p></sec><sec><title>Conclusions:</title><p>In infants with few risk factors, progressing to S2P at 3 to 6 months after the Norwood procedure was associated with maximal TFS. Early S2P did not rescue patients with greater risk factor burdens. Instead, referral for heart transplantation may offer their best chance at long-term survival.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00115934.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1737
10.1161/CIRCULATIONAHA.117.028481
None

5
Circulation
β<sub>2</sub>-Glycoprotein I/IgA Immune Complexes
<sec><title>Background:</title><p>Antiphospholipid syndrome is characterized by recurrent thrombosis and gestational morbidity in patients with antiphospholipid autoantibodies (aPLs). Predictive value of the presence of aPLs is low, and new markers are necessary to identify aPL carriers at higher risk and take preventive measures on them. The presence of circulating immune complexes of IgA bound to β<sub>2</sub>-glycoprotein I (B2A-CIC) has been associated with occurrence of acute thrombotic events. In this work we study its possible predictive value for the appearance of acute thrombotic events in patients who are going to undergo transplant surgery, a well-known trigger of acute thrombotic events in aPL carriers.</p></sec><sec><title>Methods:</title><p>We performed a follow-up study based on the Magnum 12+12 Cohort of patients who received a kidney transplant (n=1339). Three groups were established: group 1 patients who were <strong><span style="color:yellowgreen">posit</span></strong>ive for IgA anti-β<sub>2</sub>-glycoprotein I (aB2GP1) and B2A-CIC (n=125); group 2 patients who were <strong><span style="color:yellowgreen">posit</span></strong>ive only for IgA aB2GP1 (n=240); and control group, patients who were negative for IgA aB2GP1 (n=974). Levels of autoantibodies and B2A-CIC were quantified immediately before the transplant surgery and patients were followed up for 6 months.</p></sec><sec><title>Results:</title><p>In group 1, 46.4% of patients experienced any type of thrombosis versus 10.4% in group 2 (<i>P</i><0.001) and 8.6% in the control group (<i>P</i><0.001). The incidence of graft thrombosis in group 1 (31.2%) was significantly higher than that observed in group 2 (3.3%, <i>P</i><0.001) and the control group (2.6%, <i>P</i><0.001). In a multivariate analysis, the presence of B2A-CIC was an independent variable to experience any type of posttransplant thrombosis (hazard ratio, 6.72; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 4.81–9.37) and, prominently, for graft thrombosis (hazard ratio, 14.75; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 9.11–23.89). No significant differences were found between B2A-CIC–negative and control group patients.</p></sec><sec><title>Conclusions:</title><p>The presence of B2A-CIC is a predictor of acute thrombotic events. Patients who were <strong><span style="color:yellowgreen">posit</span></strong>ive for IgA aB2GP1 only are at risk of experiencing thrombosis if they are B2A-CIC <strong><span style="color:yellowgreen">posit</span></strong>ive. If they are B2A-CIC–negative patients, they have the same risk as the control group. Treatments to prevent acute thrombotic events should focus on B2A-CIC–<strong><span style="color:yellowgreen">posit</span></strong>ive patients.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/20/1922
10.1161/CIRCULATIONAHA.116.025992
None

5
Circulation
Genetic Risk Prediction of Atrial Fibrillation
<sec><title>Background:</title><p>Atrial fibrillation (AF) has a substantial genetic basis. Identification of individuals at greatest AF risk could minimize the incidence of cardioembolic stroke.</p></sec><sec><title>Methods:</title><p>To determine whether genetic data can stratify risk for development of AF, we examined associations between AF genetic risk scores and incident AF in 5 prospective studies comprising 18 919 individuals of European ancestry. We examined associations between AF genetic risk scores and ischemic stroke in a <strong><span style="color:yellowgreen">separ</span></strong>ate study of 509 ischemic stroke cases (202 cardioembolic [40%]) and 3028 referents. Scores were based on 11 to 719 common variants (≥5%) associated with AF at <i>P</i> values ranging from <1×10<sup>−3</sup> to <1×10<sup>−8</sup> in a prior independent genetic association study.</p></sec><sec><title>Results:</title><p>Incident AF occurred in 1032 individuals (5.5%). AF genetic risk scores were associated with new-onset AF after adjustment for clinical risk factors. The pooled hazard ratio for incident AF for the highest versus lowest quartile of genetic risk scores ranged from 1.28 (719 variants; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.13–1.46; <i>P</i>=1.5×10<sup>−4</sup>) to 1.67 (25 variants; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.47–1.90; <i>P</i>=9.3×10<sup>−15</sup>). Discrimination of combined clinical and genetic risk scores varied across studies and scores (maximum C statistic, 0.629–0.811; maximum ΔC statistic from clinical score alone, 0.009–0.017). AF genetic risk was associated with stroke in age- and sex-adjusted models. For example, individuals in the highest versus lowest quartile of a 127-variant score had a 2.49-fold increased odds of cardioembolic stroke (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.39–4.58; <i>P</i>=2.7×10<sup>−3</sup>). The effect persisted after the exclusion of individuals (n=70) with known AF (odds ratio, 2.25; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.20–4.40; <i>P</i>=0.01).</p></sec><sec><title>Conclusions:</title><p>Comprehensive AF genetic risk scores were associated with incident AF beyond associations for clinical AF risk factors but offered small improvements in discrimination. AF genetic risk was also associated with cardioembolic stroke in age- and sex-adjusted analyses. Efforts are warranted to determine whether AF genetic risk may improve identification of subclinical AF or help distinguish between stroke mechanisms.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/14/1311
10.1161/CIRCULATIONAHA.116.024143
None

5
Circulation
Association Between a Prolonged PR Interval and Outcomes of Cardiac Resynchronization Therapy
<sec><title>Background:</title><p>A prolonged PR <strong><span style="color:yellowgreen">interv</span></strong>al is common among cardiac resynchronization therapy (CRT) candidates; however, the association between PR <strong><span style="color:yellowgreen">interv</span></strong>al and outcomes is unclear, and the data are conflicting.</p></sec><sec><title>Methods:</title><p>We conducted inverse probability weighted analyses of 26 451 CRT-eligible (ejection fraction ≤35, QRS ≥120 ms) patients from the National Cardiovascular Data Registry ICD Registry to assess the association between a prolonged PR <strong><span style="color:yellowgreen">interv</span></strong>al (≥230 ms), receipt of CRT with defibrillator (CRT-D) versus implantable cardioverter defibrillator (ICD), and outcomes. We first tested the association between a prolonged PR <strong><span style="color:yellowgreen">interv</span></strong>al and outcomes among patients stratified by device type. Next, we performed a comparative effectiveness analysis of CRT-D versus ICD among patients when stratified by PR <strong><span style="color:yellowgreen">interv</span></strong>al. Using Medicare claims data, we followed up with patients up to 5 years for incident heart failure hospitalization or death.</p></sec><sec><title>Results:</title><p>Patients with a PR≥230 ms (15%; n=4035) were older and had more comorbidities, including coronary artery disease, atrial arrhythmias, diabetes mellitus, and chronic kidney disease. After risk adjustment, a PR≥230 ms (versus PR<230 ms) was associated with increased risk of heart failure hospitalization or death among CRT-D (hazard ratio, 1.23; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.14–1.31; <i>P</i><0.001) but not ICD recipients (hazard ratio, 1.08; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.97–1.20; <i>P</i>=0.17) (<i>P</i><sub>interaction</sub>=0.043). CRT-D (versus ICD) was associated with lower rates of heart failure hospitalization or death among patients with PR<230 ms (hazard ratio, 0.79; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.73–0.85; <i>P</i><0.001) but not PR≥230 ms (hazard ratio, 1.01; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.87–1.17; <i>P</i>=0.90) (<i>P</i><sub>interaction</sub>=0.0025).</p></sec><sec><title>Conclusions:</title><p>A PR≥230 ms is associated with increased rates of heart failure hospitalization or death among CRT-D patients. The real-world comparative effectiveness of CRT-D (versus ICD) is significantly less among patients with a PR≥230 ms in comparison with patients with a PR<230 ms.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/21/1617
10.1161/CIRCULATIONAHA.116.022913
None

5
Circulation
Long-Term Safety and Effectiveness of Mechanical Versus Biologic Aortic Valve Prostheses in Older Patients
<sec><title>Background—</title><p>There is a paucity of long-term data comparing biological versus mechanical aortic valve prostheses in older individuals.</p></sec><sec><title>Methods and Results—</title><p>We performed follow-up of patients aged 65 to 80 years undergoing aortic valve replacement with a biological (n=24 410) or mechanical (n=14 789) prosthesis from 1991 to 1999 at 605 centers within the Society of Thoracic Surgeons Adult Cardiac Surgery Database using Medicare inpatient claims (mean, 12.6 years; maximum, 17 years; minimum, 8 years), and outcomes were compared by propensity methods. Among Medicare-linked patients undergoing aortic valve replacement (mean age, 73 years), both reoperation (4.0%) and endocarditis (1.9%) were uncommon to 12 years; however, the risk for other adverse outcomes was high, including death (66.5%), stroke (14.1%), and bleeding (17.9%). Compared with those receiving a mechanical valve, patients given a bioprosthesis had a similar adjusted risk for death (hazard ratio, 1.04; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.01–1.07), higher risks for reoperation (hazard ratio, 2.55; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 2.14–3.03) and endocarditis (hazard ratio, 1.60; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.31–1.94), and lower risks for stroke (hazard ratio, 0.87; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.82–0.93) and bleeding (hazard ratio, 0.66; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.62–0.70). Although these results were generally consistent among patient subgroups, bioprosthesis patients aged 65 to 69 years had a substantially elevated 12-year absolute risk of reoperation (10.5%).</p></sec><sec><title>Conclusions—</title><p>Among patients undergoing aortic valve replacement, long-term mortality rates were similar for those who received bioprosthetic versus mechanical valves. Bioprostheses were associated with a higher long-term risk of reoperation and endocarditis but a lower risk of stroke and hemorrhage. These risks varied as a function of a patient’s age and comorbidities.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/16/1647
10.1161/CIRCULATIONAHA.113.002003
None

5
Circulation
Long-Chain Monounsaturated Fatty Acids and Incidence of Congestive Heart Failure in 2 Prospective Cohorts
<sec><title>Background—</title><p>Decades-old animal experiments suggested that dietary long-chain monounsaturated fatty acids (LCMUFAs) caused cardiotoxicity, leading, for example, development of Canola oil (Canadian oil low in erucic acid) from rapeseed. However, potential cardiotoxicity in humans and contemporary dietary sources of LCMUFAs are unknown.</p></sec><sec><title>Methods and Results—</title><p>We prospectively investigated the associations of plasma phospholipid LCMUFAs (20:1, 22:1, and 24:1), assessed as objective biomarkers of exposure, with incidence congestive heart failure in 2 independent cohorts: 3694 older adults (mean age, 75.2±5.2 years) in the Cardiovascular Health Study (CHS; 1992–2006) and 3577 middle-aged adults (mean age, 54.1±5.8 years) in the Atherosclerosis Risk in Communities Study, Minnesota subcohort (ARIC; 1987–2008). We further examined dietary correlates of circulating LCMUFAs in CHS and ARIC and US dietary sources of LCMUFAs in the 2003–2010 National Health and Nutrition Examination Survey (NHANES). In CHS, 997 congestive heart failure events occurred during 39 238 person-years; in ARIC, 330 events congestive heart failure events occurred during 64 438 person-years. After multivariable adjustment, higher levels of 22:1 and 24:1 were <strong><span style="color:yellowgreen">posit</span></strong>ively associated with greater incident congestive heart failure in both CHS and ARIC; hazard ratios were 1.34 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.02–1.76) and 1.57 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.11–2.23) for highest versus lowest quintiles of 22:1, respectively, and 1.75 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.23–2.50) and 1.92 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.22–3.03) for 24:1, respectively (<i>P</i> for trend ≤0.03 each). A variety of foods were related to circulating LCMUFAs in CHS and ARIC, consistent with food sources of LCMUFAs in NHANES, including fish, poultry, meats, whole grains, and mustard.</p></sec><sec><title>Conclusions—</title><p>Higher circulating levels of 22:1 and 24:1, with apparently diverse dietary sources, were associated with incident congestive heart failure in 2 independent cohorts, suggesting possible cardiotoxicity of LCMUFAs in humans.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/14/1512
10.1161/CIRCULATIONAHA.112.001197
['mustard', 'fish']

5
Circulation
Genetic Determinants of Dabigatran Plasma Levels and Their Relation to Bleeding
<sec><title>Background—</title><p>Fixed-dose unmonitored treatment with dabigatran etexilate is effective and has a favorable safety profile in the prevention of stroke in atrial fibrillation patients compared with warfarin. We hypothesized that genetic variants could contribute to interindividual variability in blood concentrations of the active metabolite of dabigatran etexilate and influence the safety and efficacy of dabigatran.</p></sec><sec><title>Methods and Results—</title><p>We successfully conducted a genome-wide association study in 2944 Randomized Evaluation of Long-term Anticoagulation Therapy (RE-LY) participants. The <i>CES1</i> single-nucleotide polymorphism rs2244613 was associated with trough concentrations, and the <i>ABCB1</i> single-nucleotide polymorphism rs4148738 and the <i>CES1</i> single-nucleotide polymorphism rs8192935 were associated with peak concentrations at genome-wide significance (<i>P</i><9×10<sup>−8</sup>) with a gene-dose effect. Each minor allele of the <i>CES1</i> single-nucleotide polymorphism rs2244613 was associated with lower trough concentrations (15% decrease per allele; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 10–19; <i>P</i>=1.2×10<sup>−8</sup>) and a lower risk of any bleeding (odds ratio, 0.67; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.55–0.82; <i>P</i>=7×10<sup>−5</sup>) in dabigatran-treated participants, with a consistent but nonsignificant lower risk of major bleeding (odds ratio, 0.66; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.43–1.01). The interaction between treatment (warfarin versus all dabigatran) and carrier status was statistically significant (<i>P</i>=0.002), with carriers having less bleeding with dabigatran than warfarin (hazard ratio, 0.59; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.46–0.76; <i>P</i>=5.2×10<sup>−</sup>5) in contrast to no difference in noncarriers (hazard ratio, 0.96; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.81–1.14; <i>P</i>=0.65). There was no association with ischemic events, and neither rs4148738 nor rs8192935 was associated with bleeding or ischemic events.</p></sec><sec><title>Conclusions—</title><p>Genome-wide association analysis identified that carriage of the <i>CES1</i> rs2244613 minor allele occurred in 32.8% of patients in RE-LY and was associated with lower exposure to active dabigatran metabolite. The presence of the polymorphism was associated with a lower risk of bleeding.</p></sec><sec><title>Clinical Trial Registration—</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00262600.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/13/1404
10.1161/CIRCULATIONAHA.112.001233
None

5
Circulation
Association Between Physician Follow-Up and Outcomes of Care After Chest Pain Assessment in High-Risk Patients
<sec><title>Background—</title><p>Assessment of chest pain is one of the most common reasons for emergency department visits in developed countries. Although guidelines recommend primary care physician (PCP) follow-up for patients who are subsequently discharged, little is known about the relationship between physician follow-up and clinical outcomes.</p></sec><sec><title>Methods and Results—</title><p>An observational study was conducted on patients with higher baseline risk, defined as having diabetes mellitus or established cardiovascular disease, who were evaluated for chest pain, discharged, and without adverse clinical outcomes for 30 days in Ontario from 2004 to 2010. Multivariable proportional hazard models were constructed to adjust for potential confounding between physician groups (cardiologist, PCP, or none). Among 56767 included patients, 17% were evaluated by cardiologists, 58% were evaluated by PCPs alone, and 25% had no physician follow-up. The mean age was 66±15 years, and 53% were male. The highest rates of diagnostic testing, medical therapy, and coronary revascularization were seen among patients treated by cardiologists. At 1 year, the rate of death or MI was 5.5% (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 5.0–5.9) in the cardiology group, 7.7% (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 7.4–7.9) in the PCP group, and 8.6% (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 8.2–9.1) in the no-physician group. After adjustment, cardiologist follow-up was associated with significantly lower adjusted hazard ratio of death or MI compared with PCP (hazard ratio, 0.85; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.78–0.92) and no physician (hazard ratio, 0.79; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.71–0.88) follow-up.</p></sec><sec><title>Conclusions—</title><p>Among patients with higher baseline cardiovascular risk who were discharged from the emergency department after evaluation for chest pain in Ontario, follow-up with a cardiologist was associated with a decreased risk of all-cause mortality or hospitalization for MI at 1 year compared with follow-up with a PCP or no physician follow-up.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/127/13/1386
10.1161/CIRCULATIONAHA.112.000737
None

4
Molecular Biology and Evolution
Natural Selection in the Great Apes
<p>Natural selection is crucial for the adaptation of populations to their environments. Here, we present the first global study of natural selection in the <i>Hominidae</i> (humans and great apes) based on genome-wide information from population samples representing all extant species (including most subspecies). Combining several neutrality tests we create a multi-species map of signatures of natural selection covering all major types of natural selection. We find that the estimated efficiency of both purifying and <strong><span style="color:yellowgreen">posit</span></strong>ive selection varies between species and is significantly correlated with their long-term effective population size. Thus, even the modest differences in population size among the closely related <i>Hominidae</i> lineages have resulted in differences in their ability to remove deleterious alleles and to adapt to changing environments. Most signatures of balancing and <strong><span style="color:yellowgreen">posit</span></strong>ive selection are species-specific, with signatures of balancing selection more often being shared among species. We also identify loci with evidence of <strong><span style="color:yellowgreen">posit</span></strong>ive selection across several lineages. Notably, we detect signatures of <strong><span style="color:yellowgreen">posit</span></strong>ive selection in several genes related to brain function, anatomy, diet and immune processes. Our results contribute to a better understanding of human evolution by putting the evidence of natural selection in humans within its larger evolutionary context. The global map of natural selection in our closest living relatives is available as an interactive browser at <ext-link>http://tinyurl.com/nf8qmzh</ext-link>.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/33/12/3268
10.1093/molbev/msw215
['human', 'Hominidae']

4
Molecular Biology and Evolution
Evidence for Selection on Gene Expression in Cultivated Rice (<i>Oryza sativa</i>)
<p>Artificial selection has been used throughout plant domestication and breeding to develop crops that are adapted to diverse environments. Here, we investigate whether gene regulatory changes have been widespread targets of lineage-specific selection in cultivated lines Minghui 63 and Zhenshan 97 of rice, <i>Oryza sativa</i>. A line experiencing <strong><span style="color:yellowgreen">posit</span></strong>ive selection for either an increase or a decrease in genes' transcript abundances is expected to have an overabundance of expression quantitative trait locus (eQTL) alleles that increase or decrease those genes' expression, respectively. Results indicate that several genes that share Gene Ontology terms or are members of the same coexpression module have eQTL alleles from one parent that consistently increase gene expression relative to the second parent. A second line of evidence for lineage-specific selection is an overabundance of <i>cis–trans</i> pairs of eQTL alleles that affect gene expression in the same direction (are reinforcing). Across all <i>cis–trans</i> pairs of eQTL, including pairs that both weakly and strongly affect gene expression, there is no evidence for selection. However, the frequency of genes with reinforcing eQTL increases with eQTL strength. Therefore, there is evidence that eQTL with strong effects were <strong><span style="color:yellowgreen">posit</span></strong>ively selected during rice cultivation. Among 41 <i>cis–trans</i> pairs with strong <i>trans</i> eQTL, 31 have reinforcing eQTL. Several of the candidate genes under <strong><span style="color:yellowgreen">posit</span></strong>ive selection accurately predict phenotypic differences between Minghui 63 and Zhenshan 97. Overall, our results suggest that <strong><span style="color:yellowgreen">posit</span></strong>ive selection for regulatory alleles may be a key factor in plant improvement.</p>
http://mbe.oxfordjournals.org/cgi/content/abstract/31/6/1514
10.1093/molbev/msu110
['Oryza', 'Oryza sativa', 'rice']

4
Journal of Experimental Biology
Measuring gill paracellular permeability with polyethylene glycol-4000 in freely swimming trout: proof of principle
<p>The influence of swimming activity on gill paracellular permeability has not been measured previously in fishes. We critically assessed the use of tritium-labeled polyethylene glycol ([<sup>3</sup>H]PEG-4000) for this purpose, a substance that is also a classic marker for extracellular fluid volume, glomerular filtration rate and drinking rate. Tests (8 h) on resting freshwater trout showed that when measuring [<sup>3</sup>H]PEG-4000 <strong><span style="color:yellowgreen">clearanc</span></strong>e from the plasma in the efflux direction, correction for a large excretion via glomerular filtration was essential, necessitating urinary catheterization. When measuring [<sup>3</sup>H]PEG-4000 <strong><span style="color:yellowgreen">clearanc</span></strong>e from the water in the influx direction, correction for a significant uptake by drinking was essential, necessitating terminal gut removal, whereas glomerular filtration losses were minimal. After correction for these alternate routes of loss and uptake, [<sup>3</sup>H]PEG-4000 <strong><span style="color:yellowgreen">clearanc</span></strong>e rates by efflux from the plasma and by influx from the water were identical, showing that gill paracellular permeability is not rectified, and can be measured in either direction. The influx technique with terminal gut removal was used to assess gill paracellular permeability in trout without urinary catheters freely swimming at 1.2 body lengths s<sup>−1</sup> for 8 h. Branchial [<sup>3</sup>H]PEG-4000 <strong><span style="color:yellowgreen">clearanc</span></strong>e rate (by influx from the water) increased significantly by ~80% in accord with a similar measured increase in O<sub>2</sub> consumption rate. Thus in trout, gill paracellular permeability does increase during exercise, in accord with the traditional concept of the osmorespiratory compromise.</p>
http://jeb.biologists.org/cgi/content/abstract/217/9/1425
10.1242/jeb.099879
None

4
Journal of Experimental Biology
Cold acclimation alters the connective tissue content of the zebrafish (<i>Danio rerio</i>) heart
<p>Thermal acclimation can alter cardiac function and morphology in a number of fish species, but little is known about the regulation of these changes. The purpose of the present study was to determine how cold acclimation affects zebrafish (<i>Danio rerio</i>) cardiac morphology, collagen com<strong><span style="color:yellowgreen">posit</span></strong>ion and connective tissue regulation. Heart volume, the <strong><span style="color:yellowgreen">thick</span></strong>ness of the compact myocardium, collagen content and collagen fiber com<strong><span style="color:yellowgreen">posit</span></strong>ion were compared between control (27°C) and cold-acclimated (20°C) zebrafish using serially sectioned hearts stained with Picrosirius Red. Collagen content and fiber com<strong><span style="color:yellowgreen">posit</span></strong>ion of the pericardial membrane were also examined. Cold acclimation did not affect the volume of the contracted heart; however, there was a significant decrease in the <strong><span style="color:yellowgreen">thick</span></strong>ness of the compact myocardium. There was also a decrease in the collagen content of the compact myocardium and in the amount of <strong><span style="color:yellowgreen">thick</span></strong> collagen fibers throughout the heart. Cold-acclimated zebrafish also increased expression of the gene transcript for matrix metalloproteinase 2, matrix metalloproteinase 9, tissue inhibitor of metalloproteinase 2 and collagen Type I α1. We propose that the reduction in the <strong><span style="color:yellowgreen">thick</span></strong>ness of the compact myocardium as well as the change in collagen content may help to maintain the compliance of the ventricle as temperatures decrease. Together, these results clearly demonstrate that the zebrafish heart undergoes significant remodeling in response to cold acclimation.</p>
http://jeb.biologists.org/cgi/content/abstract/217/11/1868
10.1242/jeb.101196
['Danio', 'Danio rerio', 'zebrafish', 'fish']

4
The Bone & Joint Journal
The effect of operating lights on laminar flow
<sec><title>Aims</title><p>The interaction between surgical lighting and laminar airflow   is poorly understood. We undertook an experiment to identify any   effect contemporary surgical lights have on laminar flow and recommend   practical strategies to limit any negative effects.</p></sec><sec><title>Materials and Methods</title><p>Neutrally buoyant bubbles were introduced into the surgical field   of a simulated setup for a routine total knee arthroplasty in a   laminar flow theatre. Patterns of airflow were observed and the   number of bubbles remaining above the surgical field over time identified.   Five different lighting configurations were assessed. Data were analysed   using simple linear regression after logarithmic transformation.</p></sec><sec><title>Results</title><p>In the absence of surgical lights, laminar airflow was observed,   bubbles were cleared rapidly and did not accumulate. If lights were   placed above the surgical field laminar airflow was abolished and   bubbles rose from the surgical field to the lights then circulated   back to the surgical field. The value of the decay parameter (slope)   of the two setups differed significantly; no light (b = -1.589) <i>versus</i> one   light (b = -0.1273, p < 0.001).</p><p>Two lights touching (b = -0.1191) above the surgical field had   a similar effect to that of a single light (p = 0. 2719). Two lights   <strong><span style="color:yellowgreen">posit</span></strong>ioned by arms outstretched had a similar effect    (b = -0.1204) to two lights touching (p = 0.998) and one light (p   = 0.444). When lights were <strong><span style="color:yellowgreen">separ</span></strong>ated widely (160 cm), laminar airflow   was observed but the rate of <strong><span style="color:yellowgreen">clearanc</span></strong>e of the bubbles remained slower   (b = -1.1165) than with no lights present (p = 0.004). </p></sec><sec><title>Conclusion</title><p>Surgical lights have a significantly negative effect on laminar   airflow. Lights should be <strong><span style="color:yellowgreen">posit</span></strong>ioned as far away as practicable   from the surgical field to limit this effect.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1061–6.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/8/1061
10.1302/0301-620X.99B8.BJJ-2016-0581.R2
['rose']

4
The Bone & Joint Journal
Spinopelvic mobility and acetabular component position for total hip arthroplasty
<sec><title>Aims</title><p>Posterior tilt of the pelvis with sitting provides biological   acetabular opening. Our goal was to study the post-operative interaction   of skeletal mobility and sagittal acetabular component <strong><span style="color:yellowgreen">posit</span></strong>ion.</p></sec><sec><title>Materials and Methods</title><p>This was a radiographic study of 160 hips (151 patients) who   prospectively had lateral spinopelvic hip radiographs for skeletal   and implant measurements. Intra-operative acetabular component <strong><span style="color:yellowgreen">posit</span></strong>ion   was determined according to the pre-operative spinal mobility. Sagittal   implant measurements of ante-inclination and sacral acetabular angle were   used as surrogate measurements for the risk of impingement, and   intra-operative acetabular component angles were compared with these.</p></sec><sec><title>Results</title><p>Post-operatively, ante-inclination and sacral acetabular angles   were within normal range in 133 hips (83.1%). A total of seven hips   (4.4%) had pathological imbalance and were biologically or surgically   fused hips. In all, 23 of 24 hips had pre-operative dangerous spinal   imbalance corrected.</p></sec><sec><title>Conclusions</title><p>In all, 145 of 160 hips (90%) were considered safe from impingement.   Patients with highest risk are those with biological or surgical   spinal fusion; patients with dangerous spinal imbalance can be safe   with correct acetabular component <strong><span style="color:yellowgreen">posit</span></strong>ion. The clinical relevance   of the study is that it correlates acetabular component <strong><span style="color:yellowgreen">posit</span></strong>ion   to spinal pelvic mobility which provides guidelines for total hip   arthroplasty.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B(1   Supple A):37–45.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/1_Supple_A/37
10.1302/0301-620X.99B1.BJJ-2016-0415.R1
None

4
The Bone & Joint Journal
The presence of Waddell signs depends on age and gender, not diagnosis
<sec><title>Aims</title><p>The aim of this study was to determine if <strong><span style="color:yellowgreen">posit</span></strong>ive Waddell signs   were related to patients’ demographics or to perception of their   quality of life.</p></sec><sec><title>Patients and Methods</title><p>This prospective cross-sectional study included 479 adult patients   with back pain from a university spine centre. Each completed SF-12   and Oswestry Disability Index (ODI) questionnaires and underwent   standard spinal examinations to elicit Waddell signs. The relationship   between Waddell signs and age, gender, ODI, Mental Component Score   (MCS), and Physical Component Score (PCS) scores was determined.</p></sec><sec><title>Results</title><p>Of the 479 patients, 128 (27%) had at least one <strong><span style="color:yellowgreen">posit</span></strong>ive Waddell   sign. There were significantly more women with two or more Waddell   signs than men. The proportion of patients with at least one <strong><span style="color:yellowgreen">posit</span></strong>ive   Waddell sign increased with age until 55 years, and then declined   rapidly; none had a <strong><span style="color:yellowgreen">posit</span></strong>ive sign over the age of 75 years. Functional outcome   scores were significantly worse in those with a single Waddell sign   (p < 0.01). With one or more Waddell signs, patients’ PCS and   ODI scores indicated a perception of severe disability; with three   or more Waddell signs, patients’ MCS scores indicated severe disability.   With five Waddell signs, ODI scores indicated that patients perceived   themselves as crippled.</p></sec><sec><title>Conclusion</title><p><strong><span style="color:yellowgreen">posit</span></strong>ive Waddell signs, a potential indicator of central sensitization,   indicated a likelihood of having functional limitations and an impaired   quality of life, particularly in young women.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:219–25.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/219
10.1302/0301-620X.100B2.BJJ-2017-0684.R2
None

4
The Bone & Joint Journal
Fractures of the femoral shaft in children
<sec><title>Aims</title><p>The aim of this study was to describe the epidemiology of closed   <strong><span style="color:yellowgreen">isol</span></strong>ated fractures of the femoral shaft in children, and to compare   the treatment and length of stay (LOS) between major trauma centres   (MTCs) and trauma units (TUs) in England.</p></sec><sec><title>Patients and Methods</title><p>National data were obtained from the Trauma and Audit Research   Network for all <strong><span style="color:yellowgreen">isol</span></strong>ated, closed fractures of the femoral shaft   in children from birth to 15 years of age, between 2012 and 2015.   Age, gender, the season in which the fracture occurred, non-accidental   injury, the mechanism of injury, hospital trauma status, LOS and   type of treatment were recorded.</p></sec><sec><title>Results</title><p>A total of 1852 fractures were identified. The mean annual incidence   was 5.82 per 100 000 children (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al (CI) 5.20   to 6.44). The age of peak incidence was two years for both boys   and girls; this decreased with increasing age. Children aged four   to six years treated in MTCs were more likely to be managed with   open reduction and internal fixation compared with those treated   in TUs (odds ratio 3.20; 95% CI 1.12 to 9.14; p = 0.03). The median LOS   was significantly less in MTCs than in TUs for children aged between   18 months and three years treated in both a spica (p = 0.005) and   traction (p = 0.0004). </p></sec><sec><title>Conclusion</title><p>This study highlights the current national trends in the management   of closed <strong><span style="color:yellowgreen">isol</span></strong>ated fractures of the femoral shaft in children following   activation of major trauma networks in 2012. Future studies focusing   on the reasons for the differences which have been identified may   help to achieve more consistency in the management of these injuries across   the trauma networks.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:109–18.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1/109
10.1302/0301-620X.100B1.BJJ-2016-1315.R3
None

4
Circulation
Duct Stenting Versus Modified Blalock-Taussig Shunt in Neonates With Duct-Dependent Pulmonary Blood Flow
<sec><title>Background:</title><p>Infants born with cardiac abnormalities causing dependence on the arterial duct for pulmonary blood flow are often palliated with a shunt usually between the subclavian artery and either pulmonary artery. A so-called modified Blalock-Taussig shunt allows progress through early life to an age and weight at which repair or further more stable palliation can be safely achieved. Modified Blalock-Taussig shunts continue to present concern for postprocedural instability and early mortality such that other alternatives continue to be explored. Duct stenting (DS) is emerging as one such alternative with potential for greater early stability and improved survival.</p></sec><sec><title>Methods:</title><p>The purpose of this study was to compare postprocedural outcomes and survival to next-stage palliative or reparative surgery between patients undergoing a modified Blalock-Taussig shunt or a DS in infants with duct-dependent pulmonary blood flow. All patients undergoing cardiac surgery and congenital <strong><span style="color:yellowgreen">interv</span></strong>entions in the United Kingdom are prospectively recruited to an externally validated national outcome audit. From this audit, participating UK centers identified infants <30 days of age undergoing either a Blalock-Taussig shunt or a DS for cardiac conditions with duct-dependent pulmonary blood flow between January 2012 and December 31, 2015. One hundred seventy-one patients underwent a modified Blalock-Taussig shunt, and in 83 patients, DS was attempted. Primary and secondary outcomes of survival and need for extracorporeal support were analyzed with multivariable logistic regression. Longer-term mortality before repair and re<strong><span style="color:yellowgreen">interv</span></strong>ention were analyzed with Cox proportional hazards regression. All multivariable analyses accommodated a propensity score to balance patient characteristics between the groups.</p></sec><sec><title>Results:</title><p>There was an early (to discharge) survival advantage for infants before next-stage surgery in the DS group (odds ratio, 4.24; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.37–13.14; <i>P</i>=0.012). There was also a difference in the need for postprocedural extracorporeal support in favor of the DS group (odds ratio, 0.22; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.05–1.05; <i>P</i>=0.058). Longer-term survival outcomes showed a reduced risk of death before repair in the DS group (hazard ratio, 0.25; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.07–0.85; <i>P</i>=0.026) but a slightly increased risk of re<strong><span style="color:yellowgreen">interv</span></strong>ention (hazard ratio, 1.50; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.85–2.64; <i>P</i>=0.165).</p></sec><sec><title>Conclusions:</title><p>DS is emerging as a preferred alternative to a surgical shunt for neonatal palliation with evidence for greater postprocedural stability and improved patient survival to destination surgical treatment.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/6/581
10.1161/CIRCULATIONAHA.117.028972
None

4
Circulation
Time to Epinephrine Administration and Survival From Nonshockable Out-of-Hospital Cardiac Arrest Among Children and Adults
<sec><title>Background:</title><p>Previous studies have demonstrated that earlier epinephrine administration is associated with improved survival from out-of-hospital cardiac arrest (OHCA) with shockable initial rhythms. However, the effect of epinephrine timing on patients with nonshockable initial rhythms is unclear. The objective of this study was to measure the association between time to epinephrine administration and survival in adults and children with emergency medical services (EMS)–treated OHCA with nonshockable initial rhythms.</p></sec><sec><title>Methods:</title><p>We performed a secondary analysis of OHCAs prospectively identified by the Resuscitation Outcomes Consortium network from June 4, 2011, to June 30, 2015. We included patients of all ages with an EMS-treated OHCA and an initial nonshockable rhythm. We excluded those with return of spontaneous circulation in <10 minutes. We conducted a subgroup analysis involving patients <18 years of age. The primary exposure was time (minutes) from arrival of the first EMS agency to the first dose of epinephrine. Secondary exposure was time to epinephrine dichotomized as early (<10 minutes) or late (≥10 minutes). The primary outcome was survival to hospital discharge. We adjusted for Utstein covariates and Resuscitation Outcomes Consortium study site.</p></sec><sec><title>Results:</title><p>From 55 568 EMS-treated OHCAs, 32 101 patients with initial nonshockable rhythms were included. There were 12 238 in the early group, 14 517 in the late group, and 5346 not treated with epinephrine. After adjusting for potential confounders, each minute from EMS arrival to epinephrine administration was associated with a 4% decrease in odds of survival for adults, odds ratio=0.96 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.95–0.98). A subgroup analysis (n=13 290) examining neurological outcomes showed a similar association (adjusted odds ratio, 0.94 per minute; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.89–0.98). When epinephrine was given late in comparison with early, odds of survival were 18% lower (odds ratio, 0.82; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.68–0.98). In a pediatric analysis (n=595), odds of survival were 9% lower (odds ratio, 0.91; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.81–1.01) for each minute delay in epinephrine.</p></sec><sec><title>Conclusions:</title><p>Among OHCAs with nonshockable initial rhythms, the majority of patients were administered epinephrine >10 minutes after EMS arrival. Each minute delay in epinephrine administration was associated with decreased survival and unfavorable neurological outcomes. EMS agencies should consider strategies to reduce epinephrine administration times in patients with initial nonshockable rhythms.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/19/2032
10.1161/CIRCULATIONAHA.117.033067
None

4
Circulation
Global Pulmonary Vascular Remodeling in Pulmonary Hypertension Associated With Heart Failure and Preserved or Reduced Ejection Fraction
<sec><title>Background:</title><p>We hypothesized that pulmonary venous hypertension in heart failure (HF) leads to predominate remodeling of pulmonary veins and that the severity of venous remodeling is associated with the severity of pulmonary hypertension (PH) in HF.</p></sec><sec><title>Methods:</title><p>Patients with HF (n=108; 53 preserved and 55 reduced ejection fraction) with PH (HF-PH; pulmonary artery systolic pressure [PASP] ≥40 mm Hg) were compared to normal controls (n=12) and patients with primary pulmonary veno-occlusive disease (PVOD; n=17). In lung specimens from autopsy (control, HF-PH, and 7 PVOD) or surgery (10 PVOD), quantitative histomorphometry was performed in all analyzable arteries (n=4949), veins (n=7630), and small indeterminate vessels (IV; n=2168) to define percent medial <strong><span style="color:yellowgreen">thick</span></strong>ness (arteries) and percent intimal <strong><span style="color:yellowgreen">thick</span></strong>ness (%IT) (arteries, veins, and IV) relative to external diameter.</p></sec><sec><title>Results:</title><p>The average arterial percent medial <strong><span style="color:yellowgreen">thick</span></strong>ness (control, 6.9; HF-PH, 11.0; PVOD, 15.0), arterial %IT (control, 4.9; HF-PH, 14.9; PVOD, 31.1), venous %IT (control, 14.0; HF-PH, 24.9; PVOD, 43.9), and IV %IT (control, 10.6; HF-PH, 25.8; PVOD, 50.0) in HF-PH were higher than controls (<i>P</i><0.0001 for all) but lower than PVOD (<i>P</i>≤0.005 for all). PASP (mm Hg) was lower in HF-PH (median, 59 [interquartile range, 50–70]) than in PVOD (median, 91 [interquartile range, 82–103]). PASP correlated with arterial percent medial <strong><span style="color:yellowgreen">thick</span></strong>ness (<i>r</i>=0.41) and arterial %IT (<i>r</i>=0.35) but more strongly with venous %IT (<i>r</i>=0.49) and IV %IT (<i>r</i>=0.55) (<i>P</i><0.0001 for all). Associations between PASP and venous or IV %IT remained significant after adjusting for arterial percent medial <strong><span style="color:yellowgreen">thick</span></strong>ness and %IT and did not vary by HF type. In patients with right heart catheterization (30 HF-PH, 14 PVOD), similar associations between the transpulmonary gradient and pulmonary vascular remodeling existed, with numerically stronger associations for venous and IV %IT. Although the PASP was slightly higher in patients with HF-PH with right ventricular dysfunction, pulmonary vascular remodeling was not more severe. Pulmonary vascular remodeling severity was associated with reductions in the diffusing capacity of the lungs.</p></sec><sec><title>Conclusions:</title><p>In HF, PH is associated with global pulmonary vascular remodeling, but the severity of PH correlates most strongly with venous and small IV intimal <strong><span style="color:yellowgreen">thick</span></strong>ening, similar to the pattern observed in PVOD. These findings expand our understanding of the pathobiology of PH in HF.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/17/1796
10.1161/CIRCULATIONAHA.117.031608
None

4
Circulation
Particulate Matter Air Pollution Exposure and Heart Disease Mortality Risks by Race and Ethnicity in the United States
<sec><title>Background:</title><p>Most US studies of mortality and air pollution have been conducted on largely non-Hispanic white study populations. However, many health and mortality outcomes differ by race and ethnicity, and non-Hispanic white persons experience lower air pollution exposure than those who are non-Hispanic black or Hispanic. This study examines whether associations between air pollution and heart disease mortality differ by race/ethnicity.</p></sec><sec><title>Methods:</title><p>We used data from the 1997 to 2009 National Health <strong><span style="color:yellowgreen">interv</span></strong>iew Survey linked to mortality records through December 2011 and annual estimates of fine particulate matter (PM<sub>2.5</sub>) by census tract. Proportional hazards models were used to estimate hazard ratios and 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>als between PM<sub>2.5</sub> (per 10 µg/m<sup>3</sup>) and heart disease mortality using the full sample and the sample adults, which have information on additional health variables. Interaction terms were used to examine differences in the PM<sub>2.5</sub>-mortality association by race/ethnicity.</p></sec><sec><title>Results:</title><p>Overall, 65 936 of the full sample died during follow-up, and 22 152 died from heart disease. After adjustment for several factors, we found a significant <strong><span style="color:yellowgreen">posit</span></strong>ive association between PM<sub>2.5</sub> and heart disease mortality (hazard ratio, 1.16; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.08–1.25). This association was similar in sample adults with adjustment for smoking and body mass index (hazard ratio, 1.18; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.06–1.31). Interaction terms for non-Hispanic black and Hispanic groups compared with the non-Hispanic white group were not statistically significant.</p></sec><sec><title>Conclusions:</title><p>Using a nationally representative sample, the association between PM<sub>2.5</sub> and heart disease mortality was elevated and similar to previous estimates. Associations for non-Hispanic black and Hispanic adults were not statistically significantly different from those for non-Hispanic white adults.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/16/1688
10.1161/CIRCULATIONAHA.117.029376
None

4
Circulation
Association of Statin Dose With Amputation and Survival in Patients With Peripheral Artery Disease
<sec><title>Background:</title><p>Statin dose guidelines for patients with peripheral artery disease (PAD) are largely based on coronary artery disease and stroke data. The aim of this study is to determine the effect of statin intensity on PAD outcomes of amputation and mortality.</p></sec><sec><title>Methods:</title><p>Using an observational cohort study design and a validated algorithm, we identified patients with incident PAD (2003–2014) in the national Veterans Affairs data. Highest statin intensity exposure (high-intensity versus low-to-moderate–intensity versus antiplatelet therapy but no statin use) was determined within 1 year of diagnosis of PAD. Outcomes of interest were lower extremity amputations and death. The association of statin intensity with incident amputation and mortality was assessed with Kaplan-Meier plots, Cox proportional hazards modeling, propensity score–matched analysis, and sensitivity and subgroup analyses, as well, to reduce confounding.</p></sec><sec><title>Results:</title><p>In 155 647 patients with incident PAD, more than a quarter (28%) were not on statins. Use of high-intensity statins was lowest in patients with PAD only (6.4%) in comparison with comorbid coronary/carotid disease (18.4%). Incident amputation and mortality risk declined significantly with any statin use in comparison with the antiplatelet therapy–only group. In adjusted Cox models, the high-intensity statin users were associated with lower amputation risk and mortality in comparison with antiplatelet therapy–only users (hazard ratio, 0.67; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.61–0.74 and hazard ratio, 0.74; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.70–0.77, respectively). Low-to-moderate–intensity statins also had significant reductions in the risk of amputation and mortality (hazard ratio amputation, 0.81; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.75– 0.86; hazard ratio death, 0.83; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.81–0.86) in comparison with no statins (antiplatelet therapy only), but effect size was significantly weaker than the high-intensity statins (<i>P</i><0.001). The association of high-intensity statins with lower amputation and death risk remained significant and robust in propensity score–matched, sensitivity, and subgroup analyses.</p></sec><sec><title>Conclusions:</title><p>Statins, especially high-intensity formulations, are underused in patients with PAD. This is the first population-based study to show that high-intensity statin use at the time of PAD diagnosis is associated with a significant reduction in limb loss and mortality in comparison with low-to-moderate–intensity statin users, and patients treated only with antiplatelet medications but not with statins, as well.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/14/1435
10.1161/CIRCULATIONAHA.117.032361
None

4
Circulation
Effect of Intensive Blood Pressure Lowering on Left Ventricular Hypertrophy in Patients With Hypertension
<sec><title>Background:</title><p>It is currently unknown whether intensive blood pressure (BP) lowering beyond that recommended would lead to more lowering of the risk of left ventricular hypertrophy (LVH) in patients with hypertension and whether reducing the risk of LVH explains the reported cardiovascular disease (CVD) benefits of intensive BP lowering in this population.</p></sec><sec><title>Methods:</title><p>This analysis included 8164 participants (mean age, 67.9 years; 35.3% women; 31.2% blacks) with hypertension but no diabetes mellitus from the SPRINT trial (Systolic Blood Pressure <strong><span style="color:yellowgreen">interv</span></strong>ention Trial): 4086 randomly assigned to intensive BP lowering (target SBP <120 mm Hg) and 4078 assigned to standard BP lowering (target SBP <140 mm Hg). Progression and regression of LVH as defined by Cornell voltage criteria derived from standard 12-lead ECGs recorded at baseline and biannually were compared between treatment arms during a median follow-up of 3.81 years. The effect of intensive (versus standard) BP lowering on the SPRINT primary CVD outcome (a com<strong><span style="color:yellowgreen">posit</span></strong>e of myocardial infarction, acute coronary syndrome, stroke, heart failure, and CVD death) was compared before and after adjustment for LVH as a time-varying covariate.</p></sec><sec><title>Results:</title><p>Among SPRINT participants without baseline LVH (n=7559), intensive (versus standard) BP lowering was associated with a 46% lower risk of developing LVH (hazard ratio=0.54; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.43–0.68). Similarly, among SPRINT participants with baseline LVH (n=605, 7.4%), those assigned to the intensive (versus standard) BP lowering were 66% more likely to regress/improve their LVH (hazard ratio=1.66; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.31–2.11). Adjustment for LVH as a time-varying covariate did not substantially attenuate the effect of intensive BP therapy on CVD events (hazard ratio of intensive versus standard BP lowering on CVD, 0.76 [95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.64–0.90] and 0.77 [95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.65–0.91] before and after adjustment for LVH as a time-varying covariate, respectively).</p></sec><sec><title>Conclusions:</title><p>Among patients with hypertension but no diabetes mellitus, intensive BP lowering (target systolic BP <120 mm Hg) compared with standard BP lowering (target systolic BP <140 mm Hg) resulted in lower rates of developing new LVH in those without LVH and higher rates of regression of LVH in those with existing LVH. This favorable effect on LVH did not explain most of the reduction in CVD events associated with intensive BP lowering in the SPRINT trial.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01206062.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/5/440
10.1161/CIRCULATIONAHA.117.028441
None

4
Circulation
Black-White Differences in Incident Fatal, Nonfatal, and Total Coronary Heart Disease
<sec><title>Background:</title><p>Blacks have higher coronary heart disease (CHD) mortality compared with whites. However, a previous study suggests that nonfatal CHD risk may be lower for black versus white men.</p></sec><sec><title>Methods:</title><p>We compared fatal and nonfatal CHD incidence and CHD case-fatality among blacks and whites in the Atherosclerosis Risk in Communities study (ARIC), the Cardiovascular Health Study (CHS), and the Reasons for Geographic and Racial Differences in Stroke study (REGARDS) by sex. Participants 45 to 64 years of age in ARIC (men=6479, women=8488) and REGARDS (men=5296, women=7822), and ≥65 years of age in CHS (men=1836, women=2790) and REGARDS (men=3381, women=4112), all without a history of CHD, were analyzed. Fatal and nonfatal CHD incidence was assessed from baseline (ARIC=1987–1989, CHS=1989–1990, REGARDS=2003–2007) through up to 11 years of follow-up.</p></sec><sec><title>Results:</title><p>Age-adjusted hazard ratios comparing black versus white men 45 to 64 years of age in ARIC and REGARDS were 2.09 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.42–3.06) and 2.11 (1.32–3.38), respectively, for fatal CHD, and 0.82 (0.64–1.05) and 0.94 (0.69–1.28), respectively, for nonfatal CHD. After adjustment for social determinants of health and cardiovascular risk factors, hazard ratios in ARIC and REGARDS were 1.19 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.74–1.92) and 1.09 (0.62–1.93), respectively, for fatal CHD, and 0.64 (0.47–0.86) and 0.67 (0.48–0.95), respectively, for nonfatal CHD. Similar patterns were present among men ≥65 years of age in CHS and REGARDS. Among women 45 to 64 years of age in ARIC and REGARDS, age-adjusted hazard ratios comparing blacks versus whites were 2.61 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.57–4.34) and 1.79 (1.06–3.03), respectively, for fatal CHD, and 1.47 (1.13–1.91) and 1.29 (0.91–1.83), respectively, for nonfatal CHD. After multivariable adjustment, hazard ratios in ARIC and REGARDS were 0.67 (95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.36–1.24) and 1.00 (0.54–1.85), respectively, for fatal CHD, and 0.70 (0.51–0.97) and 0.70 (0.46–1.06), respectively, for nonfatal CHD. Racial differences in CHD incidence were attenuated among older women. CHD case fatality was higher among black versus white men and women, and the difference remained similar after multivariable adjustment.</p></sec><sec><title>Conclusions:</title><p>After accounting for social determinants of health and risk factors, black men and women have similar risk for fatal CHD compared with white men and women, respectively. However, the risk for nonfatal CHD is consistently lower for black versus white men and women.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/2/152
10.1161/CIRCULATIONAHA.116.025848
None

4
Circulation
Potential Cardiovascular and Total Mortality Benefits of Air Pollution Control in Urban China
<sec><title>Background:</title><p>Outdoor air pollution ranks fourth among preventable causes of China’s burden of disease. We hypothesized that the magnitude of health gains from air quality improvement in urban China could compare with achieving recommended blood pressure or smoking control goals.</p></sec><sec><title>Methods:</title><p>The Cardiovascular Disease Policy Model–China projected coronary heart disease, stroke, and all-cause deaths in urban Chinese adults 35 to 84 years of age from 2017 to 2030 if recent air quality (particulate matter with aerodynamic diameter ≤2.5 µm, PM<sub>2.5</sub>) and traditional cardiovascular risk factor trends continue. We projected life-years gained if urban China were to reach 1 of 3 air quality goals: Beijing Olympic Games level (mean PM<sub>2.5</sub>, 55 μg/m<sup>3</sup>), China Class II standard (35 μg/m<sup>3</sup>), or World Health Organization standard (10 μg/m<sup>3</sup>). We compared projected air pollution reduction control benefits with potential benefits of reaching World Health Organization hypertension and tobacco control goals.</p></sec><sec><title>Results:</title><p>Mean PM<sub>2.5</sub> reduction to Beijing Olympic levels by 2030 would gain ≈241,000 (95% uncertainty <strong><span style="color:yellowgreen">interv</span></strong>al, 189 000–293 000) life-years annually. Achieving either the China Class II or World Health Organization PM<sub>2.5</sub> standard would yield greater health benefits (992 000 [95% uncertainty <strong><span style="color:yellowgreen">interv</span></strong>al, 790 000–1 180 000] or 1 827 000 [95% uncertainty <strong><span style="color:yellowgreen">interv</span></strong>al, 1 481 00–2 129 000] annual life-years gained, respectively) than World Health Organization–recommended goals of 25% improvement in systolic hypertension control and 30% reduction in smoking combined (928 000 [95% uncertainty <strong><span style="color:yellowgreen">interv</span></strong>al, 830 000–1 033 000] life-years).</p></sec><sec><title>Conclusions:</title><p>Air quality improvement in different scenarios could lead to graded health benefits ranging from 241 000 life-years gained to much greater benefits equal to or greater than the combined benefits of 25% improvement in systolic hypertension control and 30% smoking reduction.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/17/1575
10.1161/CIRCULATIONAHA.116.026487
['tobacco']

4
Circulation
Body Mass Index and Mortality Among Adults Undergoing Cardiac Surgery
<sec><title>Background:</title><p>In an apparent paradox, morbidity and mortality are lower in obese patients undergoing cardiac surgery, although the nature of this association is unclear. We sought to determine whether the obesity paradox observed in cardiac surgery is attributable to reverse epidemiology, bias, or confounding.</p></sec><sec><title>Methods:</title><p>Data from the National Adult Cardiac Surgery registry for all cardiac surgical procedures performed between April 2002 and March 2013 were extracted. A parallel systematic review and meta-analysis (MEDLINE, Embase, SCOPUS, Cochrane Library) through June 2015 were also accomplished. Exposure of interest was body mass index categorized into 6 groups according to the World Health Organization classification.</p></sec><sec><title>Results:</title><p>A total of 401 227 adult patients in the cohort study and 557 720 patients in the systematic review were included. A U-shaped association between mortality and body mass index classes was observed in both studies, with lower mortality in overweight (adjusted odds ratio, 0.79; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.76–0.83) and obese class I and II (odds ratio, 0.81; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.76–0.86; and odds ratio, 0.83; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.74–0.94) patients relative to normal-weight patients and increased mortality in underweight individuals (odds ratio, 1.51; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.41–1.62). In the cohort study, a U-shaped relationship was observed for stroke and low cardiac output syndrome but not for renal replacement therapy or deep sternal wound infection. Counter to the reverse epidemiology hypotheses, the protective effects of obesity were less in patients with severe chronic renal, lung, or cardiac disease and greater in older patients and in those with complications of obesity, including the metabolic syndrome and atherosclerosis. Adjustments for important confounders did not alter our results.</p></sec><sec><title>Conclusions:</title><p>Obesity is associated with lower risks after cardiac surgery, with consistent effects noted in multiple analyses attempting to address residual confounding and reverse causation.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/9/850
10.1161/CIRCULATIONAHA.116.022840
None

4
Circulation
Extended-Duration Betrixaban Reduces the Risk of Stroke Versus Standard-Dose Enoxaparin Among Hospitalized Medically Ill Patients
<sec><title>Background:</title><p>Stroke is a morbid and potentially mortal complication among patients hospitalized with acute medical illness. The potential of extended-duration thromboprophylaxis with the factor Xa inhibitor betrixaban to reduce the risk of stroke compared with standard-dose enoxaparin in this population was assessed in this retrospective APEX trial substudy (Acute Medically Ill Venous Thromboembolism Prevention With Extended Duration Betrixaban).</p></sec><sec><title>Methods:</title><p>Hospitalized acutely medically ill subjects (n=7513) were randomized in a double-dummy double-blind fashion to either extended-duration oral betrixaban (80 mg once daily for 35–42 days) or standard-dose subcutaneous enoxaparin (40 mg once daily for 10±4 days) for venous thromboprophylaxis. Stroke events were adjudicated by an independent, blinded event adjudication committee.</p></sec><sec><title>Results:</title><p>The mean age of study participants was 76 years; 45% were male; 13% had had a stroke; and 45% had congestive heart failure. There were fewer all-cause strokes (0.54% versus 0.97%; relative risk [RR]=0.56; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.32–0.96; <i>P</i>=0.032; adjusted RR=0.43%; number needed to treat=233) and ischemic strokes (0.48% versus 0.91%; RR=0.53; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.30–0.94; <i>P</i>=0.026; adjusted RR=0.43%; number needed to treat=233) among patients treated with betrixaban versus enoxaparin through 77 days of follow-up. Among high-risk subjects, those with congestive heart failure or ischemic stroke as their index event, betrixaban reduced the risk of all-cause stroke (0.72% versus 1.48%; RR=0.49; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.26–0.90; <i>P</i>=0.019; adjusted RR=0.76%; number needed to treat=132) and ischemic stroke (0.63% versus 1.38%; RR=0.45; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.24–0.87; <i>P</i>=0.014; adjusted RR=0.75%; number needed to treat=134) compared with enoxaparin.</p></sec><sec><title>Conclusions:</title><p>Among hospitalized medically ill patients, extended-duration betrixaban significantly reduced all-cause stroke and ischemic stroke through 77 days of follow-up</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01583218.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/7/648
10.1161/CIRCULATIONAHA.116.025427
None

4
Circulation
Anti-Müllerian Hormone Trajectories Are Associated With Cardiovascular Disease in Women
<sec><title>Background:</title><p>Earlier age at menopause is widely considered to be associated with an increased risk of cardiovascular disease. However, the underlying mechanisms of this relationship remain undetermined. Indications suggest that anti-Müllerian hormone (AMH), an ovarian reserve marker, plays a physiological role outside of the reproductive system. Therefore, we investigated whether longitudinal AMH decline trajectories are associated with an increased risk of cardiovascular disease (CVD) occurrence.</p></sec><sec><title>Methods:</title><p>This study included 3108 female participants between 20 and 60 years of age at baseline of the population-based Doetinchem Cohort. Participants completed ≥1 of 5 consecutive quinquennial visits between 1987 and 2010, resulting in a total follow-up time of 20 years. AMH was measured in 8507 stored plasma samples. Information on total CVD, stroke, and coronary heart disease was obtained through a hospital discharge registry linkage. The association of AMH trajectories with CVD was quantified with joint modeling, with adjustment for age, smoking, oral contraceptive use, body mass index, menopausal status, postmenopausal hormone therapy use, diastolic blood pressure, total cholesterol, high-density lipoprotein cholesterol, and glucose levels.</p></sec><sec><title>Results:</title><p>By the end of follow-up, 8.2% of the women had suffered from CVD, 4.9% had suffered from coronary heart disease, and 2.6% had experienced a stroke. After adjustment, each ng/mL lower <sub>log</sub>AMH level was associated with a 21% higher risk of CVD (hazard ratio, 1.21; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.07–1.36) and a 26% higher risk of coronary heart disease (hazard ratio, 1.25; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.08–1.46). Each additional ng/mL/year decrease of <sub>log</sub>AMH was associated with a significantly higher risk of CVD (hazard ratio, 1.46; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.14–1.87) and coronary heart disease (hazard ratio, 1.56; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.15–2.12). No association between AMH and stroke was found.</p></sec><sec><title>Conclusions:</title><p>These results indicate that AMH trajectories in women are independently associated with CVD risk. Therefore, we postulate that the decline of circulating AMH levels may be part of the pathophysiology of the increased cardiovascular risk of earlier menopause. Confirmation of this association and elucidation of its underlying mechanisms are needed to place these results in a clinical perspective.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/6/556
10.1161/CIRCULATIONAHA.116.025968
None

4
Circulation
Thrombus Aspiration in ST-Segment–Elevation Myocardial Infarction
<sec><title>Background:</title><p>Thrombus aspiration during percutaneous coronary <strong><span style="color:yellowgreen">interv</span></strong>ention (PCI) for the treatment of ST-segment–elevation myocardial infarction (STEMI) has been widely used; however, recent trials have questioned its value and safety. In this meta-analysis, we, the trial investigators, aimed to pool the individual patient data from these trials to determine the benefits and risks of thrombus aspiration during PCI in patients with ST-segment–elevation myocardial infarction.</p></sec><sec><title>Methods:</title><p>Included were large (n≥1000), randomized, controlled trials comparing manual thrombectomy and PCI alone in patients with ST-segment–elevation myocardial infarction. Individual patient data were provided by the leadership of each trial. The prespecified primary efficacy outcome was cardiovascular mortality within 30 days, and the primary safety outcome was stroke or transient ischemic attack within 30 days.</p></sec><sec><title>Results:</title><p>The 3 eligible randomized trials (TAPAS [Thrombus Aspiration During Percutaneous Coronary <strong><span style="color:yellowgreen">interv</span></strong>ention in Acute Myocardial Infarction], TASTE [Thrombus Aspiration in ST-Elevation Myocardial Infarction in Scandinavia], and TOTAL [Trial of Routine Aspiration Thrombectomy With PCI Versus PCI Alone in Patients With STEMI]) enrolled 19 047 patients, of whom 18 306 underwent PCI and were included in the primary analysis. Cardiovascular death at 30 days occurred in 221 of 9155 patients (2.4%) randomized to thrombus aspiration and 262 of 9151 (2.9%) randomized to PCI alone (hazard ratio, 0.84; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.70–1.01; <i>P</i>=0.06). Stroke or transient ischemic attack occurred in 66 (0.8%) randomized to thrombus aspiration and 46 (0.5%) randomized to PCI alone (odds ratio, 1.43; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.98–2.10; <i>P</i>=0.06). There were no significant differences in recurrent myocardial infarction, stent thrombosis, heart failure, or target vessel revascularization. In the subgroup with high thrombus burden (TIMI [Thrombolysis in Myocardial Infarction] thrombus grade ≥3), thrombus aspiration was associated with fewer cardiovascular deaths (170 [2.5%] versus 205 [3.1%]; hazard ratio, 0.80; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.65–0.98; <i>P</i>=0.03) and with more strokes or transient ischemic attacks (55 [0.9%] versus 34 [0.5%]; odds ratio, 1.56; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.02–2.42, <i>P</i>=0.04). However, the interaction <i>P</i> values were 0.32 and 0.34, respectively.</p></sec><sec><title>Conclusions:</title><p>Routine thrombus aspiration during PCI for ST-segment–elevation myocardial infarction did not improve clinical outcomes. In the high thrombus burden group, the trends toward reduced cardiovascular death and increased stroke or transient ischemic attack provide a rationale for future trials of improved thrombus aspiration technologies in this high-risk subgroup.</p></sec><sec><title>Clinical Trial Registration:</title><p>URLs: <ext-link>http://www.ClinicalTrials.gov</ext-link> <ext-link>http://www.crd.york.ac.uk/prospero/</ext-link>. Unique identifiers: NCT02552407 and CRD42015025936.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/2/143
10.1161/CIRCULATIONAHA.116.025371
['Thrombus']

4
Circulation
Cardiac Outcomes After Ischemic Stroke or Transient Ischemic Attack
<sec><title>Background:</title><p>Insulin resistance is highly prevalent among patients with atherosclerosis and is associated with an increased risk for myocardial infarction (MI) and stroke. The IRIS trial (Insulin Resistance <strong><span style="color:yellowgreen">interv</span></strong>ention after Stroke) demonstrated that pioglitazone decreased the com<strong><span style="color:yellowgreen">posit</span></strong>e risk for fatal or nonfatal stroke and MI in patients with insulin resistance without diabetes mellitus, after a recent ischemic stroke or transient ischemic attack. The type and severity of cardiac events in this population and the impact of pioglitazone on these events have not been described.</p></sec><sec><title>Methods:</title><p>We performed a secondary analysis of the effects of pioglitazone, in comparison with placebo, on acute coronary syndromes (MI and unstable angina) among IRIS participants. All potential acute coronary syndrome episodes were adjudicated in a blinded fashion by an independent clinical events committee.</p></sec><sec><title>Results:</title><p>The study cohort was composed of 3876 IRIS participants, mean age 63 years, 65% male, 89% white race, and 12% with a history of coronary artery disease. Over a median follow-up of 4.8 years, there were 225 acute coronary syndrome events, including 141 MIs and 84 episodes of unstable angina. The MIs included 28 (19%) with ST-segment elevation. The majority of MIs were type 1 (94, 65%), followed by type 2 (45, 32%). Serum troponin was 10× to 100× upper limit of normal in 49 (35%) and >100× upper limit of normal in 39 (28%). Pioglitazone reduced the risk of acute coronary syndrome (hazard ratio, 0.71; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.54–0.94; <i>P</i>=0.02). Pioglitazone also reduced the risk of type 1 MI (hazard ratio, 0.62; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.40–0.96; log-rank <i>P</i>=0.03), but not type 2 MI (hazard ratio, 1.05; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.58–1.91; <i>P</i>=0.87). Similarly, pioglitazone reduced the risk of large MIs with serum troponin >100× upper limit of normal (hazard ratio, 0.44; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.22–0.87; <i>P</i>=0.02), but not smaller MIs.</p></sec><sec><title>Conclusions:</title><p>Among patients with insulin resistance without diabetes mellitus, pioglitazone reduced the risk for acute coronary syndromes after a recent cerebrovascular event. Pioglitazone appeared to have its most prominent effect in preventing spontaneous type 1 MIs.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT00091949.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/20/1882
10.1161/CIRCULATIONAHA.116.024863
None

4
Circulation
Patients With Long-QT Syndrome Caused by Impaired <i>hERG</i>-Encoded K<sub>v</sub>11.1 Potassium Channel Have Exaggerated Endocrine Pancreatic and Incretin Function Associated With Reactive Hypoglycemia
<sec><title>Background:</title><p>Loss-of-function mutations in <i>hERG</i> (encoding the K<sub>v</sub>11.1 voltage-gated potassium channel) cause long-QT syndrome type 2 (LQT2) because of prolonged cardiac repolarization. However, K<sub>v</sub>11.1 is also present in pancreatic α and β cells and intestinal L and K cells, secreting glucagon, insulin, and the incretins glucagon-like peptide-1 (GLP-1) and GIP (glucose-dependent insulinotropic polypeptide), respectively. These hormones are crucial for glucose regulation, and long-QT syndrome may cause disturbed glucose regulation. We measured secretion of these hormones and cardiac repolarization in response to glucose ingestion in LQT2 patients with functional mutations in <i>hERG</i> and matched healthy participants, testing the hypothesis that LQT2 patients have increased incretin and β-cell function and decreased α-cell function, and thus lower glucose levels.</p></sec><sec><title>Methods:</title><p>Eleven patients with LQT2 and 22 sex-, age-, and body mass index–matched control participants underwent a 6-hour 75-g oral glucose tolerance test with ECG recording and blood sampling for measurements of glucose, insulin, C-peptide, glucagon, GLP-1, and GIP.</p></sec><sec><title>Results:</title><p>In comparison with matched control participants, LQT2 patients had 56% to 78% increased serum insulin, serum C-peptide, plasma GLP-1, and plasma GIP responses (<i>P</i>=0.03–0.001) and decreased plasma glucose levels after glucose ingestion (<i>P</i>=0.02) with more symptoms of hypoglycemia (<i>P</i>=0.04). Sixty-three percent of LQT2 patients developed hypoglycemic plasma glucose levels (<70 mg/dL) versus 36% control participants (<i>P</i>=0.16), and 18% patients developed serious hypoglycemia (<50 mg/dL) versus none of the controls. LQT2 patients had defective glucagon responses to low glucose, <i>P</i>=0.008. β-Cell function (Insulin Secretion Sensitivity Index-2) was 2-fold higher in LQT2 patients than in controls (4398 [95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 2259–8562] versus 2156 [1961–3201], <i>P</i>=0.03). Pharmacological K<sub>v</sub>11.1 blockade (dofetilide) in rats had similar effect, and small interfering RNA inhibition of <i>hERG</i> in β and L cells increased insulin and GLP-1 secretion up to 50%. Glucose ingestion caused cardiac repolarization disturbances with increased QTc <strong><span style="color:yellowgreen">interv</span></strong>als in both patients and controls, but with a 122% greater increase in QTcF <strong><span style="color:yellowgreen">interv</span></strong>al in LQT2 patients (<i>P</i>=0.004).</p></sec><sec><title>Conclusions:</title><p>Besides a prolonged cardiac repolarization phase, LQT2 patients display increased GLP-1, GIP, and insulin secretion and defective glucagon secretion, causing decreased plasma glucose and thus increased risk of hypoglycemia. Furthermore, glucose ingestion increased QT <strong><span style="color:yellowgreen">interv</span></strong>al and aggravated the cardiac repolarization disturbances in LQT2 patients.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://clinicaltrials.gov</ext-link>. Unique identifier: NCT02775513.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/18/1705
10.1161/CIRCULATIONAHA.116.024279
None

4
Circulation
Risk of Cerebrovascular Events in 178 962 Five-Year Survivors of Cancer Diagnosed at 15 to 39 Years of Age
<sec><title>Background:</title><p>Survivors of teenage and young adult cancer are at risk of cerebrovascular events, but the magnitude of and extent to which this risk varies by cancer type, decade of diagnosis, age at diagnosis, and attained age remains uncertain. This is the largest-ever cohort study to evaluate the risks of hospitalization for a cerebrovascular event among long-term survivors of teenage and young adult cancer.</p></sec><sec><title>Methods:</title><p>The population-based TYACSS (Teenage and Young Adult Cancer Survivor Study) (N=178,962) was linked to Hospital Episode Statistics data for England to investigate the risks of hospitalization for a cerebrovascular event among 5-year survivors of cancer diagnosed when 15 to 39 years of age. Observed numbers of first hospitalizations for cerebrovascular events were compared with that expected from the general population using standardized hospitalization ratios (SHRs) and absolute excess risks per 10 000 person-years. Cumulative incidence was calculated with death considered a competing risk.</p></sec><sec><title>Results:</title><p>Overall, 2782 cancer survivors were hospitalized for a cerebrovascular event—40% higher than expected (SHR=1.4, 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.3–1.4). Survivors of central nervous system (CNS) tumors (SHR=4.6, 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 4.3–5.0), head and neck tumors (SHR=2.6, 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 2.2–3.1), and leukemia (SHR=2.5, 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.9–3.1) were at greatest risk. Males had significantly higher absolute excess risks than females (absolute excess risks =7 versus 3), especially among head and neck tumor survivors (absolute excess risks =30 versus 11). By 60 years of age, 9%, 6%, and 5% of CNS tumor, head and neck tumor, and leukemia survivors, respectively, had been hospitalized for a cerebrovascular event. Beyond 60 years of age, every year, 0.4% of CNS tumor survivors were hospitalized for a cerebral infarction (versus 0.1% expected), whereas at any age, every year, 0.2% of head and neck tumor survivors were hospitalized for a cerebral infarction (versus 0.06% expected).</p></sec><sec><title>Conclusions:</title><p>Survivors of a CNS tumor, head and neck tumor, and leukemia are particularly at risk of hospitalization for a cerebrovascular event. The excess risk of cerebral infarction among CNS tumor survivors increases with attained age. For head and neck tumor survivors, this excess risk remains high across all ages. These groups of survivors, particularly males, should be considered for surveillance of cerebrovascular risk factors and potential pharmacological <strong><span style="color:yellowgreen">interv</span></strong>entions for cerebral infarction prevention.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/13/1194
10.1161/CIRCULATIONAHA.116.025778
None

4
Circulation
Comparative Prognostic Utility of Indexes of Microvascular Function Alone or in Combination in Patients With an Acute ST-Segment–Elevation Myocardial Infarction
<sec><title>Background:</title><p>Primary percutaneous coronary <strong><span style="color:yellowgreen">interv</span></strong>ention is frequently successful at restoring coronary artery blood flow in patients with acute ST-segment–elevation myocardial infarction; however, failed myocardial reperfusion commonly passes undetected in up to half of these patients. The index of microvascular resistance (IMR) is a novel invasive measure of coronary microvascular function. We aimed to investigate the pathological and prognostic significance of an IMR>40, alone or in combination with a coronary flow reserve (CFR≤2.0), in the culprit artery after emergency percutaneous coronary <strong><span style="color:yellowgreen">interv</span></strong>ention for acute ST-segment–elevation myocardial infarction.</p></sec><sec><title>Methods:</title><p>Patients with acute ST-segment–elevation myocardial infarction were prospectively enrolled during emergency percutaneous coronary <strong><span style="color:yellowgreen">interv</span></strong>ention and categorized according to IMR (≤40 or >40) and CFR (≤2.0 or >2.0). Cardiac magnetic resonance imaging was acquired 2 days and 6 months after myocardial infarction. All-cause death or first heart failure hospitalization was a prespecified outcome (median follow-up, 845 days).</p></sec><sec><title>Results:</title><p>IMR and CFR were measured in the culprit artery at the end of percutaneous coronary <strong><span style="color:yellowgreen">interv</span></strong>ention in 283 patients with ST-segment–elevation myocardial infarction (mean±SD age, 60±12 years; 73% male). The median IMR and CFR were 25 (interquartile range, 15–48) and 1.6 (interquartile range, 1.1–2.1), respectively. An IMR>40 was a multivariable associate of myocardial hemorrhage (odds ratio, 2.10; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 1.03–4.27; <i>P</i>=0.042). An IMR>40 was closely associated with microvascular obstruction. Symptom-to-reperfusion time, TIMI (Thrombolysis in Myocardial Infarction) blush grade, and no (≤30%) ST-segment resolution were not associated with these pathologies. An IMR>40 was a multivariable associate of the changes in left ventricular ejection fraction (coefficient, −2.12; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, −4.02 to −0.23; <i>P</i>=0.028) and left ventricular end-diastolic volume (coefficient, 7.85; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 0.41–15.29; <i>P</i>=0.039) at 6 months independently of infarct size. An IMR>40 (odds ratio, 4.36; 95% confidence <strong><span style="color:yellowgreen">interv</span></strong>al, 2.10–9.06; <i>P</i><0.001) was a multivariable associate of all-cause death or heart failure. Compared with an IMR>40, the combination of IMR>40 and CFR≤2.0 did not have incremental prognostic value.</p></sec><sec><title>Conclusions:</title><p>An IMR>40 is a multivariable associate of left ventricular and clinical outcomes after ST-segment–elevation myocardial infarction independently of the infarction size. Compared with standard clinical measures of the efficacy of myocardial reperfusion, including the ischemic time, ST-segment elevation, angiographic blush grade, and CFR, IMR has superior clinical value for risk stratification and may be considered a reference test for failed myocardial reperfusion.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https//www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02072850.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/23/1833
10.1161/CIRCULATIONAHA.116.022603
None

