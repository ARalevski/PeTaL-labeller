17
Circulation
Myocardial Infarction Risk After Discontinuation of Thienopyridine Therapy in the Randomized DAPT Study (Dual Antiplatelet Therapy)
<sec><title>Background:</title><p>Thienopyridine plus aspirin beyond 1 year after coronary stenting reduces myocardial infarction (MI) risk and increases bleeding risk in comparison with aspirin alone. The hazard associated with late thienopyridine discontinuation and risk factors for MI after discontinuation are poorly defined.</p></sec><sec><title>Methods:</title><p>In the DAPT Study (Dual Antiplatelet Therapy), after percutaneous coronary intervention and 12 <strong><span style="color:yellowgreen">month</span></strong>s of thienopyridine (clopidogrel or prasugrel) plus aspirin, eligible patients remained on aspirin and were randomly assigned to continued thienopyridine versus placebo for 18 <strong><span style="color:yellowgreen">month</span></strong>s. At 30 <strong><span style="color:yellowgreen">month</span></strong>s, patients stopped the study drug and were observed for 3 <strong><span style="color:yellowgreen">month</span></strong>s. Cumulative incidence of MI was assessed over 3 <strong><span style="color:yellowgreen">month</span></strong>s after randomization (<strong><span style="color:yellowgreen">month</span></strong>s 12–15) and 3 <strong><span style="color:yellowgreen">month</span></strong>s after study drug discontinuation (<strong><span style="color:yellowgreen">month</span></strong>s 30–33). The MI hazard for each of these periods was assessed across randomized treatment arms and by DAPT score values <2 or ≥2.</p></sec><sec><title>Results:</title><p>Among the 11 648 randomly assigned patients, the <strong><span style="color:yellowgreen">month</span></strong>ly cumulative incidence of MI was lower with continued thienopyridine versus placebo at 12 to 15 <strong><span style="color:yellowgreen">month</span></strong>s (0.12% versus 0.37%, <i>P</i><0.001, in all patients; 0.13% versus 0.27%, <i>P</i>=0.02, in patients not treated with paclitaxel-eluting stents), and higher at 30 to 33 <strong><span style="color:yellowgreen">month</span></strong>s (0.30% versus 0.15%, <i>P</i>=0.013, in all patients; in patients without paclitaxel-eluting stents, 0.18% versus 0.17%, <i>P</i>=0.91). The majority of MIs in both <strong><span style="color:yellowgreen">time</span></strong> periods (74% and 76%) were not related to stent thrombosis. After multivariable adjustment, treatment arm independently predicted MI at <strong><span style="color:yellowgreen">month</span></strong>s 12 to 15 (<i>P</i><0.001) and 30 to 33 (<i>P</i>=0.011). During <strong><span style="color:yellowgreen">month</span></strong>s 12 to 15, patients with DAPT scores <2 or ≥2 both had lower rates of MI with continued thienopyridine (MI <strong><span style="color:yellowgreen">month</span></strong>ly incidence 0.16% versus 0.51%, <i>P</i><0.001, for scores ≥2; 0.08% versus 0.24%, <i>P</i>=0.012, for scores<2, interaction <i>P</i>=0.064).</p></sec><sec><title>Conclusions:</title><p>Discontinuing thienopyridine after either 12 or 30 <strong><span style="color:yellowgreen">month</span></strong>s is associated with an early increase in MI risk, mainly unrelated to stent thrombosis; the magnitude of risk is highest in the earlier <strong><span style="color:yellowgreen">time</span></strong> frame, and lower in patients not treated with paclitaxel-eluting stents. Although higher DAPT scores identify patients with greater absolute ischemic benefit (relative to bleeding harm) with continued thienopyridine therapy, discontinuation at 12 <strong><span style="color:yellowgreen">month</span></strong>s increases MI hazard regardless of DAPT score group.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00977938.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/18/1720
10.1161/CIRCULATIONAHA.116.024835
None

16
Circulation
Association of Bystander Cardiopulmonary Resuscitation and Survival According to Ambulance Response Times After Out-of-Hospital Cardiac Arrest
<sec><title>Background:</title><p>Bystander-initiated cardiopulmonary resuscitation (CPR) increases patient survival after out-of-hospital cardiac arrest, but it is unknown to what degree bystander CPR remains positively associated with survival with increasing <strong><span style="color:yellowgreen">time</span></strong> to potential defibrillation. The main objective was to examine the association of bystander CPR with survival as <strong><span style="color:yellowgreen">time</span></strong> to advanced treatment increases.</p></sec><sec><title>Methods:</title><p>We studied 7623 out-of-hospital cardiac arrest patients between 2005 and 2011, identified through the nationwide Danish Cardiac Arrest Registry. Multiple logistic regression analysis was used to examine the association between <strong><span style="color:yellowgreen">time</span></strong> from 911 call to emergency medical service arrival (response <strong><span style="color:yellowgreen">time</span></strong>) and survival according to whether bystander CPR was provided (yes or no). Reported are 30-day survival chances with 95% bootstrap confidence intervals.</p></sec><sec><title>Results:</title><p>With increasing response <strong><span style="color:yellowgreen">time</span></strong>s, adjusted 30-day survival chances decreased for both patients with bystander CPR and those without. However, the contrast between the survival chances of patients with versus without bystander CPR increased over <strong><span style="color:yellowgreen">time</span></strong>: within 5 minutes, 30-day survival was 14.5% (95% confidence interval [CI]: 12.8–16.4) versus 6.3% (95% CI: 5.1–7.6), corresponding to 2.3 <strong><span style="color:yellowgreen">time</span></strong>s higher chances of survival associated with bystander CPR; within 10 minutes, 30-day survival chances were 6.7% (95% CI: 5.4–8.1) versus 2.2% (95% CI: 1.5–3.1), corresponding to 3.0 <strong><span style="color:yellowgreen">time</span></strong>s higher chances of 30-day survival associated with bystander CPR. The contrast in 30-day survival became statistically insignificant when response <strong><span style="color:yellowgreen">time</span></strong> was >13 minutes (bystander CPR vs no bystander CPR: 3.7% [95% CI: 2.2–5.4] vs 1.5% [95% CI: 0.6–2.7]), but 30-day survival was still 2.5 <strong><span style="color:yellowgreen">time</span></strong>s higher associated with bystander CPR. Based on the model and Danish out-of-hospital cardiac arrest statistics, an additional 233 patients could potentially be saved annually if response <strong><span style="color:yellowgreen">time</span></strong> was reduced from 10 to 5 minutes and 119 patients if response <strong><span style="color:yellowgreen">time</span></strong> was reduced from 7 (the median response <strong><span style="color:yellowgreen">time</span></strong> in this study) to 5 minutes.</p></sec><sec><title>Conclusions:</title><p>The absolute survival associated with bystander CPR declined rapidly with <strong><span style="color:yellowgreen">time</span></strong>. Yet bystander CPR while waiting for an ambulance was associated with a more than doubling of 30-day survival even in case of long ambulance response <strong><span style="color:yellowgreen">time</span></strong>. Decreasing ambulance response <strong><span style="color:yellowgreen">time</span></strong> by even a few minutes could potentially lead to many additional lives saved every year.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/25/2095
10.1161/CIRCULATIONAHA.116.024400
None

11
The Bone & Joint Journal
Quantifying the ‘law of diminishing returns’ in magnetically controlled growing rods
<sec><title>Aims</title><p>Magnetically controlled growing rods (MCGRs) allow non-invasive   correction of the spinal deformity in the treatment of early-onset   scoliosis. Conventional growing rod systems (CGRS) need repeated   surgical distractions: these are associated with the effect of the   ‘law of diminishing returns’.</p><p>The primary aim of this study was to quantify this effect in   MCGRs over sequential distractions. </p></sec><sec><title>Patients and Methods</title><p>A total of 35 patients with a maximum follow-up of 57 <strong><span style="color:yellowgreen">month</span></strong>s   were included in the study. There were 17 boys and 18 girls with   a mean age of 7.4 years (2 to 14). True Distraction (TD) was determined   by measuring the expansion gap on fluoroscopy. This was compared   with Intended Distraction (ID) and expressed as the ‘T/I’ ratio.   The T/I ratio and the Cobb angle were calculated at several <strong><span style="color:yellowgreen">time</span></strong>   points during follow-up.</p></sec><sec><title>Results</title><p>The mean follow-up was 30 <strong><span style="color:yellowgreen">month</span></strong>s (6 to 57). There was a significant   decrease in the mean T/I ratio over <strong><span style="color:yellowgreen">time</span></strong> (convex rod at 3 <strong><span style="color:yellowgreen">month</span></strong>s   0.81, <sc>sd</sc> 0.58 <i>vs</i> 51 <strong><span style="color:yellowgreen">month</span></strong>s 0.17, <sc>sd </sc>0.16,    p = 0.0001; concave rod at 3 <strong><span style="color:yellowgreen">month</span></strong>s 0.93, <sc>sd</sc> 0.67 <i>vs</i> 51   <strong><span style="color:yellowgreen">month</span></strong>s 0.18, <sc>sd</sc> 0.15, p = 0.0001). A linear decline of   the mean T/I ratios was noted for both convex rods (r<sup>2</sup> =   0.90, p = 0.004) and concave rods (r<sup>2</sup> = 0.81, p = 0.015)   over 51 <strong><span style="color:yellowgreen">month</span></strong>s. At the 24-<strong><span style="color:yellowgreen">month</span></strong> follow-up stage, there was a significant   negative correlation between the mean T/I ratio of the concave rod   with weight (r = -0.59, p = 0.01), age (r = -0.59, p = 0.01), and   BMI of the child (r = -0.54,    p = 0.01).</p></sec><sec><title>Conclusions</title><p>The ‘law of diminishing returns’ is also seen after serial distraction   using MCGR. Compared to previously published data for CGRS, there   is a gradual linear decline rather than a rapid initial decline   in lengthening. In older, heavier children a reduced distraction   ratio in the concave rod of the MCGR device is noted over <strong><span style="color:yellowgreen">time</span></strong>.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1658–64.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/12/1658
10.1302/0301-620X.99B12.BJJ-2017-0402.R2
None

9
Circulation
Prolonged, Uninterrupted Sedentary Behavior and Glycemic Biomarkers Among US Hispanic/Latino Adults
<sec><title>Background:</title><p>Excessive sedentary <strong><span style="color:yellowgreen">time</span></strong> is ubiquitous in developed nations and is associated with deleterious health outcomes. Few studies have examined whether the manner in which sedentary <strong><span style="color:yellowgreen">time</span></strong> is accrued (in short or long bouts) carries any clinical relevance. The purpose of this study was to examine the association of prolonged, uninterrupted sedentary behavior with glycemic biomarkers in a cohort of US Hispanic/Latino adults.</p></sec><sec><title>Methods:</title><p>We studied 12 083 participants from the HCHS/SOL (Hispanic Community Health Study/Study of Latinos), a population-based study of Hispanic/Latino adults 18 to 74 years of age. Homeostatic model assessment of insulin resistance and glycosylated hemoglobin were measured from a fasting blood sample, and 2-hour glucose was measured after an oral glucose tolerance test. Sedentary <strong><span style="color:yellowgreen">time</span></strong> was objectively measured with a hip-mounted accelerometer. Prolonged, uninterrupted sedentariness was expressed as mean sedentary bout length.</p></sec><sec><title>Results:</title><p>After adjustment for potential confounders and moderate to vigorous physical activity, longer sedentary bout duration was dose-dependently associated with increased homeostatic model assessment of insulin resistance (<i>P</i> for trend<0.001) and 2-hour glucose levels (<i>P</i> for trend=0.015). These associations were not independent of total sedentary <strong><span style="color:yellowgreen">time</span></strong>; however, a significant interaction between sedentary bout duration and total sedentary <strong><span style="color:yellowgreen">time</span></strong> was observed. Evaluation of the joint association of total sedentary <strong><span style="color:yellowgreen">time</span></strong> and sedentary bout duration showed that participants in the upper quartile for both sedentary characteristics (ie, high total sedentary <strong><span style="color:yellowgreen">time</span></strong> and high sedentary bout duration) had the highest levels of homeostatic model assessment of insulin resistance (<i>P</i><0.001 versus low group for both sedentary characteristics) and 2-hour glucose (<i>P</i>=0.002 versus low group for both sedentary characteristics). High total sedentary <strong><span style="color:yellowgreen">time</span></strong> or high sedentary bout duration alone were not associated with differences in any glycemic biomarkers.</p></sec><sec><title>Conclusions:</title><p>Accruing sedentary <strong><span style="color:yellowgreen">time</span></strong> in prolonged, uninterrupted bouts may be deleteriously associated with biomarkers of glucose regulation.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/15/1362
10.1161/CIRCULATIONAHA.116.026858
None

8
Science
Midbrain dopamine neurons control judgment of time
<p>Our sense of <strong><span style="color:yellowgreen">time</span></strong> is far from constant. For instance, <strong><span style="color:yellowgreen">time</span></strong> flies when we are having fun, and it slows to a trickle when we are bored. Midbrain dopamine neurons have been implicated in variable <strong><span style="color:yellowgreen">time</span></strong> estimation. However, a direct link between signals carried by dopamine neurons and temporal judgments is lacking. We measured and manipulated the activity of dopamine neurons as mice judged the duration of <strong><span style="color:yellowgreen">time</span></strong> intervals. We found that pharmacogenetic suppression of dopamine neurons decreased behavioral sensitivity to <strong><span style="color:yellowgreen">time</span></strong> and that dopamine neurons encoded information about trial-to-trial variability in <strong><span style="color:yellowgreen">time</span></strong> estimates. Last, we found that transient activation or inhibition of dopamine neurons was sufficient to slow down or speed up <strong><span style="color:yellowgreen">time</span></strong> estimation, respectively. Dopamine neuron activity thus reflects and can directly control the judgment of <strong><span style="color:yellowgreen">time</span></strong>.</p>
http://sciencemag.org/cgi/content/abstract/354/6317/1273
10.1126/science.aah5234
None

8
The Bone & Joint Journal
Post-operative outcomes of atypical femoral subtrochanteric fracture in patients on bisphosphonate therapy
<p>Management of bisphosphonate-associated subtrochanteric   fractures remains opinion- or consensus-based. There are limited   data regarding the outcomes of this fracture.</p><p>We retrospectively reviewed 33 consecutive female patients with   a mean age of 67.5 years (47 to 91) who were treated surgically   between May 2004 and October 2009. The mean follow-up was 21.7 <strong><span style="color:yellowgreen">month</span></strong>s   (0 to 53). Medical records and radiographs were reviewed to determine   the post-operative ambulatory status, <strong><span style="color:yellowgreen">time</span></strong> to clinical and radiological   union and post-fixation complications such as implant failure and   need for second surgery. </p><p>The predominant fixation method was with an extramedullary device   in 23 patients. 25 (75%) patients were placed on wheelchair mobilisation   or no weight-bearing initially. The mean <strong><span style="color:yellowgreen">time</span></strong> to full weight-bearing   was 7.1 <strong><span style="color:yellowgreen">month</span></strong>s (2.2 to 29.7). The mean <strong><span style="color:yellowgreen">time</span></strong> for fracture site pain   to cease was 6.2 <strong><span style="color:yellowgreen">month</span></strong>s (1.2 to 17.1). The mean <strong><span style="color:yellowgreen">time</span></strong> to radiological   union was 10.0 <strong><span style="color:yellowgreen">month</span></strong>s (2.2 to 27.5). Implant failure was seen in   seven patients (23%, 95 confidence interval (CI) 11.8 to 40.9).   Revision surgery was required in ten patients (33%, 95 CI 19.2 to   51.2).</p><p>A large proportion of the patients required revision surgery   and suffered implant failure. This fracture is associated with slow   healing and prolonged post-operative immobility.</p><p>Cite this article: <i>Bone Joint J</i> 2014;96-B:658–64.</p>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/96-B/5/658
10.1302/0301-620X.96B5.32887
None

8
The Bone & Joint Journal
Does a less intensive surveillance protocol affect the survival of patients after treatment of a sarcoma of the limb?
<sec><title>Aims</title><p>A single-centre prospective randomized trial was conducted to   investigate whether a less intensive follow-up protocol would not   be inferior to a conventional follow-up protocol, in terms of overall   survival, in patients who have undergone surgery for sarcoma of   the limb. Initial short-term results were published in 2014.</p></sec><sec><title>Patients and Methods</title><p>The primary objective was to show non-inferiority of a chest   radiograph (CXR) group compared with a CT scan group, and of a less   frequent (six-<strong><span style="color:yellowgreen">month</span></strong>ly) group than a more frequent (three-<strong><span style="color:yellowgreen">month</span></strong>ly)   group, in two-by-two comparison. The primary outcome was overall   survival and the secondary outcome was a recurrence-free survival.   Five-year survival was compared between the CXR and CT scan groups   and between the three-<strong><span style="color:yellowgreen">month</span></strong>ly and six-<strong><span style="color:yellowgreen">month</span></strong>ly groups. Of 500 patients   who were enrolled, 476 were available for follow-up. Survival analyses   were performed on a per-protocol basis (n = 412).</p></sec><sec><title>Results</title><p>The updated results recorded 12 (2.4%) local recurrences, 182   (36.8%) metastases, and 56 (11.3%) combined (local + metastases)   recurrence at a median follow-up of 81 <strong><span style="color:yellowgreen">month</span></strong>s (60 to 118). Of 68   local recurrences, 60 (88%) were identified by the patients themselves.   The six-<strong><span style="color:yellowgreen">month</span></strong>ly regime (overall survival (OS) 54%, recurrence-free   survival (RFS) 46%) did not lead to a worse survival and was not   inferior to the three-<strong><span style="color:yellowgreen">month</span></strong>ly regime (OS 55%, RFS 47%) in terms   of detecting recurrence. Although CT scans (OS 53%, RFS 54%) detected   pulmonary metastasis earlier, it did not lead to a better survival   compared with CXR (OS 56%, RFS 59%).</p></sec><sec><title>Conclusion</title><p>The overall survival of patients who are treated for a sarcoma   of the limb is not inferior to those followed up with a less intensive   regimen than a more intensive protocol, in terms of frequency of   visits and mode of imaging. CXR at six-<strong><span style="color:yellowgreen">month</span></strong>ly intervals and patient   education about examination of the site of the surgery will detect   most recurrences without deleterious effects on the eventual outcome.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:262–8.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/2/262
10.1302/0301-620X.100B2.BJJ-2017-0789.R1
None

8
Circulation
Impact of Regionalization of ST-Segment–Elevation Myocardial Infarction Care on Treatment Times and Outcomes for Emergency Medical Services–Transported Patients Presenting to Hospitals With Percutaneous Coronary Intervention
<sec><title>Background:</title><p>Regional variations in reperfusion <strong><span style="color:yellowgreen">time</span></strong>s and mortality in patients with ST-segment–elevation myocardial infarction are influenced by differences in coordinating care between emergency medical services (EMS) and hospitals. Building on the Accelerator-1 Project, we hypothesized that <strong><span style="color:yellowgreen">time</span></strong> to reperfusion could be further reduced with enhanced regional efforts.</p></sec><sec><title>Methods:</title><p>Between April 2015 and March 2017, we worked with 12 metropolitan regions across the United States with 132 percutaneous coronary intervention–capable hospitals and 946 EMS agencies. Data were collected in the ACTION (Acute Coronary Treatment and Intervention Outcomes Network)-Get With The Guidelines Registry for quarterly Mission: Lifeline reports. The primary end point was the change in the proportion of EMS-transported patients with first medical contact to device <strong><span style="color:yellowgreen">time</span></strong> ≤90 minutes from baseline to final quarter. We also compared treatment <strong><span style="color:yellowgreen">time</span></strong>s and mortality with patients treated in hospitals not participating in the project during the corresponding <strong><span style="color:yellowgreen">time</span></strong> period.</p></sec><sec><title>Results:</title><p>During the study period, 10 730 patients were transported to percutaneous coronary intervention–capable hospitals, including 974 in the baseline quarter and 972 in the final quarter who met inclusion criteria. Median age was 61 years; 27% were women, 6% had cardiac arrest, and 6% had shock on admission; 10% were black, 12% were Latino, and 10% were uninsured. By the end of the intervention, all process measures reflecting coordination between EMS and hospitals had improved, including the proportion of patients with a first medical contact to device <strong><span style="color:yellowgreen">time</span></strong> of ≤90 minutes (67%–74%; <i>P</i><0.002), a first medical contact to device <strong><span style="color:yellowgreen">time</span></strong> to catheterization laboratory activation of ≤20 minutes (38%–56%; <i>P</i><0.0001), and emergency department dwell <strong><span style="color:yellowgreen">time</span></strong> of ≤20 minutes (33%–43%; <i>P</i><0.0001). Of the 12 regions, 9 regions reduced first medical contact to device <strong><span style="color:yellowgreen">time</span></strong>, and 8 met or exceeded the national goal of 75% of patients treated in ≤90 minutes. Improvements in treatment <strong><span style="color:yellowgreen">time</span></strong>s corresponded with a significant reduction in mortality (in-hospital death, 4.4%–2.3%; <i>P</i>=0.001) that was not apparent in hospitals not participating in the project during the same <strong><span style="color:yellowgreen">time</span></strong> period.</p></sec><sec><title>Conclusions:</title><p>Organization of care among EMS and hospitals in 12 regions was associated with significant reductions in <strong><span style="color:yellowgreen">time</span></strong> to reperfusion in patients with ST-segment–elevation myocardial infarction as well as in in-hospital mortality. These findings support a more intensive regional approach to emergency care for patients with ST-segment–elevation myocardial infarction.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/4/376
10.1161/CIRCULATIONAHA.117.032446
None

8
Circulation
Impact of Practice-Based Management of Pulmonary Artery Pressures in 2000 Patients Implanted With the CardioMEMS Sensor
<sec><title>Background:</title><p>Elevated pulmonary artery (PA) pressures in patients with heart failure are associated with a high risk for hospitalization and mortality. Recent clinical trial evidence demonstrated a direct relationship between lowering remotely monitored PA pressures and heart failure hospitalization risk reduction with a novel implantable PA pressure monitoring system (CardioMEMS HF System, St. Jude Medical). This study examines PA pressure changes in the first 2000 US patients implanted in general practice use.</p></sec><sec><title>Methods:</title><p>Deidentified data from the remote monitoring Merlin.net (St. Jude Medical) database were used to examine PA pressure trends from the first consecutive 2000 patients with at least 6 <strong><span style="color:yellowgreen">month</span></strong>s of follow-up. Changes in PA pressures were evaluated with an area under the curve methodology to estimate the total sum increase or decrease in pressures (mm Hg-day) during the follow-up period relative to the baseline pressure. As a reference, the PA pressure trends were compared with the historic CHAMPION clinical trial (CardioMEMS Heart Sensor Allows Monitoring of Pressure to Improve Outcomes in New York Heart Association [NYHA] Functional Class III Heart Failure Patients). The area under the curve results are presented as mean±2 SE, and <i>P</i> values comparing the area under the curve of the general-use cohort with outcomes in the CHAMPION trial were computed by the <i>t</i> test with equal variance.</p></sec><sec><title>Results:</title><p>Patients were on average 70±12 years old; 60% were male; 34% had preserved ejection fraction; and patients were followed up for an average of 333±125 days. At implantation, the mean PA pressure for the general-use patients was 34.9±10.2 mm Hg compared with 31.3±10.9 mm Hg for CHAMPION treatment and 32.0±10.5 mm Hg for CHAMPION control groups. The general-use patients had an area under the curve of −32.8 mm Hg-day at the 1-<strong><span style="color:yellowgreen">month</span></strong> <strong><span style="color:yellowgreen">time</span></strong> mark, −156.2 mm Hg-day at the 3-<strong><span style="color:yellowgreen">month</span></strong> <strong><span style="color:yellowgreen">time</span></strong> mark, and −434.0 mm Hg-day after 6 <strong><span style="color:yellowgreen">month</span></strong>s of hemodynamic guided care, which was significantly lower than the treatment group in the CHAMPION trial. Patients consistently transmitted pressure information with a median of 1.27 days between transmissions after 6 <strong><span style="color:yellowgreen">month</span></strong>s.</p></sec><sec><title>Conclusions:</title><p>The first 2000 general-use patients managed with hemodynamic-guided heart failure care had higher PA pressures at baseline and experienced greater reduction in PA pressure over <strong><span style="color:yellowgreen">time</span></strong> compared with the pivotal CHAMPION clinical trial. These data demonstrate that general use of implantable hemodynamic technology in a nontrial setting leads to significant lowering of PA pressures.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/16/1509
10.1161/CIRCULATIONAHA.116.026184
None

7
Science Signaling
Mapping the stochastic sequence of individual ligand-receptor binding events to cellular activation: T cells act on the rare events
<p>T cell receptor (TCR) binding to agonist peptide major histocompatibility complex (pMHC) triggers signaling events that initiate T cell responses. This system is remarkably sensitive, requiring only a few binding events to successfully activate a cellular response. On average, activating pMHC ligands exhibit mean dwell <strong><span style="color:yellowgreen">time</span></strong>s of at least a few seconds when bound to the TCR. However, a T cell accumulates pMHC-TCR interactions as a stochastic series of discrete, single-molecule binding events whose individual dwell <strong><span style="color:yellowgreen">time</span></strong>s are broadly distributed. With activation occurring in response to only a handful of such binding events, individual cells are unlikely to experience the average binding <strong><span style="color:yellowgreen">time</span></strong>. Here, we mapped the ensemble of pMHC-TCR binding events in space and <strong><span style="color:yellowgreen">time</span></strong> while simultaneously monitoring cellular activation. Our findings revealed that T cell activation hinges on rare, long–dwell <strong><span style="color:yellowgreen">time</span></strong> binding events that are an order of magnitude longer than the average agonist pMHC-TCR dwell <strong><span style="color:yellowgreen">time</span></strong>. Furthermore, we observed that short pMHC-TCR binding events that were spatially correlated and temporally sequential led to cellular activation. These observations indicate that T cell antigen discrimination likely occurs by sensing the tail end of the pMHC-TCR binding dwell <strong><span style="color:yellowgreen">time</span></strong> distribution rather than its average properties.</p>
http://classic.stke.sciencemag.org/cgi/content/summary/12/564/eaat8715
10.1126/scisignal.aat8715
None

7
PLANT PHYSIOLOGY
Genome-Wide Analysis of the Arabidopsis Replication Timing Program
<p>Eukaryotes use a temporally regulated process, known as the replication timing program, to ensure that their genomes are fully and accurately duplicated during S phase. Replication timing programs are predictive of genomic features and activity and are considered to be functional readouts of chromatin organization. Although replication timing programs have been described for yeast and animal systems, much less is known about the temporal regulation of plant DNA replication or its relationship to genome sequence and chromatin structure. We used the thymidine analog, 5-ethynyl-2′-deoxyuridine, in combination with flow sorting and Repli-Seq to describe, at high-resolution, the genome-wide replication timing program for Arabidopsis (<i>Arabidopsis thaliana</i>) Col-0 suspension cells. We identified genomic regions that replicate predominantly during early, mid, and late S phase, and correlated these regions with genomic features and with data for chromatin state, accessibility, and long-distance interaction. Arabidopsis chromosome arms tend to replicate early while pericentromeric regions replicate late. Early and mid-replicating regions are gene-rich and predominantly euchromatic, while late regions are rich in transposable elements and primarily heterochromatic. However, the distribution of chromatin states across the different <strong><span style="color:yellowgreen">time</span></strong>s is complex, with each replication <strong><span style="color:yellowgreen">time</span></strong> corresponding to a mixture of states. Early and mid-replicating sequences interact with each other and not with late sequences, but early regions are more accessible than mid regions. The replication timing program in Arabidopsis reflects a bipartite genomic organization with early/mid-replicating regions and late regions forming separate, noninteracting compartments. The temporal order of DNA replication within the early/mid compartment may be modulated largely by chromatin accessibility.</p>
http://plantphysiol.org/cgi/content/abstract/176/3/2166
10.1104/pp.17.01537
['Arabidopsis', 'Arabidopsis thaliana']

7
Circulation
The Optimal Timing of Stage 2 Palliation for Hypoplastic Left Heart Syndrome
<sec><title>Background:</title><p>In infants requiring 3-stage single-ventricle palliation for hypoplastic left heart syndrome, attrition after the Norwood procedure remains significant. The effect of the timing of stage 2 palliation (S2P), a physician-modifiable factor, on long-term survival is not well understood. We hypothesized that an optimal interval between the Norwood and S2P that both minimizes pre-S2P attrition and maximizes post-S2P survival exists and is associated with individual patient characteristics.</p></sec><sec><title>Methods:</title><p>The National Institutes of Health/National Heart, Lung, and Blood Institute Pediatric Heart Network Single Ventricle Reconstruction Trial public data set was used. Transplant-free survival (TFS) was modeled from (1) Norwood to S2P and (2) S2P to 3 years by using parametric hazard analysis. Factors associated with death or heart transplantation were determined for each interval. To account for staged procedures, risk-adjusted, 3-year, post-Norwood TFS (the probability of TFS at 3 years given survival to S2P) was calculated using parametric conditional survival analysis. TFS from the Norwood to S2P was first predicted. TFS after S2P to 3 years was then predicted and adjusted for attrition before S2P by multiplying by the estimate of TFS to S2P. The optimal timing of S2P was determined by generating nomograms of risk-adjusted, 3-year, post-Norwood, TFS versus the interval from the Norwood to S2P.</p></sec><sec><title>Results:</title><p>Of 547 included patients, 399 survived to S2P (73%). Of the survivors to S2P, 349 (87%) survived to 3-year follow-up. The median interval from the Norwood to S2P was 5.1 (interquartile range, 4.1–6.0) <strong><span style="color:yellowgreen">month</span></strong>s. The risk-adjusted, 3-year, TFS was 68±7%. A Norwood-S2P interval of 3 to 6 <strong><span style="color:yellowgreen">month</span></strong>s was associated with greatest 3-year TFS overall and in patients with few risk factors. In patients with multiple risk factors, TFS was severely compromised, regardless of the timing of S2P and most severely when S2P was performed early. No difference in the optimal timing of S2P existed when stratified by shunt type.</p></sec><sec><title>Conclusions:</title><p>In infants with few risk factors, progressing to S2P at 3 to 6 <strong><span style="color:yellowgreen">month</span></strong>s after the Norwood procedure was associated with maximal TFS. Early S2P did not rescue patients with greater risk factor burdens. Instead, referral for heart transplantation may offer their best chance at long-term survival.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00115934.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/18/1737
10.1161/CIRCULATIONAHA.117.028481
None

7
Circulation
Dynamic Edematous Response of the Human Heart to Myocardial Infarction
<sec><title>Background:</title><p>Clinical protocols aimed to characterize the post–myocardial infarction (MI) heart by cardiac magnetic resonance (CMR) need to be standardized to take account of dynamic biological phenomena evolving early after the index ischemic event. Here, we evaluated the <strong><span style="color:yellowgreen">time</span></strong> course of edema reaction in patients with ST-segment–elevation MI by CMR and assessed its implications for myocardium-at-risk (MaR) quantification both in patients and in a large-animal model.</p></sec><sec><title>Methods:</title><p>A total of 16 patients with anterior ST-segment–elevation MI successfully treated by primary angioplasty and 16 matched controls were prospectively recruited. In total, 94 clinical CMR examinations were performed: patients with ST-segment–elevation MI were serially scanned (within the first 3 hours after reperfusion and at 1, 4, 7, and 40 days), and controls were scanned only once. T2 relaxation <strong><span style="color:yellowgreen">time</span></strong> in the myocardium (T2 mapping) and the extent of edema on T2-weighted short-tau triple inversion-recovery (ie, CMR-MaR) were evaluated at all <strong><span style="color:yellowgreen">time</span></strong> points. In the experimental study, 20 pigs underwent 40-minute ischemia/reperfusion followed by serial CMR examinations at 120 minutes and 1, 4, and 7 days after reperfusion. Reference MaR was assessed by contrast-multidetector computed tomography during the index coronary occlusion. Generalized linear mixed models were used to take account of repeated measurements.</p></sec><sec><title>Results:</title><p>In humans, T2 relaxation <strong><span style="color:yellowgreen">time</span></strong> in the ischemic myocardium declines significantly from early after reperfusion to 24 hours, and then increases up to day 4, reaching a plateau from which it decreases from day 7. Consequently, edema extent measured by T2-weighted short-tau triple inversion-recovery (CMR-MaR) varied with the timing of the CMR examination. These findings were confirmed in the experimental model by showing that only CMR-MaR values for day 4 and day 7 postreperfusion, coinciding with the deferred edema wave, were similar to values measured by reference contrast-multidetector computed tomography.</p></sec><sec><title>Conclusions:</title><p>Post-MI edema in patients follows a bimodal pattern that affects CMR estimates of MaR. Dynamic changes in post–ST-segment–elevation MI edema highlight the need for standardization of CMR timing to retrospectively delineate MaR and quantify myocardial salvage. According to the present clinical and experimental data, a <strong><span style="color:yellowgreen">time</span></strong> window between days 4 and 7 post-MI seems a good compromise solution for standardization. Further studies are needed to study the effect of other factors on these variables.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/14/1288
10.1161/CIRCULATIONAHA.116.025582
['pigs']

7
Circulation
Optimizing a Drone Network to Deliver Automated External Defibrillators
<sec><title>Background:</title><p>Public access defibrillation programs can improve survival after out-of-hospital cardiac arrest, but automated external defibrillators (AEDs) are rarely available for bystander use at the scene. Drones are an emerging technology that can deliver an AED to the scene of an out-of-hospital cardiac arrest for bystander use. We hypothesize that a drone network designed with the aid of a mathematical model combining both optimization and queuing can reduce the <strong><span style="color:yellowgreen">time</span></strong> to AED arrival.</p></sec><sec><title>Methods:</title><p>We applied our model to 53 702 out-of-hospital cardiac arrests that occurred in the 8 regions of the Toronto Regional RescuNET between January 1, 2006, and December 31, 2014. Our primary analysis quantified the drone network size required to deliver an AED 1, 2, or 3 minutes faster than historical median 911 response <strong><span style="color:yellowgreen">time</span></strong>s for each region independently. A secondary analysis quantified the reduction in drone resources required if RescuNET was treated as a large coordinated region.</p></sec><sec><title>Results:</title><p>The region-specific analysis determined that 81 bases and 100 drones would be required to deliver an AED ahead of median 911 response <strong><span style="color:yellowgreen">time</span></strong>s by 3 minutes. In the most urban region, the 90th percentile of the AED arrival <strong><span style="color:yellowgreen">time</span></strong> was reduced by 6 minutes and 43 seconds relative to historical 911 response <strong><span style="color:yellowgreen">time</span></strong>s in the region. In the most rural region, the 90th percentile was reduced by 10 minutes and 34 seconds. A single coordinated drone network across all regions required 39.5% fewer bases and 30.0% fewer drones to achieve similar AED delivery <strong><span style="color:yellowgreen">time</span></strong>s.</p></sec><sec><title>Conclusions:</title><p>An optimized drone network designed with the aid of a novel mathematical model can substantially reduce the AED delivery <strong><span style="color:yellowgreen">time</span></strong> to an out-of-hospital cardiac arrest event.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/25/2454
10.1161/CIRCULATIONAHA.116.026318
None

7
Circulation
Total Anomalous Pulmonary Venous Connection
<sec><title>Background:</title><p>Total anomalous pulmonary venous connection (TAPVC) is a rare form of congenital heart disease. This study describes current surgical treatment strategies and experiences in a cohort of patients from 2 congenital cardiac centers in Shanghai and Guangdong in China.</p></sec><sec><title>Methods:</title><p>This retrospective study included 768 patients operated on between 2005 and 2014. Although most patients (n=690) underwent conventional repair, a sutureless technique was used in 10% (n=78) of cases. A multilevel mixed-effects parametric survival model and a competing-risk analysis were used to analyze associated risk factors for death and recurrent pulmonary venous obstruction (PVO), respectively. Kaplan-Meier analysis was used to analyze the overall survival. The Nelson-Aalen cumulative risk curve was used to compare distributions of <strong><span style="color:yellowgreen">time</span></strong> with recurrent PVO.</p></sec><sec><title>Results:</title><p>The mean surgical age and weight were 214.9±39.2 days and 5.4±3.6 kg, respectively. Obstructed TAPVC (PVO) was documented in 192 (25%) of the 768 patients. There were 38 intraoperative deaths and 13 late deaths. A younger age at the <strong><span style="color:yellowgreen">time</span></strong> of repair (<i>P</i>=0.001), mixed (<i>P</i>=0.004) and infracardiac (<i>P</i>=0.035) TAPVC, preoperative PVO (<i>P</i>=0.027), prolonged cardiopulmonary bypass <strong><span style="color:yellowgreen">time</span></strong> (<i>P</i><0.001), and longer duration of ventilation (<i>P</i>=0.028) were associated with mortality. The median follow-up was 23.2 <strong><span style="color:yellowgreen">month</span></strong>s (range; 1–112 <strong><span style="color:yellowgreen">month</span></strong>s). Among the 717 survivors, recurrent PVO was observed in 111 patients (15%). Associated risk factors for recurrent PVO included preoperative PVO (<i>P</i><0.001), infracardiac TAPVC (<i>P</i><0.001), mixed TAPVC (<i>P</i>=0.013), and prolonged cardiopulmonary bypass <strong><span style="color:yellowgreen">time</span></strong> (<i>P</i><0.001). Sutureless technique was associated with a lower restenosis rate compared with conventional repair in patients with preoperative PVO (<i>P</i>=0.038), except in newborn patients (<i>P</i>=0.443). Reintervention for restenosis was performed in 24 patients. The function of most survivors (91%) was classified according to the New York Heart Association as functional class I or II.</p></sec><sec><title>Conclusions:</title><p>Surgical correction in patients with TAPVC with a biventricular anatomy can achieve an acceptable outcome. Risk factors such as a younger age at the <strong><span style="color:yellowgreen">time</span></strong> of repair, infracardiac and mixed TAPVC, and preoperative PVO were associated with a poorer prognosis.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/1/48
10.1161/CIRCULATIONAHA.116.023889
None

6
PLANT PHYSIOLOGY
Genetic Architecture of Flowering-Time Variation in <i>Brachypodium distachyon</i><xref><sup>1</sup></xref>
<p>The transition to reproductive development is a crucial step in the plant life cycle, and the timing of this transition is an important factor in crop yields. Here, we report new insights into the genetic control of natural variation in flowering <strong><span style="color:yellowgreen">time</span></strong> in <i>Brachypodium distachyon</i>, a nondomesticated pooid grass closely related to cereals such as wheat (<i>Triticum</i> spp.) and barley (<i>Hordeum vulgare</i> L.). A recombinant inbred line population derived from a cross between the rapid-flowering accession Bd21 and the delayed-flowering accession Bd1-1 were grown in a variety of environmental conditions to enable exploration of the genetic architecture of flowering <strong><span style="color:yellowgreen">time</span></strong>. A genotyping-by-sequencing approach was used to develop SNP markers for genetic map construction, and quantitative trait loci (QTLs) that control differences in flowering <strong><span style="color:yellowgreen">time</span></strong> were identified. Many of the flowering-<strong><span style="color:yellowgreen">time</span></strong> QTLs are detected across a range of photoperiod and vernalization conditions, suggesting that the genetic control of flowering within this population is robust. The two major QTLs identified in undomesticated <i>B. distachyon</i> colocalize with <i>VERNALIZATION1/PHYTOCHROME C</i> and <i>VERNALIZATION2</i>, loci identified as flowering regulators in the domesticated crops wheat and barley. This suggests that variation in flowering <strong><span style="color:yellowgreen">time</span></strong> is controlled in part by a set of genes broadly conserved within pooid grasses.</p>
http://plantphysiol.org/cgi/content/abstract/173/1/269
10.1104/pp.16.01178
['Brachypodium', 'Brachypodium distachyon', 'Hordeum', 'Hordeum vulgare', 'Triticum', 'barley', 'grasses', 'wheat']

6
PLANT PHYSIOLOGY
Natural Variation in <i>Brachypodium</i> Links Vernalization and Flowering Time Loci as Major Flowering Determinants
<p>The domestication of plants is underscored by the selection of agriculturally favorable developmental traits, including flowering <strong><span style="color:yellowgreen">time</span></strong>, which resulted in the creation of varieties with altered growth habits. Research into the pathways underlying these growth habits in cereals has highlighted the role of three main flowering regulators: <i>VERNALIZATION1</i> (<i>VRN1</i>), <i>VRN2</i>, and <i>FLOWERING LOCUS T</i> (<i>FT</i>). Previous reverse genetic studies suggested that the roles of <i>VRN1</i> and <i>FT</i> are conserved in <i>Brachypodium distachyon</i> yet identified considerable ambiguity surrounding the role of <i>VRN2</i>. To investigate the natural diversity governing flowering <strong><span style="color:yellowgreen">time</span></strong> pathways in a nondomesticated grass, the reference <i>B. distachyon</i> accession Bd21 was crossed with the vernalization-dependent accession ABR6. Resequencing of ABR6 allowed the creation of a single-nucleotide polymorphism-based genetic map at the F4 stage of the mapping population. Flowering <strong><span style="color:yellowgreen">time</span></strong> was evaluated in F4:5 families in five environmental conditions, and three major loci were found to govern flowering <strong><span style="color:yellowgreen">time</span></strong>. Interestingly, two of these loci colocalize with the <i>B. distachyon</i> homologs of the major flowering pathway genes <i>VRN2</i> and <i>FT</i>, whereas no linkage was observed at <i>VRN1</i>. Characterization of these candidates identified sequence and expression variation between the two parental genotypes, which may explain the contrasting growth habits. However, the identification of additional quantitative trait loci suggests that greater complexity underlies flowering <strong><span style="color:yellowgreen">time</span></strong> in this nondomesticated system. Studying the interaction of these regulators in <i>B. distachyon</i> provides insights into the evolutionary context of flowering <strong><span style="color:yellowgreen">time</span></strong> regulation in the Poaceae as well as elucidates the way humans have utilized the natural variation present in grasses to create modern temperate cereals.</p>
http://plantphysiol.org/cgi/content/abstract/173/1/256
10.1104/pp.16.00813
['Brachypodium', 'Brachypodium distachyon', 'Poaceae', 'grasses', 'plants']

6
The Bone & Joint Journal
No difference in time-dependent improvement in functional outcome following closing wedge <i>versus</i> opening wedge high tibial osteotomy
<sec><title>Aims</title><p>The aim of this prospective randomised study was to compare the   <strong><span style="color:yellowgreen">time</span></strong> course of clinical improvement during the first two years following   a closing or opening wedge high tibial osteotomy (HTO). It was hypothesised   that there would be no differences in clinical outcome between the   two techniques.</p></sec><sec><title>Patients and Methods</title><p>Between 2007 and 2013, 70 consecutive patients were randomly   allocated to undergo either a closing or opening wedge HTO. All   patients had medial compartment osteoarthritis (OA), and were aged   between 30 years and 60 years. They were evaluated by independent   investigators pre-operatively and at three and six <strong><span style="color:yellowgreen">month</span></strong>s, and one   and two years post-operatively using the Knee Injury and Osteoarthritis   Outcome Score (KOOS), the Oxford Knee Score (OKS), the Lysholm score,   the Tegner activity score, the University of California, Los Angeles   (UCLA) activity scale and range of movement (ROM).</p></sec><sec><title>Results</title><p>There were no significant differences at any <strong><span style="color:yellowgreen">time</span></strong> between the   two techniques for any clinical outcome score (p > 0.05). The mean   scores for all the systems, except UCLA and Tegner, significantly   improved until six <strong><span style="color:yellowgreen">month</span></strong>s post-operatively (p < 0.001). For some   scores, the improvement continued until one and two years.</p></sec><sec><title>Conclusion</title><p>This prospective randomised study suggests that there are no   differences in the <strong><span style="color:yellowgreen">time</span></strong> course of the clinical improvement between   the closing and opening wedge techniques for HTO during the first   two post-operative years. Patients can expect continued improvement   in physical function for between six <strong><span style="color:yellowgreen">month</span></strong>s and one year after HTO   regardless of the technique used.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1157–66</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/9/1157
10.1302/0301-620X.99B9.BJJ-2017-0062.R1
None

6
The Bone & Joint Journal
Proximal translation of > 1 mm within the first two years of revision total hip arthroplasty correctly predicts whether or not an acetabular component is loose in 80% of cases
<sec><title>Aims</title><p>The purpose of this study was to determine the sensitivity, specificity   and predictive values of previously reported thresholds of proximal   translation and sagittal rotation of cementless acetabular components   used for revision total hip arthroplasty (THA) at various <strong><span style="color:yellowgreen">time</span></strong>s   during early follow-up.</p></sec><sec><title>Patients and Methods</title><p>Migration of cementless acetabular components was measured retrospectively   in 84 patients (94 components) using Ein-Bild-Rontgen-Analyse (EBRA-Cup)   in two groups of patients. In Group A, components were recorded   as not being loose intra-operatively at re-revision THA (52 components/48   patients) and Group B components were recorded to be loose at re-revision   (42 components/36 patients).</p></sec><sec><title>Results</title><p>The mean proximal translation and sagittal rotation were significantly   higher in Group B than in Group A from three <strong><span style="color:yellowgreen">month</span></strong>s onwards (p <   0.02). Proximal translation > 1.0 mm within 24 <strong><span style="color:yellowgreen">month</span></strong>s had a positive   predictive value (PPV) of 90% and a specificity of 94%, but a sensitivity   of 64%. Proximal translation > 1.0 mm within the first 24 <strong><span style="color:yellowgreen">month</span></strong>s correctly   identified 76 of 94 (81%) of components to be either loose or not   loose. However, ten components in Group B (24%) did not migrate   proximally above 1.0 mm within the first 60 <strong><span style="color:yellowgreen">month</span></strong>s.</p></sec><sec><title>Conclusion</title><p>The high PPV of EBRA-Cup measurements of proximal translation   (90%) shows that this can be used in early follow-up to identify   patients at risk of aseptic loosening. The absence of proximal translation   within the first 60 <strong><span style="color:yellowgreen">month</span></strong>s indicates a component is not likely to   be loose at re-revision THA although it does not exclude late aseptic loosening   as a cause of failure.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:465–74.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/465
10.1302/0301-620X.99B4.BJJ-2016-0805.R1
None

6
Circulation
Time to Endovascular Treatment and Outcome in Acute Ischemic Stroke
<sec><title>Background:</title><p>Randomized, clinical trials in selected acute ischemic stroke patients reported that for every hour delay of endovascular treatment (EVT), chances of functional independence diminish by up to 3.4%. These findings may not be fully generalizable to clinical practice because of strict in- and exclusion criteria in these trials. Therefore, we aim to assess the association of <strong><span style="color:yellowgreen">time</span></strong> to EVT with functional outcome in current, everyday clinical practice.</p></sec><sec><title>Methods:</title><p>The MR CLEAN Registry (Multicenter Randomized Clinical Trial of Endovascular Treatment for Acute Ischemic Stroke in The Netherlands) is an ongoing, prospective, observational study in all centers that perform EVT in The Netherlands. Data were analyzed from patients treated between March 2014 and June 2016. In the primary analysis we assessed the association of <strong><span style="color:yellowgreen">time</span></strong> from stroke onset to start of EVT and <strong><span style="color:yellowgreen">time</span></strong> from stroke onset to successful reperfusion with functional outcome (measured with the modified Rankin Scale), by means of ordinal logistic regression.</p></sec><sec><title>Results:</title><p>We analyzed 1488 patients with acute ischemic stroke who underwent EVT. An increased <strong><span style="color:yellowgreen">time</span></strong> to start of EVT was associated with worse functional outcome (adjusted common odds ratio, 0.83 per hour; 95% confidence interval, 0.77–0.89) and a 2.2% increase in mortality. Every hour increase from stroke onset to EVT start resulted in a 5.3% decreased probability of functional independence (modified Rankin Scale, 0–2). In the 742 patients with successful reperfusion, every hour increase from stroke onset to reperfusion was associated with a 7.7% decreased probability of functional independence.</p></sec><sec><title>Conclusions:</title><p><strong><span style="color:yellowgreen">time</span></strong> to EVT for acute ischemic stroke in current clinical practice is strongly associated with functional outcome. Our data suggest that this association might be even stronger than previously suggested in reports on more selected patient populations from randomized, controlled trials. These findings emphasize that functional outcome of EVT patients can be greatly improved by shortening onset to treatment <strong><span style="color:yellowgreen">time</span></strong>s.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/138/3/232
10.1161/CIRCULATIONAHA.117.032600
None

6
Circulation
Predictors and Association With Clinical Outcomes of the Changes in Exercise Capacity After Transcatheter Aortic Valve Replacement
<sec><title>Background:</title><p>At present, there are no objective data specifically examining the clinical impact of variations in exercise capacity post–transcatheter aortic valve replacement (TAVR). We describe the changes in exercise capacity between baseline and 6 <strong><span style="color:yellowgreen">month</span></strong>s post-TAVR, and ascertain factors associated with and clinical implications of a lack of improvement in exercise capacity post-TAVR.</p></sec><sec><title>Methods:</title><p>A total of 305 patients (mean age, 79±9 years; 44% men; Society of Thoracic Surgeons predicted risk mortality score, 6.7±4.2%) undergoing TAVR completed both baseline and follow-up exercise capacity assessments at 6 <strong><span style="color:yellowgreen">month</span></strong>s post-TAVR. Exercise capacity was evaluated by the 6-minute walk test (6MWT). Clinical outcomes were compared between patients displaying greater than (n=152; improving group) versus less than (n=153; nonimproving group) the median percentage change in distance walked between baseline and 6-<strong><span style="color:yellowgreen">month</span></strong> follow-up examinations. The primary outcome measure was clinical event rates, measured from the 6-<strong><span style="color:yellowgreen">month</span></strong> post-TAVR period onward. Further dichotomization according to baseline 6MWT distance (less than versus more than median walking distance, or slow walker versus fast walker) was also assessed.</p></sec><sec><title>Results:</title><p>The mean overall distances walked pre- and post-TAVR (6 <strong><span style="color:yellowgreen">month</span></strong>s post-TAVR) were 204±119 and 263±116 m, respectively (Δ6MWT=60±106 m), with 219 (72%) patients demonstrating an increase in their walking distance (median percentage increase of the entire population was 20% [interquartile range, 0%–80%]). Factors independently correlated with reduced exercise capacity improvement included a range of baseline clinical characteristics (older age, female sex, chronic obstructive pulmonary disease; <i>P</i><0.05 for all), periprocedural major or life-threatening bleeding (<i>P</i>=0.009) and new-onset anemia at 6 <strong><span style="color:yellowgreen">month</span></strong>s post-TAVR (<i>P</i>=0.009). Failure to improve the 6MWT distance by at least 20% was independently associated with all-cause mortality (<i>P</i>=0.002) and cardiovascular death or rehospitalization for cardiovascular causes (<i>P</i>=0.001). Baseline slow walkers who were able to improve the 6MWT distance presented with significantly better outcomes than nonimprovers (<i>P</i>=0.01 for all-cause mortality; <i>P</i>=0.001 for cardiovascular end point).</p></sec><sec><title>Conclusions:</title><p>Approximately one-third of patients undergoing TAVR did not improve their exercise capacity postprocedure. The lack of functional improvement post-TAVR was predicted by a mix of baseline and periprocedural factors translating into poorer clinical outcomes. These results suggest that systematically implementing exercise capacity assessment pre- and post-TAVR may help to improve patient risk stratification.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/7/632
10.1161/CIRCULATIONAHA.116.026349
None

6
Circulation
Randomized Comparison of Paclitaxel-Eluting Balloon and Stenting Versus Plain Balloon Plus Stenting Versus Directional Atherectomy for Femoral Artery Disease (ISAR-STATH)
<sec><title>Background:</title><p>Atherosclerosis in the superficial femoral artery is common in patients suffering from peripheral artery disease. Paclitaxel-eluting balloon (PEB) angioplasty, stenting, and directional atherectomy (DA) have provided new options for the treatment of superficial femoral artery disease; however, the comparative efficacy of these interventional strategies remains uncertain.</p></sec><sec><title>Methods:</title><p>One hundred and fifty-five patients with symptomatic peripheral artery disease due to de novo superficial femoral artery stenotic or occlusive lesions were randomized to treatment with plain balloon angioplasty (BA) followed by PEB angioplasty and stenting (n=48), BA and stenting (n=52), or DA with distal protection and bailout stenting (n=55). The primary end point of the study was percentage diameter stenosis after 6 <strong><span style="color:yellowgreen">month</span></strong>s measured by angiography. Other end points included target lesion revascularization, thrombosis, ipsilateral amputation, binary restenosis, and all-cause mortality at 6 and 24 <strong><span style="color:yellowgreen">month</span></strong>s.</p></sec><sec><title>Results:</title><p>Baseline and lesion characteristics were comparable in all groups with a mean lesion length of 65.9±46.8 mm and 56% total occlusions. At 6 <strong><span style="color:yellowgreen">month</span></strong>s angiography, the percent diameter stenosis was significantly lower in patients treated by PEB angioplasty and stenting (34±31%) as compared with BA angioplasty and stenting (56±29%, <i>P</i>=0.009) or DA (55±29%, <i>P</i>=0.007). Similarly, binary restenosis was significantly lower after treatment with PEB and stenting as compared with BA and stenting or DA. Clinical follow-up at 24 <strong><span style="color:yellowgreen">month</span></strong>s revealed a lower risk for target lesion revascularization after PEB angioplasty and stenting as compared with BA and stenting or DA. We found no difference in terms of target lesion thrombosis and mortality among groups, and no patient underwent amputation.</p></sec><sec><title>Conclusions:</title><p>Treatment of de novo superficial femoral artery lesions with PEB angioplasty and stenting is superior to BA angioplasty and stenting or DA in terms of angiographic diameter stenosis at 6 <strong><span style="color:yellowgreen">month</span></strong>s and target lesion revascularization at 24 <strong><span style="color:yellowgreen">month</span></strong>s.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT00986752.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/23/2218
10.1161/CIRCULATIONAHA.116.025329
None

6
Circulation
Sudden Cardiac Death in Patients With Ischemic Heart Failure Undergoing Coronary Artery Bypass Grafting
<sec><title>Background:</title><p>The risk of sudden cardiac death (SCD) in patients with heart failure after coronary artery bypass graft surgery (CABG) has not been examined in a contemporary clinical trial of surgical revascularization. This analysis describes the incidence, timing, and clinical predictors of SCD after CABG.</p></sec><sec><title>Methods:</title><p>Patients enrolled in the STICH trial (Surgical Treatment of Ischemic Heart Failure) who underwent CABG with or without surgical ventricular reconstruction were included. We excluded patients with prior implantable cardioverter-defibrillator and those randomized only to medical therapy. The primary outcome was SCD as adjudicated by a blinded committee. A Cox model was used to examine and identify predictors of SCD. The Fine and Gray method was used to estimate the incidence of SCD accounting for the competing risk of other deaths.</p></sec><sec><title>Results:</title><p>Over a median follow-up of 46 <strong><span style="color:yellowgreen">month</span></strong>s, 113 of 1411 patients who received CABG without (n = 934) or with (n = 477) surgical ventricular reconstruction had SCD; 311 died of other causes. The mean left ventricular ejection fraction at enrollment was 28±9%. The 5-year cumulative incidence of SCD was 8.5%. Patients who had SCD and those who did not die were younger and had fewer comorbid conditions than did those who died of causes other than SCD. In the first 30 days after CABG, SCD (n=5) accounted for 7% of all deaths. The numerically greatest <strong><span style="color:yellowgreen">month</span></strong>ly rate of SCD was in the 31- to 90-day <strong><span style="color:yellowgreen">time</span></strong> period. In a multivariable analysis including baseline demographics, risk factors, coronary anatomy, and left ventricular function, end-systolic volume index and B-type natriuretic peptide were most strongly associated with SCD.</p></sec><sec><title>Conclusions:</title><p>The <strong><span style="color:yellowgreen">month</span></strong>ly risk of SCD shortly after CABG among patients with a low left ventricular ejection fraction is highest between the first and third <strong><span style="color:yellowgreen">month</span></strong>s, suggesting that risk stratification for SCD should occur early in the postoperative period, particularly in patients with increased preoperative end-systolic volume index or B-type natriuretic peptide.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT0002359.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/12/1136
10.1161/CIRCULATIONAHA.116.026075
None

5
Science
Seasonal water storage, stress modulation, and California seismicity
<p>Establishing what controls the timing of earthquakes is fundamental to understanding the nature of the earthquake cycle and critical to determining <strong><span style="color:yellowgreen">time</span></strong>-dependent earthquake hazard. Seasonal loading provides a natural laboratory to explore the crustal response to a quantifiable transient force. In California, water storage deforms the crust as snow and water accumulates during the wet winter <strong><span style="color:yellowgreen">month</span></strong>s. We used 9 years of global positioning system (GPS) vertical deformation <strong><span style="color:yellowgreen">time</span></strong> series to constrain models of <strong><span style="color:yellowgreen">month</span></strong>ly hydrospheric loading and the resulting stress changes on fault planes of small earthquakes. The seasonal loading analysis reveals earthquakes occurring more frequently during stress conditions that favor earthquake rupture. We infer that California seismicity rates are modestly modulated by natural hydrological loading cycles.</p>
http://sciencemag.org/cgi/content/abstract/356/6343/1161
10.1126/science.aak9547
None

5
Science
Submillihertz magnetic spectroscopy performed with a nanoscale quantum sensor
<p>Precise <strong><span style="color:yellowgreen">time</span></strong>keeping is critical to metrology, forming the basis by which standards of <strong><span style="color:yellowgreen">time</span></strong>, length, and fundamental constants are determined. Stable clocks are particularly valuable in spectroscopy because they define the ultimate frequency precision that can be reached. In quantum metrology, the qubit coherence <strong><span style="color:yellowgreen">time</span></strong> defines the clock stability, from which the spectral linewidth and frequency precision are determined. We demonstrate a quantum sensing protocol in which the spectral precision goes beyond the sensor coherence <strong><span style="color:yellowgreen">time</span></strong> and is limited by the stability of a classical clock. Using this technique, we observed a precision in frequency estimation scaling in <strong><span style="color:yellowgreen">time</span></strong> <i>T</i> as <i>T</i><sup>–3/2</sup> for classical oscillating fields. The narrow linewidth magnetometer based on single spins in diamond is used to sense nanoscale magnetic fields with an intrinsic frequency resolution of 607 microhertz, which is eight orders of magnitude narrower than the qubit coherence <strong><span style="color:yellowgreen">time</span></strong>.</p>
http://sciencemag.org/cgi/content/abstract/356/6340/832
10.1126/science.aam5532
None

5
The Bone & Joint Journal
Radiation reduction of minimally invasive transforaminal lumbar interbody fusion with localisation system in overweight patients
<sec><title>Aims</title><p>Minimally invasive transforaminal lumbar interbody fusion (MITLIF)   has been well validated in overweight and obese patients who are   consequently subject to a higher radiation exposure. This prospective   multicentre study aimed to investigate the efficacy of a novel lumbar   localisation system for MITLIF in overweight patients.</p></sec><sec><title>Patients and Methods</title><p>The initial study group consisted of 175 patients. After excluding   49 patients for various reasons, 126 patients were divided into   two groups. Those in Group A were treated using the localisation   system while those in Group B were treated by conventional means.   The primary outcomes were the effective radiation dosage to the   surgeon and the exposure <strong><span style="color:yellowgreen">time</span></strong>.</p></sec><sec><title>Results</title><p>There were 62 patients in Group A and 64 in Group B. The mean   effective dosage was 0.0217 mSv (standard deviation (<sc>sd</sc>) 0.0079)   in Group A and 0.0383 mSv (<sc>sd</sc> 0.0104) in Group B (p < 0.001).   The mean fluoroscopy exposure <strong><span style="color:yellowgreen">time</span></strong> was 26.42 seconds (<sc>sd</sc> 5.91)   in Group A and 40.67 seconds (<sc>sd</sc> 8.18) in Group B (p <   0.001). The operating <strong><span style="color:yellowgreen">time</span></strong> was 175.56 minutes (<sc>sd</sc> 32.23)   and 206.08 minutes (<sc>sd</sc> 30.15) (p < 0.001), respectively.   The mean pre-operative localisation <strong><span style="color:yellowgreen">time</span></strong> was 4.73 minutes (<sc>sd</sc> 0.84)   in Group A and 7.03 minutes (<sc>sd</sc> 1.51) in Group B (p <   0.001). The mean screw placement <strong><span style="color:yellowgreen">time</span></strong> was 47.37 minutes (<sc>sd</sc> 10.43)   in Group A and 67.86 minutes (<sc>sd</sc> 14.15) in Group B (p <   0.001). The pedicle screw violation rate was 0.35% (one out of 283)   in Group A and 2.79% (eight out of 287) in Group B (p = 0.020).</p></sec><sec><title>Conclusion</title><p>The study shows that the localisation system can effectively   reduce radiation exposure, exposure <strong><span style="color:yellowgreen">time</span></strong>, operating <strong><span style="color:yellowgreen">time</span></strong>, pre-operative   localisation <strong><span style="color:yellowgreen">time</span></strong>, and screw placement <strong><span style="color:yellowgreen">time</span></strong> in overweight patients   undergoing MITLIF.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:944–50.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/7/944
10.1302/0301-620X.99B7.BJJ-2016-0853.R1
None

5
The Bone & Joint Journal
Transforaminal lumbar interbody fusion using polyetheretherketone oblique cages with and without a titanium coating
<sec><title>Aims</title><p>We compared the clinical and radiological outcomes of using a   polyetheretherketone cage with (TiPEEK) and without a titanium coating   (PEEK) for instrumented transforaminal lumbar interbody fusion (TLIF).</p></sec><sec><title>Materials and Methods</title><p>We conducted a randomised clinical pilot trial of 40 patients   who were <strong><span style="color:yellowgreen">schedul</span></strong>ed to undergo a TLIF procedure at one or two levels   between L2 and L5. The Oswestry disability index (ODI), EuroQoL-5D,   and back and leg pain were determined pre-operatively, and at three,   six, and 12 <strong><span style="color:yellowgreen">month</span></strong>s post-operatively. Fusion rates were assessed   by thin slice CT at three <strong><span style="color:yellowgreen">month</span></strong>s and by functional radiography at   12 <strong><span style="color:yellowgreen">month</span></strong>s.</p></sec><sec><title>Results</title><p>At final follow-up, one patient in each group had been lost to   follow-up. Two patients in each of the PEEK and TiPEEK groups were   revised for pseudarthrosis (p = 1.00). The rate of complete or partial   fusion at three <strong><span style="color:yellowgreen">month</span></strong>s was 91.7% in both groups. Overall, there   were no significant differences in ODI or in radiological outcomes   between the groups.</p></sec><sec><title>Conclusion</title><p>Favourable results with identical clinical outcomes and a high   rate of fusion was seen in both groups. The titanium coating appears   to have no negative effects on outcome or safety in the short term.   A future study to determine the effect of titanium coating is warranted.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1366–72.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/10/1366
10.1302/0301-620X.99B10.BJJ-2016-1292.R2
None

5
The Bone & Joint Journal
Wound irrigation does not affect health-related quality of life after open fractures: results of a randomized controlled trial
<sec><title>Aims</title><p>The Fluid Lavage in Open Fracture Wounds (FLOW) trial was a multicentre,   blinded, randomized controlled trial that used a 2 × 3 factorial   design to evaluate the effect of irrigation solution (soap <i>versus</i> normal   saline) and irrigation pressure (very low <i>versus</i> low <i>versus</i> high)   on health-related quality of life (HRQL) in patients with open fractures.   In this study, we used this dataset to ascertain whether these factors   affect whether HRQL returns to pre-injury levels at 12-<strong><span style="color:yellowgreen">month</span></strong>s post-injury.</p></sec><sec><title>Patients and Methods</title><p>Participants completed the Short Form-12 (SF-12) and the EuroQol-5   Dimensions (EQ-5D) at baseline (pre-injury recall), at two and six   weeks, and at three, six, nine and 12-<strong><span style="color:yellowgreen">month</span></strong>s post-fracture. We calculated   the Physical Component Score (PCS) and the Mental Component Score   (MCS) of the SF-12 and the EQ-5D utility score, conducted an analysis   using a multi-level generalized linear model, and compared differences   between the baseline and 12-<strong><span style="color:yellowgreen">month</span></strong> scores.</p></sec><sec><title>Results</title><p>We found no clinically important differences between irrigating   solutions or pressures for the SF-12 PCS, SF-12 MCS and EQ-5D. Irrespective   of treatment, participants had not returned to their pre-injury   function at 12-<strong><span style="color:yellowgreen">month</span></strong>s for any of the three outcomes (p < 0.001).</p></sec><sec><title>Conclusion</title><p>Neither the composition of the irrigation solution nor irrigation   pressure applied had an effect on HRQL. Irrespective of treatment,   patients had not returned to their pre-injury HRQL at 12 <strong><span style="color:yellowgreen">month</span></strong>s   post-fracture.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B:88–94.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1/88
10.1302/0301-620X.100B1.BJJ-2017-0955.R1
None

5
Circulation
Treatment With Tissue Plasminogen Activator in the Golden Hour and the Shape of the 4.5-Hour Time-Benefit Curve in the National United States Get With The Guidelines-Stroke Population
<sec><title>Background:</title><p>Earlier tissue plasminogen activator treatment improves ischemic stroke outcome, but aspects of the <strong><span style="color:yellowgreen">time</span></strong>-benefit relationship still not well delineated are: (1) the degree of additional benefit accrued with treatment in the first 60 minutes after onset, and (2) the shape of the <strong><span style="color:yellowgreen">time</span></strong>-benefit curve through 4.5 hours.</p></sec><sec><title>Methods:</title><p>We analyzed patients who had acute ischemic stroke treated with intravenous tissue plasminogen activator within 4.5 hours of onset from the Get With The Guidelines-Stroke US national program. Onset-to-treatment <strong><span style="color:yellowgreen">time</span></strong> was analyzed as a continuous, potentially nonlinear variable and as a categorical variable comparing patients treated within 60 minutes of onset with later epochs.</p></sec><sec><title>Results:</title><p>Among 65 384 tissue plasminogen activator–treated patients, the median onset-to-treatment <strong><span style="color:yellowgreen">time</span></strong> was 141 minutes (interquartile range, 110–173) and 878 patients (1.3%) were treated within the first 60 minutes. Treatment within 60 minutes, compared with treatment within 61 to 270 minutes, was associated with increased odds of discharge to home (adjusted odds ratio, 1.25; 95% confidence interval, 1.07–1.45), independent ambulation at discharge (adjusted odds ratio, 1.22; 95% confidence interval, 1.03–1.45), and freedom from disability (modified Rankin Scale 0–1) at discharge (adjusted odds ratio, 1.72; 95% confidence interval, 1.21–2.46), without increased hemorrhagic complications or in-hospital mortality. The pace of decline in benefit of tissue plasminogen activator from onset-to-treatment <strong><span style="color:yellowgreen">time</span></strong>s of 20 through 270 minutes was mildly nonlinear for discharge to home, with more rapid benefit loss in the first 170 minutes than later, and linear for independent ambulation and in-hospital mortality.</p></sec><sec><title>Conclusions:</title><p>Thrombolysis started within the first 60 minutes after onset is associated with best outcomes for patients with acute ischemic stroke, and benefit declined more rapidly early after onset for the ability to be discharged home. These findings support intensive efforts to organize stroke systems of care to improve the <strong><span style="color:yellowgreen">time</span></strong>liness of thrombolytic therapy in acute ischemic stroke.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/2/128
10.1161/CIRCULATIONAHA.116.023336
None

5
Circulation
Nationwide Study of the Treatment of Mycotic Abdominal Aortic Aneurysms Comparing Open and Endovascular Repair
<sec><title>Background:</title><p>No reliable comparative data exist between open repair (OR) and endovascular aneurysm repair (EVAR) for mycotic abdominal aortic aneurysms (MAAAs). This nationwide study assessed outcomes after OR and EVAR for MAAA in a population-based cohort.</p></sec><sec><title>Methods:</title><p>All patients treated for MAAAs in Sweden between 1994 and 2014 were identified in the Swedish vascular registry. The primary aim was to assess survival after MAAA with OR and EVAR. Secondary aims were analyses of the rate of recurrent infections and reoperations, and <strong><span style="color:yellowgreen">time</span></strong> trends in surgical treatment. Survival was analyzed using Kaplan-Meier and log-rank tests. A propensity score–weighted correction for risk factor differences in the 2 groups was performed, including the operation year to account for differences in treatment and outcomes over <strong><span style="color:yellowgreen">time</span></strong>.</p></sec><sec><title>Results:</title><p>We identified 132 patients (0.6% of all operated abdominal aortic aneurysms in Sweden). Mean age was 70 years (standard deviation, 9.2), and 50 presented with rupture. Survival at 3 <strong><span style="color:yellowgreen">month</span></strong>s was 86% (95% confidence interval, 80%–92%), at 1 year 79% (72%–86%), and at 5 years 59% (50%–68%). The preferred operative technique shifted from OR to EVAR after 2001 (proportion EVAR 1994–2000 0%, 2001–2007 58%, 2008–2014 60%). Open repair was performed in 62 patients (47%): aortic resection and extra-anatomic bypass (n=7), in situ reconstruction (n=50), and patch plasty (n=3); 2 patients died intraoperatively. EVAR was performed in 70 patients (53%): standard EVAR (n=55), fenestrated/branched EVAR (n=8), and visceral deviation with stent grafting (n=7); no deaths occurred intraoperatively. Survival at 3 <strong><span style="color:yellowgreen">month</span></strong>s was lower for OR than for EVAR (74% versus 96%, <i>P</i><0.001), with a similar trend present at 1 year (73% versus 84%, <i>P</i>=0.054). A propensity score–weighted risk-adjusted analysis confirmed the early better survival associated with EVAR. During median follow-up of 36 and 41 <strong><span style="color:yellowgreen">month</span></strong>s for OR and EVAR, respectively, there was no difference in long-term survival (5 years 60% versus 58%, <i>P</i>=0.771), infection-related complications (18% versus 24%, <i>P</i>=0.439), or reoperation (21% versus 24%, <i>P</i>=0.650).</p></sec><sec><title>Conclusion:</title><p>This study demonstrates a paradigm shift in treatment of MAAA in Sweden, with EVAR being the preferred treatment modality. EVAR was associated with improved short-term survival in comparison with OR, without higher associated incidence of serious infection-related complications or reoperations.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/23/1822
10.1161/CIRCULATIONAHA.116.024021
None

5
Circulation
Adherence to Antihypertensive Treatment and the Blood Pressure–Lowering Effects of Renal Denervation in the Renal Denervation for Hypertension (DENERHTN) Trial
<sec><title>Background:</title><p>The DENERHTN trial (Renal Denervation for Hypertension) confirmed the blood pressure–lowering efficacy of renal denervation added to a standardized stepped-care antihypertensive treatment for resistant hypertension at 6 <strong><span style="color:yellowgreen">month</span></strong>s. We report the influence of adherence to antihypertensive treatment on blood pressure control.</p></sec><sec><title>Methods:</title><p>One hundred six patients with hypertension resistant to 4 weeks of treatment with indapamide 1.5 mg/d, ramipril 10 mg/d (or irbesartan 300 mg/d), and amlodipine 10 mg/d were randomly assigned to renal denervation plus standardized stepped-care antihypertensive treatment, or the same antihypertensive treatment alone. For standardized stepped-care antihypertensive treatment, spironolactone 25 mg/d, bisoprolol 10 mg/d, prazosin 5 mg/d, and rilmenidine 1 mg/d were sequentially added at <strong><span style="color:yellowgreen">month</span></strong>ly visits if home blood pressure was ≥135/85 mm Hg after randomization. We assessed adherence to antihypertensive treatment at 6 <strong><span style="color:yellowgreen">month</span></strong>s by drug screening in urine/plasma samples from 85 patients.</p></sec><sec><title>Results:</title><p>The numbers of fully adherent (20/40 versus 21/45), partially nonadherent (13/40 versus 20/45), or completely nonadherent patients (7/40 versus 4/45) to antihypertensive treatment were not different in the renal denervation and the control groups, respectively (<i>P</i>=0.3605). The difference in the change in day<strong><span style="color:yellowgreen">time</span></strong> ambulatory systolic blood pressure from baseline to 6 <strong><span style="color:yellowgreen">month</span></strong>s between the 2 groups was –6.7 mm Hg (<i>P</i>=0.0461) in fully adherent and –7.8 mm Hg (<i>P</i>=0.0996) in nonadherent (partially nonadherent plus completely nonadherent) patients. The between-patient variability of day<strong><span style="color:yellowgreen">time</span></strong> ambulatory systolic blood pressure was greater for nonadherent than for fully adherent patients.</p></sec><sec><title>Conclusions:</title><p>In the DENERHTN trial, the prevalence of nonadherence to antihypertensive drugs at 6 <strong><span style="color:yellowgreen">month</span></strong>s was high (≈50%) but not different in the renal denervation and control groups. Regardless of adherence to treatment, renal denervation plus standardized stepped-care antihypertensive treatment resulted in a greater decrease in blood pressure than standardized stepped-care antihypertensive treatment alone.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>http://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT01570777.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/134/12/847
10.1161/CIRCULATIONAHA.116.022922
None

4
PLANT PHYSIOLOGY
Leaf Starch Turnover Occurs in Long Days and in Falling Light at the End of the Day
<p>We investigated whether starch degradation occurs at the same <strong><span style="color:yellowgreen">time</span></strong> as starch synthesis in Arabidopsis (<i>Arabidopsis thaliana</i>) leaves in the light. Starch accumulated in a linear fashion for about 12 h after dawn, then accumulation slowed and content plateaued. Following decreases in light intensity, the rate of accumulation of starch declined in proportion to the decline in photosynthesis if the decrease occurred <10 h after dawn, but accumulation ceased or loss of starch occurred if the same decrease in light intensity was imposed more than 10 h after dawn. These changes in starch accumulation patterns after prolonged periods in the light occurred at both high and low starch contents and were not related to <strong><span style="color:yellowgreen">time</span></strong>-dependent changes in either the rate of photosynthesis or the partitioning of assimilate between starch and Suc, as assessed from metabolite measurements and <sup>14</sup>CO<sub>2</sub> pulse experiments. Instead, measurements of incorporation of <sup>13</sup>C from <sup>13</sup>CO<sub>2</sub> into starch and of levels of the starch degradation product maltose showed that substantial starch degradation occurred simultaneously with synthesis at <strong><span style="color:yellowgreen">time</span></strong> points >14 h after dawn and in response to decreases in light intensity that occurred >10 h after dawn. Starch measurements in circadian clock mutants suggested that the clock influences the timing of onset of degradation. We conclude that the propensity for leaf starch to be degraded increases with <strong><span style="color:yellowgreen">time</span></strong> after dawn. The importance of this phenomenon for efficient use of carbon for growth in long days and for prevention of starvation during twilight is discussed.</p>
http://plantphysiol.org/cgi/content/abstract/174/4/2199
10.1104/pp.17.00601
['Arabidopsis', 'Arabidopsis thaliana']

4
Journal of Experimental Biology
Changes in protein expression in the salt marsh mussel <i>Geukensia demissa</i>: evidence for a shift from anaerobic to aerobic metabolism during prolonged aerial exposure
<p>During aerial exposure (emersion), most sessile intertidal invertebrates experience cellular stress caused by hypoxia, and the amount and types of hypoxia-induced stress will differ as exposure <strong><span style="color:yellowgreen">time</span></strong> increases, likely leading to altered metabolic responses. We examined proteomic responses to increasing emersion <strong><span style="color:yellowgreen">time</span></strong>s and decreasing recovery (immersion) <strong><span style="color:yellowgreen">time</span></strong>s in the mussel <i>Geukensia demissa</i>, which occurs in salt marshes along the east coast of North America. Individuals are found above mean tide level, and can be emersed for over 18 h during spring tides. We acclimated mussels to full immersion at 15°C for 4 weeks, and compared changes in gill protein expression between groups of mussels that were continually immersed (control), were emersed for 6 h and immersed during recovery for 18 h (6E/18R), were emersed for 12 h and recovered for 12 h (12E/12R), or were emersed for 18 h with a 6 h recovery (18E/6R). We found clear differences in protein expression patterns among the treatments. Proteins associated with anaerobic fermentation increased in abundance in 6E/18R but not in 12E/12R or 18E/6R. Increases in oxidative stress proteins were most apparent in 12E/12R, and in 18E/6R changes in cytoskeletal protein expression predominated. We conclude that <i>G. demissa</i> alters its strategy for coping with emersion stress over <strong><span style="color:yellowgreen">time</span></strong>, relying on anaerobic metabolism for short- to medium-duration exposure, but switching to an air-gaping strategy for long-term exposure, which reduces hypoxia stress but may cause structural damage to gill tissue.</p>
http://jeb.biologists.org/cgi/content/abstract/217/9/1601
10.1242/jeb.101758
['Geukensia', 'Geukensia demissa', 'marsh']

4
The Bone & Joint Journal
Long-term outcomes of cemented <i>versus</i> cementless humeral components in arthroplasty of the shoulder
<sec><title>Aims</title><p>In the initial development of total shoulder arthroplasty (TSA),   the humeral component was usually fixed with cement. Cementless   components were subsequently introduced. The aim of this study was   to compare the long-term outcome of cemented and cementless humeral   components in arthroplasty of the shoulder.</p></sec><sec><title>Patients and Methods</title><p>All patients who underwent primary arthroplasty of the shoulder   at our institution between 1970 and 2012 were included in the study.   There were 4636 patients with 1167 cemented humeral components and   3469 cementless components. Patients with the two types of fixation   were matched for nine different covariates using a propensity score   analysis. A total of 551 well-balanced pairs of patients with cemented   and cementless components were available after matching for comparison   of the outcomes. The clinical outcomes which were analysed included loosening   of the humeral component determined at revision surgery, periprosthetic   fractures, post-operative infection and operating <strong><span style="color:yellowgreen">time</span></strong>.</p></sec><sec><title>Results</title><p>The overall five-, ten-, 15- and 20-year rates of survival were   98.9%, 97.2%, 95.5%, and 94.4%, respectively. Survival without loosening   at 20 years was 98% for cemented components and 92.4% for cementless   components. After propensity score matching including fixation as   determined by the design of the component, humeral loosening was   also found to be significantly higher in the cementless group. Survival   without humeral loosening at 20 years was 98.7% for cemented components   and 91.0% for cementless components. There was no significant difference   in the risk of intra- or post-operative fracture. The rate of survival   without deep infection and the mean operating <strong><span style="color:yellowgreen">time</span></strong> were significantly   higher in the cemented group.</p></sec><sec><title>Conclusion</title><p>Both types of fixation give rates of long-term survival of >   90%. Cemented components have better rates of survival without loosening   but this should be weighed against increased operating <strong><span style="color:yellowgreen">time</span></strong> and   the risk of bony destruction of the proximal humerus at the <strong><span style="color:yellowgreen">time</span></strong>   of revision of a cemented humeral component.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:666–73.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/5/666
10.1302/0301-620X.99B5.BJJ-2016-0910.R1
None

4
The Bone & Joint Journal
Epidermal growth factor receptor mutations should be considered as a prognostic factor for survival of patients with pathological fractures or painful bone metastases from non-small cell lung cancer
<sec><title>Aims</title><p>This study aims to assess first, whether mutations in the epidermal   growth factor receptor (EGFR) and Kirsten rat sarcoma (kRAS) genes   are associated with overall survival (OS) in patients who present   with symptomatic bone metastases from non-small cell lung cancer   (NSCLC) and secondly, whether mutation status should be incorporated into   prognostic models that are used when deciding on the appropriate   palliative treatment for symptomatic bone metastases.</p></sec><sec><title>Patients and Methods</title><p>We studied 139 patients with NSCLC treated between 2007 and 2014   for symptomatic bone metastases and whose mutation status was known.   The association between mutation status and overall survival was   analysed and the results applied to a recently published prognostic   model to determine whether including the mutation status would improve   its discriminatory power.</p></sec><sec><title>Results</title><p>The median OS was 3.9 <strong><span style="color:yellowgreen">month</span></strong>s (95% confidence interval (CI) 2.1   to 5.7). Patients with EGFR (15%) or kRAS mutations (34%) had a   median OS of 17.3 <strong><span style="color:yellowgreen">month</span></strong>s (95% CI 12.7 to 22.0) and 1.8 <strong><span style="color:yellowgreen">month</span></strong>s (95%   CI 1.0 to 2.7), respectively. Compared with EGFR-positive patients,   EGFR-negative patients had a 2.5 <strong><span style="color:yellowgreen">time</span></strong>s higher risk of death (95%   CI 1.5 to 4.2). Incorporating EGFR mutation status in the prognostic   model improved its discriminatory power.</p></sec><sec><title>Conclusion</title><p>Survival prediction models for patients with symptomatic bone   metastases are used to determine the most appropriate (surgical)   treatment for painful or fractured lesions. This study shows that   NSCLC should not be regarded as a single entity in such models.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:516–21.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/516
10.1302/0301-620X.99B4.BJJ-2016-0872.R1
None

4
The Bone & Joint Journal
Low-intensity pulsed ultrasound does not influence bone healing by distraction osteogenesis
<sec><title>Aims</title><p>The aim of this double-blind prospective randomised controlled   trial was to assess whether low intensity pulsed ultrasound (LIPUS)   accelerated or enhanced the rate of bone healing in adult patients   undergoing distraction osteogenesis.</p></sec><sec><title>Patients and Methods</title><p>A total of 62 adult patients undergoing limb lengthening or bone   transport by distraction osteogenesis were randomised to treatment   with either an active (n = 32) or a placebo (n = 30) ultrasound   device. A standardised corticotomy was performed in the proximal   tibial metaphysis and a circular Ilizarov frame was used in all   patients. The rate of distraction was also standardised. The primary   outcome measure was the <strong><span style="color:yellowgreen">time</span></strong> to removal of the frame after adjusting   for the length of distraction in days/cm for both the per protocol   (PP) and the intention-to-treat (ITT) groups. The assessor was blinded   to the form of treatment. A secondary outcome was to identify covariates affecting   the <strong><span style="color:yellowgreen">time</span></strong> to removal of the frame.</p></sec><sec><title>Results</title><p>There was no difference in the <strong><span style="color:yellowgreen">time</span></strong> to removal of the frame between   the PP (difference in favour of the control group was 10.1 days/cm,   95% confidence interval (CI) -3.2 to 23.4, p = 0.054) or ITT (difference   5.0 days/cm, 95% CI -8.2 to 18.21, p = 0.226) groups. The smoking   status was the only covariate which increased the <strong><span style="color:yellowgreen">time</span></strong> to removal   of the frame (hazard ratio 0.47, 95% CI 0.22 to 0.97, p = 0.042).</p></sec><sec><title>Conclusion</title><p>LIPUS does not influence the rate of bone healing in patients   who undergo distraction osteogenesis. Smoking may influence bone   healing. </p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:494–502.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/494
10.1302/0301-620X.99B4.BJJ-2016-0559.R1
None

4
The Bone & Joint Journal
Risk factors for post-operative periprosthetic fractures following primary total hip arthroplasty with a proximally coated double-tapered cementless femoral component
<sec><title>Aims</title><p>The aim of this study was to identify patient- and surgery-related   risk factors for sustaining an early periprosthetic fracture following   primary total hip arthroplasty (THA) performed using a double-tapered   cementless femoral component (Bi-Metric femoral stem; Biomet Inc.,   Warsaw, Indiana).</p></sec><sec><title>Patients and Methods</title><p>A total of 1598 consecutive hips, in 1441 patients receiving   primary THA between January 2010 and June 2015, were retrospectively   identified. Level of pre-operative osteoarthritis, femoral Dorr   type and cortical index were recorded. Varus/valgus placement of   the stem and canal fill ratio were recorded post-operatively. Periprosthetic   fractures were identified and classified according to the Vancouver   classification. Regression analysis was performed to identify risk   factors for early periprosthetic fracture.</p></sec><sec><title>Results</title><p>The mean follow-up was 713 days (1 to 2058). A total of 48 periprosthetic   fractures (3.0%) were identified during the follow-up and median   <strong><span style="color:yellowgreen">time</span></strong> until fracture was 16 days, (interquartile range 10 to 31.5).   Patients with femoral Dorr type C had a 5.2 <strong><span style="color:yellowgreen">time</span></strong>s increased risk   of post-operative periprosthetic fracture compared with type B,   while female patients had a near significant two <strong><span style="color:yellowgreen">time</span></strong>s increased   risk over <strong><span style="color:yellowgreen">time</span></strong> for post-operative fracture.</p></sec><sec><title>Conclusion</title><p>Dorr type C is an independent risk factor for early periprosthetic   fracture, following THA using a double tapered cementless stem such   as the Bi-Metric. Surgeons should take bone morphology into consideration   when planning for primary THA and consider using cemented femoral   components in female patients with poor bone quality.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:451–7.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/4/451
10.1302/0301-620X.99B4.BJJ-2016-0266.R2
['Varus']

4
The Bone & Joint Journal
Fixation and clinical outcome of uncemented peri-apatite-coated <i>versus</i> cemented total knee arthroplasty
<sec><title>Aims</title><p>The optimal method of tibial component fixation remains uncertain   in total knee arthroplasty (TKA). Hydroxyapatite coatings have been   applied to improve bone ingrowth in uncemented designs, but may   only coat the directly accessible surface. As peri-apatite (PA)   is solution deposited, this may increase the coverage of the implant   surface and thereby fixation. We assessed the tibial component fixation   of uncemented PA-coated TKAs <i>versus</i> cemented TKAs.</p></sec><sec><title>Patients and Methods</title><p>Patients were randomised to PA-coated or cemented TKAs. In 60   patients (30 in each group), radiostereometric analysis of tibial   component migration was evaluated as the primary outcome at baseline,   three <strong><span style="color:yellowgreen">month</span></strong>s post-operatively and at one, two and five years. A   linear mixed-effects model was used to analyse the repeated measurements.</p></sec><sec><title>Results</title><p>After five years of follow-up, one (cemented) component was revised   due to ligament instability. Overall, uncemented PA-coated tibial   components migrated significantly more    (p = 0.003), with the mean maximum total point motion (MTPM) at   five years being 0.62 mm (95% confidence intervals (CI) 0.49 to   0.76) for cemented tibial components and 0.97 mm (95% CI 0.81 to   1.15) for PA-coated tibial components in TKA. However, between three   <strong><span style="color:yellowgreen">month</span></strong>s and five years the cemented TKAs migrated significantly more   (p = 0.02), displaying a MTPM of 0.27 mm (95% CI, 0.19 to 0.36) <i>versus</i> 0.13   mm (95% CI, 0.01 to 0.25) for PA-coated tibial components. One implant   in each group was considered at risk for aseptic loosening due to continuous   migration after five years of follow-up, albeit with different migration   patterns for each group (i.e. higher initial migration but diminishing   over <strong><span style="color:yellowgreen">time</span></strong> for the PA-coated component <i>versus</i> gradually   increasing migration for the cemented component).</p></sec><sec><title>Conclusion</title><p>The tibial components of PA-coated TKAs showed more overall migration   compared with the tibial components of cemented TKAs. However, <i>post   hoc</i> analysis showed that this difference was caused by   higher migration of PA-coated components in the first three <strong><span style="color:yellowgreen">month</span></strong>s,   after which a stable migration pattern was observed. Clinically,   there was no significant difference in outcome between the groups.</p><p>Cite this article: <i>Bone Joint J</i> 2017;99-B:1467–76.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/99-B/11/1467
10.1302/0301-620X.99B11.BJJ-2016-1347.R3
None

4
The Bone & Joint Journal
What is the morbidity of a non-invasive growing prosthesis?
<sec><title>Aims</title><p>Extendible endoprostheses have been available for more than 30   years and have become more sophisticated with <strong><span style="color:yellowgreen">time</span></strong>. The latest generation   is ‘non-invasive’ and can be lengthened with an external magnetic   force. Early results have shown a worryingly high rate of complications   such as infection. This study investigates the incidence of complications   and the need for further surgery in a cohort of patients with a   non-invasive growing endoprosthesis.</p></sec><sec><title>Patients and Methods</title><p>Between 2003 and June 2014, 50 children (51 prostheses) had a   non-invasive growing prosthesis implanted for a primary bone sarcoma.   The minimum follow-up was 24 <strong><span style="color:yellowgreen">month</span></strong>s for those who survived. Their   mean age was 10.4 years (6 to 14). The incidence of complications   and further surgery was documented.</p></sec><sec><title>Results</title><p>The mean follow-up was 64 <strong><span style="color:yellowgreen">month</span></strong>s (20 to 145). The overall survivorship   of the patients was 84% at three years and 70% at five years. Revision-free   survival was 81.7% at three years and 61.6% at five years with competing   risk analysis. Deep infection occurred in 19.6% of implants at a   mean of 12.5 <strong><span style="color:yellowgreen">month</span></strong>s (0 to 55). Other complications were a failure   of the lengthening mechanism in five prostheses (9.8%) and breakage   of the implant in two (3.9%). Overall, there were 53 additional   operations (0 to 5 per patient). A total of seven patients (14%)   underwent amputation, three for local recurrence and four for infection.   Their mean limb length discrepancy was 4.3 mm (0 to 25) and mean Musculoskeletal   Tumor Society Score functional score was 26.5 (18 to 30) at the   final follow-up.</p></sec><sec><title>Conclusions</title><p>When compared with previously published early results, this mid-term   series has shown continued good functional outcomes and compensation   for leg-length discrepancy. Infection is still the most common complication:   post-operative wound healing problems, central line infection and   proximal tibial location are the main risk factors.</p><p>Cite this article: <i>Bone Joint J</i> 2016;98-B:1697–1703.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/98-B/12/1697
10.1302/0301-620X.98B12.BJJ-2016-0467
None

4
The Bone & Joint Journal
Costs, quality of life and cost-effectiveness of arthroscopic and open repair for rotator cuff tears
<sec><title>Aims</title><p>A trial-based comparison of the use of resources, costs and quality   of life outcomes of arthroscopic and open surgical management for   rotator cuff tears in the United Kingdom NHS was performed using   data from the United Kingdom Rotator Cuff Study (UKUFF) randomised   controlled trial.</p></sec><sec><title>Patients and Methods</title><p>Using data from 273 patients, healthcare-related use of resources,   costs and quality-adjusted life years (QALYs) were estimated at   12 <strong><span style="color:yellowgreen">month</span></strong>s and 24 <strong><span style="color:yellowgreen">month</span></strong>s after surgery on an intention-to-treat basis   with adjustment for covariates. Uncertainty about the incremental   cost-effectiveness ratio for arthroscopic <i>versus</i> open   management at 24 <strong><span style="color:yellowgreen">month</span></strong>s of follow-up was incorporated using bootstrapping.   Multiple imputation methods were used to deal with missing data.</p></sec><sec><title>Results</title><p>There were no significant differences between the arthroscopic   and open groups in terms of total mean use and cost of resources   or QALYs at any <strong><span style="color:yellowgreen">time</span></strong> post-operatively. Open management dominated   arthroscopic management in 59.8% of bootstrapped cost and effect   differences. The probability that arthroscopic management was cost-effective   compared with open management at a willingness-to-pay threshold   of £20 000 per QALY gained was 20.9%.</p></sec><sec><title>Conclusion</title><p>There was no significant overall difference in the use or cost   of resources or quality of life between arthroscopic and open management   in the trial. There was uncertainty about which strategy was most   cost-effective.</p><p>Cite this article: <i>Bone Joint J</i> 2016;98-B:1648–55.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/98-B/12/1648
10.1302/0301-620X.98B12.BJJ-2016-0121.R1
None

4
The Bone & Joint Journal
Trends and risk factors for prolonged opioid use after unicompartmental knee arthroplasty
<sec><title>Aims</title><p>The purpose of this study was to evaluate trends in opioid use   after unicompartmental knee arthroplasty (UKA), to identify predictors   of prolonged use and to compare the rates of opioid use after UKA,   total knee arthroplasty (TKA) and total hip arthroplasty (THA).</p></sec><sec><title>Materials and Methods</title><p>We identified 4205 patients who had undergone UKA between 2007   and 2015 from the Humana Inc. administrative claims database. Post-operative   opioid use for one year post-operatively was assessed using the   rates of <strong><span style="color:yellowgreen">month</span></strong>ly repeat prescription. These were then compared between   patients with and without a specific variable of interest and with   those of patients who had undergone TKA and THA.</p></sec><sec><title>Results</title><p>A total of 4205 UKA patients were analysed. Of these, 1362 patients   (32.4%) were users of opioids. Pre-operative opioid use was the   strongest predictor of prolonged opioid use after UKA. Opioid users   were 1.4 (81.6% <i>versus</i> 57.7%), 3.7 (49.5% <i>versus</i> 13.3%)   and 5.5    (35.8% <i>versus</i> 6.5%) <strong><span style="color:yellowgreen">time</span></strong>s more likely to be taking   opioids at one, two and three <strong><span style="color:yellowgreen">month</span></strong>s post-operatively, respectively   (p < 0.05 for all). Younger age and specific comorbidities such   as anxiety/depression, smoking, back pain and substance abuse were   found to significantly increase the rate of repeat prescription   for opioids after UKA. Overall, UKA patients required significantly   less opioid prescriptions than patients who had undergone THA and TKA.</p></sec><sec><title>Conclusion</title><p>One-third of patients who undergo UKA are given opioids in the   three <strong><span style="color:yellowgreen">month</span></strong>s pre-operatively. Pre-operative opioid use is the best   predictor of increased repeat prescriptions after UKA. However,   other intrinsic patient characteristics are also predictive.</p><p>Cite this article: <i>Bone Joint J</i> 2018;100-B(1   Supple A):62–7.</p></sec>
http://bjj.boneandjoint.org.uk/cgi/content/abstract/100-B/1_Supple_A/62
10.1302/0301-620X.100B1.BJJ-2017-0547.R1
None

4
Disease Models & Mechanisms
Role of insulin signaling impairment, adiponectin and dyslipidemia in peripheral and central neuropathy in mice
<p>One of the tissues or organs affected by diabetes is the nervous system, predominantly the peripheral system (peripheral polyneuropathy and/or painful peripheral neuropathy) but also the central system with impaired learning, memory and mental flexibility. The aim of this study was to test the hypothesis that the pre-diabetic or diabetic condition caused by a high-fat diet (HFD) can damage both the peripheral and central nervous systems. Groups of C57BL6 and Swiss Webster mice were fed a diet containing 60% fat for 8 <strong><span style="color:yellowgreen">month</span></strong>s and compared to control and streptozotocin (STZ)-induced diabetic groups that were fed a standard diet containing 10% fat. Aspects of peripheral nerve function (conduction velocity, thermal sensitivity) and central nervous system function (learning ability, memory) were measured at assorted <strong><span style="color:yellowgreen">time</span></strong>s during the study. Both strains of mice on HFD developed impaired glucose tolerance, indicative of insulin resistance, but only the C57BL6 mice showed statistically significant hyperglycemia. STZ-diabetic C57BL6 mice developed learning deficits in the Barnes maze after 8 weeks of diabetes, whereas neither C57BL6 nor Swiss Webster mice fed a HFD showed signs of defects at that <strong><span style="color:yellowgreen">time</span></strong> point. By 6 <strong><span style="color:yellowgreen">month</span></strong>s on HFD, Swiss Webster mice developed learning and memory deficits in the Barnes maze test, whereas their peripheral nervous system remained normal. In contrast, C57BL6 mice fed the HFD developed peripheral nerve dysfunction, as indicated by nerve conduction slowing and thermal hyperalgesia, but showed normal learning and memory functions. Our data indicate that STZ-induced diabetes or a HFD can damage both peripheral and central nervous systems, but learning deficits develop more rapidly in insulin-deficient than in insulin-resistant conditions and only in Swiss Webster mice. In addition to insulin impairment, dyslipidemia or adiponectinemia might determine the neuropathy phenotype.</p>
http://dmm.biologists.org/cgi/content/abstract/7/6/625
10.1242/dmm.015750
None

4
Circulation
Availability and Use of Shared Data From Cardiometabolic Clinical Trials
<sec><title>Background:</title><p>Sharing of patient-level clinical trial data has been widely endorsed. Little is known about how extensively these data have been used for cardiometabolic diseases. We sought to evaluate the availability and use of shared data from cardiometabolic clinical trials.</p></sec><sec><title>Methods:</title><p>We extracted data from ClinicalStudyDataRequest.com, a large, multisponsor data-sharing platform hosting individual patient–level data from completed studies sponsored by 13 pharmaceutical companies.</p></sec><sec><title>Results:</title><p>From January 2013 to May 2017, the platform had data from 3374 clinical trials, of which 537 (16%) evaluated cardiometabolic therapeutics (phase 1, 36%; phase 2, 17%; phase 2/3, 1%; phase 3, 42%; phase 4, 4%). They covered 74 therapies and 398 925 patients. Diabetes mellitus (60%) and hypertension (15%) were the most common study topics. Median <strong><span style="color:yellowgreen">time</span></strong> from study completion to data availability was 79 <strong><span style="color:yellowgreen">month</span></strong>s. As of May 2017, ClinicalStudyDataRequest.com had received 318 submitted proposals, of which 163 had signed data-sharing agreements. Thirty of these proposals were related to cardiometabolic therapies and requested data from 79 unique studies (15% of all trials, 29% of phase 3/4 trials). Most (96%) data requesters of cardiometabolic clinical trial data were from academic centers in North America and Western Europe, and half the proposals were unfunded. Most proposals were for secondary hypothesis-generating questions, with only 1 proposed reanalysis of the original study primary hypothesis. To date, 3 peer-reviewed articles have been published after a median of 19 <strong><span style="color:yellowgreen">month</span></strong>s (9–32 <strong><span style="color:yellowgreen">month</span></strong>s) from the data-sharing agreement.</p></sec><sec><title>Conclusions:</title><p>Despite availability of data from >500 cardiometabolic trials in a multisponsor data-sharing platform, only 15% of these trials and 29% of phase 3/4 trials have been accessed by investigators thus far, and a negligible minority of analyses have reached publication.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/9/938
10.1161/CIRCULATIONAHA.117.031883
None

4
Circulation
Prognostic Value of Follow-Up Hemodynamic Variables After Initial Management in Pulmonary Arterial Hypertension
<sec><title>Background:</title><p>Hemodynamic variables such as cardiac index and right atrial pressure have consistently been associated with survival in pulmonary arterial hypertension (PAH) at the <strong><span style="color:yellowgreen">time</span></strong> of diagnosis. Recent studies have suggested that pulmonary arterial compliance may also predict prognosis in PAH. The prognostic importance of hemodynamic values achieved after treatment initiation is less well established.</p></sec><sec><title>Methods:</title><p>Our objective was to evaluate the prognostic importance of clinical and hemodynamic variables during follow-up, including pulmonary arterial compliance, after initial management in PAH. We evaluated incident patients with idiopathic, drug- and toxin-induced, or heritable PAH enrolled in the French pulmonary hypertension registry between 2006 and 2016 who had a follow-up right-sided heart catheterization (RHC). The primary outcome was death or lung transplantation. We used stepwise Cox regression and the Kaplan-Meier method to assess variables obtained at baseline and at first follow-up RHC.</p></sec><sec><title>Results:</title><p>Of 981 patients, a primary outcome occurred in 331 patients (33.7%) over a median follow-up duration of 2.8 years (interquartile range, 1.1–4.6 years). In a multivariable model considering only baseline variables, no hemodynamic variables independently predicted prognosis. Median <strong><span style="color:yellowgreen">time</span></strong> to first follow-up RHC was 4.6 <strong><span style="color:yellowgreen">month</span></strong>s (interquartile range, 3.7–7.8 <strong><span style="color:yellowgreen">month</span></strong>s). At first follow-up RHC (n=763), New York Heart Association functional class, 6-minute walk distance, stroke volume index (SVI), and right atrial pressure were independently associated with death or lung transplantation, adjusted for age, sex, and type of PAH. Pulmonary arterial compliance did not independently predict outcomes at baseline or during follow-up. The adjusted hazard ratio for SVI was 1.28 (95% confidence interval, 1.11–1.49; <i>P</i><0.01) per 10-mL/m<sup>2</sup> decrease and for right atrial pressure was 1.05 (95% confidence interval, 1.02–1.09; <i>P</i><0.01) per 1–mm Hg increase. Among patients who had 2 (n=355) or 3 (n=193) low-risk prognostic features at follow-up, including a cardiac index ≥2.5 L·min<sup>−1</sup>·m<sup>−2</sup>, 6-minute walk distance >440 m, and New York Heart Association class I or II functional class, lower SVI was still associated with higher rates of death or lung transplantation (<i>P</i><0.01).</p></sec><sec><title>Conclusions:</title><p>SVI and right atrial pressure were the hemodynamic variables that were independently associated with death or lung transplantation at first follow-up RHC after initial PAH treatment. These findings suggest that the SVI could be a more appropriate treatment target than cardiac index in PAH.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/7/693
10.1161/CIRCULATIONAHA.117.029254
None

4
Circulation
Transcatheter Interatrial Shunt Device for the Treatment of Heart Failure With Preserved Ejection Fraction (REDUCE LAP-HF I [Reduce Elevated Left Atrial Pressure in Patients With Heart Failure])
<sec><title>Background:</title><p>In nonrandomized, open-label studies, a transcatheter interatrial shunt device (IASD, Corvia Medical) was associated with lower pulmonary capillary wedge pressure (PCWP), fewer symptoms, and greater quality of life and exercise capacity in patients with heart failure (HF) and midrange or preserved ejection fraction (EF ≥40%). We conducted the first randomized sham-controlled trial to evaluate the IASD in HF with EF ≥40%.</p></sec><sec><title>Methods:</title><p>REDUCE LAP-HF I (Reduce Elevated Left Atrial Pressure in Patients With Heart Failure) was a phase 2, randomized, parallel-group, blinded multicenter trial in patients with New York Heart Association class III or ambulatory class IV HF, EF ≥40%, exercise PCWP ≥25 mm Hg, and PCWP-right atrial pressure gradient ≥5 mm Hg. Participants were randomized (1:1) to the IASD versus a sham procedure (femoral venous access with intracardiac echocardiography but no IASD placement). The participants and investigators assessing the participants during follow-up were blinded to treatment assignment. The primary effectiveness end point was exercise PCWP at 1 <strong><span style="color:yellowgreen">month</span></strong>. The primary safety end point was major adverse cardiac, cerebrovascular, and renal events at 1 <strong><span style="color:yellowgreen">month</span></strong>. PCWP during exercise was compared between treatment groups using a mixed-effects repeated measures model analysis of covariance that included data from all available stages of exercise.</p></sec><sec><title>Results:</title><p>A total of 94 patients were enrolled, of whom 44 met inclusion/exclusion criteria and were randomized to the IASD (n=22) and control (n=22) groups. Mean age was 70±9 years, and 50% were female. At 1 <strong><span style="color:yellowgreen">month</span></strong>, the IASD resulted in a greater reduction in PCWP compared with sham control (<i>P</i>=0.028 accounting for all stages of exercise). Peak PCWP decreased by 3.5±6.4 mm Hg in the treatment group versus 0.5±5.0 mm Hg in the control group (<i>P</i>=0.14). There were no peri-procedural or 1-<strong><span style="color:yellowgreen">month</span></strong> major adverse cardiac, cerebrovascular, and renal events in the IASD group and 1 event (worsening renal function) in the control group (<i>P</i>=1.0).</p></sec><sec><title>Conclusions:</title><p>In patients with HF and EF ≥40%, IASD treatment reduces PCWP during exercise. Whether this mechanistic effect will translate into sustained improvements in symptoms and outcomes requires further evaluation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://clinicaltrials.gov</ext-link>. Unique identifier: NCT02600234.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/4/364
10.1161/CIRCULATIONAHA.117.032094
None

4
Circulation
Cardiac Implantable Electronic Device Interrogation at Forensic Autopsy
<sec><title>Background:</title><p>Postmortem interrogations of cardiac implantable electronic devices (CIEDs), recommended at autopsy in suspected cases of sudden cardiac death, are rarely performed, and data on systematic postmortem CIED analysis in the forensic pathology are missing. The aim of the study was to determine whether nonselective postmortem CIED interrogations and data analysis are useful to the forensic pathologist to determine the cause, mechanism, and <strong><span style="color:yellowgreen">time</span></strong> of death and to detect potential CIED-related safety issues.</p></sec><sec><title>Methods:</title><p>From February 2012 to April 2017, all autopsy subjects in the department of forensic medicine at the University Hospital Charité who had a CIED underwent device removal and interrogation. Over the study period, 5368 autopsies were performed. One hundred fifty subjects had in total 151 CIEDs, including 109 pacemakers, 35 defibrillators, and 7 implantable loop recorders.</p></sec><sec><title>Results:</title><p>In 40 cases (26.7%) <strong><span style="color:yellowgreen">time</span></strong> of death and in 51 cases (34.0%) cause of death could not be determined by forensic autopsy. Of these, CIED interrogation facilitated the determination of <strong><span style="color:yellowgreen">time</span></strong> of death in 70.0% of the cases and clarified the cause of death in 60.8%. Device concerns were identified in 9 cases (6.0%), including 3 hardware, 4 programming, and 2 algorithm issues. One CIED was submitted to the manufacturer for a detailed technical analysis.</p></sec><sec><title>Conclusions:</title><p>Our data demonstrate the necessity of systematic postmortem CIED interrogation in forensic medicine to determine the cause and timing of death more accurately. In addition, CIED analysis is an important tool to detect potential CIED-related safety issues.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/25/2730
10.1161/CIRCULATIONAHA.117.032367
None

4
Circulation
Pharmacodynamic Effects of Switching From Ticagrelor to Clopidogrel in Patients With Coronary Artery Disease
<sec><title>Background:</title><p>Switching between different classes of P2Y<sub>12</sub> inhibitors, including de-escalation from ticagrelor to clopidogrel, commonly occurs in clinical practice. However, the pharmacodynamic profiles of this strategy have been poorly explored.</p></sec><sec><title>Methods:</title><p>This was a prospective, randomized, open-label study conducted in patients on maintenance dosing (MD) of aspirin (81 mg/d) and clopidogrel (75 mg/d). After a 7-day run-in with ticagrelor (180 mg loading dose [LD] followed by 90 mg twice daily MD), patients (n=80) were randomized into 1 of 4 groups: group A, clopidogrel 600 mg LD 24 hours after the last MD of ticagrelor (C-600 mg-24h); group B, clopidogrel 600 mg LD 12 hours after the last MD of ticagrelor (C-600 mg-12h); group C, clopidogrel 75 mg/d MD 24 hours after the last MD of ticagrelor (C-75 mg-24h); and group D, ticagrelor 90 mg twice daily MD (T-90 mg twice daily). MD of the randomized treatment was maintained for 10±3 days. Pharmacodynamic assessments were performed at baseline, after run-in, and at 2, 24, 48, and 72 hours and 10 days with P2Y<sub>12</sub> reaction units by VerifyNow; platelet reactivity index was assessed by vasodilator-stimulated phosphoprotein; and maximal platelet aggregation was determined by light transmittance aggregometry.</p></sec><sec><title>Results:</title><p>T-90 mg twice daily led to lower platelet reactivity than any clopidogrel regimen using all assays at all <strong><span style="color:yellowgreen">time</span></strong> points. P2Y<sub>12</sub> reaction unit levels were similar between the C-600 mg-24h (group A) and the C-75 mg-24h (group C) (<i>P</i>=0.29), including at 48 hours (primary end point; least mean difference, −6.9; 95% confidence interval, −38.1 to 24.3; <i>P</i>=0.66). P2Y<sub>12</sub> reaction unit levels were lower with C-600 mg-12h (group B) than with C-75 mg-24h (group C; <i>P</i>=0.024). Maximal platelet aggregation over <strong><span style="color:yellowgreen">time</span></strong> was lower with both C-600 mg-24h (group A; <i>P</i>=0.041) and C-600 mg-12h (group B; <i>P</i>=0.028) compared with C-75 mg-24h (group C). Platelet reactivity index profiles paralleled those observed with P2Y<sub>12</sub> reaction units. There were no pharmacodynamic differences for all tests between C-600 mg-24h (group A) and C-600 mg-12h (group B). In group C (C-75 mg-24h), platelet reactivity increased compared with baseline as early as 24 hours, reaching statistical significance at 48 and 72 hours and up to 10 days. These pharmacodynamic findings were delayed and blunted in magnitude with the administration of an LD, regardless of the timing of administration.</p></sec><sec><title>Conclusions:</title><p>De-escalation from ticagrelor to clopidogrel therapy is associated with an increase in platelet reactivity. The use of an LD before the initiation of an MD regimen of clopidogrel mitigates these observations, although this is not affected by the timing of its administration after ticagrelor discontinuation.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.clinicaltrials.gov</ext-link>. Unique identifier: NCT02287909.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/23/2450
10.1161/CIRCULATIONAHA.118.033983
None

4
Circulation
Association Between Hospital Volume, Processes of Care, and Outcomes in Patients Admitted With Heart Failure
<sec><title>Background:</title><p>Hospital volume is frequently used as a structural metric for assessing quality of care, but its utility in patients admitted with acute heart failure (HF) is not well characterized. Accordingly, we sought to determine the relationship between admission volume, process-of-care metrics, and short- and long-term outcomes in patients admitted with acute HF.</p></sec><sec><title>Methods:</title><p>Patients enrolled in the Get With The Guidelines-HF registry with linked Medicare inpatient data at 342 hospitals were assessed. Volume was assessed both as a continuous variable, and quartiles based on the admitting hospital annual HF case volume, as well: 5 to 38 (quartile 1), 39 to 77 (quartile 2), 78 to 122 (quartile 3), 123 to 457 (quartile 4). The main outcome measures were (1) process measures at discharge (achievement of HF achievement, quality, reporting, and composite metrics); (2) 30-day mortality and hospital readmission; and (3) 6-<strong><span style="color:yellowgreen">month</span></strong> mortality and hospital readmission. Adjusted logistic and Cox proportional hazards models were used to study these associations with hospital volume.</p></sec><sec><title>Results:</title><p>A total of 125 595 patients with HF were included. Patients admitted to high-volume hospitals had a higher burden of comorbidities. On multivariable modeling, lower-volume hospitals were significantly less likely to be adherent to HF process measures than higher-volume hospitals. Higher hospital volume was not associated with a difference in in-hospital (odds ratio, 0.99; 95% confidence interval [CI], 0.94–1.05; <i>P</i>=0.78) or 30-day mortality (hazard ratio, 0.99; 95% CI, 0.97–1.01; <i>P</i>=0.26), or 30-day readmissions (hazard ratio, 0.99; 95% CI, 0.97–1.00; <i>P</i>=0.10). There was a weak association of higher volumes with lower 6-<strong><span style="color:yellowgreen">month</span></strong> mortality (hazard ratio, 0.98; 95% CI, 0.97–0.99; <i>P</i>=0.001) and lower 6-<strong><span style="color:yellowgreen">month</span></strong> all-cause readmissions (hazard ratio, 0.98; 95%, CI 0.97–1.00; <i>P</i>=0.025).</p></sec><sec><title>Conclusions:</title><p>Our analysis of a large contemporary prospective national quality improvement registry of older patients with HF indicates that hospital volume as a structural metric correlates with process measures, but not with 30-day outcomes, and only marginally with outcomes up to 6 <strong><span style="color:yellowgreen">month</span></strong>s of follow-up. Hospital profiling should focus on participation in systems of care, adherence to process metrics, and risk-standardized outcomes rather than on hospital volume itself.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/137/16/1661
10.1161/CIRCULATIONAHA.117.028077
None

4
Circulation
Assessment of Remote Heart Rhythm Sampling Using the AliveCor Heart Monitor to Screen for Atrial Fibrillation
<sec><title>Background:</title><p>Asymptomatic atrial fibrillation (AF) is increasingly common in the aging population and implicated in many ischemic strokes. Earlier identification of AF with appropriate anticoagulation may decrease stroke morbidity and mortality.</p></sec><sec><title>Methods:</title><p>We conducted a randomized controlled trial of AF screening using an AliveCor Kardia monitor attached to a WiFi-enabled iPod to obtain ECGs (iECGs) in ambulatory patients. Patients ≥65 years of age with a CHADS-VASc score ≥2 free from AF were randomized to the iECG arm or routine care (RC). iECG participants acquired iECGs twice weekly over 12 <strong><span style="color:yellowgreen">month</span></strong>s (plus additional iECGs if symptomatic) onto a secure study server with overread by an automated AF detection algorithm and by a cardiac physiologist and/or consultant cardiologist. Time to diagnosis of AF was the primary outcome measure. The overall cost of the devices, ECG interpretation, and patient management were captured and used to generate the cost per AF diagnosis in iECG patients. Clinical events and patient attitudes/experience were also evaluated.</p></sec><sec><title>Results:</title><p>We studied 1001 patients (500 iECG, 501 RC) who were 72.6±5.4 years of age; 534 were female. Mean CHADS-VASc score was 3.0 (heart failure, 1.4%; hypertension, 54%; diabetes mellitus, 30%; prior stroke/transient ischemic attack, 6.5%; arterial disease, 15.9%; all CHADS-VASc risk factors were evenly distributed between groups). Nineteen patients in the iECG group were diagnosed with AF over the 12-<strong><span style="color:yellowgreen">month</span></strong> study period versus 5 in the RC arm (hazard ratio, 3.9; 95% confidence interval=1.4–10.4; <i>P</i>=0.007) at a cost per AF diagnosis of $10 780 (£8255). There was a similar number of stroke/transient ischemic attack/systemic embolic events (6 versus 10, iECG versus RC; hazard ratio=0.61; 95% confidence interval=0.22–1.69; <i>P</i>=0.34). The majority of iECG patients were satisfied with the device, finding it easy to use without restricting activities or causing anxiety.</p></sec><sec><title>Conclusions:</title><p>Screening with twice-weekly single-lead iECG with remote interpretation in ambulatory patients ≥65 years of age at increased risk of stroke is significantly more likely to identify incident AF than RC over a 12-<strong><span style="color:yellowgreen">month</span></strong> period. This approach is also highly acceptable to this group of patients, supporting further evaluation in an appropriately powered, event-driven clinical trial.</p></sec><sec><title>Clinical Trial Registration:</title><p>URL: <ext-link>https://www.isrctn.com</ext-link>. Unique identifier: ISRCTN10709813.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/136/19/1784
10.1161/CIRCULATIONAHA.117.030583
None

4
Circulation
Three Arterial Grafts Improve Late Survival
<sec><title>Background:</title><p>Little evidence shows whether a third arterial graft provides superior outcomes compared with the use of 2 arterial grafts in patients undergoing coronary artery bypass grafting. A meta-analysis of all the propensity score-matched observational studies comparing the long-term outcomes of coronary artery bypass grafting with the use of 2-arterial versus 3-arterial grafts was performed.</p></sec><sec><title>Methods:</title><p>A literature search was conducted using MEDLINE, EMBASE, and Web of Science to identify relevant articles. Long-term mortality in the propensity score-matched populations was the primary end point. Secondary end points were in-hospital/30-day mortality for the propensity score-matched populations and long-term mortality for the unmatched populations. In the matched population, <strong><span style="color:yellowgreen">time</span></strong>-to-event outcome for long-term mortality was extracted as hazard ratios, along with their variance. Statistical pooling of survival (<strong><span style="color:yellowgreen">time</span></strong>-to-event) was performed according to a random effect model, computing risk estimates with 95% confidence intervals.</p></sec><sec><title>Results:</title><p>Eight propensity score-matched studies reporting on 10 287 matched patients (2-arterial graft: 5346; 3-arterial graft: 4941) were selected for final comparison. The mean follow-up <strong><span style="color:yellowgreen">time</span></strong> ranged from 37.2 to 196.8 <strong><span style="color:yellowgreen">month</span></strong>s. The use of 3 arterial grafts was not statistically associated with early mortality (hazard ratio, 0.93; 95% confidence interval, 0.71–1.22; <i>P</i>=0.62). The use of 3 arterial grafts was associated with statistically significantly lower hazard for late death (hazard ratio, 0.8; 95% confidence interval, 0.75–0.87; <i>P</i><0.001), irrespective of sex and diabetic mellitus status. This result was qualitatively similar in the unmatched population (hazard ratio, 0.57; 95% confidence interval, 0.33–0.98; <i>P</i>=0.04).</p></sec><sec><title>Conclusions:</title><p>The use of a third arterial conduit in patients with coronary artery bypass grafting is not associated with higher operative risk and is associated with superior long-term survival, irrespective of sex and diabetic mellitus status.</p></sec>
http://circ.ahajournals.org/cgi/content/abstract/135/11/1036
10.1161/CIRCULATIONAHA.116.025453
None

