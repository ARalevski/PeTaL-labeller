{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto-labeler-prototype.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d63456f0c5c1446ebde4cf20f783ae3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97aefea2f8ba49e08537b264d09743e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bca63259d95f41e2ba450de5b6525e1d",
              "IPY_MODEL_4eb87dfd518141979dba05cbd52b0312"
            ]
          }
        },
        "97aefea2f8ba49e08537b264d09743e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bca63259d95f41e2ba450de5b6525e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c16955666804683bba086db2bd51e9f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56220ee8bd6946c3960422f4941b7ee8"
          }
        },
        "4eb87dfd518141979dba05cbd52b0312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6320ba0468ee4fcf994436d2d5c248cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 727kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ff28789e0b14dfa9f81570f70307acd"
          }
        },
        "8c16955666804683bba086db2bd51e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56220ee8bd6946c3960422f4941b7ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6320ba0468ee4fcf994436d2d5c248cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ff28789e0b14dfa9f81570f70307acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasa/PeTaL-labeller/blob/JQ/auto-labeler/auto_labeler_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft-7aQbboP7f",
        "outputId": "20260bc9-e821-4a5d-e341-529b10d9cb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorboardX\n",
        "!pip install wikipedia\n",
        "!pip install swifter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 15.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=31f5c58254269c872a38fd4b52d5d0e417e6a7f2b692330b891200c928f11051\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 317kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n",
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=182d483436bca8c3dd1cbf82430511dab5da3270b44316eccf4173690f7a7c4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Collecting swifter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/15/8a38d51ad3ce448956aad35f288da43a5e7aa174d6bfc3f809810d821fd8/swifter-1.0.6.tar.gz (632kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 634kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (1.1.2)\n",
            "Collecting psutil>=5.6.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/3e/d18f2c04cf2b528e18515999b0c8e698c136db78f62df34eee89cee205f1/psutil-5.7.2.tar.gz (460kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460kB 24.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask[dataframe]>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (2.12.0)\n",
            "Requirement already satisfied: tqdm>=4.33.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (4.41.1)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0cloudpickle>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from swifter) (7.5.1)\n",
            "Requirement already satisfied: parso>0.4.0 in /usr/local/lib/python3.6/dist-packages (from swifter) (0.7.1)\n",
            "Requirement already satisfied: bleach>=3.1.1 in /usr/local/lib/python3.6/dist-packages (from swifter) (3.2.1)\n",
            "Collecting modin[ray]>=0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/5e/658f152a38a1286f89b5eefef44f5ea7c3ef75d89ff9e7436587c9c852e1/modin-0.8.1.1-py3-none-manylinux1_x86_64.whl (538kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 542kB 16.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->swifter) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->swifter) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.0->swifter) (2018.9)\n",
            "Collecting partd>=0.3.10; extra == \"dataframe\"\n",
            "  Downloading https://files.pythonhosted.org/packages/44/e1/68dbe731c9c067655bff1eca5b7d40c20ca4b23fd5ec9f3d17e201a6f36b/partd-1.1.0-py3-none-any.whl\n",
            "Collecting fsspec>=0.6.0; extra == \"dataframe\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/38/39b83c70ff47192255c15da1b602322cb9918682199d5c1d9cf128bdd531/fsspec-0.8.3-py3-none-any.whl (88kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in /usr/local/lib/python3.6/dist-packages (from dask[dataframe]>=2.10.0->swifter) (0.11.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.0.7)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.5.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach>=3.1.1->swifter) (0.5.1)\n",
            "Requirement already satisfied: pyarrow<0.17; extra == \"ray\" in /usr/local/lib/python3.6/dist-packages (from modin[ray]>=0.7.4->swifter) (0.14.1)\n",
            "Collecting ray>=1.0.0; extra == \"ray\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/ed/ff896981d4ac684614236f73c1a20cde5f6cb0e2a590c182f62b22706ab4/ray-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (22.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.9MB 1.8MB/s \n",
            "\u001b[?25hCollecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/22/3c0f97614e0be8386542facb3a7dcfc2584f7b83608c02333bced641281c/locket-0.2.0.tar.gz\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.4.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.1.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.6.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.6.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (50.3.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach>=3.1.1->swifter) (2.4.7)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (2.23.0)\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.0.0)\n",
            "Collecting redis<3.5.0,>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.4MB/s \n",
            "\u001b[?25hCollecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/9c/d40e3408e72d02612acf247d829e3fa9ff15c59f7ad81418ed79962f8681/opencensus-0.7.10-py2.py3-none-any.whl (126kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 58.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (3.0.12)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (2.0.3)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (0.8.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (3.13)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.32.0)\n",
            "Collecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 11.2MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2MB 49.9MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.9.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (2.11.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (19.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.24.3)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (7.352.0)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Collecting opencensus-context==0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/2b/b7/720d4507e97aa3916ac47054cd75490de6b6148c46d8c2c487638f16ad95/opencensus_context-0.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (4.6.3)\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/7d/6acf1c8d4f2fb327ff6feec000b4c56a20628fbe966a4c7cd16c0b80343c/hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting async-timeout\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c9/379b807a9c298b9694d0af8ee4260be7d40ab1a11fb9d4ae9e70b1e69d96/yarl-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 266kB 54.1MB/s \n",
            "\u001b[?25hCollecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 56.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (20.2.0)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (3.7.4.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter) (1.1.1)\n",
            "Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.52.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (1.17.2)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (4.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.7.4->swifter) (0.4.8)\n",
            "Building wheels for collected packages: swifter, psutil, locket, gpustat, idna-ssl, contextvars\n",
            "  Building wheel for swifter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swifter: filename=swifter-1.0.6-cp36-none-any.whl size=13728 sha256=eb475605ab5d20d9ccac890ba183ebf88337d4b971cf9eaa59ce8965865458c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/50/86/a1a417f8f2e24d0e7e958341d24405c596fb3af00a40d9408b\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.7.2-cp36-cp36m-linux_x86_64.whl size=279881 sha256=26e5ebf16581ccd631f5bc0ed0b1af53458bb572405884ac64977799543d87ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/a0/f5/c4fa280463e29aea07797acb5312358fefb067c1f4f98e11b1\n",
            "  Building wheel for locket (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for locket: filename=locket-0.2.0-cp36-none-any.whl size=4040 sha256=e884fc0f7d4f16f27a6960e6862ea83cb25c5216b28c4d7d9e1e9f5fdd5534b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/1e/e8/4fa236ec931b1a0cdd61578e20d4934d7bf188858723b84698\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=323ef0228823dd1f152627353529511e34d02254471fc381344a892355531c4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3161 sha256=0ea3ed7d78dafbacd59cb67a0cc21df8c1cd7639338434c424a944033fbad8e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=3776774b594e40f660fc1a8af99ee830186cb29d6d5e14b68b13f071794f3e02\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built swifter psutil locket gpustat idna-ssl contextvars\n",
            "Installing collected packages: psutil, blessings, gpustat, redis, immutables, contextvars, opencensus-context, opencensus, colorama, async-timeout, multidict, yarl, idna-ssl, aiohttp, aiohttp-cors, colorful, hiredis, aioredis, py-spy, ray, modin, swifter, locket, partd, fsspec\n",
            "  Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-3.6.2 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.3 colorful-0.5.4 contextvars-2.4 fsspec-0.8.3 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 locket-0.2.0 modin-0.8.1.1 multidict-4.7.6 opencensus-0.7.10 opencensus-context-0.1.1 partd-1.1.0 psutil-5.7.2 py-spy-0.3.3 ray-1.0.0 redis-3.4.1 swifter-1.0.6 yarl-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpdAH3eLn9KA"
      },
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import wikipedia \n",
        "import swifter\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe0Z6A0rNUgf"
      },
      "source": [
        "## GPU Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9vxghfPocM5",
        "outputId": "35cb1c3e-3d9c-45a0-fc64-0cd646c8abe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# GPU detection \n",
        "\n",
        "# Get GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGAOqbInomgX",
        "outputId": "e05113be-d6e1-4c6c-d54d-10c725925c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# If there is a GPU available\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-btVsbT0WETf"
      },
      "source": [
        "## Import, Parse, and Store Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz8CT3qvovyy"
      },
      "source": [
        "#Creating PyDrive instance to load in data from PeTaL shared drive, follow the steps to authenticate\n",
        "!pip install -U -q PyDrive \n",
        "  \n",
        "from pydrive.auth import GoogleAuth \n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials \n",
        "  \n",
        "  \n",
        "# Authenticate and create the PyDrive client. \n",
        "auth.authenticate_user() \n",
        "gauth = GoogleAuth() \n",
        "gauth.credentials = GoogleCredentials.get_application_default() \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5MO_gJnov1A"
      },
      "source": [
        "\n",
        "\n",
        "#this is the un-parsed articles\n",
        "# link = 'https://drive.google.com/file/d/1iIZgKs1swHHJuumCU5xyW8tXSAnKAg18/view?usp=sharing'\n",
        "# id = link.split(\"/\")[-2] \n",
        "  \n",
        "# downloaded = drive.CreateFile({'id':id})  \n",
        "# downloaded.GetContentFile('articles.csv')   \n",
        "#df = pd.read_csv('articles.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yveU_TvB7ZkD"
      },
      "source": [
        "#'https://petscan.wmflabs.org/' link to pull wikipedia articles and their page ID's"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCTYZEDsov41"
      },
      "source": [
        "#Scraping article content by ID\n",
        "def wiki_content(row):\n",
        "  id = row['pageid']\n",
        "  try:\n",
        "    content = wikipedia.page(pageid=id).content\n",
        "  except:\n",
        "    content = 'error'\n",
        "  return content\n",
        "\n",
        "df['Content'] = df.swifter.apply(wiki_content, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryadSHM_GdAO"
      },
      "source": [
        "#Scraping article summary by ID\n",
        "\n",
        "def wiki_summary(row):\n",
        "  id = row['pageid']\n",
        "  try:\n",
        "    summary = wikipedia.page(pageid=id).summary\n",
        "  except:\n",
        "    summary = 'error'\n",
        "  return summary\n",
        "\n",
        "df['Summary'] = df.swifter.apply(wiki_summary, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSf2JM6Ub7lI"
      },
      "source": [
        "#Saving parsed articles as csv, can be accessed in the \"Files\" folder on the left, then download if you want\n",
        "df.to_csv('parsed_articles.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-mVCjGb-nsw"
      },
      "source": [
        "#Google drive link to the parsed articles\n",
        "link = 'https://drive.google.com/file/d/1XRWsEsNUHjWOjPavwrfuUpaq3DwGGE4D/view?usp=sharing'\n",
        "id = link.split(\"/\")[-2] \n",
        " \n",
        "downloaded = drive.CreateFile({'id':id})  \n",
        "downloaded.GetContentFile('parsed_articles.csv') \n",
        "df = pd.read_csv('parsed_articles.csv')\n",
        "\n",
        "df = df[(df['Content'] != 'error') & df['Content'].notnull()]\n",
        "\n",
        "#Df 'Content' column into list\n",
        "docs = list(df['Content'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXiUqqPwBZfB"
      },
      "source": [
        "#Labels\n",
        "\n",
        "labels = ['Maintain homeostasis', 'Protect from temperature']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnZWpxgW07DY"
      },
      "source": [
        "df['Content'].value_counts().to_frame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATWOcwK7QFpx"
      },
      "source": [
        "labeled_df_link = 'https://drive.google.com/file/d/1OZnAk64SPXfnaEzQFfhDJd6AX3dntIy9/view?usp=sharing'\n",
        "labeled_id = labeled_df_link.split(\"/\")[-2]\n",
        "labeled_downloaded = drive.CreateFile({'id':labeled_id})  \n",
        "labeled_downloaded.GetContentFile('Biological-Strategies-Export-2020-October-01-1849 (1).csv') \n",
        "labeled_df = pd.read_csv('Biological-Strategies-Export-2020-October-01-1849 (1).csv')\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJhIOLN_bd0S",
        "outputId": "71101833-c27b-4989-fbe3-7ccf41ff512b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "labeled_df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Hook</th>\n",
              "      <th>Living Systems</th>\n",
              "      <th>Sources_required_info</th>\n",
              "      <th>Sources_source_type</th>\n",
              "      <th>Sources_source_title</th>\n",
              "      <th>Sources_source_link</th>\n",
              "      <th>Sources_source_authors</th>\n",
              "      <th>Sources_source_publication</th>\n",
              "      <th>Sources_source_publish_date</th>\n",
              "      <th>Sources_excerpt</th>\n",
              "      <th>Sources_optional_info</th>\n",
              "      <th>Sources_source_editors</th>\n",
              "      <th>Sources_doi</th>\n",
              "      <th>Sources_source_amazon_asin</th>\n",
              "      <th>Sources_legacy_ref_type_of_work</th>\n",
              "      <th>Sources_legacy_ref_type</th>\n",
              "      <th>Sources_legacy_ref_masterid</th>\n",
              "      <th>Sources_legacy_ref_timestamp</th>\n",
              "      <th>Sources_legacy_ref_secondary_title</th>\n",
              "      <th>Sources_legacy_ref_authors</th>\n",
              "      <th>Sources_legacy_ref_secondary_authors</th>\n",
              "      <th>Sources_legacy_ref_pages</th>\n",
              "      <th>Sources_legacy_ref_volume</th>\n",
              "      <th>Sources_legacy_ref_number</th>\n",
              "      <th>Sources_legacy_ref_section</th>\n",
              "      <th>Sources_legacy_ref_publication_year</th>\n",
              "      <th>Sources_legacy_ref_publisher</th>\n",
              "      <th>Sources_legacy_ref_isbn</th>\n",
              "      <th>Sources_legacy_ref_accession_number</th>\n",
              "      <th>Sources_legacy_ref_access_date</th>\n",
              "      <th>Sources_legacy_ref_keywords</th>\n",
              "      <th>Sources_legacy_ref_abstract_excerpt</th>\n",
              "      <th>Functions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>542</td>\n",
              "      <td>Plumage releases air to propel body out of water</td>\n",
              "      <td>Micro-bubbles released underwater from the plu...</td>\n",
              "      <td>Aptenodytes forsteri</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>Drag reduction by air release promotes fast as...</td>\n",
              "      <td>http://www.int-res.com/articles/theme/m430p171...</td>\n",
              "      <td>Davenport J; Hughes RN; Shorten M; Larsen PS</td>\n",
              "      <td>Inter-Research</td>\n",
              "      <td>NaN</td>\n",
              "      <td>â€œTo jump out of water onto sea ice, emperor pe...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>doi: 10.3354/meps08868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Journal Article</td>\n",
              "      <td>7</td>\n",
              "      <td>36c0771e8d2b92ad1e7c0e231afbd233</td>\n",
              "      <td>2013-09-30 14:54:14</td>\n",
              "      <td>Marine Ecology Progress Series</td>\n",
              "      <td>Davenport J; Hughes RN; Shorten M; Larsen PS</td>\n",
              "      <td>NaN</td>\n",
              "      <td>171-182</td>\n",
              "      <td>430</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2011</td>\n",
              "      <td>Inter-Research</td>\n",
              "      <td>1616-1599</td>\n",
              "      <td>doi: 10.3354/meps08868</td>\n",
              "      <td>29 Sept 2011</td>\n",
              "      <td>Emperor penguin, Aptenodytes forsteri, torpedo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Modify speed|Move in/on liquids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1286</td>\n",
              "      <td>Swim bladder helps maintain buoyancy</td>\n",
              "      <td>Swim bladders of fish at depth help maintain b...</td>\n",
              "      <td>Actinopterygii</td>\n",
              "      <td>,,</td>\n",
              "      <td>1,2,1</td>\n",
              "      <td>Comparative Biomechanics: Life's Physical Worl...</td>\n",
              "      <td>http://www.amazon.com/Comparative-Biomechanics...</td>\n",
              "      <td>Vogel S,Liem KF,Bone Q; Marshall NB; Blaxter JHS</td>\n",
              "      <td>,Encyclopedia of Fishes. eds. Paxton J. R., Es...</td>\n",
              "      <td>17/06/2013,01/01/1998,30/06/1995</td>\n",
              "      <td>\"But the swimbladder must be filled from disso...</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>0691155666,,0415375622</td>\n",
              "      <td>,,</td>\n",
              "      <td>1,2,1</td>\n",
              "      <td>,552c5c9ed4739fb10ea4cc8350958bf4,2dbd93d28247...</td>\n",
              "      <td>2015-08-03 17:24:37,2015-08-03 17:23:21,2015-0...</td>\n",
              "      <td>,Encyclopedia of Fishes,</td>\n",
              "      <td>Vogel S,Liem KF,Bone Q, Marshall NB, Blaxter JHS</td>\n",
              "      <td>,Paxton JR, Eschmeyer WN,</td>\n",
              "      <td>580,14-19.,332</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>2003,1998,1995</td>\n",
              "      <td>Princeton University Press,Academic Press,Chap...</td>\n",
              "      <td>0-691-11297-5,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>,,</td>\n",
              "      <td>Modify buoyancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1289</td>\n",
              "      <td>Leaves resist crosswise tearing</td>\n",
              "      <td>The leaves of grasses resist crosswise tearing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>Comparative Biomechanics: Life's Physical World</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Vogel S</td>\n",
              "      <td>Princeton University Press</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1109</td>\n",
              "      <td>2015-08-03 17:24:37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Vogel S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2003</td>\n",
              "      <td>Princeton University Press</td>\n",
              "      <td>0-691-11297-5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Prevent fracture/rupture|Protect from loss of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1648</td>\n",
              "      <td>Eyes squirt blood</td>\n",
              "      <td>Blood-filled sinuses within the eye sockets of...</td>\n",
              "      <td>Phrynosoma</td>\n",
              "      <td>,,</td>\n",
              "      <td>1,7,14</td>\n",
              "      <td>The Hidden Powers of Animals: Uncovering the S...</td>\n",
              "      <td>http://www.amazon.com/Hidden-Powers-Animals-Un...</td>\n",
              "      <td>Dr. Karl P. N. Shuker,Wade C. Sherbrooke, Geor...</td>\n",
              "      <td>,Copeia,</td>\n",
              "      <td>01/10/2020,18/07/2006,</td>\n",
              "      <td>\"Among the most famous, and spectacular, perfo...</td>\n",
              "      <td>,,</td>\n",
              "      <td>,C. Guyer,</td>\n",
              "      <td>,10.1643/0045-8511(2001)001[1114:bsvihl]2.0.co;2,</td>\n",
              "      <td>1840285265,,</td>\n",
              "      <td>,Journal Article,Book</td>\n",
              "      <td>1,7,1</td>\n",
              "      <td>,c6310416c70be660299fd02b5f11dd76,9fa1f237974e...</td>\n",
              "      <td>2014-06-13 20:23:29,2014-06-13 20:24:07,2014-0...</td>\n",
              "      <td>,Copeia,</td>\n",
              "      <td>Shuker, KPN,Sherbrooke, Wc and Middendorf, GA,...</td>\n",
              "      <td>,,</td>\n",
              "      <td>240,1114-1122,64</td>\n",
              "      <td>,2001,</td>\n",
              "      <td>,4,</td>\n",
              "      <td>,,</td>\n",
              "      <td>2001,2001,2003</td>\n",
              "      <td>Marshall Editions Ltd.,American Society of Ich...</td>\n",
              "      <td>,,0520228251, 9780520228252, 0520228278, 97805...</td>\n",
              "      <td>,,</td>\n",
              "      <td>,13 Jun 2014,13 Jun 2014</td>\n",
              "      <td>,phrynosoma, autohemorrhage, reflex bleeding, ...</td>\n",
              "      <td>,,</td>\n",
              "      <td>Expel liquids|Expel solids|Protect from animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1938</td>\n",
              "      <td>Buckling valve sucks in prey</td>\n",
              "      <td>Tiny transparent capsules found on bladderwort...</td>\n",
              "      <td>Lentibulariaceae</td>\n",
              "      <td>,</td>\n",
              "      <td>1,7</td>\n",
              "      <td>The Private Life of Plants,Ultra-fast underwat...</td>\n",
              "      <td>http://www.amazon.com/Private-Life-Plants-Davi...</td>\n",
              "      <td>David Attenborough,Olivier Vincent, Carmen Wei...</td>\n",
              "      <td>,Proceedings of the Royal Society B: Biologica...</td>\n",
              "      <td>21/08/1995,16/02/2020</td>\n",
              "      <td>,\"Carnivorous aquatic Utricularia species catc...</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>0691006393,0691006393</td>\n",
              "      <td>,</td>\n",
              "      <td>1,</td>\n",
              "      <td>,</td>\n",
              "      <td>2013-09-05 20:08:30,</td>\n",
              "      <td>,</td>\n",
              "      <td>Attenborough, D.,</td>\n",
              "      <td>,</td>\n",
              "      <td>320,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>1995,</td>\n",
              "      <td>BBC Books,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>Capture, absorb, or filter organisms</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  ...                                          Functions\n",
              "0   542  ...                    Modify speed|Move in/on liquids\n",
              "1  1286  ...                                    Modify buoyancy\n",
              "2  1289  ...  Prevent fracture/rupture|Protect from loss of ...\n",
              "3  1648  ...    Expel liquids|Expel solids|Protect from animals\n",
              "4  1938  ...               Capture, absorb, or filter organisms\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOad079GRUvS",
        "outputId": "ef5b6233-884e-480c-96b5-c3a00b8b5574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labeled_df = labeled_df[['id', 'Title', 'Living Systems', 'Sources_source_link', 'Functions']]\n",
        "labeled_df = labeled_df[labeled_df['Functions'].notnull( )]\n",
        "labeled_df = labeled_df[labeled_df['Sources_source_link'].notnull()]\n",
        "len(labeled_df[labeled_df['Sources_source_link'].str.contains('.pdf')])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EFtH2bLZJ4a",
        "outputId": "3bc6e29c-8edb-4160-a1ac-0f3f49ac825a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "labeled_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Title</th>\n",
              "      <th>Living Systems</th>\n",
              "      <th>Sources_source_link</th>\n",
              "      <th>Functions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>542</td>\n",
              "      <td>Plumage releases air to propel body out of water</td>\n",
              "      <td>Aptenodytes forsteri</td>\n",
              "      <td>http://www.int-res.com/articles/theme/m430p171...</td>\n",
              "      <td>Modify speed|Move in/on liquids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1286</td>\n",
              "      <td>Swim bladder helps maintain buoyancy</td>\n",
              "      <td>Actinopterygii</td>\n",
              "      <td>http://www.amazon.com/Comparative-Biomechanics...</td>\n",
              "      <td>Modify buoyancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1648</td>\n",
              "      <td>Eyes squirt blood</td>\n",
              "      <td>Phrynosoma</td>\n",
              "      <td>http://www.amazon.com/Hidden-Powers-Animals-Un...</td>\n",
              "      <td>Expel liquids|Expel solids|Protect from animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1938</td>\n",
              "      <td>Buckling valve sucks in prey</td>\n",
              "      <td>Lentibulariaceae</td>\n",
              "      <td>http://www.amazon.com/Private-Life-Plants-Davi...</td>\n",
              "      <td>Capture, absorb, or filter organisms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2012</td>\n",
              "      <td>Biofilm-inhibiting chemical protects surfaces</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://dx.doi.org/10.3354/meps318153,http://ww...</td>\n",
              "      <td>Protect from microbes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1719</th>\n",
              "      <td>93283</td>\n",
              "      <td>Interaction with adults leads to faster nest b...</td>\n",
              "      <td>Taeniopygia guttata</td>\n",
              "      <td>https://academic.oup.com/beheco/article/31/4/8...</td>\n",
              "      <td>Physically assemble structure|Self-replicate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1720</th>\n",
              "      <td>93287</td>\n",
              "      <td>Chemicals in oregano act as fungicide</td>\n",
              "      <td>Origanum vulgare</td>\n",
              "      <td>https://sci-hub.st/10.1111/1750-3841.12700,htt...</td>\n",
              "      <td>Chemically break down organic compounds|Distri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1721</th>\n",
              "      <td>93338</td>\n",
              "      <td>Brain acts as both teacher and student</td>\n",
              "      <td>Taeniopygia guttata|zebra finch</td>\n",
              "      <td>https://elifesciences.org/articles/20944,https...</td>\n",
              "      <td>Encode/Decode|Learn|Differentiate signal from ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>93385</td>\n",
              "      <td>Leaf pores draw water through plants</td>\n",
              "      <td>Quercus</td>\n",
              "      <td>http://www.amazon.com/Work-Nature-Diversity-Li...</td>\n",
              "      <td>Regulate hydrological flows|Regulate water sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>93416</td>\n",
              "      <td>Birds build responsively</td>\n",
              "      <td>Taeniopygia guttata, zebra finch|Charadrius me...</td>\n",
              "      <td>https://sci-hub.st/10.1098/rspb.2013.3225,http...</td>\n",
              "      <td>Physically assemble structure|Adapt behaviors|...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>570 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                          Functions\n",
              "0       542  ...                    Modify speed|Move in/on liquids\n",
              "1      1286  ...                                    Modify buoyancy\n",
              "3      1648  ...    Expel liquids|Expel solids|Protect from animals\n",
              "4      1938  ...               Capture, absorb, or filter organisms\n",
              "9      2012  ...                              Protect from microbes\n",
              "...     ...  ...                                                ...\n",
              "1719  93283  ...       Physically assemble structure|Self-replicate\n",
              "1720  93287  ...  Chemically break down organic compounds|Distri...\n",
              "1721  93338  ...  Encode/Decode|Learn|Differentiate signal from ...\n",
              "1723  93385  ...  Regulate hydrological flows|Regulate water sto...\n",
              "1724  93416  ...  Physically assemble structure|Adapt behaviors|...\n",
              "\n",
              "[570 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_5P3YHmZKBD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX5JoachgKHG"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X9M8btjgL4h"
      },
      "source": [
        "# Calculate accuracy of predictions vs labels\n",
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ0gJZfGgfbt"
      },
      "source": [
        "# Format elapsed times as hh:mm:ss\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foqKWTvsNdaz"
      },
      "source": [
        "## BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ21pfQvgtNA",
        "outputId": "81a4990e-42ab-4340-feb0-2d16b97db23f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "d63456f0c5c1446ebde4cf20f783ae3c",
            "97aefea2f8ba49e08537b264d09743e5",
            "bca63259d95f41e2ba450de5b6525e1d",
            "4eb87dfd518141979dba05cbd52b0312",
            "8c16955666804683bba086db2bd51e9f",
            "56220ee8bd6946c3960422f4941b7ee8",
            "6320ba0468ee4fcf994436d2d5c248cc",
            "3ff28789e0b14dfa9f81570f70307acd"
          ]
        }
      },
      "source": [
        "from transformers import BertModel, BertConfig\n",
        "\n",
        "# Load BERT tokenizer\n",
        "print('Loading BERT tokenizer')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d63456f0c5c1446ebde4cf20f783ae3c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTUSIIZAhcVT"
      },
      "source": [
        "# Make sure it is tokenizing correctly:\n",
        "\n",
        "# Print original articles\n",
        "print(' Original: ', docs[0])\n",
        "\n",
        "# Print a doc split into tokens\n",
        "print('Tokenized: ', tokenizer.tokenize(docs[0]))\n",
        "\n",
        "# Print docs as mapped to ids\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(docs[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9mSOV7GhvdA"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "for d in docs:\n",
        "\n",
        "    # Tokenize text and add `[CLS]` and `[SEP]` tokens\n",
        "    input_ids = tokenizer.encode(d, add_special_tokens=True)\n",
        "\n",
        "    # Update max length\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgtsq-3s0jyF",
        "outputId": "2507bab8-f897-4d8b-def0-bdea74e66306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# Finishing tokenizing all docs and map tokens to thier word IDs\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for d in docs:\n",
        "\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        d,                      # Docs to encode.\n",
        "                        truncation=True,\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,           # Pad & truncate all docs\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Attention masks\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', docs[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Reverse:', tokenizer.convert_ids_to_tokens(input_ids[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2b35847e5fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Print sentence 0, now as a list of IDs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVofTi9U01pb"
      },
      "source": [
        "# Split up training & testing/validation\n",
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# 80:20 split\n",
        "\n",
        "# Number of docs to include per set\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training docs'.format(train_size))\n",
        "print('{:>5,} validation docs'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo-Gh4q78BJM"
      },
      "source": [
        "# Iterator using torch DataLoader class so that entire dataset doesn't need to be stored in memory\n",
        "\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch size can be 16 or 32\n",
        "batch_size = 32\n",
        "\n",
        "# Sample in random order when training\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  \n",
        "            sampler = RandomSampler(train_dataset), \n",
        "            batch_size = batch_size \n",
        "        )\n",
        "\n",
        "# Sample sequentially for validation\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za2M5jHMV3LU"
      },
      "source": [
        "## Training the Classification Model w/ Sequence Classification\n",
        "  (fine-tune BERT)\n",
        "\n",
        "  [HuggingFace documentation](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BMF2gFEV0Y8"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# BertForSequenceClassification -> BERT model w/ added classification layer \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # 12-layer model, uncased vocab\n",
        "    num_labels = 7, # Number of labels \n",
        "    \"\"\"CHANGE ABOVE\"\"\"\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "# this needs to be run on GPU\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "775rSApKXaHu"
      },
      "source": [
        "## Optimizer for our hypermarameters / Learning Rate Scheduler\n",
        "AdamW\n",
        "\n",
        "Possible hyperparamters: \n",
        "* batch size: 16, 32\n",
        "* learning rate: 5e-5, 3e-5, 2e-5\n",
        "* number of epochs: 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa5RhInLXfIv"
      },
      "source": [
        "# Exeprimenting w/ different parameters\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 # epsilon prevents division by 0??\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV6rf_-BYLWS"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Training epochs should be betw 2- 4 (reduce if overfitting)\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# LR scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAdyiqxGYpg5"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk9UkHBSYsDS"
      },
      "source": [
        "import random\n",
        "\n",
        "# based on huggingface transformers `run_glue.py` script : https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_vals = []\n",
        "\n",
        "total_time = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):    \n",
        "    \n",
        "    ## TRAINING\n",
        "\n",
        "    print(\"\")\n",
        "    print('-------- Epoch {:} / {:} --------'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "    print(\"\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 20 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # progress from every 20 batches\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # pytorch tensors in batch (gpu usage)\n",
        "        #   batch[0] -> input ids \n",
        "        #   batch[1] -> attention masks\n",
        "        #   batch[2] -> labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # clear gradients before forward and backward passes\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # forward pass\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # clip to prevent exploding gradients (??)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # optimizer and lr updare\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    ## VALIDATION\n",
        "    \n",
        "    print(\"\")\n",
        "    print(\"Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # pytorch tensors in batch (gpu usage)\n",
        "        #   batch[0] -> input ids \n",
        "        #   batch[1] -> attention masks\n",
        "        #   batch[2] -> labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # forward pass\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # move logits and labels -> CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    \n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # print final validation accuracy\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # epoch values & stats\n",
        "    training_vals.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training done\")\n",
        "\n",
        "print(\"Time to train: {:} (h:mm:ss)\".format(format_time(time.time()-total_time)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-ijNX7XD9-n"
      },
      "source": [
        "# Display metrics of training process in a dataframe\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_vals = pd.DataFrame(data=training_stats)\n",
        "df_vals = df_vals.set_index('epoch')\n",
        "\n",
        "df_vals"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceVT2Jmoph4x"
      },
      "source": [
        "## Ignore this cell for now\n",
        "# Trying out example BERT\n",
        "\n",
        "# Single training/test example for simple sequence classification\n",
        "class InputExample(object):\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"Single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gp0ZzW6Taop"
      },
      "source": [
        "# Initializing a BERT bert-base-uncased style configuration\n",
        "configuration = BertConfig()\n",
        "\n",
        "# Initializing a model from the bert-base-uncased style configuration\n",
        "model = BertModel(configuration)\n",
        "\n",
        "model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr0ajbVbFL7y"
      },
      "source": [
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}